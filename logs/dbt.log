[0m23:30:18.177957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EE977EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EC5F3800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EC520DD0>]}


============================== 23:30:18.183958 | f598d1bd-3815-4c39-a336-34d5abe6bc9b ==============================
[0m23:30:18.183958 [info ] [MainThread]: Running with dbt=1.9.3
[0m23:30:18.185432 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt init dbtlearn', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:30:18.220035 [debug] [MainThread]: Starter project path: C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\venv\Lib\site-packages\dbt\include\starter_project
[0m23:30:18.268459 [info ] [MainThread]: 
Your new dbt project "dbtlearn" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m23:30:18.269463 [info ] [MainThread]: Setting up your profile.
[0m23:33:32.341961 [info ] [MainThread]: Profile dbtlearn written to C:\Users\marco\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m23:33:32.343959 [debug] [MainThread]: Command `dbt init` succeeded at 23:33:32.343959 after 194.36 seconds
[0m23:33:32.343959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EF0D9AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EE207D40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EF3F7950>]}
[0m23:33:32.344965 [debug] [MainThread]: Flushing usage events
[0m23:33:33.277981 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:08:08.304736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022371485C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223716A92D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002237122B7D0>]}


============================== 14:08:08.312383 | fa9a4809-69de-499f-925f-a1ac01b2b989 ==============================
[0m14:08:08.312383 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:08:08.313380 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:08:08.314386 [info ] [MainThread]: dbt version: 1.7.3
[0m14:08:08.315892 [info ] [MainThread]: python version: 3.11.7
[0m14:08:08.316901 [info ] [MainThread]: python path: C:\Users\marco\AppData\Local\Programs\Python\Python311\python.exe
[0m14:08:08.317899 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m14:08:08.491461 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.bigquery'
[0m14:08:08.496599 [info ] [MainThread]: Using profiles dir at C:\Users\marco\.dbt
[0m14:08:08.497630 [info ] [MainThread]: Using profiles.yml file at C:\Users\marco\.dbt\profiles.yml
[0m14:08:08.498679 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
[0m14:08:08.499734 [info ] [MainThread]: Configuration:
[0m14:08:08.501296 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:08:08.502380 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m14:08:08.503474 [info ] [MainThread]: Required dependencies:
[0m14:08:08.504483 [debug] [MainThread]: Executing "git --help"
[0m14:08:08.588638 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:08:08.589157 [debug] [MainThread]: STDERR: "b''"
[0m14:08:08.589157 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:08:08.590161 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:08:08.590161 [info ] [MainThread]: [31m2 checks failed:[0m
[0m14:08:08.592537 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "lessons", target "dev" invalid: Runtime Error
    Could not find adapter type bigquery!


[0m14:08:08.593544 [info ] [MainThread]: Project loading failed for the following reason:
 project path <C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml> not found

[0m14:08:08.595023 [debug] [MainThread]: Command `dbt debug` failed at 14:08:08.595023 after 0.38 seconds
[0m14:08:08.595023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002237195A190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002236A2B1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022370B86B10>]}
[0m14:08:08.596030 [debug] [MainThread]: Flushing usage events
[0m14:08:52.914637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F47421E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F47201290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F46C2AA50>]}


============================== 14:08:52.919215 | c31f6dd1-6bb5-481a-8b27-ba9c13df7d43 ==============================
[0m14:08:52.919215 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:08:52.920189 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:08:52.921226 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:08:52.924187 [debug] [MainThread]: Command `dbt run` failed at 14:08:52.923187 after 0.08 seconds
[0m14:08:52.924187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F3FCD1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F46C2A6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F3FFCFD50>]}
[0m14:08:52.925186 [debug] [MainThread]: Flushing usage events
[0m14:10:47.381873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239464468D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023949D03F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239490E4C50>]}


============================== 14:10:47.386877 | 81babd98-3bcb-40dd-9e48-feac09ac0f91 ==============================
[0m14:10:47.386877 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:10:47.387873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:10:47.387873 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:10:47.390273 [debug] [MainThread]: Command `dbt run` failed at 14:10:47.390273 after 0.07 seconds
[0m14:10:47.390273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023942D31010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002394A4D7C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002394A066390>]}
[0m14:10:47.391306 [debug] [MainThread]: Flushing usage events
[0m14:11:35.815548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7D4A550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A823BE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7A50390>]}


============================== 14:11:35.819547 | 7de46b32-0753-4bd6-8afc-8b472f5a4ad4 ==============================
[0m14:11:35.819547 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:11:35.819547 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:11:36.124274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8406750>]}
[0m14:11:36.207136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8203F90>]}
[0m14:11:36.208669 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:11:36.225253 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:11:36.226253 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:11:36.227254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A84CA710>]}
[0m14:11:37.871611 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.src
[0m14:11:37.876642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A83FE710>]}
[0m14:11:37.902965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8623550>]}
[0m14:11:37.903967 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:11:37.905962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A85469D0>]}
[0m14:11:37.908006 [info ] [MainThread]: 
[0m14:11:37.908972 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:11:37.910962 [debug] [MainThread]: Command end result
[0m14:11:37.922033 [debug] [MainThread]: Command `dbt run` succeeded at 14:11:37.922033 after 2.17 seconds
[0m14:11:37.922033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A09BE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7A1DD90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7406B10>]}
[0m14:11:37.923030 [debug] [MainThread]: Flushing usage events
[0m14:16:32.994251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150C18D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025114EB1A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025114C41D90>]}


============================== 14:16:32.998254 | 2c51030f-1bba-456d-ac7f-990e2c5d7b69 ==============================
[0m14:16:32.998254 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:16:32.999252 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:16:33.206891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150E03D0>]}
[0m14:16:33.282673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150E03D0>]}
[0m14:16:33.284878 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:16:33.292531 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:16:33.318143 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:16:33.319137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115279D90>]}
[0m14:16:34.011638 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn
[0m14:16:34.017401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115105010>]}
[0m14:16:34.031922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251152C59D0>]}
[0m14:16:34.031922 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:16:34.032922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115464A50>]}
[0m14:16:34.034922 [info ] [MainThread]: 
[0m14:16:34.035433 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:16:34.037442 [debug] [MainThread]: Command end result
[0m14:16:34.049448 [debug] [MainThread]: Command `dbt run` succeeded at 14:16:34.048447 after 1.13 seconds
[0m14:16:34.050448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002510D971010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251148C3C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002510DBE4390>]}
[0m14:16:34.050448 [debug] [MainThread]: Flushing usage events
[0m14:18:42.716220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1205E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF0EF5150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF0ED2C50>]}


============================== 14:18:42.722229 | eef7ded4-a0c0-458f-aff9-b2fab91772cc ==============================
[0m14:18:42.722229 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:18:42.723219 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:18:42.944981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1702050>]}
[0m14:18:43.020957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF16AA4D0>]}
[0m14:18:43.022957 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:18:43.030487 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:18:43.051073 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m14:18:43.053076 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:18:43.054073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF11D63D0>]}
[0m14:18:43.758533 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.src
[0m14:18:43.763055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1A1EA90>]}
[0m14:18:43.778083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1A88650>]}
[0m14:18:43.779081 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:18:43.780082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF17B5F50>]}
[0m14:18:43.781086 [info ] [MainThread]: 
[0m14:18:43.783107 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:18:43.784114 [debug] [MainThread]: Command end result
[0m14:18:43.792851 [debug] [MainThread]: Command `dbt run` succeeded at 14:18:43.791848 after 1.16 seconds
[0m14:18:43.792851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF11D7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EE9F51010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1914610>]}
[0m14:18:43.793878 [debug] [MainThread]: Flushing usage events
[0m14:19:52.578602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27159950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26C87890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26C86190>]}


============================== 14:19:52.583599 | 65801f51-a4ee-474b-9fba-6a834fa64fc9 ==============================
[0m14:19:52.583599 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:19:52.584601 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:19:52.793040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F271B0090>]}
[0m14:19:52.870409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2726BE10>]}
[0m14:19:52.872053 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:19:52.879230 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:19:52.901295 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:19:52.902296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2731D390>]}
[0m14:19:53.602502 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.models.src
[0m14:19:53.608007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27142BD0>]}
[0m14:19:53.620025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2749B010>]}
[0m14:19:53.621029 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:19:53.621536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27492750>]}
[0m14:19:53.622536 [info ] [MainThread]: 
[0m14:19:53.623540 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:19:53.624538 [debug] [MainThread]: Command end result
[0m14:19:53.636320 [debug] [MainThread]: Command `dbt run` succeeded at 14:19:53.636320 after 1.14 seconds
[0m14:19:53.637320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F1F92E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26995810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27160D10>]}
[0m14:19:53.638320 [debug] [MainThread]: Flushing usage events
[0m14:20:31.630997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016557122A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556C15910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556CA66D0>]}


============================== 14:20:31.635087 | a2e6be0e-07c6-4220-ba75-a9978b8f61dd ==============================
[0m14:20:31.635087 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:20:31.636087 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:20:31.637091 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:20:31.638124 [debug] [MainThread]: Command `dbt run` failed at 14:20:31.638124 after 0.07 seconds
[0m14:20:31.639086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001655691DB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001654F9C1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556921310>]}
[0m14:20:31.639086 [debug] [MainThread]: Flushing usage events
[0m14:20:48.116047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F201310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F2016D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FA05C10>]}


============================== 14:20:48.120140 | 74fa53d7-1e75-447f-b957-20289922a437 ==============================
[0m14:20:48.120140 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:20:48.121107 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:20:48.335102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105ED2EAD0>]}
[0m14:20:48.412802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F2D0410>]}
[0m14:20:48.414721 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:20:48.422114 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:20:48.503415 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:20:48.504420 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:20:48.505421 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.models.src
[0m14:20:48.509776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F7EF010>]}
[0m14:20:48.521893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FC40D50>]}
[0m14:20:48.522894 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:20:48.523901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FB50310>]}
[0m14:20:48.524931 [info ] [MainThread]: 
[0m14:20:48.526443 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:20:48.528009 [debug] [MainThread]: Command end result
[0m14:20:48.580313 [debug] [MainThread]: Command `dbt run` succeeded at 14:20:48.579315 after 0.53 seconds
[0m14:20:48.580313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021058261010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105ECBEED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105854FE10>]}
[0m14:20:48.581313 [debug] [MainThread]: Flushing usage events
[0m14:22:12.507346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B41C310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AC09310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AB76790>]}


============================== 14:22:12.512072 | 3f8faea2-9fc3-4b18-a904-7dea78056716 ==============================
[0m14:22:12.512072 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:22:12.512896 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:22:12.731511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AF41410>]}
[0m14:22:12.812509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B610C10>]}
[0m14:22:12.814478 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:22:12.821344 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:22:12.828752 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:22:12.829715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B5BEFD0>]}
[0m14:22:13.636968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B752A10>]}
[0m14:22:13.648581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B843650>]}
[0m14:22:13.649588 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:22:13.649588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B69C990>]}
[0m14:22:13.651091 [info ] [MainThread]: 
[0m14:22:13.653096 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:22:13.655098 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:22:13.665049 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:22:13.665049 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:22:13.666048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:22:14.998114 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:22:14.999207 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:22:15.001206 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:22:15.007240 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:22:15.007240 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:22:15.007240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:22:15.208959 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.209967 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:22:15.209967 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:22:15.261228 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:22:15.262394 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:22:15.299688 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:22:15.304688 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.305687 [debug] [MainThread]: On master: BEGIN
[0m14:22:15.305687 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:22:15.504276 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.505266 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.505266 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:22:15.568062 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:22:15.569041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B451990>]}
[0m14:22:15.570072 [debug] [MainThread]: On master: ROLLBACK
[0m14:22:15.603384 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.604347 [debug] [MainThread]: On master: BEGIN
[0m14:22:15.662353 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.662353 [debug] [MainThread]: On master: COMMIT
[0m14:22:15.663393 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.664381 [debug] [MainThread]: On master: COMMIT
[0m14:22:15.698906 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:22:15.699967 [debug] [MainThread]: On master: Close
[0m14:22:15.700916 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:22:15.701917 [info ] [MainThread]: 
[0m14:22:15.710978 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:22:15.710978 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:22:15.712977 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:22:15.713979 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:22:15.721345 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:22:15.726358 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:22:15.713979 => 14:22:15.725339
[0m14:22:15.726358 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:22:15.760870 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:22:15.764837 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:22:15.765838 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:22:15.765838 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:22:15.952069 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.953056 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:22:15.953056 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:22:15.991008 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw_listings" does not exist
LINE 10:   raw_listings rl 
           ^
DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.

[0m14:22:15.992023 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: ROLLBACK
[0m14:22:16.027093 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:22:15.727343 => 14:22:16.027093
[0m14:22:16.028110 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:22:16.139655 [debug] [Thread-1 (]: Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings rl 
             ^
  DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
  HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:22:16.140697 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B8C68D0>]}
[0m14:22:16.141674 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.src_listings ......................... [[31mERROR[0m in 0.43s]
[0m14:22:16.142662 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:22:16.144661 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:16.144661 [debug] [MainThread]: On master: BEGIN
[0m14:22:16.145661 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:22:16.342764 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:16.343934 [debug] [MainThread]: On master: COMMIT
[0m14:22:16.343934 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:16.345009 [debug] [MainThread]: On master: COMMIT
[0m14:22:16.379046 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:22:16.379551 [debug] [MainThread]: On master: Close
[0m14:22:16.380561 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:22:16.380561 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:22:16.381557 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:22:16.381557 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:22:16.382558 [info ] [MainThread]: 
[0m14:22:16.383557 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.73 seconds (2.73s).
[0m14:22:16.384556 [debug] [MainThread]: Command end result
[0m14:22:16.394588 [info ] [MainThread]: 
[0m14:22:16.395586 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:22:16.396586 [info ] [MainThread]: 
[0m14:22:16.397588 [error] [MainThread]:   Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings rl 
             ^
  DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
  HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:22:16.399109 [info ] [MainThread]: 
[0m14:22:16.400127 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:22:16.402672 [debug] [MainThread]: Command `dbt run` failed at 14:22:16.402672 after 3.97 seconds
[0m14:22:16.403746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AF413D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B23CAE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AC0A150>]}
[0m14:22:16.405033 [debug] [MainThread]: Flushing usage events
[0m14:23:24.897496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23867810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF235907D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF238F0BD0>]}


============================== 14:23:24.902219 | 79c8ca5e-8f95-4e94-8a8a-bb898296346d ==============================
[0m14:23:24.902219 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:23:24.903187 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:23:25.106658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23F4CD90>]}
[0m14:23:25.183060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23D5B150>]}
[0m14:23:25.184879 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:23:25.193740 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:23:25.213875 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:23:25.215021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF2393ECD0>]}
[0m14:23:26.028667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF240198D0>]}
[0m14:23:26.040178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF24222690>]}
[0m14:23:26.041213 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:23:26.041213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23DB0350>]}
[0m14:23:26.043751 [info ] [MainThread]: 
[0m14:23:26.044881 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:23:26.046881 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:23:26.056145 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:23:26.056145 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:23:26.057148 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:23:27.417248 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:23:27.418258 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:23:27.421243 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:23:27.425839 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:23:27.426847 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:23:27.426847 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:23:27.659333 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:23:27.660302 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:23:27.660302 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:23:27.711350 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:23:27.713378 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:23:27.748149 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:23:27.753772 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:27.754739 [debug] [MainThread]: On master: BEGIN
[0m14:23:27.754739 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:23:27.970376 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:27.971375 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:27.972377 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:23:28.038711 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:23:28.039976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23F48790>]}
[0m14:23:28.040974 [debug] [MainThread]: On master: ROLLBACK
[0m14:23:28.074116 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.074636 [debug] [MainThread]: On master: BEGIN
[0m14:23:28.143471 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.144530 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.145069 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.145590 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.184159 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:23:28.185273 [debug] [MainThread]: On master: Close
[0m14:23:28.186932 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:23:28.187983 [info ] [MainThread]: 
[0m14:23:28.191772 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:23:28.192332 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:23:28.193411 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:23:28.194438 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:23:28.201220 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:23:28.202218 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:23:28.194993 => 14:23:28.202218
[0m14:23:28.203221 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:23:28.235374 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:23:28.237377 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:23:28.237377 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:23:28.238342 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:23:28.468384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.469160 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:23:28.469160 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings_ AS (
	SELECT *
	FROM   
		raw_listings 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings_
  );
[0m14:23:28.512776 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw_listings" does not exist
LINE 10:   raw_listings 
           ^

[0m14:23:28.513826 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: ROLLBACK
[0m14:23:28.555945 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:23:28.204225 => 14:23:28.555945
[0m14:23:28.557889 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:23:28.562921 [debug] [Thread-1 (]: Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings 
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:23:28.562921 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF2415E5D0>]}
[0m14:23:28.563911 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.src_listings ......................... [[31mERROR[0m in 0.37s]
[0m14:23:28.564902 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:23:28.566949 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.567329 [debug] [MainThread]: On master: BEGIN
[0m14:23:28.567969 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:23:28.811311 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.812313 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.812313 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.813330 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.854228 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:23:28.854839 [debug] [MainThread]: On master: Close
[0m14:23:28.855969 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:23:28.857013 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:23:28.857013 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:23:28.858008 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:23:28.858008 [info ] [MainThread]: 
[0m14:23:28.859043 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.81 seconds (2.81s).
[0m14:23:28.860050 [debug] [MainThread]: Command end result
[0m14:23:28.870426 [info ] [MainThread]: 
[0m14:23:28.871409 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:23:28.872407 [info ] [MainThread]: 
[0m14:23:28.873407 [error] [MainThread]:   Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings 
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:23:28.873697 [info ] [MainThread]: 
[0m14:23:28.874703 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:23:28.875704 [debug] [MainThread]: Command `dbt run` failed at 14:23:28.875704 after 4.05 seconds
[0m14:23:28.876704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23D53ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF1C5A1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23546AD0>]}
[0m14:23:28.876704 [debug] [MainThread]: Flushing usage events
[0m14:24:44.702084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAE72E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA770E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAEB99D0>]}


============================== 14:24:44.705622 | 20e8be37-3de7-4264-a23a-bb7e3e8bf8dc ==============================
[0m14:24:44.705622 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:24:44.706624 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:24:44.917075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAFDEB90>]}
[0m14:24:45.003858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA947950>]}
[0m14:24:45.005433 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:24:45.014230 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:24:45.119312 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:24:45.119312 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_listings.sql
[0m14:24:45.282289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB0B2DD0>]}
[0m14:24:45.294479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB386810>]}
[0m14:24:45.295479 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:24:45.296485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB205310>]}
[0m14:24:45.298512 [info ] [MainThread]: 
[0m14:24:45.298897 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:24:45.300752 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:24:45.310434 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:24:45.310434 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:24:45.311397 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:46.659018 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:24:46.660776 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:24:46.662783 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:24:46.668815 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:24:46.668815 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:24:46.669782 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:46.901069 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:24:46.902116 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:24:46.903080 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:24:46.955380 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:24:46.956381 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:24:46.991989 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:24:46.997054 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:46.997054 [debug] [MainThread]: On master: BEGIN
[0m14:24:46.998128 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:24:47.194326 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.195362 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.195876 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:24:47.257223 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:24:47.258782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB0E8850>]}
[0m14:24:47.259297 [debug] [MainThread]: On master: ROLLBACK
[0m14:24:47.289400 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.290419 [debug] [MainThread]: On master: BEGIN
[0m14:24:47.350581 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.351628 [debug] [MainThread]: On master: COMMIT
[0m14:24:47.351628 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.352620 [debug] [MainThread]: On master: COMMIT
[0m14:24:47.387762 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:24:47.388752 [debug] [MainThread]: On master: Close
[0m14:24:47.389753 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:47.390753 [info ] [MainThread]: 
[0m14:24:47.393753 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:24:47.393753 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:24:47.394759 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:24:47.396017 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:24:47.403983 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:24:47.406043 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:24:47.396017 => 14:24:47.406043
[0m14:24:47.407047 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:24:47.440641 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:24:47.442713 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.442713 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:24:47.443940 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:24:47.645384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.646228 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.647273 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:24:47.713429 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:24:47.719504 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.720505 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:24:47.752322 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:24:47.766405 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:24:47.767410 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.768004 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:24:47.797656 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:24:47.804687 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:24:47.809687 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.810688 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:24:47.840036 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:24:47.842037 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:24:47.408048 => 14:24:47.842037
[0m14:24:47.842037 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:24:47.844038 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA9B05D0>]}
[0m14:24:47.844038 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:24:47.846038 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:24:47.847034 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.848071 [debug] [MainThread]: On master: BEGIN
[0m14:24:47.849067 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:24:48.040439 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:48.041436 [debug] [MainThread]: On master: COMMIT
[0m14:24:48.042436 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:48.042942 [debug] [MainThread]: On master: COMMIT
[0m14:24:48.078516 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:24:48.078516 [debug] [MainThread]: On master: Close
[0m14:24:48.079777 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:48.080770 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:24:48.080770 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:24:48.081749 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:24:48.081749 [info ] [MainThread]: 
[0m14:24:48.082737 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.78 seconds (2.78s).
[0m14:24:48.084762 [debug] [MainThread]: Command end result
[0m14:24:48.093343 [info ] [MainThread]: 
[0m14:24:48.093883 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:24:48.094912 [info ] [MainThread]: 
[0m14:24:48.096920 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:24:48.098918 [debug] [MainThread]: Command `dbt run` succeeded at 14:24:48.098918 after 3.46 seconds
[0m14:24:48.099918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAA23010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDB37A1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDB37A0F50>]}
[0m14:24:48.099918 [debug] [MainThread]: Flushing usage events
[0m14:30:46.179498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B5E8C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3ADF75D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3AEA0B10>]}


============================== 14:30:46.183496 | f52816ad-50ab-40d6-ada6-6774a7c16420 ==============================
[0m14:30:46.183496 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:30:46.184500 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:30:46.395034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B609A10>]}
[0m14:30:46.473761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B0C5B10>]}
[0m14:30:46.475884 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:30:46.483889 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:30:46.585065 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:30:46.585065 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\src\src_reviews.sql
[0m14:30:46.747171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B846C10>]}
[0m14:30:46.759880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3BACCD10>]}
[0m14:30:46.759880 [info ] [MainThread]: Found 2 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:30:46.761385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B891210>]}
[0m14:30:46.763394 [info ] [MainThread]: 
[0m14:30:46.764391 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:30:46.766983 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:30:46.776516 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:30:46.777532 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:30:46.777532 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:48.165570 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:30:48.167615 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:30:48.169223 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:30:48.174768 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:48.175767 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:30:48.176778 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:48.418018 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.419523 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:48.420037 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:30:48.471512 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.0 seconds
[0m14:30:48.473564 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:30:48.503929 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:30:48.509161 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.510162 [debug] [MainThread]: On master: BEGIN
[0m14:30:48.510162 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:30:48.741145 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.742141 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.743138 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:30:48.808499 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:48.810499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B86E2D0>]}
[0m14:30:48.810499 [debug] [MainThread]: On master: ROLLBACK
[0m14:30:48.847004 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.847004 [debug] [MainThread]: On master: BEGIN
[0m14:30:48.914062 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.915074 [debug] [MainThread]: On master: COMMIT
[0m14:30:48.915074 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.916074 [debug] [MainThread]: On master: COMMIT
[0m14:30:48.954591 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:30:48.955590 [debug] [MainThread]: On master: Close
[0m14:30:48.956586 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:30:48.957587 [info ] [MainThread]: 
[0m14:30:48.960621 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:30:48.962065 [info ] [Thread-1 (]: 1 of 2 START sql view model test.src_listings .................................. [RUN]
[0m14:30:48.963034 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:30:48.964034 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:30:48.971541 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:30:48.973705 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:30:48.964034 => 14:30:48.973705
[0m14:30:48.974756 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:30:49.009269 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:30:49.010678 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.010678 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:30:49.011679 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:30:49.237193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:30:49.238364 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.238364 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:30:49.291454 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:30:49.297032 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.298119 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:30:49.331468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.335598 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.335598 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:30:49.370526 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.387694 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:30:49.387694 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.388658 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:30:49.422644 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:30:49.429197 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:30:49.435322 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.435322 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:30:49.474248 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:30:49.475838 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:30:48.975755 => 14:30:49.475838
[0m14:30:49.477358 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:30:49.478413 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3CB48450>]}
[0m14:30:49.478413 [info ] [Thread-1 (]: 1 of 2 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.51s]
[0m14:30:49.479452 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:30:49.480418 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:30:49.481418 [info ] [Thread-1 (]: 2 of 2 START sql view model test.src_reviews ................................... [RUN]
[0m14:30:49.482418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:30:49.483452 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:30:49.485419 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:30:49.487419 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:30:49.483452 => 14:30:49.487419
[0m14:30:49.488419 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:30:49.492577 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:30:49.494582 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.495152 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:30:49.495152 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:30:49.720359 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:30:49.721120 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.722119 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:30:49.772134 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:30:49.775669 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.776672 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:30:49.811330 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.813834 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:30:49.814348 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.815353 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:30:49.847495 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:30:49.850030 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:30:49.852561 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.852561 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:30:49.888147 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:30:49.890146 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:30:49.488419 => 14:30:49.889146
[0m14:30:49.890146 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:30:49.891146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3CAFFC10>]}
[0m14:30:49.892146 [info ] [Thread-1 (]: 2 of 2 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:30:49.893147 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:30:49.895150 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:49.896148 [debug] [MainThread]: On master: BEGIN
[0m14:30:49.896148 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:30:50.115779 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:50.116784 [debug] [MainThread]: On master: COMMIT
[0m14:30:50.116784 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:50.117783 [debug] [MainThread]: On master: COMMIT
[0m14:30:50.158363 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:30:50.159365 [debug] [MainThread]: On master: Close
[0m14:30:50.160367 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:30:50.160367 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:30:50.161367 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:30:50.161367 [debug] [MainThread]: Connection 'model.dbtlearn.src_reviews' was properly closed.
[0m14:30:50.162365 [info ] [MainThread]: 
[0m14:30:50.163445 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 3.40 seconds (3.40s).
[0m14:30:50.164656 [debug] [MainThread]: Command end result
[0m14:30:50.172658 [info ] [MainThread]: 
[0m14:30:50.174166 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:30:50.174166 [info ] [MainThread]: 
[0m14:30:50.175898 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m14:30:50.176905 [debug] [MainThread]: Command `dbt run` succeeded at 14:30:50.176905 after 4.06 seconds
[0m14:30:50.177904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB33E11010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3A7CA790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3410FD50>]}
[0m14:30:50.178906 [debug] [MainThread]: Flushing usage events
[0m14:35:40.970476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52FA1D0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D53351B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533541210>]}


============================== 14:35:40.974475 | 9b4809fe-fb41-4c61-b1aa-76904a89487e ==============================
[0m14:35:40.974475 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:35:40.975479 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:35:41.271089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D532D70A50>]}
[0m14:35:41.355146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D532D42B90>]}
[0m14:35:41.357116 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:35:41.365747 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:35:41.478662 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:35:41.479667 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m14:35:41.659839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533817D90>]}
[0m14:35:41.673038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5339033D0>]}
[0m14:35:41.673038 [info ] [MainThread]: Found 3 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:35:41.674043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5337B4CD0>]}
[0m14:35:41.675078 [info ] [MainThread]: 
[0m14:35:41.677593 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:35:41.679992 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:35:41.693031 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:35:41.695023 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:35:41.695023 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:35:43.017657 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:35:43.020658 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:35:43.023688 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:35:43.032687 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:35:43.034195 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:35:43.036108 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:35:43.241126 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.243118 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:35:43.244117 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:35:43.286680 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m14:35:43.287923 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:35:43.321898 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:35:43.327315 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.327315 [debug] [MainThread]: On master: BEGIN
[0m14:35:43.328318 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:35:43.536410 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.537297 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.538296 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:35:43.599176 [debug] [MainThread]: SQL status: SELECT 2 in 0.0 seconds
[0m14:35:43.601480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5339DEA50>]}
[0m14:35:43.602480 [debug] [MainThread]: On master: ROLLBACK
[0m14:35:43.631071 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.632037 [debug] [MainThread]: On master: BEGIN
[0m14:35:43.689808 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.690810 [debug] [MainThread]: On master: COMMIT
[0m14:35:43.690810 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.691805 [debug] [MainThread]: On master: COMMIT
[0m14:35:43.726491 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:35:43.726491 [debug] [MainThread]: On master: Close
[0m14:35:43.727497 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:35:43.728498 [info ] [MainThread]: 
[0m14:35:43.732841 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:35:43.733838 [info ] [Thread-1 (]: 1 of 3 START sql view model test.src_hosts ..................................... [RUN]
[0m14:35:43.734835 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:35:43.735840 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:35:43.744022 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:35:43.749713 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:35:43.736837 => 14:35:43.749713
[0m14:35:43.750745 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:35:43.796399 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:35:43.799369 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:43.800399 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:35:43.800399 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:35:43.992193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.993197 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:43.993197 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:35:44.040502 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.047050 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.048057 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:35:44.079529 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.092615 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:35:44.093620 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.093620 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:35:44.126404 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:44.133167 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:35:44.139163 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.139163 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:35:44.169136 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:44.171173 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:35:43.751715 => 14:35:44.171173
[0m14:35:44.171173 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:35:44.172169 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D534A77190>]}
[0m14:35:44.173170 [info ] [Thread-1 (]: 1 of 3 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.44s]
[0m14:35:44.174146 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:35:44.175170 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:35:44.176136 [info ] [Thread-1 (]: 2 of 3 START sql view model test.src_listings .................................. [RUN]
[0m14:35:44.177650 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:35:44.177650 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:35:44.180658 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:35:44.182649 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:35:44.178648 => 14:35:44.181649
[0m14:35:44.183648 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:35:44.189730 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:35:44.191735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.192725 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:35:44.193725 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:35:44.418402 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:44.419446 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.419446 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:35:44.469960 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.473926 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.474927 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:35:44.511903 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.515627 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.517624 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:35:44.552272 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.556299 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:35:44.557267 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.557267 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:35:44.591761 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:44.594762 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:35:44.595728 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.596728 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:35:44.634902 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:44.636916 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:35:44.183648 => 14:35:44.636916
[0m14:35:44.637914 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:35:44.638946 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D534A982D0>]}
[0m14:35:44.639912 [info ] [Thread-1 (]: 2 of 3 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m14:35:44.640912 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:35:44.640912 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:35:44.641912 [info ] [Thread-1 (]: 3 of 3 START sql view model test.src_reviews ................................... [RUN]
[0m14:35:44.642915 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:35:44.643911 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:35:44.645417 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:35:44.647420 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:35:44.643911 => 14:35:44.646418
[0m14:35:44.648427 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:35:44.652419 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:35:44.654421 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.655421 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:35:44.656931 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:35:44.885384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:44.886361 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.886361 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:35:44.936182 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.940182 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.941183 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:35:44.975771 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.979767 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.979767 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:35:45.014788 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:45.018563 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:35:45.019077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:45.019592 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:35:45.053276 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:45.056452 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:35:45.058052 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:45.058586 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:35:45.094662 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:45.096215 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:35:44.648427 => 14:35:45.096215
[0m14:35:45.096731 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:35:45.097796 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5336ADB50>]}
[0m14:35:45.098402 [info ] [Thread-1 (]: 3 of 3 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:35:45.100411 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:35:45.102920 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:45.103919 [debug] [MainThread]: On master: BEGIN
[0m14:35:45.104247 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:35:45.330162 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:45.331153 [debug] [MainThread]: On master: COMMIT
[0m14:35:45.331153 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:45.332248 [debug] [MainThread]: On master: COMMIT
[0m14:35:45.368397 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:35:45.369177 [debug] [MainThread]: On master: Close
[0m14:35:45.370169 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:35:45.371170 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:35:45.371170 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:35:45.372164 [debug] [MainThread]: Connection 'model.dbtlearn.src_reviews' was properly closed.
[0m14:35:45.372164 [info ] [MainThread]: 
[0m14:35:45.373163 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 3.70 seconds (3.70s).
[0m14:35:45.375197 [debug] [MainThread]: Command end result
[0m14:35:45.388363 [info ] [MainThread]: 
[0m14:35:45.388363 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:35:45.390902 [info ] [MainThread]: 
[0m14:35:45.392012 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m14:35:45.394008 [debug] [MainThread]: Command `dbt run` succeeded at 14:35:45.394008 after 4.49 seconds
[0m14:35:45.395007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533342150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52C0D4390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52C15EF90>]}
[0m14:35:45.396009 [debug] [MainThread]: Flushing usage events
[0m14:57:14.650571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE0EB050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCCD34F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCC6BC810>]}


============================== 14:57:14.654080 | ee50d8b0-c9e3-4a50-a08c-489bcf38536d ==============================
[0m14:57:14.654080 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:57:14.656288 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:57:14.870865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCDB60CD0>]}
[0m14:57:14.947529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC6A25B90>]}
[0m14:57:14.949171 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:57:14.957031 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:57:14.980251 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:57:14.981057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE13FCD0>]}
[0m14:57:15.805139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE4B8F10>]}
[0m14:57:15.817681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF64DD50>]}
[0m14:57:15.817681 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:57:15.819197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE5F7950>]}
[0m14:57:15.821879 [info ] [MainThread]: 
[0m14:57:15.822847 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:57:15.824240 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:57:15.834774 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:57:15.835795 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:57:15.835795 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:17.185752 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:57:17.186746 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:57:17.189255 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:57:17.194765 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:17.194765 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:57:17.195767 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:17.385859 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.386902 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:17.386902 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:57:17.434139 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:57:17.435933 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:57:17.465437 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:57:17.471040 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.472040 [debug] [MainThread]: On master: BEGIN
[0m14:57:17.472040 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:57:17.663341 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.663341 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.664376 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:57:17.727931 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:57:17.729813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE3A0550>]}
[0m14:57:17.731130 [debug] [MainThread]: On master: ROLLBACK
[0m14:57:17.759512 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.760386 [debug] [MainThread]: On master: BEGIN
[0m14:57:17.820097 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.821099 [debug] [MainThread]: On master: COMMIT
[0m14:57:17.822104 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.822104 [debug] [MainThread]: On master: COMMIT
[0m14:57:17.849954 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:17.851074 [debug] [MainThread]: On master: Close
[0m14:57:17.853325 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:57:17.855337 [info ] [MainThread]: 
[0m14:57:17.861343 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:57:17.862328 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:57:17.864543 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:57:17.865560 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:57:17.872540 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:57:17.875615 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:57:17.865560 => 14:57:17.875615
[0m14:57:17.876626 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:57:17.919083 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:57:17.922053 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:17.923217 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:57:17.923580 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:57:18.112282 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:18.113055 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.113055 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:57:18.161309 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:18.168327 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.169328 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:57:18.199224 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.202265 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.203265 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:57:18.234931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.249967 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:57:18.250967 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.250967 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:57:18.280439 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:18.286475 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:57:18.291476 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.291476 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:57:18.327027 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:18.329035 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:57:17.877618 => 14:57:18.328041
[0m14:57:18.329035 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:57:18.330034 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE63B390>]}
[0m14:57:18.331548 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.47s]
[0m14:57:18.332553 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:57:18.333554 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:57:18.333554 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:57:18.335587 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:57:18.335587 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:57:18.337589 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:57:18.339554 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:57:18.336573 => 14:57:18.338588
[0m14:57:18.340554 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:57:18.346592 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:57:18.349600 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.350603 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:57:18.350603 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:18.565238 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:18.566243 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.567239 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:57:18.616003 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:18.619997 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.621007 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:57:18.656783 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.660171 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.660733 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:57:18.694742 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.697745 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:57:18.698743 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.698743 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:57:18.732438 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:18.735478 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:57:18.736478 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.737445 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:57:18.776513 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:18.777521 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:57:18.340554 => 14:57:18.777521
[0m14:57:18.778519 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:57:18.779519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE609C50>]}
[0m14:57:18.780519 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.44s]
[0m14:57:18.781519 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:57:18.782521 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:57:18.783519 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:57:18.784520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:57:18.785519 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:57:18.787518 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:57:18.789031 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:57:18.785519 => 14:57:18.789031
[0m14:57:18.790032 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:57:18.795031 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:57:18.797031 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:18.798033 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:57:18.799543 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:19.010800 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.011808 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.011808 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:57:19.062730 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:19.066462 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.066462 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:57:19.103388 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:19.108205 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.108205 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:57:19.143069 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:19.145074 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:57:19.146075 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.146075 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:57:19.181582 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:19.184615 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:57:19.185687 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.185687 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:57:19.220306 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:19.222589 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:57:18.790032 => 14:57:19.222589
[0m14:57:19.223618 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:57:19.224618 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF713490>]}
[0m14:57:19.224618 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.44s]
[0m14:57:19.226584 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:57:19.226584 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.227583 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:57:19.229621 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:57:19.229621 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.232708 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.235219 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:57:19.230617 => 14:57:19.235219
[0m14:57:19.236222 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.261895 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.263897 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.264902 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:57:19.265896 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:19.511072 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.512073 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.513078 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    listing_id,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:57:19.558268 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "listing_id" does not exist
LINE 20:     listing_id,
             ^
HINT:  Perhaps you meant to reference the column "src_listings.listing_url".

[0m14:57:19.558268 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:57:19.597294 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:57:19.236222 => 14:57:19.597294
[0m14:57:19.598298 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:57:19.603322 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "listing_id" does not exist
  LINE 20:     listing_id,
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.listing_url".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:57:19.603322 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE5D5110>]}
[0m14:57:19.604828 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.37s]
[0m14:57:19.606536 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.607552 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:19.608546 [debug] [MainThread]: On master: BEGIN
[0m14:57:19.608546 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:57:19.831417 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.833440 [debug] [MainThread]: On master: COMMIT
[0m14:57:19.833903 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:19.834446 [debug] [MainThread]: On master: COMMIT
[0m14:57:19.865604 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:19.865604 [debug] [MainThread]: On master: Close
[0m14:57:19.866608 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:57:19.867608 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:57:19.867608 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:57:19.869115 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:57:19.869642 [info ] [MainThread]: 
[0m14:57:19.870644 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 4.05 seconds (4.05s).
[0m14:57:19.871644 [debug] [MainThread]: Command end result
[0m14:57:19.882185 [info ] [MainThread]: 
[0m14:57:19.883586 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:57:19.884586 [info ] [MainThread]: 
[0m14:57:19.885583 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "listing_id" does not exist
  LINE 20:     listing_id,
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.listing_url".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:57:19.887584 [info ] [MainThread]: 
[0m14:57:19.888585 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:57:19.890585 [debug] [MainThread]: Command `dbt run` failed at 14:57:19.890585 after 5.32 seconds
[0m14:57:19.891584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC69E1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF657D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC6CDFD50>]}
[0m14:57:19.893657 [debug] [MainThread]: Flushing usage events
[0m14:58:08.634756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E3544D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E344210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E578DD0>]}


============================== 14:58:08.638373 | 2c8c0016-689d-44d0-8a17-1057e02aeb07 ==============================
[0m14:58:08.638373 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:58:08.639375 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:58:08.852442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E882050>]}
[0m14:58:08.937064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E344350>]}
[0m14:58:08.939158 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:58:08.948121 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:58:09.044040 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:58:09.045010 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:09.206484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E9276D0>]}
[0m14:58:09.220209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EC19950>]}
[0m14:58:09.220209 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:58:09.221649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EA83B10>]}
[0m14:58:09.223682 [info ] [MainThread]: 
[0m14:58:09.224652 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:58:09.227315 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:58:09.239338 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:58:09.240338 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:58:09.241370 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:10.567269 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:58:10.569273 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:58:10.571271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:58:10.577267 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:10.578266 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:58:10.578772 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:10.779414 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:58:10.780450 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:10.780450 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:58:10.829247 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:58:10.831289 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:58:10.860231 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:58:10.865133 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:10.866671 [debug] [MainThread]: On master: BEGIN
[0m14:58:10.866671 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:58:11.057291 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.058324 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.058836 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:58:11.122496 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:58:11.124579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2ED40C50>]}
[0m14:58:11.125622 [debug] [MainThread]: On master: ROLLBACK
[0m14:58:11.154022 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.154572 [debug] [MainThread]: On master: BEGIN
[0m14:58:11.210444 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.211251 [debug] [MainThread]: On master: COMMIT
[0m14:58:11.211251 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.212243 [debug] [MainThread]: On master: COMMIT
[0m14:58:11.237880 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:11.237880 [debug] [MainThread]: On master: Close
[0m14:58:11.239390 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:58:11.240374 [info ] [MainThread]: 
[0m14:58:11.243396 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:58:11.244397 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:58:11.245397 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:58:11.246399 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:58:11.253061 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:58:11.256062 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:58:11.246399 => 14:58:11.255061
[0m14:58:11.257060 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:58:11.291964 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:58:11.293966 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.294965 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:58:11.295967 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:58:11.495613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.496490 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.497488 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:58:11.542539 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:11.548802 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.549807 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:58:11.580122 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:11.584126 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.585123 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:58:11.619216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:11.642311 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:11.643313 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.644311 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:11.678478 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:11.686518 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:58:11.691522 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.692523 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:58:11.724827 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:11.726833 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:58:11.257060 => 14:58:11.725833
[0m14:58:11.727850 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:58:11.728834 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EAC7910>]}
[0m14:58:11.729833 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.48s]
[0m14:58:11.730836 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:58:11.732338 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:58:11.732785 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:58:11.733343 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:58:11.734382 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:58:11.736377 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:58:11.738348 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:58:11.735378 => 14:58:11.737350
[0m14:58:11.738348 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:58:11.742348 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:58:11.744371 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:11.745381 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:58:11.746377 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:11.960449 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.961570 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:11.961570 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:58:12.006706 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:12.010492 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.011491 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:58:12.042743 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.045688 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.046691 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:58:12.079485 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.082759 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:12.082759 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.083759 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:12.113994 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:12.116572 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:58:12.118660 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.119629 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:58:12.151095 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:12.153192 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:58:11.739349 => 14:58:12.153192
[0m14:58:12.154198 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:58:12.155197 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2ED168D0>]}
[0m14:58:12.155197 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.42s]
[0m14:58:12.157199 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:58:12.157199 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:58:12.158225 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:58:12.159203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:58:12.160231 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:58:12.162196 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:58:12.163197 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:58:12.160231 => 14:58:12.163197
[0m14:58:12.163197 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:58:12.169291 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:58:12.171296 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.172292 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:58:12.173292 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:12.375260 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:12.376272 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.376272 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:58:12.420661 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:12.423694 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.424665 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:58:12.455491 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.459386 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.459386 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:58:12.489985 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.493572 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:12.493572 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.494572 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:12.525000 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:12.529232 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:58:12.530232 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.531210 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:58:12.563057 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:12.565062 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:58:12.164701 => 14:58:12.565062
[0m14:58:12.565062 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:58:12.566061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2FE66450>]}
[0m14:58:12.567063 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:58:12.568066 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:58:12.569101 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.569101 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:58:12.570084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:58:12.571097 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.573637 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.574639 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:58:12.571097 => 14:58:12.574639
[0m14:58:12.575640 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.598781 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.600782 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.601784 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:58:12.601784 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:12.824343 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:12.825661 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.825661 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:58:12.870070 [debug] [Thread-1 (]: Postgres adapter: Postgres error: type "number" does not exist
LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                       ^

[0m14:58:12.871028 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:58:12.902215 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:58:12.575640 => 14:58:12.902215
[0m14:58:12.903045 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:58:12.908042 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  type "number" does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                         ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:12.908042 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2FE3F650>]}
[0m14:58:12.910063 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.34s]
[0m14:58:12.911069 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.913103 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:12.913103 [debug] [MainThread]: On master: BEGIN
[0m14:58:12.914069 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:58:13.133413 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:13.134401 [debug] [MainThread]: On master: COMMIT
[0m14:58:13.135393 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:13.135393 [debug] [MainThread]: On master: COMMIT
[0m14:58:13.164936 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:13.165937 [debug] [MainThread]: On master: Close
[0m14:58:13.166938 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:58:13.167937 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:58:13.167937 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:58:13.168939 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:58:13.168939 [info ] [MainThread]: 
[0m14:58:13.169939 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 3.95 seconds (3.95s).
[0m14:58:13.170937 [debug] [MainThread]: Command end result
[0m14:58:13.183403 [info ] [MainThread]: 
[0m14:58:13.184403 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:58:13.186434 [info ] [MainThread]: 
[0m14:58:13.187441 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  type "number" does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                         ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:13.189442 [info ] [MainThread]: 
[0m14:58:13.191443 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:58:13.193442 [debug] [MainThread]: Command `dbt run` failed at 14:58:13.193442 after 4.62 seconds
[0m14:58:13.194444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D27101010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E053950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2B484710>]}
[0m14:58:13.195442 [debug] [MainThread]: Flushing usage events
[0m14:58:54.653131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94063FF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E93F455310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E59990>]}


============================== 14:58:54.658281 | c52e07fe-be0c-4485-be5c-a736a9ce7841 ==============================
[0m14:58:54.658281 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:58:54.659281 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:58:54.956733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E28250>]}
[0m14:58:55.057299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94101DA10>]}
[0m14:58:55.058854 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:58:55.070514 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:58:55.178690 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:58:55.179690 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:55.375045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940951510>]}
[0m14:58:55.390748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94132E810>]}
[0m14:58:55.391738 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:58:55.392735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941105790>]}
[0m14:58:55.394821 [info ] [MainThread]: 
[0m14:58:55.395827 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:58:55.398828 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:58:55.408168 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:58:55.409168 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:58:55.410170 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:56.786136 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:58:56.787974 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:58:56.789521 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:58:56.795554 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:56.795554 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:58:56.796518 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:57.026805 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.026805 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:57.028135 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:58:57.082321 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:58:57.084365 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:58:57.117185 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:58:57.122984 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.122984 [debug] [MainThread]: On master: BEGIN
[0m14:58:57.124488 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:58:57.339370 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.339370 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.340917 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:58:57.405158 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:58:57.407152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9412F6F50>]}
[0m14:58:57.408152 [debug] [MainThread]: On master: ROLLBACK
[0m14:58:57.445050 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.445050 [debug] [MainThread]: On master: BEGIN
[0m14:58:57.505997 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.507015 [debug] [MainThread]: On master: COMMIT
[0m14:58:57.508010 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.508010 [debug] [MainThread]: On master: COMMIT
[0m14:58:57.535215 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:57.536225 [debug] [MainThread]: On master: Close
[0m14:58:57.537221 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:58:57.538220 [info ] [MainThread]: 
[0m14:58:57.542223 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:58:57.543223 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:58:57.545224 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:58:57.545224 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:58:57.552847 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:58:57.555853 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:58:57.546275 => 14:58:57.554858
[0m14:58:57.556851 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:58:57.592380 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:58:57.595079 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.596120 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:58:57.596120 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:58:57.792739 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.792739 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.793776 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:58:57.838741 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:57.845542 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.845542 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:58:57.877611 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:57.882123 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.882123 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:58:57.916076 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:57.931852 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:57.932851 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.932851 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:57.963329 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:57.969879 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:58:57.973874 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.974874 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:58:58.006736 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.008743 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:58:57.556851 => 14:58:58.008743
[0m14:58:58.008743 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:58:58.010743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9411FB450>]}
[0m14:58:58.010743 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.47s]
[0m14:58:58.012744 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:58:58.012744 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:58:58.013742 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:58:58.014913 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:58:58.015917 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:58:58.017921 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:58:58.019938 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:58:58.015917 => 14:58:58.019938
[0m14:58:58.020919 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:58:58.027451 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:58:58.029451 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.030471 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:58:58.031464 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:58.205063 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:58.205828 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.207067 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:58:58.252504 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:58.256511 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.256511 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:58:58.287752 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.291466 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.291466 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:58:58.320488 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.322461 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:58.323460 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.324460 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:58.354301 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:58.357828 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:58:58.358828 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.358828 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:58:58.390988 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.392751 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:58:58.020919 => 14:58:58.392751
[0m14:58:58.393752 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:58:58.394785 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941392A10>]}
[0m14:58:58.394785 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m14:58:58.396751 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:58:58.396751 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:58:58.398255 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:58:58.399267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:58:58.400272 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:58:58.402270 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:58:58.404274 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:58:58.400272 => 14:58:58.404274
[0m14:58:58.405272 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:58:58.410782 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:58:58.413791 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.414790 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:58:58.414790 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:58.595749 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:58.596756 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.596756 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:58:58.640610 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:58.643616 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.644616 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:58:58.674356 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.678016 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.678016 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:58:58.709181 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.712218 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:58.712218 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.713213 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:58.744139 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:58.747812 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:58:58.748821 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.749819 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:58:58.782099 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.784189 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:58:58.405272 => 14:58:58.784189
[0m14:58:58.785202 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:58:58.786189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941476BD0>]}
[0m14:58:58.786189 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.39s]
[0m14:58:58.787319 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:58:58.788359 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.789328 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:58:58.791087 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:58:58.791087 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.794051 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.795573 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:58:58.792106 => 14:58:58.795573
[0m14:58:58.796575 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.822288 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.825259 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.825259 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:58:58.826257 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:59.019282 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:59.020276 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:59.020276 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:58:59.059634 [debug] [Thread-1 (]: Postgres adapter: Postgres error: function replace(text, unknown) does not exist
LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
             ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m14:58:59.060641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:58:59.088666 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:58:58.796575 => 14:58:59.088666
[0m14:58:59.089696 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:58:59.093664 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  function replace(text, unknown) does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:59.095202 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94142CDD0>]}
[0m14:58:59.096179 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.31s]
[0m14:58:59.097431 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:58:59.098438 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:59.099470 [debug] [MainThread]: On master: BEGIN
[0m14:58:59.100470 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:58:59.280985 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:59.281962 [debug] [MainThread]: On master: COMMIT
[0m14:58:59.281962 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:59.282918 [debug] [MainThread]: On master: COMMIT
[0m14:58:59.309027 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:59.309027 [debug] [MainThread]: On master: Close
[0m14:58:59.310075 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:58:59.312860 [info ] [MainThread]: 
[0m14:58:59.313868 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 3.92 seconds (3.92s).
[0m14:58:59.314884 [debug] [MainThread]: Command end result
[0m14:58:59.324371 [info ] [MainThread]: 
[0m14:58:59.326377 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:58:59.326377 [info ] [MainThread]: 
[0m14:58:59.327380 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  function replace(text, unknown) does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:59.329379 [info ] [MainThread]: 
[0m14:58:59.330378 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:58:59.333381 [debug] [MainThread]: Command `dbt run` failed at 14:58:59.332387 after 4.76 seconds
[0m14:58:59.334383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E62150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9395DE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9396A6810>]}
[0m14:58:59.334383 [debug] [MainThread]: Flushing usage events
[0m14:59:50.993696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A60A1250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A56F2E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6112610>]}


============================== 14:59:50.998212 | 7d9c0351-338b-49aa-84cd-816b84e4922a ==============================
[0m14:59:50.998212 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:59:50.999216 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:59:51.208561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A65B0810>]}
[0m14:59:51.284538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A667EC90>]}
[0m14:59:51.286540 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:59:51.294541 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:59:51.391129 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:59:51.392129 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:51.569458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A68B0AD0>]}
[0m14:59:51.582652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A682F910>]}
[0m14:59:51.584165 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:59:51.585202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A60875D0>]}
[0m14:59:51.587209 [info ] [MainThread]: 
[0m14:59:51.588207 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:59:51.590211 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:59:51.599641 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:59:51.600642 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:59:51.600642 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:52.957813 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:59:52.959806 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:59:52.961804 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:59:52.967189 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:52.967789 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:59:52.967789 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:53.203567 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.204578 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:53.204578 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:59:53.254035 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:59:53.255327 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:59:53.289143 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:59:53.294233 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.295231 [debug] [MainThread]: On master: BEGIN
[0m14:59:53.295231 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:59:53.491330 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.491330 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.492376 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:59:53.555404 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:59:53.558011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6826350>]}
[0m14:59:53.558011 [debug] [MainThread]: On master: ROLLBACK
[0m14:59:53.587367 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.587367 [debug] [MainThread]: On master: BEGIN
[0m14:59:53.643860 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.643860 [debug] [MainThread]: On master: COMMIT
[0m14:59:53.644899 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.645892 [debug] [MainThread]: On master: COMMIT
[0m14:59:53.680155 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:53.680155 [debug] [MainThread]: On master: Close
[0m14:59:53.681168 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:59:53.682461 [info ] [MainThread]: 
[0m14:59:53.686466 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:59:53.687470 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:59:53.688885 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:59:53.688885 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:59:53.696444 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:59:53.699913 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:59:53.689887 => 14:59:53.699403
[0m14:59:53.700510 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:59:53.737270 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:59:53.739274 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.739274 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:59:53.740272 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:59:53.935844 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.936367 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.936896 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:59:53.984069 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:53.990503 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.991501 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:59:54.019376 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.022403 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.023948 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:59:54.054309 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.069828 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:59:54.070824 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.070824 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:59:54.102435 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:54.109217 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:59:54.113217 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.114217 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:59:54.146318 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:54.148357 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:59:53.700510 => 14:59:54.148357
[0m14:59:54.149357 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:59:54.150357 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6A65E90>]}
[0m14:59:54.150357 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.46s]
[0m14:59:54.152325 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:59:54.153324 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:59:54.153324 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:59:54.155360 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:59:54.155360 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:59:54.157432 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:59:54.159466 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:59:54.156326 => 14:59:54.159466
[0m14:59:54.160441 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:59:54.165484 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:59:54.167438 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.169045 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:59:54.170047 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:54.403716 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:54.404715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.404715 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:59:54.454427 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:54.458936 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.458936 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:59:54.493124 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.496758 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.496758 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:59:54.531722 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.534730 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:59:54.534730 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.535732 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:59:54.572000 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:54.574993 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:59:54.575994 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.576994 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:59:54.613999 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:54.615042 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:59:54.160441 => 14:59:54.615042
[0m14:59:54.616042 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:59:54.617039 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6B41810>]}
[0m14:59:54.618007 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m14:59:54.619005 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:59:54.620008 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:59:54.620008 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:59:54.622005 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:59:54.622005 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:59:54.624004 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:59:54.626079 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:59:54.623004 => 14:59:54.625512
[0m14:59:54.626079 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:59:54.631191 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:59:54.633215 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.634198 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:59:54.635203 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:54.862711 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:54.863702 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.863702 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:59:54.914340 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:54.918177 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.919147 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:59:54.953876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.957715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.958712 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:59:54.990748 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.992749 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:59:54.992749 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.993751 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:59:55.026273 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:55.031020 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:59:55.032059 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:55.032059 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:59:55.067847 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:55.069845 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:59:54.626079 => 14:59:55.069845
[0m14:59:55.070348 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:59:55.071363 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6BD67D0>]}
[0m14:59:55.072368 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:59:55.073368 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:59:55.074371 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.074371 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:59:55.076369 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:59:55.076369 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.079402 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.081385 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:59:55.077368 => 14:59:55.080402
[0m14:59:55.081890 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.107903 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.109903 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.109903 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:59:55.110903 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:55.332793 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:55.334298 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.335307 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:59:55.378446 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "updatede_at" does not exist
LINE 30:     updatede_at
             ^
HINT:  Perhaps you meant to reference the column "src_listings.updated_at".

[0m14:59:55.379447 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:59:55.418095 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:59:55.082899 => 14:59:55.416587
[0m14:59:55.419627 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:59:55.430145 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "updatede_at" does not exist
  LINE 30:     updatede_at
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:55.430670 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6BD9BD0>]}
[0m14:59:55.432679 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.36s]
[0m14:59:55.434678 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.437679 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:55.438678 [debug] [MainThread]: On master: BEGIN
[0m14:59:55.439677 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:59:55.667203 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:55.668204 [debug] [MainThread]: On master: COMMIT
[0m14:59:55.669587 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:55.671095 [debug] [MainThread]: On master: COMMIT
[0m14:59:55.702340 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:55.703340 [debug] [MainThread]: On master: Close
[0m14:59:55.704345 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:59:55.705344 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:59:55.706850 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:59:55.707838 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:59:55.708861 [info ] [MainThread]: 
[0m14:59:55.709859 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m14:59:55.712855 [debug] [MainThread]: Command end result
[0m14:59:55.724591 [info ] [MainThread]: 
[0m14:59:55.727593 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:59:55.729591 [info ] [MainThread]: 
[0m14:59:55.730593 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "updatede_at" does not exist
  LINE 30:     updatede_at
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:55.731674 [info ] [MainThread]: 
[0m14:59:55.733839 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:59:55.739841 [debug] [MainThread]: Command `dbt run` failed at 14:59:55.738839 after 4.81 seconds
[0m14:59:55.740840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002939EDE1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A5DB5850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A5DB5DD0>]}
[0m14:59:55.742842 [debug] [MainThread]: Flushing usage events
[0m15:00:07.871689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DE8DD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830CAD5150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830A38C490>]}


============================== 15:00:07.875687 | 15f63cf1-32ae-46ff-8b62-81075beb7f18 ==============================
[0m15:00:07.875687 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:00:07.876686 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:00:08.086575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DEE2050>]}
[0m15:00:08.161938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DFDC310>]}
[0m15:00:08.163901 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:00:08.173943 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:00:08.270209 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:00:08.271211 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m15:00:08.441083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E1FCE90>]}
[0m15:00:08.461114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E27D810>]}
[0m15:00:08.462113 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:00:08.463112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E1CE810>]}
[0m15:00:08.466114 [info ] [MainThread]: 
[0m15:00:08.468117 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:00:08.470616 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:00:08.488172 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:00:08.489148 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:00:08.490146 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:08.718420 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:00:08.720420 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:00:08.722387 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:00:08.729133 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:00:08.730166 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:00:08.730166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:08.910933 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:00:08.910933 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:00:08.911930 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:00:08.957759 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m15:00:08.959798 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:00:08.988020 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:00:08.993849 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:08.993849 [debug] [MainThread]: On master: BEGIN
[0m15:00:08.994815 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:00:09.184392 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.184910 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.185944 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:00:09.237947 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:00:09.240430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F3C0790>]}
[0m15:00:09.240430 [debug] [MainThread]: On master: ROLLBACK
[0m15:00:09.270708 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.271714 [debug] [MainThread]: On master: BEGIN
[0m15:00:09.328884 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.329900 [debug] [MainThread]: On master: COMMIT
[0m15:00:09.329900 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.330898 [debug] [MainThread]: On master: COMMIT
[0m15:00:09.357073 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:00:09.358081 [debug] [MainThread]: On master: Close
[0m15:00:09.359079 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:00:09.360239 [info ] [MainThread]: 
[0m15:00:09.363243 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:00:09.364245 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m15:00:09.365245 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:00:09.366245 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:00:09.372756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:00:09.375758 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:00:09.366245 => 15:00:09.374760
[0m15:00:09.376771 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:00:09.413576 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:00:09.415597 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.416547 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:00:09.416547 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:00:09.599723 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.600836 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.600836 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:00:09.642463 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:09.651644 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.652644 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:00:09.685874 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:09.689880 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.690881 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:00:09.720320 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:09.735525 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:00:09.736524 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.737524 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:00:09.765327 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:09.771378 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:00:09.776378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.777371 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:00:09.808308 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:09.810342 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:00:09.376771 => 15:00:09.810342
[0m15:00:09.811329 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:00:09.812343 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E13FFD0>]}
[0m15:00:09.813309 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.45s]
[0m15:00:09.814308 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:00:09.815822 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:00:09.815822 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m15:00:09.817212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:00:09.818246 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:00:09.820243 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:00:09.821214 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:00:09.818246 => 15:00:09.821214
[0m15:00:09.822212 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:00:09.826243 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:00:09.828326 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:09.829368 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:00:09.830346 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.006647 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.008683 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.009199 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:00:10.048525 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:10.052524 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.053526 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:00:10.087493 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.090487 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.091487 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:00:10.121727 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.124721 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:00:10.125724 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.126721 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:00:10.156397 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:10.159397 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:00:10.160397 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.161395 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:00:10.195267 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:10.199262 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:00:09.822212 => 15:00:10.198259
[0m15:00:10.200261 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:00:10.201776 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F422B10>]}
[0m15:00:10.202772 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m15:00:10.203772 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:00:10.203772 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:00:10.204773 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m15:00:10.205773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:00:10.206771 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:00:10.208771 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:00:10.210771 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:00:10.206771 => 15:00:10.210771
[0m15:00:10.210771 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:00:10.215806 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:00:10.217808 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.217808 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:00:10.218842 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.404553 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.404553 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.404553 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:00:10.447362 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:10.451227 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.451227 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:00:10.488796 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.492297 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.493297 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:00:10.524031 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.526056 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:00:10.527056 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.527056 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:00:10.559587 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:10.563682 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:00:10.564679 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.565713 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:00:10.599341 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:10.601347 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:00:10.210771 => 15:00:10.601347
[0m15:00:10.601347 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:00:10.602348 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F4C6A50>]}
[0m15:00:10.603347 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.40s]
[0m15:00:10.604351 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:00:10.605385 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.606347 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:00:10.607349 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m15:00:10.607349 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.610374 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.612375 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:00:10.607349 => 15:00:10.611374
[0m15:00:10.612375 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.635173 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.638576 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.641580 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:00:10.643592 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.847334 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.849346 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.850887 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:00:10.967836 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:00:10.971360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.972358 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:00:11.000999 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:11.006697 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:00:11.007868 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:11.008836 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:00:11.038332 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:11.042932 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:00:11.046361 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:11.046361 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:00:11.077018 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:00:11.079232 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:00:10.613374 => 15:00:11.079232
[0m15:00:11.080232 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:00:11.081267 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F3D8450>]}
[0m15:00:11.081267 [info ] [Thread-1 (]: 4 of 4 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.47s]
[0m15:00:11.083233 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:00:11.085232 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:11.085232 [debug] [MainThread]: On master: BEGIN
[0m15:00:11.086272 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:00:11.272963 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:11.273964 [debug] [MainThread]: On master: COMMIT
[0m15:00:11.274965 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:11.274965 [debug] [MainThread]: On master: COMMIT
[0m15:00:11.303017 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:00:11.304171 [debug] [MainThread]: On master: Close
[0m15:00:11.305793 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:00:11.306306 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:00:11.307348 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:00:11.308428 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:00:11.309472 [info ] [MainThread]: 
[0m15:00:11.310567 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 2.84 seconds (2.84s).
[0m15:00:11.312743 [debug] [MainThread]: Command end result
[0m15:00:11.324359 [info ] [MainThread]: 
[0m15:00:11.325470 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:00:11.327170 [info ] [MainThread]: 
[0m15:00:11.328795 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m15:00:11.330333 [debug] [MainThread]: Command `dbt run` succeeded at 15:00:11.330333 after 3.52 seconds
[0m15:00:11.330333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018306701010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830D6B2550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183069EFED0>]}
[0m15:00:11.331871 [debug] [MainThread]: Flushing usage events
[0m15:08:21.198391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C723810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C2E93D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C6EAAD0>]}


============================== 15:08:21.201903 | 9bdd196a-2021-4bec-bb96-0e65581100dc ==============================
[0m15:08:21.201903 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:08:21.202935 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:08:21.414590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C246710>]}
[0m15:08:21.494253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C82FF10>]}
[0m15:08:21.496567 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:08:21.504602 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:08:21.610884 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m15:08:21.611885 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:21.611885 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m15:08:21.781410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C1F9210>]}
[0m15:08:21.794897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CBCBCD0>]}
[0m15:08:21.794897 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:08:21.795897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CC2D6D0>]}
[0m15:08:21.797925 [info ] [MainThread]: 
[0m15:08:21.798939 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:08:21.802027 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:08:21.813960 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:08:21.815257 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:08:21.816235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:22.051920 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:08:22.052960 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:08:22.055158 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:08:22.061161 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:08:22.062162 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:08:22.062162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:22.262932 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.262932 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:08:22.263973 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:08:22.310785 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:08:22.312827 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:08:22.341545 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:08:22.347803 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.348837 [debug] [MainThread]: On master: BEGIN
[0m15:08:22.349803 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:08:22.555755 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.556770 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.556770 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:08:22.621778 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:08:22.623785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CA7ACD0>]}
[0m15:08:22.624796 [debug] [MainThread]: On master: ROLLBACK
[0m15:08:22.655537 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.655537 [debug] [MainThread]: On master: BEGIN
[0m15:08:22.714120 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.715347 [debug] [MainThread]: On master: COMMIT
[0m15:08:22.715347 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.716354 [debug] [MainThread]: On master: COMMIT
[0m15:08:22.741300 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:08:22.742205 [debug] [MainThread]: On master: Close
[0m15:08:22.743215 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:08:22.744198 [info ] [MainThread]: 
[0m15:08:22.747422 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.748429 [info ] [Thread-1 (]: 1 of 5 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:08:22.749936 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:08:22.751014 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.758019 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.760028 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:08:22.752023 => 15:08:22.760028
[0m15:08:22.762022 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.803739 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.805721 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.806707 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:08:22.807705 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:08:23.024835 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.025858 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:23.026363 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        
)
SELECT
    review_id,
	CASE 
        WHEN review_name IS NULL THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:08:23.066839 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ")"
LINE 17: )
         ^

[0m15:08:23.067837 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: ROLLBACK
[0m15:08:23.098622 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:08:22.762536 => 15:08:23.098622
[0m15:08:23.099840 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:08:23.104845 [debug] [Thread-1 (]: Database Error in model dim_hosts_cleansed (dbtlearn/models\dim\dim_hosts_cleansed.sql)
  syntax error at or near ")"
  LINE 17: )
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:23.105843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C873F50>]}
[0m15:08:23.106846 [error] [Thread-1 (]: 1 of 5 ERROR creating sql table model test.dim_hosts_cleansed .................. [[31mERROR[0m in 0.36s]
[0m15:08:23.107388 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:08:23.108428 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:08:23.109396 [info ] [Thread-1 (]: 2 of 5 START sql view model test.src_hosts ..................................... [RUN]
[0m15:08:23.110397 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.src_hosts)
[0m15:08:23.110397 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:08:23.113835 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:08:23.115854 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:08:23.111883 => 15:08:23.114867
[0m15:08:23.115854 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:08:23.139839 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:08:23.142847 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.143843 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:08:23.143843 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:23.372926 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.373933 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.373933 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:08:23.422797 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:23.429290 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.430291 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:08:23.463980 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.467053 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.468019 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:08:23.502636 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.517723 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:08:23.517723 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.519247 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:08:23.552002 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:23.558603 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:08:23.563603 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.563603 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:08:23.604534 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:23.606077 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:08:23.116838 => 15:08:23.606077
[0m15:08:23.607092 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:08:23.608077 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CC45250>]}
[0m15:08:23.609077 [info ] [Thread-1 (]: 2 of 5 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.50s]
[0m15:08:23.609407 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:08:23.610443 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:08:23.611415 [info ] [Thread-1 (]: 3 of 5 START sql view model test.src_listings .................................. [RUN]
[0m15:08:23.612443 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:08:23.612443 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:08:23.614413 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:08:23.616765 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:08:23.613442 => 15:08:23.615413
[0m15:08:23.617778 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:08:23.623762 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:08:23.625766 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.627800 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:08:23.628806 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:23.850110 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.850859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.851856 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:08:23.901612 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:23.905149 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.906148 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:08:23.946216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.949222 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.950221 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:08:23.985099 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.988143 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:08:23.988683 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.989178 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:08:24.023192 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:24.026717 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:08:24.027715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:24.028718 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:08:24.066403 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:24.068551 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:08:23.617778 => 15:08:24.068551
[0m15:08:24.069096 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:08:24.070162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DCC33D0>]}
[0m15:08:24.071191 [info ] [Thread-1 (]: 3 of 5 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m15:08:24.072236 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:08:24.073269 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:08:24.073806 [info ] [Thread-1 (]: 4 of 5 START sql view model test.src_reviews ................................... [RUN]
[0m15:08:24.074845 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:08:24.075955 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:08:24.077511 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:08:24.079032 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:08:24.076475 => 15:08:24.079032
[0m15:08:24.079032 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:08:24.087521 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:08:24.090043 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.091039 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:08:24.092039 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:24.332205 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:24.333213 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.333213 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:08:24.383303 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:24.386814 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.387815 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:08:24.427732 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.431730 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.431730 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:08:24.466992 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.468535 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:08:24.469789 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.470789 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:08:24.505937 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:24.508516 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:08:24.509480 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.510516 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:08:24.548030 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:24.550074 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:08:24.079032 => 15:08:24.549084
[0m15:08:24.550074 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:08:24.551036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DD69CD0>]}
[0m15:08:24.552576 [info ] [Thread-1 (]: 4 of 5 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.48s]
[0m15:08:24.553584 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:08:24.554594 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.554594 [info ] [Thread-1 (]: 5 of 5 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:08:24.556581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m15:08:24.556581 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.559580 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.562585 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:08:24.557581 => 15:08:24.561587
[0m15:08:24.563586 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.570120 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.572122 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.572122 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:08:24.573123 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:24.780714 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:24.781498 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.782548 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:08:24.933609 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:08:24.937189 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.937189 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:08:24.974789 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.977797 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.978797 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:08:25.008142 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:25.014280 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:08:25.014280 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:25.015281 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:08:25.046021 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:25.049689 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:08:25.052689 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:25.053689 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:08:25.094052 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:08:25.096085 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:08:24.563586 => 15:08:25.094828
[0m15:08:25.096085 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:08:25.097070 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DD8E6D0>]}
[0m15:08:25.098088 [info ] [Thread-1 (]: 5 of 5 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.54s]
[0m15:08:25.099053 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:08:25.101420 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:25.101420 [debug] [MainThread]: On master: BEGIN
[0m15:08:25.102420 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:08:25.301094 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:25.302106 [debug] [MainThread]: On master: COMMIT
[0m15:08:25.302106 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:25.303109 [debug] [MainThread]: On master: COMMIT
[0m15:08:25.329306 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:08:25.329306 [debug] [MainThread]: On master: Close
[0m15:08:25.330313 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:08:25.331313 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:08:25.331313 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:08:25.332312 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:08:25.332312 [info ] [MainThread]: 
[0m15:08:25.334427 [info ] [MainThread]: Finished running 2 table models, 3 view models in 0 hours 0 minutes and 3.53 seconds (3.53s).
[0m15:08:25.336467 [debug] [MainThread]: Command end result
[0m15:08:25.345978 [info ] [MainThread]: 
[0m15:08:25.346645 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:08:25.347655 [info ] [MainThread]: 
[0m15:08:25.348653 [error] [MainThread]:   Database Error in model dim_hosts_cleansed (dbtlearn/models\dim\dim_hosts_cleansed.sql)
  syntax error at or near ")"
  LINE 17: )
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:25.350655 [info ] [MainThread]: 
[0m15:08:25.351656 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m15:08:25.354665 [debug] [MainThread]: Command `dbt run` failed at 15:08:25.353668 after 4.22 seconds
[0m15:08:25.355666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B54FC1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5BFBAE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5BEF5490>]}
[0m15:08:25.356655 [debug] [MainThread]: Flushing usage events
[0m15:09:24.348636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855FCBB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855AF7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855AF6790>]}


============================== 15:09:24.352631 | b1207066-8e8b-4cb2-954f-2675086edf64 ==============================
[0m15:09:24.352631 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:09:24.352631 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:09:24.587362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855B003D0>]}
[0m15:09:24.680259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855FE2E10>]}
[0m15:09:24.681260 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:09:24.692070 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:09:24.794357 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:09:24.795359 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:09:24.983689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85624AA50>]}
[0m15:09:24.998795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8563BF950>]}
[0m15:09:24.999323 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:09:25.000418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F856295750>]}
[0m15:09:25.002454 [info ] [MainThread]: 
[0m15:09:25.004493 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:09:25.006256 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:09:25.018746 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:09:25.018746 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:09:25.019745 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:25.258777 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:09:25.260740 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:09:25.262740 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:09:25.268977 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:09:25.268977 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:09:25.270015 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:25.470039 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.471012 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:09:25.471981 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:09:25.519158 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:09:25.521333 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:09:25.548946 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:09:25.557462 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.558469 [debug] [MainThread]: On master: BEGIN
[0m15:09:25.558469 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:09:25.745741 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.746741 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.746741 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:09:25.796273 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:09:25.798281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8562AD690>]}
[0m15:09:25.798281 [debug] [MainThread]: On master: ROLLBACK
[0m15:09:25.828034 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.829036 [debug] [MainThread]: On master: BEGIN
[0m15:09:25.955009 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.956011 [debug] [MainThread]: On master: COMMIT
[0m15:09:25.956011 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.957009 [debug] [MainThread]: On master: COMMIT
[0m15:09:25.986792 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:09:25.986792 [debug] [MainThread]: On master: Close
[0m15:09:25.988324 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:09:25.988833 [info ] [MainThread]: 
[0m15:09:25.992137 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:09:25.993137 [info ] [Thread-1 (]: 1 of 5 START sql view model test.src_hosts ..................................... [RUN]
[0m15:09:25.995139 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:09:25.995139 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:09:26.001155 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:09:26.003168 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:09:25.996138 => 15:09:26.002161
[0m15:09:26.004168 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:09:26.044416 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:09:26.046411 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.046411 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:09:26.047414 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:09:26.264267 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:26.264958 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.266091 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:09:26.314995 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:26.322756 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.322756 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:09:26.358645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.362750 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.363754 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:09:26.397989 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.413012 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:09:26.414011 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.414011 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:09:26.453233 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:26.460506 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:09:26.465505 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.465505 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:09:26.502800 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:26.503799 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:09:26.004168 => 15:09:26.503799
[0m15:09:26.505304 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:09:26.506306 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85654DA90>]}
[0m15:09:26.506825 [info ] [Thread-1 (]: 1 of 5 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.51s]
[0m15:09:26.507828 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:09:26.508828 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:09:26.508828 [info ] [Thread-1 (]: 2 of 5 START sql view model test.src_listings .................................. [RUN]
[0m15:09:26.510830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:09:26.510830 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:09:26.512861 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:09:26.514830 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:09:26.511843 => 15:09:26.513827
[0m15:09:26.515829 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:09:26.520855 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:09:26.522859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.522859 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:09:26.524856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:26.733844 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:26.735016 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.735557 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:09:26.786291 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:26.790122 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.790122 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:09:26.827365 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.831391 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.832392 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:09:26.866613 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.868616 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:09:26.869616 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.869616 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:09:26.904045 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:26.907054 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:09:26.909054 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.909054 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:09:26.945468 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:26.947271 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:09:26.515829 => 15:09:26.947271
[0m15:09:26.948244 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:09:26.949267 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F856539E50>]}
[0m15:09:26.949267 [info ] [Thread-1 (]: 2 of 5 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.44s]
[0m15:09:26.950234 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:09:26.951637 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:09:26.952620 [info ] [Thread-1 (]: 3 of 5 START sql view model test.src_reviews ................................... [RUN]
[0m15:09:26.953611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:09:26.954605 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:09:26.955637 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:09:26.957633 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:09:26.954605 => 15:09:26.957633
[0m15:09:26.958638 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:09:26.962658 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:09:26.964124 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:26.964124 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:09:26.965124 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:27.179300 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:27.180060 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.180564 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:09:27.228979 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:27.232975 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.232975 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:09:27.268776 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.272813 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.273778 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:09:27.308772 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.311272 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:09:27.312278 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.312278 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:09:27.346778 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:27.350289 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:09:27.351288 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.352256 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:09:27.388070 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:27.390038 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:09:26.958638 => 15:09:27.390038
[0m15:09:27.391059 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:09:27.393037 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85663B250>]}
[0m15:09:27.393037 [info ] [Thread-1 (]: 3 of 5 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.44s]
[0m15:09:27.394036 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:09:27.395605 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.395605 [info ] [Thread-1 (]: 4 of 5 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:09:27.397609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:09:27.397609 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.401609 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.403609 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:09:27.398613 => 15:09:27.402610
[0m15:09:27.404609 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.427198 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.429198 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.429198 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:09:27.430721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:27.640401 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:27.641369 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.642368 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name IS NULL THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:09:27.739488 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:09:27.742485 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.743484 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:09:27.777239 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.782747 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:09:27.782747 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.783747 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:09:27.822801 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:27.825807 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:09:27.828833 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.829838 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:09:27.863300 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:09:27.864844 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:09:27.404609 => 15:09:27.864844
[0m15:09:27.865842 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:09:27.866877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85664A790>]}
[0m15:09:27.867875 [info ] [Thread-1 (]: 4 of 5 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.47s]
[0m15:09:27.869877 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.869877 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.870877 [info ] [Thread-1 (]: 5 of 5 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:09:27.871846 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:09:27.873105 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.876197 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.877937 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:09:27.873105 => 15:09:27.876764
[0m15:09:27.877937 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.882941 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.884939 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.884939 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:09:27.885946 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:28.083139 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:28.084091 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.085059 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:09:28.235996 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:09:28.239874 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.240874 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:09:28.271456 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:28.275193 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.275193 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:09:28.306544 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:28.308637 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:09:28.309674 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.310641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:09:28.345767 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:28.348638 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:09:28.349638 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.350637 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:09:28.400405 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:09:28.402286 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:09:27.878937 => 15:09:28.402286
[0m15:09:28.403285 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:09:28.404286 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85663ABD0>]}
[0m15:09:28.405369 [info ] [Thread-1 (]: 5 of 5 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.53s]
[0m15:09:28.405796 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:09:28.407798 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:28.408801 [debug] [MainThread]: On master: BEGIN
[0m15:09:28.409818 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:09:28.593987 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:28.593987 [debug] [MainThread]: On master: COMMIT
[0m15:09:28.594996 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:28.594996 [debug] [MainThread]: On master: COMMIT
[0m15:09:28.623274 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:09:28.624278 [debug] [MainThread]: On master: Close
[0m15:09:28.625305 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:09:28.625305 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:09:28.626275 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:09:28.626275 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:09:28.626275 [info ] [MainThread]: 
[0m15:09:28.627274 [info ] [MainThread]: Finished running 3 view models, 2 table models in 0 hours 0 minutes and 3.62 seconds (3.62s).
[0m15:09:28.629309 [debug] [MainThread]: Command end result
[0m15:09:28.638413 [info ] [MainThread]: 
[0m15:09:28.639411 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:09:28.640409 [info ] [MainThread]: 
[0m15:09:28.641412 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m15:09:28.643460 [debug] [MainThread]: Command `dbt run` succeeded at 15:09:28.643460 after 4.36 seconds
[0m15:09:28.643460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855B7EB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F84E8C1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F84E8C1B50>]}
[0m15:09:28.644966 [debug] [MainThread]: Flushing usage events
[0m15:11:31.920847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE7D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F70F1F42D0>]}


============================== 15:11:31.924389 | cba3c832-f59b-49fc-ba7e-c1417bf3be1d ==============================
[0m15:11:31.924389 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:11:31.925357 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s dim_hosts_cleansed', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:11:32.133993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710C1C550>]}
[0m15:11:32.210809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAF290>]}
[0m15:11:32.211838 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:11:32.220883 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:11:32.321059 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:11:32.322028 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:11:32.495970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710E9C410>]}
[0m15:11:32.508660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710F6E850>]}
[0m15:11:32.509627 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:11:32.510625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710EFC1D0>]}
[0m15:11:32.511626 [info ] [MainThread]: 
[0m15:11:32.512625 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:11:32.514659 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:11:32.523553 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:11:32.524554 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:11:32.525555 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:32.870576 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:11:32.872569 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:11:32.874393 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:11:32.879516 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:11:32.880522 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:11:32.881516 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:33.075317 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.076364 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:11:33.076364 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:11:33.126071 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:11:33.127087 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:11:33.157751 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:11:33.163749 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.164754 [debug] [MainThread]: On master: BEGIN
[0m15:11:33.164754 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:11:33.376107 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.376107 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.377102 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:11:33.435577 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:11:33.438578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710EFD590>]}
[0m15:11:33.438578 [debug] [MainThread]: On master: ROLLBACK
[0m15:11:33.467909 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.468870 [debug] [MainThread]: On master: BEGIN
[0m15:11:33.526888 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.527437 [debug] [MainThread]: On master: COMMIT
[0m15:11:33.528478 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.528478 [debug] [MainThread]: On master: COMMIT
[0m15:11:33.557443 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:11:33.557443 [debug] [MainThread]: On master: Close
[0m15:11:33.558480 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:11:33.559474 [info ] [MainThread]: 
[0m15:11:33.562970 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.563967 [info ] [Thread-1 (]: 1 of 1 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:11:33.564968 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:11:33.565970 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.574694 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.576703 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:11:33.565970 => 15:11:33.576703
[0m15:11:33.577702 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.618805 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.619805 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.621313 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:11:33.622508 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:11:33.826233 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.826765 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.827899 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	COALESCE(review_name, 'Anonymous') AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:11:33.923142 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:11:33.930875 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.931395 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:11:33.960947 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:11:33.963978 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.964981 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:11:33.993824 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:11:34.011593 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:11:34.012594 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:34.013595 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:11:34.046163 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:11:34.053149 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:11:34.057690 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:34.058691 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:11:34.097962 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:11:34.099960 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:11:33.577702 => 15:11:34.098958
[0m15:11:34.099960 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:11:34.100924 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F712102050>]}
[0m15:11:34.101924 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.54s]
[0m15:11:34.103208 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:11:34.105389 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:34.105389 [debug] [MainThread]: On master: BEGIN
[0m15:11:34.106422 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:11:34.319848 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:34.320790 [debug] [MainThread]: On master: COMMIT
[0m15:11:34.321788 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:34.321788 [debug] [MainThread]: On master: COMMIT
[0m15:11:34.353104 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:11:34.353104 [debug] [MainThread]: On master: Close
[0m15:11:34.355136 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:11:34.355136 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:11:34.355136 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:11:34.356163 [debug] [MainThread]: Connection 'model.dbtlearn.dim_hosts_cleansed' was properly closed.
[0m15:11:34.357141 [info ] [MainThread]: 
[0m15:11:34.357141 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.84 seconds (1.84s).
[0m15:11:34.359146 [debug] [MainThread]: Command end result
[0m15:11:34.369804 [info ] [MainThread]: 
[0m15:11:34.370805 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:11:34.371802 [info ] [MainThread]: 
[0m15:11:34.374805 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:11:34.376803 [debug] [MainThread]: Command `dbt run` succeeded at 15:11:34.376803 after 2.52 seconds
[0m15:11:34.378329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F709401090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F709400FD0>]}
[0m15:11:34.378953 [debug] [MainThread]: Flushing usage events
[0m15:13:13.155385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A8CAED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A0FF490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A0FE790>]}


============================== 15:13:13.158837 | 8e8710da-ad90-485a-a7f6-b053e0339ea0 ==============================
[0m15:13:13.158837 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:13:13.159805 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s dim_hosts_cleansed', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:13:13.374417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AAD8E50>]}
[0m15:13:13.451700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AAD8C90>]}
[0m15:13:13.453210 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:13:13.462435 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:13:13.575078 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:13:13.576076 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:13:13.751558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AC7FDD0>]}
[0m15:13:13.766321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB7C490>]}
[0m15:13:13.767330 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:13:13.768330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB74F90>]}
[0m15:13:13.769828 [info ] [MainThread]: 
[0m15:13:13.771416 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:13:13.772968 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:13:13.788235 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:13:13.788750 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:13:13.789781 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:15.147222 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:13:15.148729 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:13:15.151169 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:13:15.155687 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:13:15.156688 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:13:15.156688 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:15.376586 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.377630 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:13:15.378205 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:13:15.425483 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:13:15.427466 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:13:15.456348 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:13:15.461832 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.462832 [debug] [MainThread]: On master: BEGIN
[0m15:13:15.462832 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:13:15.706045 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.706984 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.707983 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:13:15.769569 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:13:15.771574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AA40850>]}
[0m15:13:15.771574 [debug] [MainThread]: On master: ROLLBACK
[0m15:13:15.799651 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.800665 [debug] [MainThread]: On master: BEGIN
[0m15:13:15.866256 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.867266 [debug] [MainThread]: On master: COMMIT
[0m15:13:15.867266 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.868300 [debug] [MainThread]: On master: COMMIT
[0m15:13:15.896489 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:13:15.897490 [debug] [MainThread]: On master: Close
[0m15:13:15.898490 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:13:15.898490 [info ] [MainThread]: 
[0m15:13:15.902491 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.903493 [info ] [Thread-1 (]: 1 of 1 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:13:15.903493 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:13:15.904999 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.915313 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.919859 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:13:15.906298 => 15:13:15.919208
[0m15:13:15.919859 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.966917 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.968500 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.969883 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:13:15.970442 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:13:16.198221 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:13:16.199234 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.199234 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:13:16.301748 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:13:16.308859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.309826 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:13:16.342355 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:13:16.346360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.346360 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:13:16.381957 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:13:16.399249 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:13:16.400286 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.401251 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:13:16.441828 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:13:16.451315 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:13:16.460170 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.462169 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:13:16.507179 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:13:16.509190 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:13:15.920865 => 15:13:16.509190
[0m15:13:16.510197 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:13:16.511189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB7C490>]}
[0m15:13:16.512191 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.61s]
[0m15:13:16.513194 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:13:16.515539 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:16.515539 [debug] [MainThread]: On master: BEGIN
[0m15:13:16.516522 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:13:16.764752 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:16.765716 [debug] [MainThread]: On master: COMMIT
[0m15:13:16.765716 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:16.766712 [debug] [MainThread]: On master: COMMIT
[0m15:13:16.809575 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:13:16.810569 [debug] [MainThread]: On master: Close
[0m15:13:16.811533 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:13:16.812531 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:13:16.812531 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:13:16.813532 [debug] [MainThread]: Connection 'model.dbtlearn.dim_hosts_cleansed' was properly closed.
[0m15:13:16.813532 [info ] [MainThread]: 
[0m15:13:16.814532 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.04 seconds (3.04s).
[0m15:13:16.815531 [debug] [MainThread]: Command end result
[0m15:13:16.825944 [info ] [MainThread]: 
[0m15:13:16.827944 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:13:16.827944 [info ] [MainThread]: 
[0m15:13:16.828943 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:13:16.830448 [debug] [MainThread]: Command `dbt run` succeeded at 15:13:16.830448 after 3.74 seconds
[0m15:13:16.831445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A9191D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A424BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E83141090>]}
[0m15:13:16.831969 [debug] [MainThread]: Flushing usage events
[0m15:22:02.572071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A352A2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A34695150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A352A2250>]}


============================== 15:22:02.576049 | 2c080157-7759-4b00-8088-84a5f178852c ==============================
[0m15:22:02.576049 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:22:02.577048 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:22:02.784691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A352A15D0>]}
[0m15:22:02.865222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A35C5E110>]}
[0m15:22:02.867236 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:22:02.874769 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:22:02.900872 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:22:02.901843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36E16490>]}
[0m15:22:03.748392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36F79AD0>]}
[0m15:22:03.760420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36F0B850>]}
[0m15:22:03.761416 [info ] [MainThread]: Found 6 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:22:03.762415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36DD0190>]}
[0m15:22:03.764509 [info ] [MainThread]: 
[0m15:22:03.765051 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:22:03.766986 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:22:03.777146 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:22:03.777146 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:22:03.778189 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:05.140419 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:22:05.141381 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:22:05.144381 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:22:05.150153 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:22:05.150153 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:22:05.151154 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:05.333369 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:22:05.334120 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:22:05.334120 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:22:05.383089 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:22:05.384943 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:22:05.419820 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:22:05.425782 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:05.426783 [debug] [MainThread]: On master: BEGIN
[0m15:22:05.426783 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:22:05.634192 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:05.635193 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:05.635193 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:22:05.698697 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:22:05.700740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A35CF73D0>]}
[0m15:22:05.701738 [debug] [MainThread]: On master: ROLLBACK
[0m15:22:05.735253 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:05.735253 [debug] [MainThread]: On master: BEGIN
[0m15:22:05.787169 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:05.788170 [debug] [MainThread]: On master: COMMIT
[0m15:22:05.788170 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:05.789170 [debug] [MainThread]: On master: COMMIT
[0m15:22:05.827048 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:05.828346 [debug] [MainThread]: On master: Close
[0m15:22:05.829448 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:22:05.830492 [info ] [MainThread]: 
[0m15:22:05.834226 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:22:05.835296 [info ] [Thread-1 (]: 1 of 6 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:22:05.836353 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.fact_reviews'
[0m15:22:05.837364 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:22:05.845645 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:22:05.848978 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:22:05.837875 => 15:22:05.848450
[0m15:22:05.850020 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:22:05.914054 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:22:05.916553 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:22:05.916553 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:22:05.917559 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:22:06.135488 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:06.136543 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:22:06.137505 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      
  
    

  create  table "inttegra_stage"."test"."fact_reviews"
  
  
    as
  
  (
    WITH src_reviews AS (
    SELECT
        *
    FROM
        refsrc_reviews
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_text IS NOT NULL
  );
  
  
[0m15:22:06.170568 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "refsrc_reviews" does not exist
LINE 17:         refsrc_reviews
                 ^

[0m15:22:06.170568 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: ROLLBACK
[0m15:22:06.199239 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:22:05.850550 => 15:22:06.199239
[0m15:22:06.200259 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:22:06.205291 [debug] [Thread-1 (]: Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  relation "refsrc_reviews" does not exist
  LINE 17:         refsrc_reviews
                   ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\fact\fact_reviews.sql
[0m15:22:06.206291 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36F67490>]}
[0m15:22:06.207291 [error] [Thread-1 (]: 1 of 6 ERROR creating sql incremental model test.fact_reviews .................. [[31mERROR[0m in 0.37s]
[0m15:22:06.208292 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:22:06.209291 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:22:06.210290 [info ] [Thread-1 (]: 2 of 6 START sql view model test.src_hosts ..................................... [RUN]
[0m15:22:06.211289 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.src_hosts)
[0m15:22:06.211289 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:22:06.213321 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:22:06.214322 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:22:06.212322 => 15:22:06.214322
[0m15:22:06.215827 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:22:06.236417 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:22:06.237418 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.238417 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:22:06.238417 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:06.481683 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:06.482696 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.482696 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:22:06.533116 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:06.539155 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.540151 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:22:06.576571 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:06.580591 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.580591 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:22:06.619950 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:06.634993 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:22:06.636500 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.638038 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:22:06.676218 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:06.682224 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:22:06.686733 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.688238 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:22:06.724782 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:06.726542 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:22:06.215827 => 15:22:06.726542
[0m15:22:06.727537 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:22:06.728537 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36F5E650>]}
[0m15:22:06.728537 [info ] [Thread-1 (]: 2 of 6 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.52s]
[0m15:22:06.730571 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:22:06.730571 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:22:06.731593 [info ] [Thread-1 (]: 3 of 6 START sql view model test.src_listings .................................. [RUN]
[0m15:22:06.732538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:22:06.732538 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:22:06.734894 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:22:06.736792 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:22:06.733928 => 15:22:06.736792
[0m15:22:06.736792 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:22:06.741831 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:22:06.742797 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:06.742797 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:22:06.744336 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:06.950035 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:06.951084 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:06.951084 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:22:06.995406 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:07.002600 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:07.003539 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:22:07.046920 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:07.050934 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:07.051933 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:22:07.090964 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:07.093441 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:22:07.094070 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:07.094580 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:22:07.131874 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:07.134882 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:22:07.135884 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:07.136885 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:22:07.174819 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:07.175833 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:22:06.737834 => 15:22:07.175833
[0m15:22:07.177349 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:22:07.178409 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A35D459D0>]}
[0m15:22:07.178871 [info ] [Thread-1 (]: 3 of 6 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.45s]
[0m15:22:07.179871 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:22:07.180904 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:22:07.181908 [info ] [Thread-1 (]: 4 of 6 START sql view model test.src_reviews ................................... [RUN]
[0m15:22:07.182888 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:22:07.183901 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:22:07.185870 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:22:07.186904 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:22:07.183901 => 15:22:07.186904
[0m15:22:07.187904 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:22:07.192661 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:22:07.193665 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.194637 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:22:07.195637 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:07.419146 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:07.420152 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.421145 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:22:07.465972 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:07.469977 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.470976 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:22:07.505118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:07.509118 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.510119 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:22:07.552938 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:07.554944 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:22:07.555944 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.555944 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:22:07.589690 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:07.592697 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:22:07.593697 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.594697 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:22:07.635142 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:07.637147 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:22:07.188879 => 15:22:07.637147
[0m15:22:07.637147 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:22:07.638149 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A370ABAD0>]}
[0m15:22:07.639206 [info ] [Thread-1 (]: 4 of 6 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.46s]
[0m15:22:07.641148 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:22:07.641148 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:22:07.642147 [info ] [Thread-1 (]: 5 of 6 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:22:07.643150 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:22:07.644148 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:22:07.646660 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.648649 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:22:07.644148 => 15:22:07.648649
[0m15:22:07.649683 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:22:07.665884 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.668874 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.670379 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:22:07.671387 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:07.890365 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:07.891378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.891378 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:22:07.990966 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:22:07.996081 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.997080 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:22:08.036051 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:08.040374 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:08.040896 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:22:08.080006 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:08.085779 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:22:08.086351 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:08.087434 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:22:08.122844 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:08.125644 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:22:08.130735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:08.131705 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:22:08.176001 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:08.178034 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:22:07.649683 => 15:22:08.177002
[0m15:22:08.178034 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:22:08.179033 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A37139210>]}
[0m15:22:08.180033 [info ] [Thread-1 (]: 5 of 6 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.54s]
[0m15:22:08.181002 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:22:08.182002 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:22:08.182002 [info ] [Thread-1 (]: 6 of 6 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:22:08.182983 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:22:08.184378 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:22:08.186913 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.187900 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:22:08.184378 => 15:22:08.187900
[0m15:22:08.187900 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:22:08.192907 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.194912 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.195914 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:22:08.196907 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:08.439292 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:08.440581 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.441581 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:22:08.596628 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:22:08.600242 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.600242 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:22:08.634927 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:08.637859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.638856 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:22:08.674079 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:08.676866 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:22:08.677831 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.677831 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:22:08.713699 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:08.717214 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:22:08.718214 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.718214 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:22:08.765820 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:08.767827 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:22:08.188940 => 15:22:08.766829
[0m15:22:08.767827 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:22:08.768826 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A37138D10>]}
[0m15:22:08.769826 [info ] [Thread-1 (]: 6 of 6 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.59s]
[0m15:22:08.770830 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:22:08.772828 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:08.772828 [debug] [MainThread]: On master: BEGIN
[0m15:22:08.773860 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:22:09.006169 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:09.007197 [debug] [MainThread]: On master: COMMIT
[0m15:22:09.007197 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:09.008212 [debug] [MainThread]: On master: COMMIT
[0m15:22:09.043509 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:09.044514 [debug] [MainThread]: On master: Close
[0m15:22:09.045499 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:22:09.046519 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:22:09.046519 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:22:09.047531 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:22:09.048532 [info ] [MainThread]: 
[0m15:22:09.049499 [info ] [MainThread]: Finished running 1 incremental model, 3 view models, 2 table models in 0 hours 0 minutes and 5.28 seconds (5.28s).
[0m15:22:09.050498 [debug] [MainThread]: Command end result
[0m15:22:09.061557 [info ] [MainThread]: 
[0m15:22:09.062536 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:22:09.065374 [info ] [MainThread]: 
[0m15:22:09.066938 [error] [MainThread]:   Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  relation "refsrc_reviews" does not exist
  LINE 17:         refsrc_reviews
                   ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\fact\fact_reviews.sql
[0m15:22:09.067916 [info ] [MainThread]: 
[0m15:22:09.068917 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m15:22:09.073521 [debug] [MainThread]: Command `dbt run` failed at 15:22:09.072922 after 6.57 seconds
[0m15:22:09.073521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A3527C350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A2E361010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A35280DD0>]}
[0m15:22:09.074530 [debug] [MainThread]: Flushing usage events
[0m15:22:44.293343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B309510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869AAE21D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028697E78790>]}


============================== 15:22:44.297375 | c48c021b-df7e-40b5-9ad6-21b248c53992 ==============================
[0m15:22:44.297375 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:22:44.299341 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:22:44.544211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B312050>]}
[0m15:22:44.634165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869AE70790>]}
[0m15:22:44.636166 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:22:44.646596 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:22:44.766078 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:22:44.767078 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\fact\fact_reviews.sql
[0m15:22:44.959582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B5FBC90>]}
[0m15:22:44.975629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B7FE810>]}
[0m15:22:44.976629 [info ] [MainThread]: Found 6 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:22:44.977630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B7BD410>]}
[0m15:22:44.979630 [info ] [MainThread]: 
[0m15:22:44.980629 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:22:44.982629 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:22:44.999355 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:22:45.001857 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:22:45.002854 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:46.359833 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:22:46.360831 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:22:46.362833 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:22:46.369343 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:22:46.369868 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:22:46.369868 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:46.588140 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:22:46.588140 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:22:46.589141 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:22:46.641214 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:22:46.643718 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:22:46.682185 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:22:46.688150 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:46.689150 [debug] [MainThread]: On master: BEGIN
[0m15:22:46.689150 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:22:46.947342 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:46.948309 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:46.948309 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:22:47.015628 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:22:47.018668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869AB04CD0>]}
[0m15:22:47.018668 [debug] [MainThread]: On master: ROLLBACK
[0m15:22:47.053558 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:47.054666 [debug] [MainThread]: On master: BEGIN
[0m15:22:47.123412 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:47.123412 [debug] [MainThread]: On master: COMMIT
[0m15:22:47.124371 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:47.124371 [debug] [MainThread]: On master: COMMIT
[0m15:22:47.155892 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:47.155892 [debug] [MainThread]: On master: Close
[0m15:22:47.156892 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:22:47.158890 [info ] [MainThread]: 
[0m15:22:47.162497 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:22:47.163504 [info ] [Thread-1 (]: 1 of 6 START sql view model test.src_hosts ..................................... [RUN]
[0m15:22:47.164503 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:22:47.165504 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:22:47.172504 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:22:47.176032 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:22:47.166506 => 15:22:47.175034
[0m15:22:47.177031 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:22:47.217898 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:22:47.219896 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.221405 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:22:47.222337 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:22:47.432229 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:47.433296 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.433840 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:22:47.481240 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:47.487283 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.488287 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:22:47.517305 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:47.522816 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.523325 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:22:47.559657 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:47.574680 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:22:47.575681 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.575681 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:22:47.604770 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:47.610462 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:22:47.615430 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.616465 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:22:47.652081 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:47.654081 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:22:47.178032 => 15:22:47.654081
[0m15:22:47.654081 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:22:47.656549 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B4886D0>]}
[0m15:22:47.656549 [info ] [Thread-1 (]: 1 of 6 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.49s]
[0m15:22:47.658510 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:22:47.659544 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:22:47.659544 [info ] [Thread-1 (]: 2 of 6 START sql view model test.src_listings .................................. [RUN]
[0m15:22:47.661514 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:22:47.661514 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:22:47.663543 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:22:47.665510 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:22:47.662546 => 15:22:47.665510
[0m15:22:47.666514 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:22:47.670654 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:22:47.672650 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:47.673621 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:22:47.673621 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:47.881602 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:47.881602 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:47.882584 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:22:47.923292 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:47.926290 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:47.927326 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:22:47.957151 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:47.960151 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:47.961151 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:22:47.997505 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.001471 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:22:48.001471 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:48.001471 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:22:48.036838 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:48.040146 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:22:48.041145 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:48.041145 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:22:48.074829 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:48.076977 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:22:47.666514 => 15:22:48.076977
[0m15:22:48.077974 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:22:48.078975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869ADE7E10>]}
[0m15:22:48.079940 [info ] [Thread-1 (]: 2 of 6 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.42s]
[0m15:22:48.080940 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:22:48.081939 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:22:48.082940 [info ] [Thread-1 (]: 3 of 6 START sql view model test.src_reviews ................................... [RUN]
[0m15:22:48.083940 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:22:48.084940 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:22:48.086940 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:22:48.088450 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:22:48.084940 => 15:22:48.088450
[0m15:22:48.088450 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:22:48.093450 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:22:48.095456 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.096452 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:22:48.097454 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:48.307356 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:48.307356 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.308392 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:22:48.347753 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:48.351295 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.352349 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:22:48.383804 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.387788 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.388792 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:22:48.416827 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.418827 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:22:48.419828 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.420828 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:22:48.457593 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:48.461557 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:22:48.462556 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.463589 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:22:48.502245 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:48.504212 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:22:48.089450 => 15:22:48.504212
[0m15:22:48.505245 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:22:48.506245 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869C90FA50>]}
[0m15:22:48.506245 [info ] [Thread-1 (]: 3 of 6 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.42s]
[0m15:22:48.507750 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:22:48.507750 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:22:48.508757 [info ] [Thread-1 (]: 4 of 6 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:22:48.510758 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:22:48.511758 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:22:48.513756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.515757 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:22:48.511758 => 15:22:48.515757
[0m15:22:48.516757 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:22:48.547694 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.548685 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.549685 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:22:48.549685 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:48.744897 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:48.745902 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.746904 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:22:48.838570 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:22:48.842570 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.842570 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:22:48.869474 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.872474 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.873473 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:22:48.906560 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.912562 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:22:48.913561 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.913561 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:22:48.950517 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:48.953598 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:22:48.956598 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.957562 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:22:48.996574 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:48.998574 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:22:48.517756 => 15:22:48.998574
[0m15:22:48.998574 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:22:49.000115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B638110>]}
[0m15:22:49.001346 [info ] [Thread-1 (]: 4 of 6 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.49s]
[0m15:22:49.002354 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:22:49.003389 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:22:49.004352 [info ] [Thread-1 (]: 5 of 6 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:22:49.005352 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:22:49.006352 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:22:49.010354 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.013871 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:22:49.006352 => 15:22:49.012863
[0m15:22:49.014880 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:22:49.021964 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.025501 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.025501 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:22:49.026771 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:49.213771 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:49.214771 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.214771 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:22:49.357735 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:22:49.360769 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.362109 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:22:49.393052 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:49.396052 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.397562 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:22:49.428173 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:49.430163 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:22:49.431162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.432132 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:22:49.460005 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:49.463002 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:22:49.464002 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.464979 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:22:49.499769 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:49.501770 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:22:49.015921 => 15:22:49.501770
[0m15:22:49.502768 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:22:49.503769 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869C7F3F50>]}
[0m15:22:49.505276 [info ] [Thread-1 (]: 5 of 6 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.50s]
[0m15:22:49.506294 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:22:49.507283 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:22:49.508320 [info ] [Thread-1 (]: 6 of 6 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:22:49.509318 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m15:22:49.510289 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:22:49.515288 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:22:49.516289 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:22:49.511287 => 15:22:49.516289
[0m15:22:49.517289 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:22:49.556776 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:22:49.559032 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:22:49.560089 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:22:49.560643 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:49.778132 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:49.779132 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:22:49.779132 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      
  
    

  create  table "inttegra_stage"."test"."fact_reviews"
  
  
    as
  
  (
    WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_text IS NOT NULL
  );
  
  
[0m15:22:49.820955 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "review_text" does not exist
LINE 24:     review_text IS NOT NULL
             ^
HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".

[0m15:22:49.821962 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: ROLLBACK
[0m15:22:49.858035 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:22:49.517289 => 15:22:49.857035
[0m15:22:49.858035 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:22:49.864036 [debug] [Thread-1 (]: Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  column "review_text" does not exist
  LINE 24:     review_text IS NOT NULL
               ^
  HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".
  compiled Code at target\run\dbtlearn\dbtlearn/models\fact\fact_reviews.sql
[0m15:22:49.864036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869C880450>]}
[0m15:22:49.865540 [error] [Thread-1 (]: 6 of 6 ERROR creating sql incremental model test.fact_reviews .................. [[31mERROR[0m in 0.35s]
[0m15:22:49.866051 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:22:49.868056 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:49.868056 [debug] [MainThread]: On master: BEGIN
[0m15:22:49.869054 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:22:50.092243 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:50.092243 [debug] [MainThread]: On master: COMMIT
[0m15:22:50.094266 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:50.094266 [debug] [MainThread]: On master: COMMIT
[0m15:22:50.133569 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:50.134536 [debug] [MainThread]: On master: Close
[0m15:22:50.135535 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:22:50.136536 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:22:50.136536 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:22:50.137535 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m15:22:50.138537 [info ] [MainThread]: 
[0m15:22:50.139539 [info ] [MainThread]: Finished running 3 view models, 2 table models, 1 incremental model in 0 hours 0 minutes and 5.16 seconds (5.16s).
[0m15:22:50.142045 [debug] [MainThread]: Command end result
[0m15:22:50.150589 [info ] [MainThread]: 
[0m15:22:50.151588 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:22:50.152588 [info ] [MainThread]: 
[0m15:22:50.154094 [error] [MainThread]:   Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  column "review_text" does not exist
  LINE 24:     review_text IS NOT NULL
               ^
  HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".
  compiled Code at target\run\dbtlearn\dbtlearn/models\fact\fact_reviews.sql
[0m15:22:50.155337 [info ] [MainThread]: 
[0m15:22:50.157332 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m15:22:50.160333 [debug] [MainThread]: Command `dbt run` failed at 15:22:50.160333 after 5.95 seconds
[0m15:22:50.161337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028693A9E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B4FE110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869AAECE10>]}
[0m15:22:50.162335 [debug] [MainThread]: Flushing usage events
[0m15:23:28.853724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7F795D190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB479CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FACB2510>]}


============================== 15:23:28.858721 | d61215f0-a709-4eda-b232-73cae1fe553d ==============================
[0m15:23:28.858721 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:23:28.859721 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:23:29.116032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB6672D0>]}
[0m15:23:29.198657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FAF780D0>]}
[0m15:23:29.200163 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:23:29.210168 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:23:29.310228 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:23:29.311229 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\fact\fact_reviews.sql
[0m15:23:29.501139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB59E190>]}
[0m15:23:29.514726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB854550>]}
[0m15:23:29.515726 [info ] [MainThread]: Found 6 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:23:29.515726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB944250>]}
[0m15:23:29.517722 [info ] [MainThread]: 
[0m15:23:29.519723 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:23:29.521723 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:23:29.531061 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:23:29.531061 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:23:29.532062 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:23:30.889402 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:23:30.891437 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:23:30.893437 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:23:30.899015 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:23:30.899986 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:23:30.899986 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:23:31.131254 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:23:31.131777 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:23:31.132304 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:23:31.186708 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:23:31.188280 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:23:31.217275 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:23:31.224307 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:31.225306 [debug] [MainThread]: On master: BEGIN
[0m15:23:31.225306 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:23:31.450676 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:23:31.451645 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:31.451645 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:23:31.515846 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:23:31.517850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB9CB810>]}
[0m15:23:31.517850 [debug] [MainThread]: On master: ROLLBACK
[0m15:23:31.554028 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:31.555576 [debug] [MainThread]: On master: BEGIN
[0m15:23:31.629303 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:23:31.629303 [debug] [MainThread]: On master: COMMIT
[0m15:23:31.630302 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:31.631300 [debug] [MainThread]: On master: COMMIT
[0m15:23:31.662860 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:23:31.663862 [debug] [MainThread]: On master: Close
[0m15:23:31.665905 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:23:31.666905 [info ] [MainThread]: 
[0m15:23:31.670905 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:23:31.671905 [info ] [Thread-1 (]: 1 of 6 START sql view model test.src_hosts ..................................... [RUN]
[0m15:23:31.672907 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:23:31.673907 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:23:31.683061 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:23:31.686029 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:23:31.674907 => 15:23:31.685043
[0m15:23:31.686029 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:23:31.721455 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:23:31.722421 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:31.723960 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:23:31.723960 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:23:31.934649 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:31.934649 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:31.935650 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:23:31.986866 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:23:31.994462 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:31.995491 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:23:32.029818 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.033784 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:32.033784 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:23:32.068668 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.084781 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:23:32.085355 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:32.085866 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:23:32.120802 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:32.127805 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:23:32.133578 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:32.133578 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:23:32.169778 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:23:32.171800 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:23:31.687538 => 15:23:32.171800
[0m15:23:32.171800 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:23:32.172765 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB84BCD0>]}
[0m15:23:32.173800 [info ] [Thread-1 (]: 1 of 6 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.50s]
[0m15:23:32.174769 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:23:32.175776 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:23:32.176767 [info ] [Thread-1 (]: 2 of 6 START sql view model test.src_listings .................................. [RUN]
[0m15:23:32.177764 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:23:32.178798 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:23:32.180894 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:23:32.182404 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:23:32.178798 => 15:23:32.181394
[0m15:23:32.182404 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:23:32.186398 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:23:32.188405 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.188405 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:23:32.189401 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:32.364934 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:32.365929 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.366928 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:23:32.411090 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:23:32.415082 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.416083 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:23:32.446055 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.449595 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.449595 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:23:32.477958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.480915 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:23:32.480915 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.481921 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:23:32.520653 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:32.523686 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:23:32.524689 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.524689 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:23:32.553637 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:23:32.555644 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:23:32.183402 => 15:23:32.554644
[0m15:23:32.555644 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:23:32.556643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB741190>]}
[0m15:23:32.557643 [info ] [Thread-1 (]: 2 of 6 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m15:23:32.558643 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:23:32.559643 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:23:32.559643 [info ] [Thread-1 (]: 3 of 6 START sql view model test.src_reviews ................................... [RUN]
[0m15:23:32.561643 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:23:32.561643 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:23:32.563648 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:23:32.565154 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:23:32.562643 => 15:23:32.565154
[0m15:23:32.566188 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:23:32.570555 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:23:32.572517 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.573522 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:23:32.574518 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:32.772686 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:32.772686 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.773721 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:23:32.817527 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:23:32.821858 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.821858 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:23:32.854571 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.858149 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.859148 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:23:32.887327 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.889833 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:23:32.890325 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.891335 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:23:32.917214 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:32.920210 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:23:32.921208 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.922209 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:23:32.954971 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:23:32.955963 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:23:32.566518 => 15:23:32.955963
[0m15:23:32.956999 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:23:32.957963 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FBACBD90>]}
[0m15:23:32.958996 [info ] [Thread-1 (]: 3 of 6 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.40s]
[0m15:23:32.959962 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:23:32.959962 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:23:32.959962 [info ] [Thread-1 (]: 4 of 6 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:23:32.961501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:23:32.962839 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:23:32.965840 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:32.966846 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:23:32.962839 => 15:23:32.966846
[0m15:23:32.967840 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:23:32.988700 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:32.990703 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:32.991701 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:23:32.992702 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:33.204163 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:33.205163 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.206164 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:23:33.329797 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:23:33.333541 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.334590 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:23:33.394145 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:33.398257 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.399257 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:23:33.458931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:33.464929 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:23:33.464929 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.466435 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:23:33.524341 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:33.527349 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:23:33.531357 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.531357 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:23:33.590126 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:23:33.592112 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:23:32.967840 => 15:23:33.592112
[0m15:23:33.593115 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:23:33.594114 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FBAB6E10>]}
[0m15:23:33.595114 [info ] [Thread-1 (]: 4 of 6 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.63s]
[0m15:23:33.596114 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:23:33.596114 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:23:33.597147 [info ] [Thread-1 (]: 5 of 6 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:23:33.598652 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:23:33.598652 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:23:33.601864 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:23:33.603831 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:23:33.599608 => 15:23:33.602865
[0m15:23:33.603831 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:23:33.608834 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:23:33.610870 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:33.610870 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:23:33.611872 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:34.017705 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:34.017705 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.019731 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:23:34.170694 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:23:34.173697 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.175200 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:23:34.224846 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:34.228871 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.228871 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:23:34.293129 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:34.295727 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:23:34.296819 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.296819 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:23:34.362836 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:34.366836 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:23:34.368344 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.369384 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:23:34.432262 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:23:34.434268 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:23:33.604831 => 15:23:34.434268
[0m15:23:34.435268 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:23:34.436270 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FBA2E210>]}
[0m15:23:34.437268 [info ] [Thread-1 (]: 5 of 6 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.84s]
[0m15:23:34.438271 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:23:34.438271 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:23:34.439777 [info ] [Thread-1 (]: 6 of 6 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:23:34.440847 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m15:23:34.440847 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:23:34.444115 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:23:34.446085 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:23:34.442083 => 15:23:34.445082
[0m15:23:34.446085 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:23:34.477007 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:23:34.478430 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:23:34.479430 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:23:34.479430 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:34.845284 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:34.846060 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:23:34.847051 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      
  
    

  create  table "inttegra_stage"."test"."fact_reviews"
  
  
    as
  
  (
    WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL
  );
  
  
[0m15:23:36.894221 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m15:23:36.896217 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:23:36.896217 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:23:36.897217 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:23:36.933330 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:36.934339 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:23:34.447085 => 15:23:36.934339
[0m15:23:36.935363 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:23:36.936364 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB567DD0>]}
[0m15:23:36.936364 [info ] [Thread-1 (]: 6 of 6 OK created sql incremental model test.fact_reviews ...................... [[32mSELECT 410284[0m in 2.49s]
[0m15:23:36.938334 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:23:36.939840 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:36.940880 [debug] [MainThread]: On master: BEGIN
[0m15:23:36.941428 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:23:37.240139 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:23:37.241237 [debug] [MainThread]: On master: COMMIT
[0m15:23:37.241237 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:37.242243 [debug] [MainThread]: On master: COMMIT
[0m15:23:37.276563 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:23:37.276952 [debug] [MainThread]: On master: Close
[0m15:23:37.277959 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:23:37.277959 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:23:37.278957 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:23:37.278957 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m15:23:37.279957 [info ] [MainThread]: 
[0m15:23:37.280959 [info ] [MainThread]: Finished running 3 view models, 2 table models, 1 incremental model in 0 hours 0 minutes and 7.76 seconds (7.76s).
[0m15:23:37.282956 [debug] [MainThread]: Command end result
[0m15:23:37.292459 [info ] [MainThread]: 
[0m15:23:37.293458 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:23:37.295455 [info ] [MainThread]: 
[0m15:23:37.296453 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m15:23:37.297454 [debug] [MainThread]: Command `dbt run` succeeded at 15:23:37.297454 after 8.51 seconds
[0m15:23:37.298268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FAF917D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7F3C8E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7F3D10FD0>]}
[0m15:23:37.298268 [debug] [MainThread]: Flushing usage events
[0m15:30:18.508682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F65B2A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6A88550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6401DD0>]}


============================== 15:30:18.512202 | 307ef2a7-98fa-4cfa-98fe-81c00f3fb010 ==============================
[0m15:30:18.512202 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:30:18.513707 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s fact_reviews', 'send_anonymous_usage_stats': 'True'}
[0m15:30:18.733747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '307ef2a7-98fa-4cfa-98fe-81c00f3fb010', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6C5F990>]}
[0m15:30:18.814554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '307ef2a7-98fa-4cfa-98fe-81c00f3fb010', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F62A3A10>]}
[0m15:30:18.816584 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:30:18.826494 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:30:18.851624 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:30:18.852628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '307ef2a7-98fa-4cfa-98fe-81c00f3fb010', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6D1A950>]}
[0m15:30:19.668509 [error] [MainThread]: Encountered an error:
Compilation Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  Encountered unknown tag 'IF'.
    line 19
      {% IF is_incremental() %}
[0m15:30:19.670516 [debug] [MainThread]: Command `dbt run` failed at 15:30:19.670516 after 1.24 seconds
[0m15:30:19.671515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266EF2D1050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6596190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6596850>]}
[0m15:30:19.672515 [debug] [MainThread]: Flushing usage events
[0m15:30:44.993206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3324D210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC31E25790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC336F2190>]}


============================== 15:30:44.997206 | 8d56c09d-2d45-43a6-9bf6-9965d93c0e93 ==============================
[0m15:30:44.997206 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:30:44.997582 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s fact_reviews', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:30:45.204579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33037190>]}
[0m15:30:45.283508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3370A890>]}
[0m15:30:45.285510 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:30:45.294223 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:30:45.302694 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:30:45.303697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33BD6F50>]}
[0m15:30:46.164573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33D012D0>]}
[0m15:30:46.176692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33CEE250>]}
[0m15:30:46.177690 [info ] [MainThread]: Found 6 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:30:46.178231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33AAD450>]}
[0m15:30:46.179736 [info ] [MainThread]: 
[0m15:30:46.180712 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:30:46.182260 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:30:46.191765 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:30:46.192774 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:30:46.192774 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:30:47.554841 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:30:47.556835 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:30:47.559799 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:30:47.566422 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:30:47.567422 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:30:47.567422 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:30:47.804184 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:30:47.805233 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:30:47.806212 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:30:47.857772 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m15:30:47.859804 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:30:47.893433 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:30:47.899509 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:47.900509 [debug] [MainThread]: On master: BEGIN
[0m15:30:47.900509 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:30:48.104712 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:48.105713 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:48.106710 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:30:48.171105 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:30:48.173172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33D18C90>]}
[0m15:30:48.173686 [debug] [MainThread]: On master: ROLLBACK
[0m15:30:48.203687 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:48.204209 [debug] [MainThread]: On master: BEGIN
[0m15:30:48.262380 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:48.263368 [debug] [MainThread]: On master: COMMIT
[0m15:30:48.263368 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:48.264368 [debug] [MainThread]: On master: COMMIT
[0m15:30:48.293955 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:30:48.294888 [debug] [MainThread]: On master: Close
[0m15:30:48.295970 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:30:48.295970 [info ] [MainThread]: 
[0m15:30:48.299976 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:30:48.299976 [info ] [Thread-1 (]: 1 of 1 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:30:48.301976 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.fact_reviews'
[0m15:30:48.301976 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:30:48.315035 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:30:48.317037 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:30:48.302978 => 15:30:48.317037
[0m15:30:48.318544 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:30:48.370114 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:48.370114 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp153048346075"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m15:30:48.371114 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:30:49.639591 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m15:30:49.646072 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.647111 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:30:49.678944 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:30:49.679968 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.680950 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp153048346075'
        
      order by ordinal_position

  
[0m15:30:49.740975 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:30:49.745968 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.746969 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:30:49.786370 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:30:49.797984 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.799191 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp153048346075'
        
      order by ordinal_position

  
[0m15:30:49.844730 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:30:49.847834 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.848835 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:30:49.885596 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:30:49.893175 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m15:30:49.903587 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:30:49.906109 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.906109 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp153048346075"
    )


  
[0m15:30:49.936644 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m15:30:49.949676 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:30:49.950683 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.950683 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:30:49.979488 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:30:49.980488 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:30:48.318544 => 15:30:49.980488
[0m15:30:49.981488 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:30:49.982489 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33CAA510>]}
[0m15:30:49.982489 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.68s]
[0m15:30:49.983488 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:30:49.985488 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:49.986488 [debug] [MainThread]: On master: BEGIN
[0m15:30:49.986488 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:30:50.180123 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:50.180123 [debug] [MainThread]: On master: COMMIT
[0m15:30:50.181486 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:50.181486 [debug] [MainThread]: On master: COMMIT
[0m15:30:50.208395 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:30:50.209226 [debug] [MainThread]: On master: Close
[0m15:30:50.210217 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:30:50.211205 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:30:50.211205 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:30:50.212228 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m15:30:50.212228 [info ] [MainThread]: 
[0m15:30:50.213159 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.03 seconds (4.03s).
[0m15:30:50.214170 [debug] [MainThread]: Command end result
[0m15:30:50.224209 [info ] [MainThread]: 
[0m15:30:50.225206 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:30:50.226203 [info ] [MainThread]: 
[0m15:30:50.227204 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:30:50.229719 [debug] [MainThread]: Command `dbt run` succeeded at 15:30:50.229719 after 5.30 seconds
[0m15:30:50.230766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC2C061050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33003010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC2C34FE10>]}
[0m15:30:50.232826 [debug] [MainThread]: Flushing usage events
[0m16:18:09.840172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66446290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF6696BE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66668E10>]}


============================== 16:18:09.845350 | f9e8f67e-8a4f-490c-8171-3c2b2e1ba354 ==============================
[0m16:18:09.845350 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:18:09.846352 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:18:10.089596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66972050>]}
[0m16:18:10.171719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF6696BED0>]}
[0m16:18:10.173716 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:18:10.182808 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:18:10.299130 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:18:10.299635 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:18:10.478855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66B2A890>]}
[0m16:18:10.492021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66ED2350>]}
[0m16:18:10.492021 [info ] [MainThread]: Found 7 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m16:18:10.494030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66BFD990>]}
[0m16:18:10.495061 [info ] [MainThread]: 
[0m16:18:10.496237 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:18:10.500278 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:18:10.509754 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:18:10.509754 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:18:10.510757 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:18:11.856316 [debug] [ThreadPool]: SQL status: SELECT 9 in 1.0 seconds
[0m16:18:11.857831 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:18:11.860371 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:18:11.867902 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:18:11.868902 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:18:11.868902 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:18:12.053042 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:18:12.053815 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:18:12.054822 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:18:12.100671 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m16:18:12.103038 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:18:12.132119 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:18:12.138382 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:12.139385 [debug] [MainThread]: On master: BEGIN
[0m16:18:12.139385 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:18:12.326837 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:18:12.326837 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:12.327839 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:18:12.389337 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:18:12.391395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66BE4DD0>]}
[0m16:18:12.392385 [debug] [MainThread]: On master: ROLLBACK
[0m16:18:12.422738 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:12.423737 [debug] [MainThread]: On master: BEGIN
[0m16:18:12.485149 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:18:12.486379 [debug] [MainThread]: On master: COMMIT
[0m16:18:12.487379 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:12.488379 [debug] [MainThread]: On master: COMMIT
[0m16:18:12.512848 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:18:12.513845 [debug] [MainThread]: On master: Close
[0m16:18:12.514847 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:18:12.515846 [info ] [MainThread]: 
[0m16:18:12.519846 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:18:12.519846 [info ] [Thread-1 (]: 1 of 7 START sql view model test.src_hosts ..................................... [RUN]
[0m16:18:12.521352 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:18:12.522439 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:18:12.529445 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:18:12.532489 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:18:12.522439 => 16:18:12.531450
[0m16:18:12.533447 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:18:12.577225 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m16:18:12.579225 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.580226 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m16:18:12.580226 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:18:12.794526 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:12.795564 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.795564 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m16:18:12.846835 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:18:12.853087 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.854123 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m16:18:12.890905 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:12.894400 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.895405 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m16:18:12.928415 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:12.944183 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:18:12.944183 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.945150 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:18:12.980749 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:12.986750 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m16:18:12.992289 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.993283 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m16:18:13.030291 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:18:13.032321 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:18:12.534576 => 16:18:13.031322
[0m16:18:13.032321 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m16:18:13.033287 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66E3CAD0>]}
[0m16:18:13.034288 [info ] [Thread-1 (]: 1 of 7 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.51s]
[0m16:18:13.035290 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:18:13.036287 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:18:13.036287 [info ] [Thread-1 (]: 2 of 7 START sql view model test.src_listings .................................. [RUN]
[0m16:18:13.037828 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:18:13.037828 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:18:13.041079 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:18:13.043077 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:18:13.039109 => 16:18:13.042075
[0m16:18:13.043077 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:18:13.047076 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m16:18:13.049077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.050585 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m16:18:13.051137 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:13.267586 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:13.268607 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.268607 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m16:18:13.317665 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:18:13.320668 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.321699 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m16:18:13.357961 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:13.360805 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.362310 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m16:18:13.397682 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:13.400194 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:18:13.401195 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.401195 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:18:13.436840 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:13.440023 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m16:18:13.441106 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.441660 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m16:18:13.479830 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:18:13.481410 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:18:13.043077 => 16:18:13.481410
[0m16:18:13.481930 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m16:18:13.483003 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66B2AA10>]}
[0m16:18:13.484081 [info ] [Thread-1 (]: 2 of 7 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.45s]
[0m16:18:13.485210 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:18:13.485952 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:18:13.487109 [info ] [Thread-1 (]: 3 of 7 START sql view model test.src_reviews ................................... [RUN]
[0m16:18:13.488156 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:18:13.488677 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:18:13.490747 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:18:13.491788 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:18:13.489197 => 16:18:13.491788
[0m16:18:13.492825 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:18:13.497661 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m16:18:13.499788 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.500863 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m16:18:13.501385 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:13.708221 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:13.708221 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.709220 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m16:18:13.755381 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:18:13.760897 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.761902 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m16:18:13.797842 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:13.801882 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.801882 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m16:18:13.838102 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:13.840894 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:18:13.840894 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.841894 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:18:13.876686 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:13.880371 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m16:18:13.881378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.882378 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m16:18:13.918991 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:18:13.920978 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:18:13.492825 => 16:18:13.919943
[0m16:18:13.920978 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m16:18:13.921941 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66C8BCD0>]}
[0m16:18:13.922978 [info ] [Thread-1 (]: 3 of 7 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.43s]
[0m16:18:13.923943 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:18:13.924943 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:18:13.924943 [info ] [Thread-1 (]: 4 of 7 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m16:18:13.925940 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m16:18:13.927445 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:18:13.930968 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:13.932967 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:18:13.927967 => 16:18:13.932967
[0m16:18:13.932967 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:18:13.959901 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:13.961900 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:13.963418 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m16:18:13.964823 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:14.194620 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:14.195642 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.195642 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m16:18:14.297883 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m16:18:14.301450 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.302418 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m16:18:14.337281 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:14.341280 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.341280 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m16:18:14.380383 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:14.385881 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:18:14.386881 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.387879 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:18:14.424499 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:14.428509 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m16:18:14.433108 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.434154 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m16:18:14.480125 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:18:14.484665 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:18:13.933970 => 16:18:14.484665
[0m16:18:14.485664 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m16:18:14.487667 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66F97150>]}
[0m16:18:14.487667 [info ] [Thread-1 (]: 4 of 7 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.56s]
[0m16:18:14.489666 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:18:14.490664 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:18:14.490664 [info ] [Thread-1 (]: 5 of 7 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m16:18:14.493227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:18:14.493699 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:18:14.498700 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.500701 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:18:14.494699 => 16:18:14.499701
[0m16:18:14.500701 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:18:14.508745 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.510735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.511735 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m16:18:14.512739 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:14.699328 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:14.700329 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.700329 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m16:18:14.846169 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:18:14.849162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.850195 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m16:18:14.880506 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:14.884549 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.885546 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m16:18:14.915259 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:14.918259 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:18:14.918259 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.919259 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:18:14.948553 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:14.952211 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m16:18:14.953211 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.953211 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m16:18:14.992245 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:18:14.994239 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:18:14.501700 => 16:18:14.994239
[0m16:18:14.995231 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m16:18:14.996231 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66FC9ED0>]}
[0m16:18:14.997231 [info ] [Thread-1 (]: 5 of 7 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.50s]
[0m16:18:14.998741 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:18:14.998741 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:18:14.999740 [info ] [Thread-1 (]: 6 of 7 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:18:15.000743 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:18:15.001741 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:18:15.009281 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:18:15.010320 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:18:15.001741 => 16:18:15.010320
[0m16:18:15.011287 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:18:15.045126 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:15.046427 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp161815034263"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:18:15.047430 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:16.175422 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:18:16.182819 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.182819 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:18:16.214084 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:16.215088 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.215088 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp161815034263'
        
      order by ordinal_position

  
[0m16:18:16.270836 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:18:16.277368 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.278363 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:18:16.316413 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:18:16.331200 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.333480 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp161815034263'
        
      order by ordinal_position

  
[0m16:18:16.369347 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:18:16.372386 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.373354 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:18:16.410608 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:18:16.419317 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m16:18:16.429522 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:18:16.431813 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.431813 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp161815034263"
    )


  
[0m16:18:16.464196 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m16:18:16.465775 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:18:16.466773 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.466773 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:18:16.496136 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:16.498128 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:18:15.012295 => 16:18:16.497128
[0m16:18:16.498128 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:18:16.499633 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66CE4A10>]}
[0m16:18:16.500104 [info ] [Thread-1 (]: 6 of 7 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.50s]
[0m16:18:16.501648 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:18:16.501648 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:18:16.502647 [info ] [Thread-1 (]: 7 of 7 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m16:18:16.503647 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:18:16.504646 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:18:16.507645 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:18:16.511154 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:18:16.504646 => 16:18:16.509647
[0m16:18:16.511672 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:18:16.517677 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:18:16.520682 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:18:16.521699 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m16:18:16.523213 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:16.823559 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:16.824809 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:18:16.824809 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.listing_id,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.update_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m16:18:16.864508 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column h.host_id does not exist
LINE 39:     h ON l.host_Id = h.host_id
                              ^
HINT:  Perhaps you meant to reference the column "l.host_id".

[0m16:18:16.864508 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: ROLLBACK
[0m16:18:16.892349 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:18:16.512682 => 16:18:16.892349
[0m16:18:16.893337 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m16:18:16.899362 [debug] [Thread-1 (]: Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column h.host_id does not exist
  LINE 39:     h ON l.host_Id = h.host_id
                                ^
  HINT:  Perhaps you meant to reference the column "l.host_id".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:18:16.900356 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66FE9E10>]}
[0m16:18:16.901361 [error] [Thread-1 (]: 7 of 7 ERROR creating sql table model test.dim_listings_with_hosts ............. [[31mERROR[0m in 0.40s]
[0m16:18:16.902361 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:18:16.904361 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:16.905364 [debug] [MainThread]: On master: BEGIN
[0m16:18:16.906357 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:18:17.550586 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m16:18:17.551324 [debug] [MainThread]: On master: COMMIT
[0m16:18:17.551324 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:17.552331 [debug] [MainThread]: On master: COMMIT
[0m16:18:17.578247 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:18:17.579247 [debug] [MainThread]: On master: Close
[0m16:18:17.583822 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:18:17.584865 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:18:17.584865 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:18:17.585833 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_with_hosts' was properly closed.
[0m16:18:17.586830 [info ] [MainThread]: 
[0m16:18:17.587853 [info ] [MainThread]: Finished running 3 view models, 3 table models, 1 incremental model in 0 hours 0 minutes and 7.09 seconds (7.09s).
[0m16:18:17.591843 [debug] [MainThread]: Command end result
[0m16:18:17.606353 [info ] [MainThread]: 
[0m16:18:17.607360 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:18:17.608360 [info ] [MainThread]: 
[0m16:18:17.611344 [error] [MainThread]:   Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column h.host_id does not exist
  LINE 39:     h ON l.host_Id = h.host_id
                                ^
  HINT:  Perhaps you meant to reference the column "l.host_id".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:18:17.612362 [info ] [MainThread]: 
[0m16:18:17.613347 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m16:18:17.618589 [debug] [MainThread]: Command `dbt run` failed at 16:18:17.615344 after 7.85 seconds
[0m16:18:17.620880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF5F171010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF6653E5D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF661EB1D0>]}
[0m16:18:17.622879 [debug] [MainThread]: Flushing usage events
[0m16:21:32.962303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248172FD5D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024816F90D50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817568E90>]}


============================== 16:21:32.966808 | bd32c307-b870-4a43-9767-c4ebd90d551a ==============================
[0m16:21:32.966808 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:21:32.967329 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:21:33.173806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817661D10>]}
[0m16:21:33.253701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248176A3210>]}
[0m16:21:33.255240 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:21:33.264238 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:21:33.365681 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m16:21:33.366649 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m16:21:33.366649 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m16:21:33.532518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002481790D0D0>]}
[0m16:21:33.545206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817A53C90>]}
[0m16:21:33.546211 [info ] [MainThread]: Found 7 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m16:21:33.546867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817815C90>]}
[0m16:21:33.548872 [info ] [MainThread]: 
[0m16:21:33.549875 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:21:33.552727 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:21:33.563242 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:21:33.564237 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:21:33.565237 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:21:34.893582 [debug] [ThreadPool]: SQL status: SELECT 11 in 1.0 seconds
[0m16:21:34.895354 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:21:34.897505 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:21:34.903036 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:21:34.903036 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:21:34.904037 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:21:35.104609 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:21:35.106157 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:21:35.106686 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:21:35.156606 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m16:21:35.158612 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:21:35.188974 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:21:35.195322 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:35.196305 [debug] [MainThread]: On master: BEGIN
[0m16:21:35.196305 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:21:35.385826 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:21:35.386826 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:35.387826 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:21:35.447417 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:21:35.450377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817984A50>]}
[0m16:21:35.451381 [debug] [MainThread]: On master: ROLLBACK
[0m16:21:35.480865 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:35.481860 [debug] [MainThread]: On master: BEGIN
[0m16:21:35.539750 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:21:35.539750 [debug] [MainThread]: On master: COMMIT
[0m16:21:35.541024 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:35.542026 [debug] [MainThread]: On master: COMMIT
[0m16:21:35.567575 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:21:35.568583 [debug] [MainThread]: On master: Close
[0m16:21:35.569583 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:21:35.570583 [info ] [MainThread]: 
[0m16:21:35.575648 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:21:35.576653 [info ] [Thread-1 (]: 1 of 7 START sql view model test.src_hosts ..................................... [RUN]
[0m16:21:35.577656 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:21:35.578653 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:21:35.585667 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:21:35.589176 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:21:35.578653 => 16:21:35.589176
[0m16:21:35.590172 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:21:35.631246 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m16:21:35.633211 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.633211 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m16:21:35.634717 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:21:35.828409 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:35.828409 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.829454 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m16:21:35.872965 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:21:35.879919 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.879919 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m16:21:35.920238 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:35.923277 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.924390 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m16:21:35.954514 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:35.969572 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:21:35.971077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.971593 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:21:36.003953 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:36.010985 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m16:21:36.016986 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:36.016986 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m16:21:36.048780 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:21:36.050784 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:21:35.591172 => 16:21:36.050784
[0m16:21:36.051785 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m16:21:36.052782 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817A590D0>]}
[0m16:21:36.052782 [info ] [Thread-1 (]: 1 of 7 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.48s]
[0m16:21:36.053781 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:21:36.055286 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:21:36.055849 [info ] [Thread-1 (]: 2 of 7 START sql view model test.src_listings .................................. [RUN]
[0m16:21:36.056858 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:21:36.057856 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:21:36.059855 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:21:36.060855 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:21:36.057856 => 16:21:36.060855
[0m16:21:36.061854 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:21:36.065854 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m16:21:36.067360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.067360 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m16:21:36.068867 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:36.279750 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:36.280536 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.281535 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m16:21:36.328378 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:21:36.331958 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.333012 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m16:21:36.363016 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:36.366022 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.367022 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m16:21:36.398849 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:36.401891 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:21:36.402432 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.402432 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:21:36.435768 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:36.438778 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m16:21:36.440278 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.440278 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m16:21:36.480787 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:21:36.482790 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:21:36.061854 => 16:21:36.482790
[0m16:21:36.482790 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m16:21:36.484787 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248178DD050>]}
[0m16:21:36.484787 [info ] [Thread-1 (]: 2 of 7 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.43s]
[0m16:21:36.486788 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:21:36.486788 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:21:36.488293 [info ] [Thread-1 (]: 3 of 7 START sql view model test.src_reviews ................................... [RUN]
[0m16:21:36.489827 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:21:36.490368 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:21:36.492997 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:21:36.495175 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:21:36.490883 => 16:21:36.494620
[0m16:21:36.495715 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:21:36.504524 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m16:21:36.507037 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.508832 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m16:21:36.509946 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:36.731968 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:36.732903 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.733859 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m16:21:36.784136 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:21:36.787145 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.788649 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m16:21:36.823497 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:36.827122 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.827122 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m16:21:36.863716 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:36.865722 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:21:36.866720 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.866720 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:21:36.900499 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:36.904068 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m16:21:36.905036 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.906065 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m16:21:36.943038 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:21:36.945037 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:21:36.496241 => 16:21:36.944038
[0m16:21:36.945559 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m16:21:36.946564 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024818B10CD0>]}
[0m16:21:36.947565 [info ] [Thread-1 (]: 3 of 7 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.46s]
[0m16:21:36.948565 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:21:36.949570 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:21:36.950565 [info ] [Thread-1 (]: 4 of 7 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m16:21:36.951580 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m16:21:36.952569 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:21:36.955568 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:36.958080 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:21:36.952569 => 16:21:36.957631
[0m16:21:36.959089 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:21:36.986192 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:36.989194 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:36.990194 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m16:21:36.991193 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:37.202936 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:37.203948 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.203948 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m16:21:37.305130 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m16:21:37.308817 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.308817 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m16:21:37.342969 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:37.346233 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.347234 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m16:21:37.384525 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:37.390649 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:21:37.390649 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.391655 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:21:37.427793 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:37.430793 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m16:21:37.434793 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.434793 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m16:21:37.478514 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:21:37.480640 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:21:36.960078 => 16:21:37.480640
[0m16:21:37.481607 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m16:21:37.482641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817594A10>]}
[0m16:21:37.482641 [info ] [Thread-1 (]: 4 of 7 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.53s]
[0m16:21:37.484606 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:21:37.485607 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:21:37.486197 [info ] [Thread-1 (]: 5 of 7 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m16:21:37.487212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:21:37.488204 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:21:37.490237 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.492228 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:21:37.488204 => 16:21:37.492228
[0m16:21:37.493203 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:21:37.498221 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.500229 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.501229 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m16:21:37.502231 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:37.734905 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:37.735914 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.736915 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m16:21:37.890988 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:21:37.895503 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.896503 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m16:21:37.930328 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:37.933637 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.934638 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m16:21:37.967556 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:37.970333 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:21:37.971333 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.971333 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:21:38.012021 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:38.015717 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m16:21:38.016064 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:38.017064 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m16:21:38.062732 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:21:38.064519 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:21:37.493203 => 16:21:38.064519
[0m16:21:38.065559 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m16:21:38.066525 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817827ED0>]}
[0m16:21:38.066525 [info ] [Thread-1 (]: 5 of 7 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.58s]
[0m16:21:38.068526 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:21:38.068526 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:21:38.069525 [info ] [Thread-1 (]: 6 of 7 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:21:38.070536 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:21:38.071576 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:21:38.078927 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:21:38.080930 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:21:38.071576 => 16:21:38.080930
[0m16:21:38.081933 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:21:38.111021 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:38.111021 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp162138104008"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:21:38.112024 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:39.343631 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:21:39.350131 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.351131 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:21:39.386486 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:39.387496 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.388494 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162138104008'
        
      order by ordinal_position

  
[0m16:21:39.449994 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:21:39.454825 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.456851 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:21:39.498558 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:21:39.510580 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.510580 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162138104008'
        
      order by ordinal_position

  
[0m16:21:39.551232 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:21:39.554992 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.554992 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:21:39.599582 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:21:39.607123 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m16:21:39.619144 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:21:39.620146 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.621144 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp162138104008"
    )


  
[0m16:21:39.655483 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m16:21:39.657281 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:21:39.658279 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.659243 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:21:39.694310 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:39.695346 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:21:38.081933 => 16:21:39.695346
[0m16:21:39.695346 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:21:39.696852 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002481778FFD0>]}
[0m16:21:39.697404 [info ] [Thread-1 (]: 6 of 7 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.63s]
[0m16:21:39.698406 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:21:39.699440 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:21:39.699440 [info ] [Thread-1 (]: 7 of 7 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m16:21:39.701410 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:21:39.701410 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:21:39.704404 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:21:39.706405 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:21:39.702442 => 16:21:39.705404
[0m16:21:39.706405 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:21:39.712090 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:21:39.714001 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:21:39.714001 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m16:21:39.715041 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:39.995887 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:39.997133 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:21:39.997133 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.listing_id,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.update_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m16:21:40.036467 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column l.listing_id does not exist
LINE 26:     l.listing_id,
             ^

[0m16:21:40.037564 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: ROLLBACK
[0m16:21:40.064205 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:21:39.707440 => 16:21:40.064205
[0m16:21:40.065253 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m16:21:40.069720 [debug] [Thread-1 (]: Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column l.listing_id does not exist
  LINE 26:     l.listing_id,
               ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:21:40.070785 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024818BC6650>]}
[0m16:21:40.071791 [error] [Thread-1 (]: 7 of 7 ERROR creating sql table model test.dim_listings_with_hosts ............. [[31mERROR[0m in 0.37s]
[0m16:21:40.072800 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:21:40.074790 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:40.075791 [debug] [MainThread]: On master: BEGIN
[0m16:21:40.075791 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:21:40.263099 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:21:40.264107 [debug] [MainThread]: On master: COMMIT
[0m16:21:40.264107 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:40.265139 [debug] [MainThread]: On master: COMMIT
[0m16:21:40.290986 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:21:40.292002 [debug] [MainThread]: On master: Close
[0m16:21:40.292987 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:21:40.292987 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:21:40.293987 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:21:40.294986 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_with_hosts' was properly closed.
[0m16:21:40.294986 [info ] [MainThread]: 
[0m16:21:40.295768 [info ] [MainThread]: Finished running 3 view models, 3 table models, 1 incremental model in 0 hours 0 minutes and 6.75 seconds (6.75s).
[0m16:21:40.298285 [debug] [MainThread]: Command end result
[0m16:21:40.306817 [info ] [MainThread]: 
[0m16:21:40.307803 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:21:40.309835 [info ] [MainThread]: 
[0m16:21:40.309835 [error] [MainThread]:   Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column l.listing_id does not exist
  LINE 26:     l.listing_id,
               ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:21:40.311980 [info ] [MainThread]: 
[0m16:21:40.313989 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m16:21:40.315970 [debug] [MainThread]: Command `dbt run` failed at 16:21:40.315970 after 7.42 seconds
[0m16:21:40.316968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002480FD81010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817078250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002480FFF4390>]}
[0m16:21:40.317969 [debug] [MainThread]: Flushing usage events
[0m16:22:13.753435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36E74E610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EF1B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EB193D0>]}


============================== 16:22:13.756902 | 5ea715e1-86bc-42f2-8fad-32f5294e6459 ==============================
[0m16:22:13.756902 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:22:13.759159 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:22:13.968277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EF722D0>]}
[0m16:22:14.047341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36F03F550>]}
[0m16:22:14.049340 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:22:14.058849 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:22:14.158709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:22:14.159709 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:22:14.322350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36F16A450>]}
[0m16:22:14.335293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3702E4F10>]}
[0m16:22:14.336292 [info ] [MainThread]: Found 7 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m16:22:14.337105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36F169090>]}
[0m16:22:14.339110 [info ] [MainThread]: 
[0m16:22:14.340115 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:22:14.343115 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:22:14.353624 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:22:14.353624 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:22:14.354627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:22:15.926496 [debug] [ThreadPool]: SQL status: SELECT 13 in 2.0 seconds
[0m16:22:15.927528 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:22:15.930527 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:22:15.936002 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:22:15.936002 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:22:15.937005 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:22:16.200912 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:22:16.201922 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:22:16.201922 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:22:16.251725 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m16:22:16.253765 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:22:16.289575 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:22:16.296444 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:16.297410 [debug] [MainThread]: On master: BEGIN
[0m16:22:16.297410 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:22:16.514241 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:16.515002 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:16.516016 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:22:16.578636 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:22:16.581338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370356DD0>]}
[0m16:22:16.582346 [debug] [MainThread]: On master: ROLLBACK
[0m16:22:16.616179 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:16.617237 [debug] [MainThread]: On master: BEGIN
[0m16:22:16.683069 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:16.683871 [debug] [MainThread]: On master: COMMIT
[0m16:22:16.684833 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:16.684833 [debug] [MainThread]: On master: COMMIT
[0m16:22:16.715552 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:22:16.716526 [debug] [MainThread]: On master: Close
[0m16:22:16.717518 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:22:16.718518 [info ] [MainThread]: 
[0m16:22:16.722518 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:22:16.722518 [info ] [Thread-1 (]: 1 of 7 START sql view model test.src_hosts ..................................... [RUN]
[0m16:22:16.724521 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:22:16.725535 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:22:16.732070 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:22:16.734043 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:22:16.726034 => 16:22:16.733048
[0m16:22:16.735040 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:22:16.772567 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m16:22:16.774765 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:16.775767 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m16:22:16.775767 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:22:16.997008 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:16.998001 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:16.998001 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m16:22:17.045881 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:17.051980 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:17.052980 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m16:22:17.087537 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.091515 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:17.091515 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m16:22:17.129031 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.143236 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:22:17.144238 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:17.145205 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:22:17.181417 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:17.188840 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m16:22:17.193860 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:17.194865 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m16:22:17.231716 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:17.233473 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:22:16.735040 => 16:22:17.233473
[0m16:22:17.234506 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m16:22:17.235474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EA63F10>]}
[0m16:22:17.236506 [info ] [Thread-1 (]: 1 of 7 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.51s]
[0m16:22:17.238472 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:22:17.238472 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:22:17.239475 [info ] [Thread-1 (]: 2 of 7 START sql view model test.src_listings .................................. [RUN]
[0m16:22:17.240475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:22:17.241474 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:22:17.243690 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:22:17.244691 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:22:17.241474 => 16:22:17.244691
[0m16:22:17.245691 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:22:17.250696 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m16:22:17.253768 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.254781 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m16:22:17.255775 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:17.457992 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:17.458999 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.458999 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m16:22:17.503315 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:17.507313 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.508317 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m16:22:17.537966 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.541968 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.542944 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m16:22:17.572690 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.574723 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:22:17.575726 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.575726 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:22:17.605083 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:17.607114 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m16:22:17.608116 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.609114 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m16:22:17.639751 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:17.641758 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:22:17.245691 => 16:22:17.640759
[0m16:22:17.641758 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m16:22:17.642757 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370469810>]}
[0m16:22:17.643757 [info ] [Thread-1 (]: 2 of 7 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.40s]
[0m16:22:17.644758 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:22:17.645757 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:22:17.645757 [info ] [Thread-1 (]: 3 of 7 START sql view model test.src_reviews ................................... [RUN]
[0m16:22:17.646757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:22:17.647791 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:22:17.649791 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:22:17.651023 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:22:17.647791 => 16:22:17.651023
[0m16:22:17.652052 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:22:17.659033 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m16:22:17.662023 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.662023 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m16:22:17.662984 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:17.855385 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:17.856282 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.857278 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m16:22:17.901212 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:17.904232 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.905233 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m16:22:17.931848 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.934955 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.935984 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m16:22:17.965294 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.967329 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:22:17.968327 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.969328 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:22:17.997474 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:18.000672 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m16:22:18.001230 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:18.002238 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m16:22:18.032629 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:18.034823 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:22:17.652052 => 16:22:18.034306
[0m16:22:18.035359 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m16:22:18.036501 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370510C50>]}
[0m16:22:18.037506 [info ] [Thread-1 (]: 3 of 7 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.39s]
[0m16:22:18.038508 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:22:18.038508 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:22:18.039508 [info ] [Thread-1 (]: 4 of 7 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m16:22:18.041509 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m16:22:18.041509 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:22:18.044507 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.045506 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:22:18.042509 => 16:22:18.045506
[0m16:22:18.046506 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:22:18.072526 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.073520 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.074520 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m16:22:18.075520 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:18.278413 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:18.279215 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.280171 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m16:22:18.370186 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m16:22:18.373735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.373735 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m16:22:18.404435 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:18.408466 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.408466 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m16:22:18.438584 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:18.444596 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:22:18.445596 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.445596 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:22:18.477477 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:18.480892 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m16:22:18.484893 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.485895 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m16:22:18.525801 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:18.527849 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:22:18.047535 => 16:22:18.527849
[0m16:22:18.527849 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m16:22:18.529353 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370480450>]}
[0m16:22:18.530359 [info ] [Thread-1 (]: 4 of 7 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.49s]
[0m16:22:18.531364 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:22:18.532360 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:22:18.533360 [info ] [Thread-1 (]: 5 of 7 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m16:22:18.534361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:22:18.534361 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:22:18.537393 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.539360 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:22:18.535359 => 16:22:18.538360
[0m16:22:18.539865 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:22:18.544904 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.545905 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.546908 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m16:22:18.547876 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:18.731335 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:18.731850 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.732857 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m16:22:18.874963 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:22:18.880162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.880162 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m16:22:18.909555 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:18.913169 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.914137 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m16:22:18.942180 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:18.945232 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:22:18.946195 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.946195 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:22:18.977197 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:18.981190 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m16:22:18.982190 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.982190 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m16:22:19.024161 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:19.026919 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:22:18.540872 => 16:22:19.025918
[0m16:22:19.026919 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m16:22:19.028918 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370469810>]}
[0m16:22:19.029918 [info ] [Thread-1 (]: 5 of 7 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.49s]
[0m16:22:19.030416 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:22:19.031425 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:22:19.032323 [info ] [Thread-1 (]: 6 of 7 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:22:19.032879 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:22:19.033890 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:22:19.043885 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:22:19.045394 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:22:19.034889 => 16:22:19.044875
[0m16:22:19.046397 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:22:19.077451 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:19.078450 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp162219069409"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:22:19.078450 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:20.406400 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:22:20.412399 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.413902 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:22:20.448641 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:20.448641 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.450148 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162219069409'
        
      order by ordinal_position

  
[0m16:22:20.510358 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:20.516479 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.517446 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:22:20.558314 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:20.571581 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.572086 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162219069409'
        
      order by ordinal_position

  
[0m16:22:20.614908 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:20.618654 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.619158 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:22:20.660327 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:20.669237 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m16:22:20.679745 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:22:20.681716 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.682716 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp162219069409"
    )


  
[0m16:22:20.719115 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m16:22:20.722121 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:22:20.723129 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.724116 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:22:20.756414 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:20.758422 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:22:19.046397 => 16:22:20.757421
[0m16:22:20.758422 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:22:20.759423 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3704BBC90>]}
[0m16:22:20.760422 [info ] [Thread-1 (]: 6 of 7 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.73s]
[0m16:22:20.762455 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:22:20.762455 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:22:20.763664 [info ] [Thread-1 (]: 7 of 7 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m16:22:20.764633 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:22:20.765635 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:22:20.768635 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:20.770634 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:22:20.765635 => 16:22:20.770634
[0m16:22:20.771632 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:22:20.786914 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:20.789045 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:20.790044 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m16:22:20.791044 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:21.142571 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:21.143587 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:21.143587 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.update_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m16:22:21.188582 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column h.update_at does not exist
LINE 35:     GREATEST(l.updated_at, h.update_at) AS update_at
                                    ^
HINT:  Perhaps you meant to reference the column "h.updated_at".

[0m16:22:21.189580 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: ROLLBACK
[0m16:22:21.227445 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:22:20.772630 => 16:22:21.227445
[0m16:22:21.228446 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m16:22:21.233939 [debug] [Thread-1 (]: Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column h.update_at does not exist
  LINE 35:     GREATEST(l.updated_at, h.update_at) AS update_at
                                      ^
  HINT:  Perhaps you meant to reference the column "h.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:22:21.234944 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36E751450>]}
[0m16:22:21.235949 [error] [Thread-1 (]: 7 of 7 ERROR creating sql table model test.dim_listings_with_hosts ............. [[31mERROR[0m in 0.47s]
[0m16:22:21.236604 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:22:21.238609 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:21.239611 [debug] [MainThread]: On master: BEGIN
[0m16:22:21.239611 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:22:21.469981 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:21.469981 [debug] [MainThread]: On master: COMMIT
[0m16:22:21.471494 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:21.471494 [debug] [MainThread]: On master: COMMIT
[0m16:22:21.502377 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:22:21.503255 [debug] [MainThread]: On master: Close
[0m16:22:21.504252 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:22:21.505251 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:22:21.505251 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:22:21.506251 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_with_hosts' was properly closed.
[0m16:22:21.506251 [info ] [MainThread]: 
[0m16:22:21.507756 [info ] [MainThread]: Finished running 3 view models, 3 table models, 1 incremental model in 0 hours 0 minutes and 7.17 seconds (7.17s).
[0m16:22:21.509293 [debug] [MainThread]: Command end result
[0m16:22:21.518294 [info ] [MainThread]: 
[0m16:22:21.520845 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:22:21.520845 [info ] [MainThread]: 
[0m16:22:21.521852 [error] [MainThread]:   Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column h.update_at does not exist
  LINE 35:     GREATEST(l.updated_at, h.update_at) AS update_at
                                      ^
  HINT:  Perhaps you meant to reference the column "h.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:22:21.523855 [info ] [MainThread]: 
[0m16:22:21.524853 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m16:22:21.528854 [debug] [MainThread]: Command `dbt run` failed at 16:22:21.528854 after 7.84 seconds
[0m16:22:21.529859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D367791010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36E9F7B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EF421D0>]}
[0m16:22:21.530851 [debug] [MainThread]: Flushing usage events
[0m16:22:37.811425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022974DF6810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229755EB710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022974E41D10>]}


============================== 16:22:37.815430 | 405b6fbc-fafe-4943-b918-348baa505995 ==============================
[0m16:22:37.815430 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:22:37.816431 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:22:38.026534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297573F910>]}
[0m16:22:38.134232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022974E41D50>]}
[0m16:22:38.135546 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:22:38.144780 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:22:38.240608 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:22:38.240608 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:22:38.404014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297595BE50>]}
[0m16:22:38.417077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976B72290>]}
[0m16:22:38.418445 [info ] [MainThread]: Found 7 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m16:22:38.419446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229756141D0>]}
[0m16:22:38.421480 [info ] [MainThread]: 
[0m16:22:38.422453 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:22:38.424444 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:22:38.436501 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:22:38.437501 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:22:38.438501 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:22:39.802972 [debug] [ThreadPool]: SQL status: SELECT 15 in 1.0 seconds
[0m16:22:39.804983 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:22:39.807985 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:22:39.813020 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:22:39.814019 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:22:39.815019 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:22:40.030913 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:22:40.031870 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:22:40.031870 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:22:40.084026 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m16:22:40.086063 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:22:40.121280 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:22:40.128368 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:40.128368 [debug] [MainThread]: On master: BEGIN
[0m16:22:40.129368 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:22:40.356740 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:40.357788 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:40.357788 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:22:40.422798 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:22:40.425836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022975617150>]}
[0m16:22:40.426837 [debug] [MainThread]: On master: ROLLBACK
[0m16:22:40.459162 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:40.460667 [debug] [MainThread]: On master: BEGIN
[0m16:22:40.529937 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:40.529937 [debug] [MainThread]: On master: COMMIT
[0m16:22:40.530939 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:40.530939 [debug] [MainThread]: On master: COMMIT
[0m16:22:40.563992 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:22:40.565022 [debug] [MainThread]: On master: Close
[0m16:22:40.566011 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:22:40.566011 [info ] [MainThread]: 
[0m16:22:40.569746 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:22:40.570785 [info ] [Thread-1 (]: 1 of 7 START sql view model test.src_hosts ..................................... [RUN]
[0m16:22:40.571751 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:22:40.572752 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:22:40.578757 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:22:40.582091 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:22:40.572752 => 16:22:40.581262
[0m16:22:40.583271 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:22:40.620198 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m16:22:40.621200 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.622202 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m16:22:40.622202 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:22:40.805199 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:40.806493 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.806493 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m16:22:40.850182 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:40.856179 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.857179 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m16:22:40.886440 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:40.889435 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.890436 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m16:22:40.921359 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:40.936417 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:22:40.937378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.937378 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:22:40.968207 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:40.974198 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m16:22:40.979432 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.979432 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m16:22:41.013032 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:41.014774 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:22:40.583271 => 16:22:41.014774
[0m16:22:41.015775 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m16:22:41.016810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022975B13E10>]}
[0m16:22:41.016810 [info ] [Thread-1 (]: 1 of 7 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.44s]
[0m16:22:41.018776 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:22:41.018776 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:22:41.020091 [info ] [Thread-1 (]: 2 of 7 START sql view model test.src_listings .................................. [RUN]
[0m16:22:41.020723 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:22:41.022046 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:22:41.024046 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:22:41.025549 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:22:41.022046 => 16:22:41.025037
[0m16:22:41.026141 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:22:41.029712 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m16:22:41.031703 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.032680 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m16:22:41.033679 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:41.213407 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:41.214420 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.214420 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m16:22:41.261992 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:41.265482 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.266733 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m16:22:41.296770 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:41.299803 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.300785 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m16:22:41.331180 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:41.333186 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:22:41.334186 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.334186 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:22:41.361761 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:41.365313 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m16:22:41.366285 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.367314 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m16:22:41.398804 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:41.400302 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:22:41.026677 => 16:22:41.400302
[0m16:22:41.401301 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m16:22:41.402303 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976B71590>]}
[0m16:22:41.403303 [info ] [Thread-1 (]: 2 of 7 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m16:22:41.404305 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:22:41.405302 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:22:41.406303 [info ] [Thread-1 (]: 3 of 7 START sql view model test.src_reviews ................................... [RUN]
[0m16:22:41.407322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:22:41.408302 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:22:41.410323 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:22:41.412329 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:22:41.408302 => 16:22:41.411328
[0m16:22:41.412329 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:22:41.419329 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m16:22:41.420328 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.422371 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m16:22:41.422371 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:41.606630 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:41.607679 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.607679 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m16:22:41.654514 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:41.658554 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.658554 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m16:22:41.690217 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:41.693211 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.693211 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m16:22:41.724133 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:41.725703 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:22:41.726703 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.727670 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:22:41.758045 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:41.761431 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m16:22:41.762414 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.763431 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m16:22:41.794506 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:41.796663 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:22:41.413328 => 16:22:41.795656
[0m16:22:41.796663 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m16:22:41.797662 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976BEC110>]}
[0m16:22:41.798695 [info ] [Thread-1 (]: 3 of 7 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.39s]
[0m16:22:41.799661 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:22:41.800695 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:22:41.801661 [info ] [Thread-1 (]: 4 of 7 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m16:22:41.802661 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m16:22:41.803660 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:22:41.806661 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:41.808173 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:22:41.803660 => 16:22:41.807165
[0m16:22:41.808173 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:22:41.834205 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:41.836172 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:41.837173 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m16:22:41.837173 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:42.010847 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:42.012324 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.013323 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m16:22:42.104089 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m16:22:42.107128 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.108191 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m16:22:42.135434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:42.138230 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.139230 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m16:22:42.170630 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:42.176639 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:22:42.176639 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.177639 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:22:42.207609 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:42.210609 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m16:22:42.213638 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.213638 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m16:22:42.253860 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:42.255892 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:22:41.809171 => 16:22:42.255892
[0m16:22:42.255892 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m16:22:42.256892 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229758FBE10>]}
[0m16:22:42.257892 [info ] [Thread-1 (]: 4 of 7 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.45s]
[0m16:22:42.258857 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:22:42.259892 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:22:42.260858 [info ] [Thread-1 (]: 5 of 7 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m16:22:42.261858 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:22:42.261858 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:22:42.264915 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.266916 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:22:42.262859 => 16:22:42.266916
[0m16:22:42.266916 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:22:42.273925 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.276397 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.277398 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m16:22:42.278395 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:42.492750 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:42.493272 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.494281 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m16:22:42.637675 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:22:42.642675 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.643676 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m16:22:42.677566 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:42.681573 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.682567 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m16:22:42.711006 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:42.713006 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:22:42.714011 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.715006 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:22:42.751002 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:42.754011 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m16:22:42.755011 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.756010 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m16:22:42.794251 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:42.796294 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:22:42.267917 => 16:22:42.796294
[0m16:22:42.796294 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m16:22:42.797294 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229756F61D0>]}
[0m16:22:42.798298 [info ] [Thread-1 (]: 5 of 7 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.54s]
[0m16:22:42.799181 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:22:42.800220 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:22:42.801009 [info ] [Thread-1 (]: 6 of 7 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:22:42.802015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:22:42.802015 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:22:42.810524 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:22:42.812527 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:22:42.803014 => 16:22:42.811527
[0m16:22:42.812527 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:22:42.844479 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:42.844479 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp162242837506"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:22:42.845446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:44.061735 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:22:44.069391 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.069946 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:22:44.099892 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:44.100895 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.102404 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162242837506'
        
      order by ordinal_position

  
[0m16:22:44.159038 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:44.164090 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.164090 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:22:44.201752 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:44.213309 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.214309 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162242837506'
        
      order by ordinal_position

  
[0m16:22:44.251541 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:44.254573 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.255576 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:22:44.292535 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:44.301200 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m16:22:44.310413 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:22:44.312412 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.312412 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp162242837506"
    )


  
[0m16:22:44.341012 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m16:22:44.343591 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:22:44.344603 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.344603 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:22:44.374810 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:44.375850 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:22:42.813528 => 16:22:44.375850
[0m16:22:44.376808 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:22:44.376808 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297575EA90>]}
[0m16:22:44.378348 [info ] [Thread-1 (]: 6 of 7 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.58s]
[0m16:22:44.379495 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:22:44.380504 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:22:44.381501 [info ] [Thread-1 (]: 7 of 7 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m16:22:44.382504 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:22:44.383521 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:22:44.386499 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.388381 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:22:44.383521 => 16:22:44.388381
[0m16:22:44.389387 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:22:44.394860 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.396843 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.397833 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m16:22:44.398826 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:44.698113 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:44.699125 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.700122 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m16:22:44.849034 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:22:44.854031 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.855032 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m16:22:44.885445 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:44.887412 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m16:22:44.888413 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.889415 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m16:22:44.927139 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:44.931136 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m16:22:44.932681 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.932681 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m16:22:44.963193 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:44.965205 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:22:44.389387 => 16:22:44.965205
[0m16:22:44.965205 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m16:22:44.966205 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022975897550>]}
[0m16:22:44.967204 [info ] [Thread-1 (]: 7 of 7 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 0.58s]
[0m16:22:44.968228 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:22:44.969715 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:44.969715 [debug] [MainThread]: On master: BEGIN
[0m16:22:44.970714 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:22:45.160543 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:45.160543 [debug] [MainThread]: On master: COMMIT
[0m16:22:45.161578 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:45.162578 [debug] [MainThread]: On master: COMMIT
[0m16:22:45.190143 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:22:45.190874 [debug] [MainThread]: On master: Close
[0m16:22:45.191888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:22:45.191888 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:22:45.192914 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:22:45.192914 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_with_hosts' was properly closed.
[0m16:22:45.193883 [info ] [MainThread]: 
[0m16:22:45.193883 [info ] [MainThread]: Finished running 3 view models, 3 table models, 1 incremental model in 0 hours 0 minutes and 6.77 seconds (6.77s).
[0m16:22:45.196466 [debug] [MainThread]: Command end result
[0m16:22:45.205473 [info ] [MainThread]: 
[0m16:22:45.206473 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:22:45.207978 [info ] [MainThread]: 
[0m16:22:45.208639 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m16:22:45.210735 [debug] [MainThread]: Command `dbt run` succeeded at 16:22:45.210735 after 7.47 seconds
[0m16:22:45.211731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002296DEAE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002296E22F210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002296E22FD50>]}
[0m16:22:45.211731 [debug] [MainThread]: Flushing usage events
[0m13:38:11.012902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C95C50D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9553D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C441E5D0>]}


============================== 13:38:11.016536 | cefb3a39-d4ae-4877-b62c-5886c8976392 ==============================
[0m13:38:11.016536 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:38:11.016536 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt seed', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:38:11.329397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9ACDBD0>]}
[0m13:38:11.413894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9C8B7D0>]}
[0m13:38:11.416438 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:38:11.434148 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:38:12.423301 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m13:38:12.423301 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/seeds\seed_full_moon_dates.csv
[0m13:38:12.578424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9CC3CD0>]}
[0m13:38:12.609940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9E3E910>]}
[0m13:38:12.609940 [info ] [MainThread]: Found 7 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:38:12.609940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9D17F10>]}
[0m13:38:12.614804 [info ] [MainThread]: 
[0m13:38:12.614804 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:38:12.614804 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:38:12.627090 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:38:12.627965 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:38:12.627965 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:38:13.925539 [debug] [ThreadPool]: SQL status: SELECT 15 in 1.0 seconds
[0m13:38:13.925539 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:38:13.938445 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:38:13.945802 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:38:13.946809 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:38:13.946809 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:38:14.172813 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:38:14.173339 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:38:14.173866 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:38:14.225511 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m13:38:14.230022 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:38:14.262783 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:38:14.262783 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:14.262783 [debug] [MainThread]: On master: BEGIN
[0m13:38:14.272830 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:38:14.465995 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:38:14.465995 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:14.465995 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:38:14.538312 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:38:14.538312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9E68C90>]}
[0m13:38:14.538312 [debug] [MainThread]: On master: ROLLBACK
[0m13:38:14.574883 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:14.574883 [debug] [MainThread]: On master: BEGIN
[0m13:38:14.633706 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:38:14.633706 [debug] [MainThread]: On master: COMMIT
[0m13:38:14.633706 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:14.633706 [debug] [MainThread]: On master: COMMIT
[0m13:38:14.683126 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:38:14.683126 [debug] [MainThread]: On master: Close
[0m13:38:14.683126 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:38:14.683126 [info ] [MainThread]: 
[0m13:38:14.683126 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m13:38:14.683126 [info ] [Thread-1 (]: 1 of 1 START seed file test.seed_full_moon_dates ............................... [RUN]
[0m13:38:14.691862 [debug] [Thread-1 (]: Acquiring new postgres connection 'seed.dbtlearn.seed_full_moon_dates'
[0m13:38:14.692638 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m13:38:14.693789 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 13:38:14.693789 => 13:38:14.693789
[0m13:38:14.694316 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m13:38:14.728568 [debug] [Thread-1 (]: Using postgres connection "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:14.729535 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: BEGIN
[0m13:38:14.729535 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:38:14.957977 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:38:14.957977 [debug] [Thread-1 (]: Using postgres connection "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:14.957977 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "seed.dbtlearn.seed_full_moon_dates"} */

    create table "inttegra_stage"."test"."seed_full_moon_dates" ("full_moon_date" date)
  
[0m13:38:15.018728 [debug] [Thread-1 (]: SQL status: CREATE TABLE in 0.0 seconds
[0m13:38:15.103059 [debug] [Thread-1 (]: Using postgres connection "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:15.103059 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: 
          insert into "inttegra_stage"."test"."seed_full_moon_dates" ("full_moon_date") values
          (%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(...
[0m13:38:15.141625 [debug] [Thread-1 (]: SQL status: INSERT 0 272 in 0.0 seconds
[0m13:38:15.151271 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:15.169379 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: COMMIT
[0m13:38:15.171384 [debug] [Thread-1 (]: Using postgres connection "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:15.171384 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: COMMIT
[0m13:38:15.198679 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:38:15.204878 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 13:38:14.694316 => 13:38:15.204878
[0m13:38:15.206889 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: Close
[0m13:38:15.206889 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9FE1450>]}
[0m13:38:15.206889 [info ] [Thread-1 (]: 1 of 1 OK loaded seed file test.seed_full_moon_dates ........................... [[32mINSERT 272[0m in 0.52s]
[0m13:38:15.208895 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m13:38:15.211339 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:15.211339 [debug] [MainThread]: On master: BEGIN
[0m13:38:15.211339 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:38:15.438787 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:38:15.438787 [debug] [MainThread]: On master: COMMIT
[0m13:38:15.438787 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:15.438787 [debug] [MainThread]: On master: COMMIT
[0m13:38:15.477285 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:38:15.477285 [debug] [MainThread]: On master: Close
[0m13:38:15.477285 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:38:15.477285 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:38:15.477285 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:38:15.477285 [debug] [MainThread]: Connection 'seed.dbtlearn.seed_full_moon_dates' was properly closed.
[0m13:38:15.477285 [info ] [MainThread]: 
[0m13:38:15.477285 [info ] [MainThread]: Finished running 1 seed in 0 hours 0 minutes and 2.86 seconds (2.86s).
[0m13:38:15.477285 [debug] [MainThread]: Command end result
[0m13:38:15.494347 [info ] [MainThread]: 
[0m13:38:15.495347 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:38:15.496373 [info ] [MainThread]: 
[0m13:38:15.497350 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:38:15.498891 [debug] [MainThread]: Command `dbt seed` succeeded at 13:38:15.498891 after 4.56 seconds
[0m13:38:15.499926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9AAD710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C2614390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C23A1010>]}
[0m13:38:15.499926 [debug] [MainThread]: Flushing usage events
[0m13:48:37.547093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8301DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF85B8490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF70F5390>]}


============================== 13:48:37.554103 | f61436b8-d8fb-4286-a4be-9c8ca865c998 ==============================
[0m13:48:37.554103 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:48:37.556098 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m13:48:37.929484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF83013D0>]}
[0m13:48:38.073134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8AF9390>]}
[0m13:48:38.077185 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:48:38.093226 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:48:38.224916 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m13:48:38.224916 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:48:38.397634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8FC0A90>]}
[0m13:48:38.411082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8E6E9D0>]}
[0m13:48:38.412223 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:48:38.412698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8666F90>]}
[0m13:48:38.414728 [info ] [MainThread]: 
[0m13:48:38.415389 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:48:38.418499 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:48:38.427519 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:48:38.428521 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:48:38.429520 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:48:39.716541 [debug] [ThreadPool]: SQL status: SELECT 15 in 1.0 seconds
[0m13:48:39.717541 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:48:39.722106 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:48:39.737835 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:48:39.740831 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:48:39.741827 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:48:39.956725 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:48:39.957728 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:48:39.958725 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:48:40.007362 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:48:40.009362 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:48:40.040844 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:48:40.057460 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:40.058897 [debug] [MainThread]: On master: BEGIN
[0m13:48:40.060908 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:48:40.284538 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:48:40.286591 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:40.286591 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:48:40.351251 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:48:40.353288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8BDBF90>]}
[0m13:48:40.354282 [debug] [MainThread]: On master: ROLLBACK
[0m13:48:40.389137 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:40.389137 [debug] [MainThread]: On master: BEGIN
[0m13:48:40.454181 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:48:40.455292 [debug] [MainThread]: On master: COMMIT
[0m13:48:40.455292 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:40.456302 [debug] [MainThread]: On master: COMMIT
[0m13:48:40.484648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:48:40.484648 [debug] [MainThread]: On master: Close
[0m13:48:40.486655 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:48:40.486655 [info ] [MainThread]: 
[0m13:48:40.491685 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m13:48:40.491685 [info ] [Thread-1 (]: 1 of 8 START sql view model test.src_hosts ..................................... [RUN]
[0m13:48:40.493685 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m13:48:40.493685 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m13:48:40.500690 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m13:48:40.504737 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 13:48:40.494684 => 13:48:40.503499
[0m13:48:40.506763 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m13:48:40.550565 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m13:48:40.554581 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.555580 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m13:48:40.556581 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:48:40.752443 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:40.753441 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.754440 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m13:48:40.803944 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:48:40.811053 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.812020 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m13:48:40.846997 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:40.851365 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.852402 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m13:48:40.886875 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:40.904164 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m13:48:40.905162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.905162 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m13:48:40.936385 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:40.945351 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m13:48:40.951077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.951077 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m13:48:40.989277 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:48:40.992452 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 13:48:40.507736 => 13:48:40.991452
[0m13:48:40.992452 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m13:48:40.993454 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8C67AD0>]}
[0m13:48:40.994960 [info ] [Thread-1 (]: 1 of 8 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.50s]
[0m13:48:40.994960 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m13:48:40.996201 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m13:48:40.998202 [info ] [Thread-1 (]: 2 of 8 START sql view model test.src_listings .................................. [RUN]
[0m13:48:41.000202 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m13:48:41.001204 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m13:48:41.003200 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m13:48:41.007203 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 13:48:41.001204 => 13:48:41.006203
[0m13:48:41.007203 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m13:48:41.014661 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m13:48:41.017662 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.019170 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m13:48:41.020363 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:41.229625 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:41.231129 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.232139 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m13:48:41.279057 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:48:41.282030 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.283568 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m13:48:41.317791 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:41.320821 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.321820 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m13:48:41.357420 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:41.359428 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m13:48:41.360460 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.360460 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m13:48:41.392854 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:41.395896 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m13:48:41.396893 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.397892 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m13:48:41.437095 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:48:41.438106 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 13:48:41.008661 => 13:48:41.438106
[0m13:48:41.439612 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m13:48:41.440127 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CFA01FDD0>]}
[0m13:48:41.441132 [info ] [Thread-1 (]: 2 of 8 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.44s]
[0m13:48:41.441874 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m13:48:41.442880 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m13:48:41.443880 [info ] [Thread-1 (]: 3 of 8 START sql view model test.src_reviews ................................... [RUN]
[0m13:48:41.444879 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m13:48:41.444879 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m13:48:41.446878 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m13:48:41.447879 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 13:48:41.444879 => 13:48:41.447879
[0m13:48:41.448879 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m13:48:41.454323 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m13:48:41.456324 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.457324 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m13:48:41.458326 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:41.670397 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:41.671442 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.671442 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m13:48:41.714536 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:48:41.718576 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.718576 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m13:48:41.755431 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:41.758464 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.758464 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m13:48:41.791872 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:41.793869 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m13:48:41.794870 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.794870 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m13:48:41.827942 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:41.830948 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m13:48:41.832458 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.832458 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m13:48:41.870389 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:48:41.872826 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 13:48:41.448879 => 13:48:41.872826
[0m13:48:41.872826 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m13:48:41.873829 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8CCE710>]}
[0m13:48:41.874865 [info ] [Thread-1 (]: 3 of 8 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.43s]
[0m13:48:41.876862 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m13:48:41.876862 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m13:48:41.877829 [info ] [Thread-1 (]: 4 of 8 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m13:48:41.878875 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m13:48:41.879863 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m13:48:41.881861 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:41.882862 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 13:48:41.879863 => 13:48:41.882862
[0m13:48:41.884371 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m13:48:41.908428 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:41.910811 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:41.910811 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m13:48:41.911809 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:42.098843 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:42.099640 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.100631 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m13:48:42.196757 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m13:48:42.201156 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.202153 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m13:48:42.235874 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:42.238865 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.239864 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m13:48:42.272234 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:42.278096 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m13:48:42.279106 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.279106 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m13:48:42.312318 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:42.315319 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m13:48:42.321046 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.322046 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m13:48:42.365901 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:48:42.369074 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 13:48:41.885387 => 13:48:42.368496
[0m13:48:42.370081 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m13:48:42.371591 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8604150>]}
[0m13:48:42.371591 [info ] [Thread-1 (]: 4 of 8 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.49s]
[0m13:48:42.373601 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m13:48:42.374598 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m13:48:42.375104 [info ] [Thread-1 (]: 5 of 8 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m13:48:42.376111 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m13:48:42.377109 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m13:48:42.380196 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.381753 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 13:48:42.377613 => 13:48:42.381236
[0m13:48:42.382760 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m13:48:42.390283 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.393135 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.394245 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m13:48:42.396116 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:42.596261 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:42.597282 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.597282 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m13:48:42.751768 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m13:48:42.755773 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.756774 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m13:48:42.788226 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:42.792234 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.793250 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m13:48:42.823690 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:42.826695 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m13:48:42.826695 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.827695 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m13:48:42.859767 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:42.862775 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m13:48:42.863777 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.865787 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m13:48:42.905864 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:48:42.907406 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 13:48:42.382760 => 13:48:42.907406
[0m13:48:42.908417 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m13:48:42.909406 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8E9BC90>]}
[0m13:48:42.909406 [info ] [Thread-1 (]: 5 of 8 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.53s]
[0m13:48:42.911410 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m13:48:42.911410 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m13:48:42.912407 [info ] [Thread-1 (]: 6 of 8 START sql incremental model test.fact_reviews ........................... [RUN]
[0m13:48:42.913409 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m13:48:42.914448 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m13:48:42.922192 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m13:48:42.925056 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 13:48:42.914448 => 13:48:42.924047
[0m13:48:42.925056 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m13:48:42.959887 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:42.960887 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp134842951734"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m13:48:42.961890 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:44.174736 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m13:48:44.181598 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.181598 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m13:48:44.212089 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:44.213104 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.213104 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp134842951734'
        
      order by ordinal_position

  
[0m13:48:44.279103 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m13:48:44.284230 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.285231 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m13:48:44.326434 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m13:48:44.338098 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.338098 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp134842951734'
        
      order by ordinal_position

  
[0m13:48:44.376898 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m13:48:44.380690 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.380690 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m13:48:44.421664 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m13:48:44.428663 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m13:48:44.443400 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m13:48:44.445893 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.445893 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp134842951734"
    )


  
[0m13:48:44.478791 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m13:48:44.481358 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m13:48:44.482671 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.483673 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m13:48:44.514908 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:44.516415 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 13:48:42.926089 => 13:48:44.514908
[0m13:48:44.517482 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m13:48:44.518947 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8EADA50>]}
[0m13:48:44.519948 [info ] [Thread-1 (]: 6 of 8 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.61s]
[0m13:48:44.521949 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m13:48:44.522949 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m13:48:44.524949 [info ] [Thread-1 (]: 7 of 8 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m13:48:44.526957 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m13:48:44.529000 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m13:48:44.535009 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:44.541111 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 13:48:44.530013 => 13:48:44.539011
[0m13:48:44.541789 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m13:48:44.554214 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:44.556461 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:44.557507 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m13:48:44.558582 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:44.848414 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:44.848414 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:44.849525 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m13:48:45.003639 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m13:48:45.007639 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:45.007639 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts" rename to "dim_listings_with_hosts__dbt_backup"
[0m13:48:45.040393 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:45.044900 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:45.045916 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m13:48:45.077507 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:45.079503 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m13:48:45.079503 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:45.081008 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m13:48:45.111355 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:45.114395 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m13:48:45.115383 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:45.116395 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m13:48:45.157884 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:48:45.159926 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 13:48:44.542903 => 13:48:45.158934
[0m13:48:45.159926 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m13:48:45.160923 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CFA10F6D0>]}
[0m13:48:45.161924 [info ] [Thread-1 (]: 7 of 8 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 0.63s]
[0m13:48:45.162890 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m13:48:45.163894 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:48:45.163894 [info ] [Thread-1 (]: 8 of 8 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:48:45.165399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m13:48:45.166661 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:48:45.169659 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:48:45.171690 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:48:45.166661 => 13:48:45.171690
[0m13:48:45.172690 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:48:45.177164 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:48:45.179329 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:48:45.180328 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:48:45.181328 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:45.380204 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:45.382323 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:48:45.382323 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon,
FROM
    fact_reviews AS r
LEFT JOIN
    full_moon_dates AS fm ON TO_DATE(r.reviw_date) = DATEADD(DAR, 1, fm.full_moon_date)
  );
  
[0m13:48:45.420887 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "FROM"
LINE 33: FROM
         ^

[0m13:48:45.420887 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:48:45.452440 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:48:45.172690 => 13:48:45.452440
[0m13:48:45.453998 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:48:45.568412 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  syntax error at or near "FROM"
  LINE 33: FROM
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:48:45.569431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8B03190>]}
[0m13:48:45.570411 [error] [Thread-1 (]: 8 of 8 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.40s]
[0m13:48:45.571377 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:48:45.573884 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:45.574456 [debug] [MainThread]: On master: BEGIN
[0m13:48:45.574940 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:48:45.802228 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:48:45.803258 [debug] [MainThread]: On master: COMMIT
[0m13:48:45.803258 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:45.804269 [debug] [MainThread]: On master: COMMIT
[0m13:48:45.835069 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:48:45.835069 [debug] [MainThread]: On master: Close
[0m13:48:45.837074 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:48:45.837074 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:48:45.837074 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:48:45.838597 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:48:45.839080 [info ] [MainThread]: 
[0m13:48:45.839605 [info ] [MainThread]: Finished running 3 view models, 4 table models, 1 incremental model in 0 hours 0 minutes and 7.42 seconds (7.42s).
[0m13:48:45.841637 [debug] [MainThread]: Command end result
[0m13:48:45.851457 [info ] [MainThread]: 
[0m13:48:45.852424 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:48:45.853425 [info ] [MainThread]: 
[0m13:48:45.853425 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  syntax error at or near "FROM"
  LINE 33: FROM
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:48:45.854929 [info ] [MainThread]: 
[0m13:48:45.854929 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
[0m13:48:45.856931 [debug] [MainThread]: Command `dbt run` failed at 13:48:45.856931 after 8.40 seconds
[0m13:48:45.857932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8AE0A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF1351010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF82F7E50>]}
[0m13:48:45.858951 [debug] [MainThread]: Flushing usage events
[0m13:49:57.188683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A243B410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2467C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A23D01D0>]}


============================== 13:49:57.192680 | fdf0bb57-4069-4022-a144-1e588ac45f95 ==============================
[0m13:49:57.192680 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:49:57.193682 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'send_anonymous_usage_stats': 'True'}
[0m13:49:57.400333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2C85D90>]}
[0m13:49:57.476300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2696090>]}
[0m13:49:57.478374 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:49:57.485419 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:49:57.589326 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:49:57.590326 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:49:57.755416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A3076950>]}
[0m13:49:57.768081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2F610D0>]}
[0m13:49:57.768081 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:49:57.769114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2D68550>]}
[0m13:49:57.771084 [info ] [MainThread]: 
[0m13:49:57.771669 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:49:57.773710 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:49:57.783233 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:49:57.783740 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:49:57.783740 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:59.110731 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:49:59.112729 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:49:59.114733 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:49:59.122155 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:49:59.123273 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:49:59.124271 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:59.327204 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:49:59.327806 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:49:59.328817 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:49:59.378613 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:49:59.380638 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:49:59.411908 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:49:59.419952 [debug] [MainThread]: Using postgres connection "master"
[0m13:49:59.420950 [debug] [MainThread]: On master: BEGIN
[0m13:49:59.420950 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:49:59.622104 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:49:59.623164 [debug] [MainThread]: Using postgres connection "master"
[0m13:49:59.624131 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:49:59.688723 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:49:59.690719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A23A3810>]}
[0m13:49:59.691719 [debug] [MainThread]: On master: ROLLBACK
[0m13:49:59.723673 [debug] [MainThread]: Using postgres connection "master"
[0m13:49:59.724681 [debug] [MainThread]: On master: BEGIN
[0m13:49:59.788752 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:49:59.789525 [debug] [MainThread]: On master: COMMIT
[0m13:49:59.790520 [debug] [MainThread]: Using postgres connection "master"
[0m13:49:59.790520 [debug] [MainThread]: On master: COMMIT
[0m13:49:59.818445 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:49:59.818445 [debug] [MainThread]: On master: Close
[0m13:49:59.819919 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:49:59.821893 [info ] [MainThread]: 
[0m13:49:59.825326 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:49:59.826325 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:49:59.827326 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:49:59.828327 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:49:59.835832 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:49:59.837836 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:49:59.828327 => 13:49:59.837836
[0m13:49:59.838848 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:49:59.881950 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:49:59.883982 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:49:59.884946 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:49:59.884946 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:50:00.101436 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:50:00.102203 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:50:00.103199 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon,
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DAR, 1, fm.full_moon_date)
  );
  
[0m13:50:00.142813 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "FROM"
LINE 33: FROM
         ^

[0m13:50:00.144279 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:50:00.173113 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:49:59.839876 => 13:50:00.173113
[0m13:50:00.174160 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:50:00.179110 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  syntax error at or near "FROM"
  LINE 33: FROM
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:50:00.180063 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A3125610>]}
[0m13:50:00.181368 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.35s]
[0m13:50:00.182369 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:50:00.183368 [debug] [MainThread]: Using postgres connection "master"
[0m13:50:00.184367 [debug] [MainThread]: On master: BEGIN
[0m13:50:00.185264 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:50:00.412083 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:50:00.413491 [debug] [MainThread]: On master: COMMIT
[0m13:50:00.414502 [debug] [MainThread]: Using postgres connection "master"
[0m13:50:00.415502 [debug] [MainThread]: On master: COMMIT
[0m13:50:00.441733 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:50:00.441733 [debug] [MainThread]: On master: Close
[0m13:50:00.443276 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:50:00.444468 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:50:00.444468 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:50:00.445510 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:50:00.445510 [info ] [MainThread]: 
[0m13:50:00.446479 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.67 seconds (2.67s).
[0m13:50:00.448480 [debug] [MainThread]: Command end result
[0m13:50:00.456994 [info ] [MainThread]: 
[0m13:50:00.457994 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:50:00.458991 [info ] [MainThread]: 
[0m13:50:00.460011 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  syntax error at or near "FROM"
  LINE 33: FROM
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:50:00.461028 [info ] [MainThread]: 
[0m13:50:00.462025 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:50:00.464006 [debug] [MainThread]: Command `dbt run` failed at 13:50:00.464006 after 3.34 seconds
[0m13:50:00.464991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001739B39E550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A23C2150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A26B1A90>]}
[0m13:50:00.464991 [debug] [MainThread]: Flushing usage events
[0m13:51:05.652968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9C863FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9C82E990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9C842ED0>]}


============================== 13:51:05.652968 | 31bfab3a-0b2a-44d1-bf2a-7c64144b771a ==============================
[0m13:51:05.652968 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:51:05.652968 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:51:05.980059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9C887190>]}
[0m13:51:06.086037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D032190>]}
[0m13:51:06.087612 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:51:06.096807 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:51:06.203066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:51:06.204008 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:06.375224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D2FA1D0>]}
[0m13:51:06.387922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D5D5B50>]}
[0m13:51:06.388922 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:51:06.389921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D249110>]}
[0m13:51:06.391368 [info ] [MainThread]: 
[0m13:51:06.393101 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:51:06.394101 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:51:06.403767 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:51:06.405494 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:51:06.406502 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:07.714269 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:51:07.715274 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:51:07.719297 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:51:07.726865 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:51:07.726865 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:51:07.728873 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:07.931429 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:51:07.931429 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:51:07.931429 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:51:07.990763 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:51:07.991834 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:51:08.023334 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:51:08.031535 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.031535 [debug] [MainThread]: On master: BEGIN
[0m13:51:08.031535 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:51:08.218704 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:08.229436 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.229436 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:51:08.293840 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:51:08.293840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D573750>]}
[0m13:51:08.293840 [debug] [MainThread]: On master: ROLLBACK
[0m13:51:08.327339 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.327339 [debug] [MainThread]: On master: BEGIN
[0m13:51:08.390624 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:08.390624 [debug] [MainThread]: On master: COMMIT
[0m13:51:08.390624 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.390624 [debug] [MainThread]: On master: COMMIT
[0m13:51:08.423475 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:51:08.424160 [debug] [MainThread]: On master: Close
[0m13:51:08.424160 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:51:08.426124 [info ] [MainThread]: 
[0m13:51:08.429529 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:08.430535 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:51:08.432162 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:51:08.433026 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:08.440665 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:08.440665 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:51:08.433026 => 13:51:08.440665
[0m13:51:08.445487 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:08.483281 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:08.483281 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:08.483281 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:51:08.483281 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:51:08.677428 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:51:08.677428 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:08.677428 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DAR, 1, fm.full_moon_date)
  );
  
[0m13:51:08.718887 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column r.reviw_date does not exist
LINE 36:     full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DA...
                                           ^
HINT:  Perhaps you meant to reference the column "r.review_date".

[0m13:51:08.718887 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:51:08.747856 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:51:08.445487 => 13:51:08.747856
[0m13:51:08.755858 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:51:08.760892 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  column r.reviw_date does not exist
  LINE 36:     full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DA...
                                             ^
  HINT:  Perhaps you meant to reference the column "r.review_date".
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:08.760892 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D5ABC90>]}
[0m13:51:08.760892 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.33s]
[0m13:51:08.760892 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:08.760892 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.760892 [debug] [MainThread]: On master: BEGIN
[0m13:51:08.760892 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:51:08.987671 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:08.988814 [debug] [MainThread]: On master: COMMIT
[0m13:51:08.988814 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.988814 [debug] [MainThread]: On master: COMMIT
[0m13:51:09.019580 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:51:09.019580 [debug] [MainThread]: On master: Close
[0m13:51:09.024797 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:51:09.024797 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:51:09.025363 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:51:09.025363 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:51:09.025363 [info ] [MainThread]: 
[0m13:51:09.025363 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.63 seconds (2.63s).
[0m13:51:09.025363 [debug] [MainThread]: Command end result
[0m13:51:09.036041 [info ] [MainThread]: 
[0m13:51:09.036041 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:51:09.039354 [info ] [MainThread]: 
[0m13:51:09.040354 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  column r.reviw_date does not exist
  LINE 36:     full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DA...
                                             ^
  HINT:  Perhaps you meant to reference the column "r.review_date".
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:09.041379 [info ] [MainThread]: 
[0m13:51:09.042379 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:51:09.045642 [debug] [MainThread]: Command `dbt run` failed at 13:51:09.044791 after 3.46 seconds
[0m13:51:09.045642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B95891090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9CB888D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B95B8F210>]}
[0m13:51:09.045642 [debug] [MainThread]: Flushing usage events
[0m13:51:24.979385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF78E97D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF790778D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF75A8CBD0>]}


============================== 13:51:24.984391 | cbf34c46-9914-4813-b27c-75ba589282ec ==============================
[0m13:51:24.984391 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:51:24.984391 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:51:25.213353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF795F2050>]}
[0m13:51:25.288547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF795B3250>]}
[0m13:51:25.288547 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:51:25.297745 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:51:25.404915 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:51:25.404915 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:25.568380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF79AC3A50>]}
[0m13:51:25.586556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF7995E7D0>]}
[0m13:51:25.587978 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:51:25.589037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF79751D50>]}
[0m13:51:25.591244 [info ] [MainThread]: 
[0m13:51:25.592841 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:51:25.594965 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:51:25.610563 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:51:25.612971 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:51:25.614044 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:26.907972 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:51:26.909711 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:51:26.909711 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:51:26.919741 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:51:26.919741 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:51:26.919741 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:27.113098 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:51:27.113098 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:51:27.113098 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:51:27.159724 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:51:27.167177 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:51:27.199736 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:51:27.208398 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.208398 [debug] [MainThread]: On master: BEGIN
[0m13:51:27.208398 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:51:27.423724 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:27.423724 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.423724 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:51:27.484530 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:51:27.492651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF79866950>]}
[0m13:51:27.492651 [debug] [MainThread]: On master: ROLLBACK
[0m13:51:27.524491 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.524491 [debug] [MainThread]: On master: BEGIN
[0m13:51:27.580205 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:27.588199 [debug] [MainThread]: On master: COMMIT
[0m13:51:27.588199 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.588199 [debug] [MainThread]: On master: COMMIT
[0m13:51:27.624344 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:51:27.624344 [debug] [MainThread]: On master: Close
[0m13:51:27.624344 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:51:27.627996 [info ] [MainThread]: 
[0m13:51:27.632154 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:27.632154 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:51:27.635082 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:51:27.635082 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:27.646245 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:27.652281 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:51:27.636089 => 13:51:27.651260
[0m13:51:27.654060 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:27.693983 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:27.693983 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:27.693983 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:51:27.699836 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:51:27.896737 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:51:27.897290 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:27.897854 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON TO_DATE(r.review_date) = DATEADD(DAR, 1, fm.full_moon_date)
  );
  
[0m13:51:27.932158 [debug] [Thread-1 (]: Postgres adapter: Postgres error: function to_date(timestamp without time zone) does not exist
LINE 36:     full_moon_dates fm ON TO_DATE(r.review_date) = DATEADD(D...
                                   ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m13:51:27.932158 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:51:27.966036 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:51:27.656071 => 13:51:27.966036
[0m13:51:27.966036 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:51:27.972666 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  function to_date(timestamp without time zone) does not exist
  LINE 36:     full_moon_dates fm ON TO_DATE(r.review_date) = DATEADD(D...
                                     ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:27.972666 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF7AB1C890>]}
[0m13:51:27.972666 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.34s]
[0m13:51:27.977206 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:27.977706 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.977706 [debug] [MainThread]: On master: BEGIN
[0m13:51:27.977706 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:51:28.181816 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:28.181816 [debug] [MainThread]: On master: COMMIT
[0m13:51:28.181816 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:28.181816 [debug] [MainThread]: On master: COMMIT
[0m13:51:28.222648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:51:28.222648 [debug] [MainThread]: On master: Close
[0m13:51:28.222648 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:51:28.222648 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:51:28.222648 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:51:28.222648 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:51:28.222648 [info ] [MainThread]: 
[0m13:51:28.228976 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.63 seconds (2.63s).
[0m13:51:28.229948 [debug] [MainThread]: Command end result
[0m13:51:28.238531 [info ] [MainThread]: 
[0m13:51:28.239518 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:51:28.240872 [info ] [MainThread]: 
[0m13:51:28.241866 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  function to_date(timestamp without time zone) does not exist
  LINE 36:     full_moon_dates fm ON TO_DATE(r.review_date) = DATEADD(D...
                                     ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:28.241866 [info ] [MainThread]: 
[0m13:51:28.243207 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:51:28.243207 [debug] [MainThread]: Command `dbt run` failed at 13:51:28.243207 after 3.33 seconds
[0m13:51:28.243207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF71DF1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF790E87D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF790EA150>]}
[0m13:51:28.243207 [debug] [MainThread]: Flushing usage events
[0m13:52:09.175118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D435CA6BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D435C148D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D435C153D0>]}


============================== 13:52:09.175118 | dda1fec9-1254-43a9-aeda-efabd3ca6730 ==============================
[0m13:52:09.175118 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:52:09.179417 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:52:09.392151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436162050>]}
[0m13:52:09.464479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436257C10>]}
[0m13:52:09.464479 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:52:09.480784 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:52:09.573920 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:52:09.583913 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:52:09.798303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D43645B810>]}
[0m13:52:09.811653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436658F50>]}
[0m13:52:09.812548 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:52:09.813207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D43615BE90>]}
[0m13:52:09.815070 [info ] [MainThread]: 
[0m13:52:09.816515 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:52:09.817584 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:52:09.827026 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:52:09.827978 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:52:09.827978 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:52:11.110584 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:52:11.113906 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:52:11.113906 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:52:11.122223 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:52:11.124880 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:52:11.124880 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:52:11.331012 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:52:11.332024 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:52:11.333020 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:52:11.377222 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:52:11.377222 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:52:11.410108 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:52:11.410108 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:11.410108 [debug] [MainThread]: On master: BEGIN
[0m13:52:11.410108 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:52:11.614616 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:52:11.614616 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:11.614616 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:52:11.678644 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:52:11.678644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436622290>]}
[0m13:52:11.678644 [debug] [MainThread]: On master: ROLLBACK
[0m13:52:11.711030 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:11.711030 [debug] [MainThread]: On master: BEGIN
[0m13:52:11.783583 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:52:11.783583 [debug] [MainThread]: On master: COMMIT
[0m13:52:11.783583 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:11.785631 [debug] [MainThread]: On master: COMMIT
[0m13:52:11.807768 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:52:11.807768 [debug] [MainThread]: On master: Close
[0m13:52:11.817317 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:52:11.817317 [info ] [MainThread]: 
[0m13:52:11.822050 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:52:11.823097 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:52:11.824668 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:52:11.825806 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:52:11.838162 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:52:11.841184 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:52:11.826344 => 13:52:11.840651
[0m13:52:11.841716 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:52:11.893211 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:52:11.895347 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:52:11.896415 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:52:11.896956 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:52:12.109691 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:52:12.109691 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:52:12.109691 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m13:52:12.143446 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column fm.full_moon_dates does not exist
LINE 30:         WHEN fm.full_moon_dates IS NULL THEN 'not full moon'...
                      ^
HINT:  Perhaps you meant to reference the column "fm.full_moon_date".

[0m13:52:12.155439 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:52:12.179735 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:52:11.842772 => 13:52:12.179735
[0m13:52:12.179735 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:52:12.189440 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  column fm.full_moon_dates does not exist
  LINE 30:         WHEN fm.full_moon_dates IS NULL THEN 'not full moon'...
                        ^
  HINT:  Perhaps you meant to reference the column "fm.full_moon_date".
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:52:12.191960 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436504890>]}
[0m13:52:12.192393 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.37s]
[0m13:52:12.192393 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:52:12.192393 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:12.192393 [debug] [MainThread]: On master: BEGIN
[0m13:52:12.192393 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:52:12.408056 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:52:12.408056 [debug] [MainThread]: On master: COMMIT
[0m13:52:12.408056 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:12.408056 [debug] [MainThread]: On master: COMMIT
[0m13:52:12.434308 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:52:12.434308 [debug] [MainThread]: On master: Close
[0m13:52:12.443726 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:52:12.443726 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:52:12.443726 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:52:12.443726 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:52:12.443726 [info ] [MainThread]: 
[0m13:52:12.443726 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.63 seconds (2.63s).
[0m13:52:12.443726 [debug] [MainThread]: Command end result
[0m13:52:12.457121 [info ] [MainThread]: 
[0m13:52:12.457121 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:52:12.459103 [info ] [MainThread]: 
[0m13:52:12.459896 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  column fm.full_moon_dates does not exist
  LINE 30:         WHEN fm.full_moon_dates IS NULL THEN 'not full moon'...
                        ^
  HINT:  Perhaps you meant to reference the column "fm.full_moon_date".
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:52:12.460983 [info ] [MainThread]: 
[0m13:52:12.461843 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:52:12.463352 [debug] [MainThread]: Command `dbt run` failed at 13:52:12.463352 after 3.35 seconds
[0m13:52:12.463352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D42E9C1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D435C14890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D42EA05BD0>]}
[0m13:52:12.463352 [debug] [MainThread]: Flushing usage events
[0m13:53:21.745326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B504308CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5011D8E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5040C84D0>]}


============================== 13:53:21.753359 | 933be3af-eb59-432d-8559-949fcb373952 ==============================
[0m13:53:21.753359 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:53:21.753359 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:53:21.961781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5047C9B90>]}
[0m13:53:22.035441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5043E2750>]}
[0m13:53:22.042144 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:53:22.042144 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:53:22.174503 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:53:22.175628 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:53:22.355250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B504738850>]}
[0m13:53:22.366127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5049B1090>]}
[0m13:53:22.366127 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:53:22.371314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5048B5B50>]}
[0m13:53:22.371314 [info ] [MainThread]: 
[0m13:53:22.371314 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:53:22.371314 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:53:22.377420 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:53:22.377420 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:53:22.377420 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:53:23.672515 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:53:23.672515 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:53:23.675842 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:53:23.675842 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:53:23.686363 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:53:23.687374 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:53:23.887750 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:53:23.888749 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:53:23.889750 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:53:23.940443 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:53:23.940443 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:53:23.972194 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:53:23.976598 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:23.976598 [debug] [MainThread]: On master: BEGIN
[0m13:53:23.976598 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:53:24.182616 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:53:24.183944 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:24.184904 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:53:24.241623 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:53:24.252094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B505B09790>]}
[0m13:53:24.253109 [debug] [MainThread]: On master: ROLLBACK
[0m13:53:24.283336 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:24.284845 [debug] [MainThread]: On master: BEGIN
[0m13:53:24.346621 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:53:24.347730 [debug] [MainThread]: On master: COMMIT
[0m13:53:24.348245 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:24.348767 [debug] [MainThread]: On master: COMMIT
[0m13:53:24.377703 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:53:24.378214 [debug] [MainThread]: On master: Close
[0m13:53:24.379261 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:53:24.380298 [info ] [MainThread]: 
[0m13:53:24.383509 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:53:24.384161 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:53:24.386292 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:53:24.387379 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:53:24.398759 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:24.401705 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:53:24.387996 => 13:53:24.401049
[0m13:53:24.402785 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:53:24.448816 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:24.451586 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:24.451586 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:53:24.451586 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:53:24.664141 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:53:24.664141 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:24.666146 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_date IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m13:53:26.412865 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m13:53:26.420582 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:26.420582 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp" rename to "mart_fullmoon_reviews"
[0m13:53:26.452475 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:53:26.482327 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m13:53:26.483106 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:26.483106 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m13:53:26.517005 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:53:26.524052 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup"
[0m13:53:26.533469 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:26.533988 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
drop table if exists "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup" cascade
[0m13:53:26.578655 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:53:26.581706 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:53:24.403945 => 13:53:26.581165
[0m13:53:26.582853 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:53:26.584434 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5048F4C10>]}
[0m13:53:26.585505 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.mart_fullmoon_reviews ................... [[32mSELECT 410284[0m in 2.20s]
[0m13:53:26.587204 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:53:26.588763 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:26.589805 [debug] [MainThread]: On master: BEGIN
[0m13:53:26.590326 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:53:26.812480 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:53:26.813208 [debug] [MainThread]: On master: COMMIT
[0m13:53:26.813208 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:26.814214 [debug] [MainThread]: On master: COMMIT
[0m13:53:26.837678 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:53:26.837678 [debug] [MainThread]: On master: Close
[0m13:53:26.837678 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:53:26.845808 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:53:26.845808 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:53:26.847315 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:53:26.847827 [info ] [MainThread]: 
[0m13:53:26.848340 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 4.48 seconds (4.48s).
[0m13:53:26.848340 [debug] [MainThread]: Command end result
[0m13:53:26.860069 [info ] [MainThread]: 
[0m13:53:26.861045 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:53:26.861045 [info ] [MainThread]: 
[0m13:53:26.861045 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:53:26.864048 [debug] [MainThread]: Command `dbt run` succeeded at 13:53:26.861045 after 5.18 seconds
[0m13:53:26.864048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B57CE51090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B57D13FE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5048B6690>]}
[0m13:53:26.864875 [debug] [MainThread]: Flushing usage events
[0m14:00:50.378827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64DD8C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE646628D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64DDBD90>]}


============================== 14:00:50.382827 | 0352332d-4821-4d08-84a7-caf07b002cdf ==============================
[0m14:00:50.382827 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:00:50.384332 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s src_listings', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:00:50.590386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64662050>]}
[0m14:00:50.668965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64E05890>]}
[0m14:00:50.670401 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:00:50.679104 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:00:50.781044 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m14:00:50.781553 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\sources.yml
[0m14:00:50.783556 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_listings.sql
[0m14:00:51.016518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE66378F10>]}
[0m14:00:51.029281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE66420B90>]}
[0m14:00:51.030279 [info ] [MainThread]: Found 8 models, 1 seed, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:00:51.031278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE652B4510>]}
[0m14:00:51.032280 [info ] [MainThread]: 
[0m14:00:51.033278 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:00:51.035341 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:00:51.046551 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:00:51.047551 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:00:51.048550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:00:52.347884 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m14:00:52.348882 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:00:52.350883 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:00:52.357913 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:00:52.358913 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:00:52.359913 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:00:52.576692 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:00:52.578039 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:00:52.578039 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:00:52.628240 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:00:52.629238 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:00:52.661696 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:00:52.669496 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:52.669496 [debug] [MainThread]: On master: BEGIN
[0m14:00:52.670498 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:00:52.877741 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:00:52.878787 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:52.878787 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:00:52.944632 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:00:52.947335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64ED1010>]}
[0m14:00:52.947335 [debug] [MainThread]: On master: ROLLBACK
[0m14:00:52.979608 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:52.980155 [debug] [MainThread]: On master: BEGIN
[0m14:00:53.049829 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:00:53.049829 [debug] [MainThread]: On master: COMMIT
[0m14:00:53.050828 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:53.050828 [debug] [MainThread]: On master: COMMIT
[0m14:00:53.080461 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:00:53.080461 [debug] [MainThread]: On master: Close
[0m14:00:53.081499 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:00:53.082470 [info ] [MainThread]: 
[0m14:00:53.086746 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:00:53.086746 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:00:53.088250 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:00:53.089913 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:00:53.096923 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:00:53.098921 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:00:53.089913 => 14:00:53.098921
[0m14:00:53.098921 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:00:53.138092 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:00:53.140108 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:00:53.142129 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:00:53.142129 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:00:53.353398 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:00:53.354437 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:00:53.354957 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."raw"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:00:53.392510 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.raw_listings" does not exist
LINE 11:   "inttegra_stage"."raw"."raw_listings"
           ^

[0m14:00:53.393510 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: ROLLBACK
[0m14:00:53.423725 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:00:53.101009 => 14:00:53.423725
[0m14:00:53.425259 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:00:53.430264 [debug] [Thread-1 (]: Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw.raw_listings" does not exist
  LINE 11:   "inttegra_stage"."raw"."raw_listings"
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:00:53.430264 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE66444090>]}
[0m14:00:53.431264 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.src_listings ......................... [[31mERROR[0m in 0.34s]
[0m14:00:53.432266 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:00:53.433266 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:53.434298 [debug] [MainThread]: On master: BEGIN
[0m14:00:53.434298 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:00:53.626400 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:00:53.627159 [debug] [MainThread]: On master: COMMIT
[0m14:00:53.628156 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:53.628156 [debug] [MainThread]: On master: COMMIT
[0m14:00:53.657227 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:00:53.657227 [debug] [MainThread]: On master: Close
[0m14:00:53.658227 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:00:53.659262 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:00:53.660226 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:00:53.660226 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:00:53.661278 [info ] [MainThread]: 
[0m14:00:53.662228 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.63 seconds (2.63s).
[0m14:00:53.663227 [debug] [MainThread]: Command end result
[0m14:00:53.675756 [info ] [MainThread]: 
[0m14:00:53.678844 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:00:53.680352 [info ] [MainThread]: 
[0m14:00:53.681392 [error] [MainThread]:   Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw.raw_listings" does not exist
  LINE 11:   "inttegra_stage"."raw"."raw_listings"
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:00:53.683400 [info ] [MainThread]: 
[0m14:00:53.685361 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:00:53.687359 [debug] [MainThread]: Command `dbt run` failed at 14:00:53.687359 after 3.37 seconds
[0m14:00:53.688359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE645BCA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE5D631050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64DA2AD0>]}
[0m14:00:53.689357 [debug] [MainThread]: Flushing usage events
[0m14:01:25.361216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDB5AB750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDB5ABB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDD40A4450>]}


============================== 14:01:25.365215 | 6f6ed5e2-0e85-480c-95d6-ec2108969d88 ==============================
[0m14:01:25.365215 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:01:25.365625 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s src_listings', 'send_anonymous_usage_stats': 'True'}
[0m14:01:25.582386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDB0F2050>]}
[0m14:01:25.660495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDADD3A10>]}
[0m14:01:25.661462 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:01:25.675989 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:01:25.783305 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:01:25.784306 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m14:01:26.030301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDCB87450>]}
[0m14:01:26.043319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDCAF7490>]}
[0m14:01:26.043319 [info ] [MainThread]: Found 8 models, 1 seed, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:01:26.044583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDCB29D90>]}
[0m14:01:26.046582 [info ] [MainThread]: 
[0m14:01:26.047583 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:01:26.049805 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:01:26.060428 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:01:26.062428 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:01:26.063432 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:01:27.376392 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m14:01:27.377600 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:01:27.379598 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:01:27.385628 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:01:27.385628 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:01:27.386595 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:01:27.591152 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:01:27.592664 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:01:27.592664 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:01:27.641991 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:01:27.643994 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:01:27.676762 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:01:27.683396 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:27.684396 [debug] [MainThread]: On master: BEGIN
[0m14:01:27.685364 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:01:27.891274 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:01:27.892288 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:27.892837 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:01:27.949991 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:01:27.952034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDCB87BD0>]}
[0m14:01:27.953035 [debug] [MainThread]: On master: ROLLBACK
[0m14:01:27.985619 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:27.986579 [debug] [MainThread]: On master: BEGIN
[0m14:01:28.045973 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:01:28.046974 [debug] [MainThread]: On master: COMMIT
[0m14:01:28.046974 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:28.047975 [debug] [MainThread]: On master: COMMIT
[0m14:01:28.074829 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:01:28.076060 [debug] [MainThread]: On master: Close
[0m14:01:28.077092 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:01:28.078057 [info ] [MainThread]: 
[0m14:01:28.081057 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:01:28.082058 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:01:28.084062 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:01:28.085064 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:01:28.093580 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:01:28.095578 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:01:28.085064 => 14:01:28.095578
[0m14:01:28.096577 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:01:28.134176 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:01:28.136396 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.136396 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:01:28.137633 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:01:28.331411 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:01:28.332458 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.332458 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."test"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:01:28.381172 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:01:28.388727 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.389726 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:01:28.422055 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:01:28.426242 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.427281 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:01:28.458491 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:01:28.475612 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:01:28.476676 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.477722 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:01:28.508061 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:01:28.517589 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:01:28.526033 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.527067 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:01:28.559558 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:01:28.561518 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:01:28.097578 => 14:01:28.561518
[0m14:01:28.562519 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:01:28.562519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDAF41790>]}
[0m14:01:28.563554 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.48s]
[0m14:01:28.564568 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:01:28.566632 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:28.567095 [debug] [MainThread]: On master: BEGIN
[0m14:01:28.567095 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:01:28.769632 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:01:28.771149 [debug] [MainThread]: On master: COMMIT
[0m14:01:28.771846 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:28.771846 [debug] [MainThread]: On master: COMMIT
[0m14:01:28.801067 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:01:28.801067 [debug] [MainThread]: On master: Close
[0m14:01:28.803094 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:01:28.803094 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:01:28.804080 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:01:28.805064 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:01:28.805064 [info ] [MainThread]: 
[0m14:01:28.806573 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.76 seconds (2.76s).
[0m14:01:28.807528 [debug] [MainThread]: Command end result
[0m14:01:28.816541 [info ] [MainThread]: 
[0m14:01:28.817537 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:01:28.818540 [info ] [MainThread]: 
[0m14:01:28.819899 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:01:28.820898 [debug] [MainThread]: Command `dbt run` succeeded at 14:01:28.820898 after 3.53 seconds
[0m14:01:28.821902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDD3E31050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDAD22710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDB0D4290>]}
[0m14:01:28.822901 [debug] [MainThread]: Flushing usage events
[0m14:02:44.176490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276250650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2765B6090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2767D6050>]}


============================== 14:02:44.181484 | da4064dc-02a6-4f26-a9c9-14deea0bee3c ==============================
[0m14:02:44.181484 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:02:44.182486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:02:44.400450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276231350>]}
[0m14:02:44.477955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F275C13010>]}
[0m14:02:44.479768 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:02:44.488404 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:02:44.593426 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m14:02:44.593948 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_reviews.sql
[0m14:02:44.593948 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m14:02:44.759886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276DE2D90>]}
[0m14:02:44.773421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2769FB790>]}
[0m14:02:44.774427 [info ] [MainThread]: Found 8 models, 1 seed, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:02:44.774892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276E09310>]}
[0m14:02:44.776901 [info ] [MainThread]: 
[0m14:02:44.777666 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:02:44.779878 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:02:44.790407 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:02:44.791395 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:02:44.792395 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:02:46.107655 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m14:02:46.108665 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:02:46.111664 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:02:46.116663 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:02:46.116663 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:02:46.117664 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:02:46.577230 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:02:46.578232 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:02:46.578232 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:02:46.631735 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:02:46.633778 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:02:46.666140 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:02:46.673188 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:46.674189 [debug] [MainThread]: On master: BEGIN
[0m14:02:46.675189 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:02:46.880917 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:02:46.881679 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:46.882710 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:02:46.948158 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:02:46.949886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276B839D0>]}
[0m14:02:46.950923 [debug] [MainThread]: On master: ROLLBACK
[0m14:02:46.982479 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:46.983477 [debug] [MainThread]: On master: BEGIN
[0m14:02:47.045929 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:02:47.046935 [debug] [MainThread]: On master: COMMIT
[0m14:02:47.046935 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:47.047935 [debug] [MainThread]: On master: COMMIT
[0m14:02:47.071627 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:02:47.071627 [debug] [MainThread]: On master: Close
[0m14:02:47.073626 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:02:47.074636 [info ] [MainThread]: 
[0m14:02:47.078625 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:02:47.078625 [info ] [Thread-1 (]: 1 of 8 START sql view model test.src_hosts ..................................... [RUN]
[0m14:02:47.080625 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:02:47.082135 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:02:47.091137 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:02:47.094164 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:02:47.082135 => 14:02:47.093845
[0m14:02:47.095162 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:02:47.131009 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:02:47.132975 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.132975 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:02:47.133980 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:02:47.341327 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:47.341327 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.342361 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		"inttegra_stage"."test"."raw_hosts" rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:02:47.388762 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:02:47.395281 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.396278 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:02:47.427635 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:47.432511 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.433511 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:02:47.463630 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:47.479668 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:02:47.479668 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.480637 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:02:47.509635 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:47.515654 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:02:47.520654 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.520654 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:02:47.554857 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:02:47.556849 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:02:47.095162 => 14:02:47.556849
[0m14:02:47.557849 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:02:47.558849 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276DB7D50>]}
[0m14:02:47.559850 [info ] [Thread-1 (]: 1 of 8 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.48s]
[0m14:02:47.559850 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:02:47.561355 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:02:47.562460 [info ] [Thread-1 (]: 2 of 8 START sql view model test.src_listings .................................. [RUN]
[0m14:02:47.563145 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:02:47.564184 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:02:47.567178 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:02:47.569151 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:02:47.564184 => 14:02:47.568179
[0m14:02:47.569151 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:02:47.574279 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:02:47.576352 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.577288 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:02:47.578287 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:47.775676 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:47.776695 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.776695 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."test"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:02:47.822681 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:02:47.826597 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.827195 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:02:47.857434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:47.860321 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.861829 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:02:47.892231 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:47.895067 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:02:47.895067 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.896036 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:02:47.928932 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:47.931937 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:02:47.932938 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.933938 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:02:47.967803 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:02:47.969809 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:02:47.570186 => 14:02:47.968811
[0m14:02:47.970313 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:02:47.971319 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277FA7DD0>]}
[0m14:02:47.972319 [info ] [Thread-1 (]: 2 of 8 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:02:47.973104 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:02:47.974143 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:02:47.975111 [info ] [Thread-1 (]: 3 of 8 START sql view model test.src_reviews ................................... [RUN]
[0m14:02:47.976132 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:02:47.977116 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:02:47.979116 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:02:47.981115 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:02:47.977116 => 14:02:47.981115
[0m14:02:47.982115 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:02:47.987668 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:02:47.989665 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:47.991668 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:02:47.992681 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:48.213325 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:48.214330 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.214330 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT 
		*
	FROM
		"inttegra_stage"."test"."raw_reviews" rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:02:48.260833 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:02:48.263985 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.264983 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:02:48.295457 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:48.298163 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.299162 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:02:48.339628 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:48.341658 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:02:48.342641 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.343152 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:02:48.373721 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:48.376728 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:02:48.377729 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.378728 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:02:48.412931 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:02:48.414679 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:02:47.982636 => 14:02:48.414679
[0m14:02:48.415735 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:02:48.416775 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277FF2050>]}
[0m14:02:48.417741 [info ] [Thread-1 (]: 3 of 8 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.44s]
[0m14:02:48.418750 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:02:48.419742 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m14:02:48.420741 [info ] [Thread-1 (]: 4 of 8 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m14:02:48.421754 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m14:02:48.422775 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m14:02:48.425779 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.426739 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 14:02:48.422775 => 14:02:48.426739
[0m14:02:48.428010 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m14:02:48.453082 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.454593 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.456601 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m14:02:48.457601 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:48.663782 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:48.664791 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.664791 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m14:02:48.765035 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m14:02:48.768041 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.769041 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m14:02:48.801118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:48.805124 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.806125 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m14:02:48.838603 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:48.844392 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m14:02:48.844392 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.845358 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m14:02:48.879821 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:48.881815 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m14:02:48.886536 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.887534 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m14:02:48.931329 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:02:48.933666 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 14:02:48.428010 => 14:02:48.933666
[0m14:02:48.934627 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m14:02:48.935628 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277F31D50>]}
[0m14:02:48.936628 [info ] [Thread-1 (]: 4 of 8 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.51s]
[0m14:02:48.937661 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m14:02:48.937661 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:02:48.938741 [info ] [Thread-1 (]: 5 of 8 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:02:48.939746 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m14:02:48.939746 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:02:48.943318 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:02:48.944294 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:02:48.940747 => 14:02:48.944294
[0m14:02:48.945491 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:02:48.949494 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:02:48.951491 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:48.952495 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:02:48.953496 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:49.170145 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:49.170145 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.171653 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m14:02:49.322510 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m14:02:49.326507 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.328011 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m14:02:49.360986 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:49.364495 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.365058 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m14:02:49.398071 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:49.400580 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m14:02:49.401584 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.401584 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m14:02:49.435342 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:49.438406 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m14:02:49.439373 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.440406 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m14:02:49.480927 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:02:49.482969 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:02:48.945491 => 14:02:49.482969
[0m14:02:49.483935 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:02:49.483935 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276D93990>]}
[0m14:02:49.485105 [info ] [Thread-1 (]: 5 of 8 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.54s]
[0m14:02:49.486111 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:02:49.487146 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m14:02:49.488274 [info ] [Thread-1 (]: 6 of 8 START sql incremental model test.fact_reviews ........................... [RUN]
[0m14:02:49.488830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m14:02:49.489937 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m14:02:49.498257 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m14:02:49.500258 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 14:02:49.489937 => 14:02:49.500258
[0m14:02:49.501287 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m14:02:49.532153 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:49.532672 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp140249525580"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m14:02:49.533233 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:50.729065 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m14:02:50.735316 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.736341 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m14:02:50.769643 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:50.770475 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.771551 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp140249525580'
        
      order by ordinal_position

  
[0m14:02:50.830584 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m14:02:50.835595 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.836593 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:02:50.882163 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m14:02:50.894419 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.895382 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp140249525580'
        
      order by ordinal_position

  
[0m14:02:50.937961 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m14:02:50.941628 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.942627 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:02:50.983269 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m14:02:50.991744 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m14:02:51.001430 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m14:02:51.003402 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:51.004396 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp140249525580"
    )


  
[0m14:02:51.036754 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m14:02:51.038785 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m14:02:51.038785 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:51.039775 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m14:02:51.073033 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:51.074044 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 14:02:49.502278 => 14:02:51.074044
[0m14:02:51.075039 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m14:02:51.076038 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2780469D0>]}
[0m14:02:51.077039 [info ] [Thread-1 (]: 6 of 8 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.59s]
[0m14:02:51.077389 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m14:02:51.078428 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m14:02:51.079411 [info ] [Thread-1 (]: 7 of 8 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m14:02:51.080410 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m14:02:51.081395 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m14:02:51.085913 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.087917 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 14:02:51.081395 => 14:02:51.086914
[0m14:02:51.088918 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m14:02:51.095729 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.097737 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.098740 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m14:02:51.099738 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:51.388528 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:51.389333 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.390292 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m14:02:51.547827 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m14:02:51.551194 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.552440 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts" rename to "dim_listings_with_hosts__dbt_backup"
[0m14:02:51.584839 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:51.587938 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.587938 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m14:02:51.620724 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:51.624278 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m14:02:51.624830 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.625801 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m14:02:51.659523 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:51.663044 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m14:02:51.664044 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.665044 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m14:02:51.705912 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:02:51.708451 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 14:02:51.089915 => 14:02:51.708451
[0m14:02:51.709462 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m14:02:51.710457 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277FF3350>]}
[0m14:02:51.711461 [info ] [Thread-1 (]: 7 of 8 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 0.63s]
[0m14:02:51.712474 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m14:02:51.713463 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m14:02:51.714461 [info ] [Thread-1 (]: 8 of 8 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m14:02:51.714979 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m14:02:51.716019 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m14:02:51.718019 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:51.720604 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 14:02:51.716019 => 14:02:51.720604
[0m14:02:51.720604 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m14:02:51.726612 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:51.728618 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:51.728618 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m14:02:51.729611 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:51.947699 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:51.947699 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:51.948868 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_date IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m14:02:53.595498 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m14:02:53.598538 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:53.599537 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews" rename to "mart_fullmoon_reviews__dbt_backup"
[0m14:02:53.631631 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:53.634235 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:53.635236 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp" rename to "mart_fullmoon_reviews"
[0m14:02:53.667156 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:53.669159 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m14:02:53.670192 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:53.671197 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m14:02:53.703989 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:53.707020 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup"
[0m14:02:53.707992 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:53.707992 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
drop table if exists "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup" cascade
[0m14:02:53.794345 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:02:53.796560 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 14:02:51.721646 => 14:02:53.795560
[0m14:02:53.796560 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m14:02:53.797527 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277FA7ED0>]}
[0m14:02:53.798560 [info ] [Thread-1 (]: 8 of 8 OK created sql table model test.mart_fullmoon_reviews ................... [[32mSELECT 410284[0m in 2.08s]
[0m14:02:53.799607 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m14:02:53.801616 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:53.802612 [debug] [MainThread]: On master: BEGIN
[0m14:02:53.802612 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:02:54.006925 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:02:54.007890 [debug] [MainThread]: On master: COMMIT
[0m14:02:54.008890 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:54.008890 [debug] [MainThread]: On master: COMMIT
[0m14:02:54.037322 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:02:54.037322 [debug] [MainThread]: On master: Close
[0m14:02:54.038827 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:02:54.039825 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:02:54.039825 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:02:54.041176 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m14:02:54.042178 [info ] [MainThread]: 
[0m14:02:54.042178 [info ] [MainThread]: Finished running 3 view models, 4 table models, 1 incremental model in 0 hours 0 minutes and 9.26 seconds (9.26s).
[0m14:02:54.044176 [debug] [MainThread]: Command end result
[0m14:02:54.055684 [info ] [MainThread]: 
[0m14:02:54.056685 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:02:54.057685 [info ] [MainThread]: 
[0m14:02:54.058684 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m14:02:54.060686 [debug] [MainThread]: Command `dbt run` succeeded at 14:02:54.059685 after 9.96 seconds
[0m14:02:54.060686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F26F271010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F275D4EAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F26F56EF90>]}
[0m14:02:54.061684 [debug] [MainThread]: Flushing usage events
[0m14:03:56.226594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1E741050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1EEF07D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1E741AD0>]}


============================== 14:03:56.230592 | a999e460-d347-464b-b485-6dbbe4f46da3 ==============================
[0m14:03:56.230592 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:03:56.231591 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt compile', 'send_anonymous_usage_stats': 'True'}
[0m14:03:56.537784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F0FABD0>]}
[0m14:03:56.642431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F101810>]}
[0m14:03:56.643437 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:03:56.653318 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:03:56.817737 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:03:56.818770 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:03:56.828185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F0C3190>]}
[0m14:03:56.898876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F227350>]}
[0m14:03:56.899412 [info ] [MainThread]: Found 8 models, 1 seed, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:03:56.900481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1EF10E50>]}
[0m14:03:56.902597 [info ] [MainThread]: 
[0m14:03:56.904177 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:03:56.906783 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:03:56.924726 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:03:56.925713 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:03:56.926994 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:03:58.252603 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m14:03:58.253609 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:03:58.253609 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:03:58.302801 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:03:58.305813 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:03:58.340474 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:03:58.351821 [debug] [MainThread]: Using postgres connection "master"
[0m14:03:58.352823 [debug] [MainThread]: On master: BEGIN
[0m14:03:58.354835 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:03:58.568872 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:03:58.570883 [debug] [MainThread]: Using postgres connection "master"
[0m14:03:58.572882 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:03:58.633990 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:03:58.641066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F1CEB10>]}
[0m14:03:58.643034 [debug] [MainThread]: On master: ROLLBACK
[0m14:03:58.676086 [debug] [MainThread]: On master: Close
[0m14:03:58.679083 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:03:58.682082 [info ] [MainThread]: 
[0m14:03:58.699079 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:03:58.755400 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:03:58.758481 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:03:58.784248 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:03:58.791216 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:03:58.760516 => 14:03:58.789215
[0m14:03:58.795343 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:03:58.797343 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:03:58.796341 => 14:03:58.796341
[0m14:03:58.800342 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:03:58.801342 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:03:58.802344 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:03:58.803342 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:03:58.808399 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:03:58.811401 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:03:58.805386 => 14:03:58.810399
[0m14:03:58.813399 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:03:58.814398 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:03:58.814398 => 14:03:58.814398
[0m14:03:58.815397 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:03:58.818439 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:03:58.821439 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:03:58.822438 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:03:58.827440 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:03:58.830394 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:03:58.822438 => 14:03:58.830394
[0m14:03:58.832397 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:03:58.834395 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:03:58.833406 => 14:03:58.833406
[0m14:03:58.836394 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:03:58.838395 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m14:03:58.840951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m14:03:58.841492 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m14:03:58.847022 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 14:03:58.842498 => 14:03:58.846018
[0m14:03:58.848018 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m14:03:58.849020 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 14:03:58.849020 => 14:03:58.849020
[0m14:03:58.851021 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m14:03:58.852016 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m14:03:58.854449 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now model.dbtlearn.dim_hosts_cleansed)
[0m14:03:58.855489 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m14:03:58.860486 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m14:03:58.862487 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 14:03:58.856487 => 14:03:58.862487
[0m14:03:58.863486 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m14:03:58.863486 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 14:03:58.863486 => 14:03:58.863486
[0m14:03:58.867516 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m14:03:58.868523 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:03:58.870517 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m14:03:58.870517 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:03:58.875519 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:03:58.878552 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:03:58.871517 => 14:03:58.878089
[0m14:03:58.879554 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:03:58.881580 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:03:58.880553 => 14:03:58.880553
[0m14:03:58.883550 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:03:58.885550 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m14:03:58.890777 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m14:03:58.892296 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m14:03:58.911309 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m14:03:58.913933 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 14:03:58.893305 => 14:03:58.912819
[0m14:03:58.914318 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m14:03:58.916336 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 14:03:58.915319 => 14:03:58.915319
[0m14:03:58.918316 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m14:03:58.919315 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m14:03:58.920315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m14:03:58.922317 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m14:03:58.930379 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m14:03:58.932364 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 14:03:58.923326 => 14:03:58.932364
[0m14:03:58.933364 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m14:03:58.934364 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 14:03:58.934364 => 14:03:58.934364
[0m14:03:58.937451 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m14:03:58.939018 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m14:03:58.940027 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m14:03:58.941026 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m14:03:58.946051 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m14:03:58.949559 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 14:03:58.942028 => 14:03:58.948052
[0m14:03:58.951605 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m14:03:58.953566 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 14:03:58.952572 => 14:03:58.952572
[0m14:03:58.955571 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m14:03:58.958579 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:03:58.959570 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:03:58.959570 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m14:03:58.963611 [debug] [MainThread]: Command end result
[0m14:03:58.986706 [debug] [MainThread]: Command `dbt compile` succeeded at 14:03:58.985689 after 2.83 seconds
[0m14:03:58.987699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E17741010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1EB0B010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E17785A10>]}
[0m14:03:58.988704 [debug] [MainThread]: Flushing usage events
[0m14:30:28.898101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B6C15150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B64050D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B67B6850>]}


============================== 14:30:28.898101 | 0c406270-213f-4b28-a3d9-30f909955738 ==============================
[0m14:30:28.898101 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:30:28.898101 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt source freshness', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:30:29.137943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B64568D0>]}
[0m14:30:29.230447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B64DB050>]}
[0m14:30:29.230447 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:30:29.239170 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:30:29.331136 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:30:29.331136 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m14:30:29.643904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B700F210>]}
[0m14:30:29.660196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B700EE50>]}
[0m14:30:29.660196 [info ] [MainThread]: Found 1 seed, 8 models, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:30:29.660196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B6C4E8D0>]}
[0m14:30:29.660196 [info ] [MainThread]: 
[0m14:30:29.667174 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:30:29.671191 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:30:29.702917 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:29.704056 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:30:29.705935 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:30.004653 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:30.004653 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:30.004653 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:30:30.052812 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:30:30.052812 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:30:30.087211 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:30:30.092747 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:30.094487 [debug] [MainThread]: On master: BEGIN
[0m14:30:30.094487 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:30:30.296635 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:30.296635 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:30.296635 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:30:30.358956 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:30:30.363645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B6457990>]}
[0m14:30:30.363645 [debug] [MainThread]: On master: ROLLBACK
[0m14:30:30.393786 [debug] [MainThread]: On master: Close
[0m14:30:30.393786 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:30:30.393786 [info ] [MainThread]: 
[0m14:30:30.400738 [debug] [Thread-1 (]: Began running node source.dbtlearn.airbnb.reviews
[0m14:30:30.400738 [info ] [Thread-1 (]: 1 of 1 START freshness of airbnb.reviews ....................................... [RUN]
[0m14:30:30.400738 [debug] [Thread-1 (]: Acquiring new postgres connection 'source.dbtlearn.airbnb.reviews'
[0m14:30:30.407209 [debug] [Thread-1 (]: Began compiling node source.dbtlearn.airbnb.reviews
[0m14:30:30.408222 [debug] [Thread-1 (]: Timing info for source.dbtlearn.airbnb.reviews (compile): 14:30:30.408222 => 14:30:30.408222
[0m14:30:30.409217 [debug] [Thread-1 (]: Began executing node source.dbtlearn.airbnb.reviews
[0m14:30:30.410217 [debug] [Thread-1 (]: Using postgres connection "source.dbtlearn.airbnb.reviews"
[0m14:30:30.410217 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: BEGIN
[0m14:30:30.412259 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:30:30.596121 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:30:30.596121 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: COMMIT
[0m14:30:30.596121 [debug] [Thread-1 (]: Using postgres connection "source.dbtlearn.airbnb.reviews"
[0m14:30:30.596121 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: COMMIT
[0m14:30:30.628063 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:30:30.628063 [debug] [Thread-1 (]: Using postgres connection "source.dbtlearn.airbnb.reviews"
[0m14:30:30.628063 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "source.dbtlearn.airbnb.reviews"} */
select
      max(date) as max_loaded_at,
      now() as snapshotted_at
    from "inttegra_stage"."test"."raw_reviews"
    
  
[0m14:30:30.904680 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:30.905782 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: Close
[0m14:30:30.905782 [debug] [Thread-1 (]: Timing info for source.dbtlearn.airbnb.reviews (execute): 14:30:30.409217 => 14:30:30.905782
[0m14:30:30.910685 [error] [Thread-1 (]: 1 of 1 ERROR STALE freshness of airbnb.reviews ................................. [[31mERROR STALE[0m in 0.51s]
[0m14:30:30.910685 [debug] [Thread-1 (]: Finished running node source.dbtlearn.airbnb.reviews
[0m14:30:30.910685 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:30:30.910685 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:30:30.910685 [debug] [MainThread]: Connection 'source.dbtlearn.airbnb.reviews' was properly closed.
[0m14:30:30.927546 [info ] [MainThread]: 
[0m14:30:30.929125 [info ] [MainThread]: Done.
[0m14:30:30.932787 [debug] [MainThread]: Command `dbt source freshness` failed at 14:30:30.932068 after 2.11 seconds
[0m14:30:30.934074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B67B6850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B3851190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B6CF7510>]}
[0m14:30:30.934735 [debug] [MainThread]: Flushing usage events
[0m14:51:22.996986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FC5FCF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FC5FE790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FCE01A50>]}


============================== 14:51:23.005982 | dd9300bd-cd9a-424b-becb-5b4d479a3750 ==============================
[0m14:51:23.005982 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:51:23.007491 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:51:23.379680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd9300bd-cd9a-424b-becb-5b4d479a3750', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FCF5F010>]}
[0m14:51:23.525390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dd9300bd-cd9a-424b-becb-5b4d479a3750', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FCE40D50>]}
[0m14:51:23.527618 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:51:23.558516 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:51:23.803254 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:51:23.804233 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/snapshots\scd_raw_listings.sql
[0m14:51:23.810232 [error] [MainThread]: Encountered an error:
Compilation Error
  Reached EOF without finding a close tag for snapshot (searched from line 1)
[0m14:51:23.813921 [debug] [MainThread]: Command `dbt snapshot` failed at 14:51:23.813292 after 0.91 seconds
[0m14:51:23.813921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1F5641010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1F593FD50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FD1870D0>]}
[0m14:51:23.816180 [debug] [MainThread]: Flushing usage events
[0m14:53:16.632440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAAB2C050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE22E450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE40D5D0>]}


============================== 14:53:16.642986 | 44d8bde8-93a7-4029-bdac-c4a2ce89780a ==============================
[0m14:53:16.642986 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:53:16.703277 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:53:17.026440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CADE815D0>]}
[0m14:53:17.111578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE773A90>]}
[0m14:53:17.113084 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:53:17.123143 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:53:17.230870 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:53:17.231871 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/snapshots\scd_raw_listings.sql
[0m14:53:17.431933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE699110>]}
[0m14:53:17.446947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAEC19950>]}
[0m14:53:17.447936 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:53:17.448937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE9E2550>]}
[0m14:53:17.449971 [info ] [MainThread]: 
[0m14:53:17.450968 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:53:17.453547 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:53:17.468057 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:53:17.469059 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:53:17.469059 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:53:18.789552 [debug] [ThreadPool]: SQL status: SELECT 19 in 1.0 seconds
[0m14:53:18.791087 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:53:18.796050 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:53:18.803357 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:53:18.804347 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:53:18.805346 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:53:19.009573 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:53:19.010568 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:53:19.012073 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:53:19.061681 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:53:19.063701 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:53:19.095461 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:53:19.103436 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:19.104402 [debug] [MainThread]: On master: BEGIN
[0m14:53:19.104402 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:53:19.305590 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:53:19.305590 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:19.307009 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:53:19.369574 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:53:19.371584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE923450>]}
[0m14:53:19.372577 [debug] [MainThread]: On master: ROLLBACK
[0m14:53:19.402246 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:19.403237 [debug] [MainThread]: On master: BEGIN
[0m14:53:19.462327 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:53:19.463320 [debug] [MainThread]: On master: COMMIT
[0m14:53:19.463320 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:19.464328 [debug] [MainThread]: On master: COMMIT
[0m14:53:19.505302 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:53:19.506919 [debug] [MainThread]: On master: Close
[0m14:53:19.507928 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:53:19.509928 [info ] [MainThread]: 
[0m14:53:19.514929 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m14:53:19.515958 [info ] [Thread-1 (]: 1 of 1 START snapshot test.scd_raw_listings .................................... [RUN]
[0m14:53:19.517432 [debug] [Thread-1 (]: Acquiring new postgres connection 'snapshot.dbtlearn.scd_raw_listings'
[0m14:53:19.518442 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m14:53:19.531491 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 14:53:19.519440 => 14:53:19.530418
[0m14:53:19.532489 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m14:53:19.594381 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.dbtlearn.scd_raw_listings"
[0m14:53:19.596381 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:53:19.597382 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: BEGIN
[0m14:53:19.597382 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:53:19.796543 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:53:19.798537 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:53:19.799538 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      
  
    

  create  table "inttegra_stage"."test"."scd_raw_listings"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        



SELECT
    *
FROM
    "inttegra_stage"."test"."raw_listings"

    ) sbq



  );
  
  
[0m14:53:19.933955 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m14:53:19.952845 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:53:19.952845 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:53:19.953844 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:53:19.993410 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:53:19.995384 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 14:53:19.533488 => 14:53:19.994383
[0m14:53:19.995384 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: Close
[0m14:53:19.996402 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAEC2B590>]}
[0m14:53:19.997929 [info ] [Thread-1 (]: 1 of 1 OK snapshotted test.scd_raw_listings .................................... [[32mSELECT 17499[0m in 0.48s]
[0m14:53:19.999533 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m14:53:20.000940 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:20.000940 [debug] [MainThread]: On master: BEGIN
[0m14:53:20.001940 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:53:20.204146 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:53:20.205031 [debug] [MainThread]: On master: COMMIT
[0m14:53:20.206030 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:20.207028 [debug] [MainThread]: On master: COMMIT
[0m14:53:20.233812 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:53:20.234612 [debug] [MainThread]: On master: Close
[0m14:53:20.235569 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:53:20.236571 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:53:20.236571 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:53:20.236571 [debug] [MainThread]: Connection 'snapshot.dbtlearn.scd_raw_listings' was properly closed.
[0m14:53:20.238076 [info ] [MainThread]: 
[0m14:53:20.239153 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 2.79 seconds (2.79s).
[0m14:53:20.239153 [debug] [MainThread]: Command end result
[0m14:53:20.248160 [info ] [MainThread]: 
[0m14:53:20.249195 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:53:20.250672 [info ] [MainThread]: 
[0m14:53:20.251676 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:53:20.252675 [debug] [MainThread]: Command `dbt snapshot` succeeded at 14:53:20.252675 after 3.81 seconds
[0m14:53:20.253678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CA6EAE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE157F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE1558D0>]}
[0m14:53:20.253678 [debug] [MainThread]: Flushing usage events
[0m14:57:43.494521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1C30950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC184B010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1785390>]}


============================== 14:57:43.498884 | 8908006f-3e92-47a7-850a-ff8261d2284f ==============================
[0m14:57:43.498884 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:57:43.499884 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:57:43.722401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1C82050>]}
[0m14:57:43.804650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1D92A50>]}
[0m14:57:43.806615 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:57:43.817139 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:57:43.923276 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:57:43.924276 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:57:43.930055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1771E50>]}
[0m14:57:43.987213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1F63A50>]}
[0m14:57:43.988213 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:57:43.988213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1E3E3D0>]}
[0m14:57:43.990508 [info ] [MainThread]: 
[0m14:57:43.992510 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:57:43.994511 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:57:44.004593 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:57:44.004593 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:57:44.005594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:45.330068 [debug] [ThreadPool]: SQL status: SELECT 19 in 1.0 seconds
[0m14:57:45.332441 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:57:45.336452 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:57:45.346830 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:45.348319 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:57:45.349415 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:45.549106 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:57:45.549106 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:45.549106 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:57:45.600073 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m14:57:45.600073 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:57:45.647227 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:57:45.655237 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:45.655237 [debug] [MainThread]: On master: BEGIN
[0m14:57:45.656238 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:57:45.868562 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:45.868562 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:45.869560 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:57:45.932855 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:57:45.934896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1436C10>]}
[0m14:57:45.934896 [debug] [MainThread]: On master: ROLLBACK
[0m14:57:45.968122 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:45.968960 [debug] [MainThread]: On master: BEGIN
[0m14:57:46.032077 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:46.033084 [debug] [MainThread]: On master: COMMIT
[0m14:57:46.033084 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:46.034082 [debug] [MainThread]: On master: COMMIT
[0m14:57:46.063280 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:46.063280 [debug] [MainThread]: On master: Close
[0m14:57:46.064287 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:57:46.065287 [info ] [MainThread]: 
[0m14:57:46.069330 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m14:57:46.070329 [info ] [Thread-1 (]: 1 of 1 START snapshot test.scd_raw_listings .................................... [RUN]
[0m14:57:46.072329 [debug] [Thread-1 (]: Acquiring new postgres connection 'snapshot.dbtlearn.scd_raw_listings'
[0m14:57:46.073333 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m14:57:46.082704 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 14:57:46.073333 => 14:57:46.081667
[0m14:57:46.083666 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m14:57:46.127294 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.128412 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: BEGIN
[0m14:57:46.128923 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:57:46.330907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:46.331934 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.332655 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:57:46.397311 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:57:46.431276 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.432277 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

        
  
    

  create temporary table "scd_raw_listings__dbt_tmp145746413072"
  
  
    as
  
  (
    with snapshot_query as (

        



SELECT
    *
FROM
    "inttegra_stage"."test"."raw_listings"


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "inttegra_stage"."test"."scd_raw_listings"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    deletes_source_data as (

        select
            *,
            id as dbt_unique_key
        from snapshot_query
    ),
    

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    ),

    deletes as (

        select
            'delete' as dbt_change_type,
            source_data.*,
            now()::timestamp without time zone as dbt_valid_from,
            now()::timestamp without time zone as dbt_updated_at,
            now()::timestamp without time zone as dbt_valid_to,
            snapshotted_data.dbt_scd_id

        from snapshotted_data
        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where source_data.dbt_unique_key is null
    )

    select * from insertions
    union all
    select * from updates
    union all
    select * from deletes

  );
  
    
[0m14:57:46.716861 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m14:57:46.720062 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.721059 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145746413072'
        
      order by ordinal_position

  
[0m14:57:46.761756 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:57:46.768838 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.769840 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:57:46.810127 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:57:46.814634 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.815642 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145746413072'
        
      order by ordinal_position

  
[0m14:57:46.856433 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:57:46.861510 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.861947 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:57:46.903164 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:57:46.909822 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.909822 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145746413072'
        
      order by ordinal_position

  
[0m14:57:46.952998 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:57:46.959056 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.961026 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.962024 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      update "inttegra_stage"."test"."scd_raw_listings"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "scd_raw_listings__dbt_tmp145746413072" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "inttegra_stage"."test"."scd_raw_listings".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "inttegra_stage"."test"."scd_raw_listings".dbt_valid_to is null;

    insert into "inttegra_stage"."test"."scd_raw_listings" ("id", "listing_url", "name", "room_type", "minimum_nights", "host_id", "price", "created_at", "updated_at", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."id",DBT_INTERNAL_SOURCE."listing_url",DBT_INTERNAL_SOURCE."name",DBT_INTERNAL_SOURCE."room_type",DBT_INTERNAL_SOURCE."minimum_nights",DBT_INTERNAL_SOURCE."host_id",DBT_INTERNAL_SOURCE."price",DBT_INTERNAL_SOURCE."created_at",DBT_INTERNAL_SOURCE."updated_at",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "scd_raw_listings__dbt_tmp145746413072" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
[0m14:57:46.995435 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m14:57:47.008680 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:57:47.009642 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:47.010643 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:57:47.041936 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:47.044937 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 14:57:46.083666 => 14:57:47.044937
[0m14:57:47.045936 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: Close
[0m14:57:47.046938 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC145EF10>]}
[0m14:57:47.047935 [info ] [Thread-1 (]: 1 of 1 OK snapshotted test.scd_raw_listings .................................... [[32mINSERT 0 0[0m in 0.98s]
[0m14:57:47.048938 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m14:57:47.049938 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:47.050936 [debug] [MainThread]: On master: BEGIN
[0m14:57:47.050936 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:57:47.247434 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:47.248216 [debug] [MainThread]: On master: COMMIT
[0m14:57:47.249243 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:47.249243 [debug] [MainThread]: On master: COMMIT
[0m14:57:47.277805 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:47.278849 [debug] [MainThread]: On master: Close
[0m14:57:47.279839 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:57:47.279839 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:57:47.280807 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:57:47.281351 [debug] [MainThread]: Connection 'snapshot.dbtlearn.scd_raw_listings' was properly closed.
[0m14:57:47.281351 [info ] [MainThread]: 
[0m14:57:47.282358 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 3.29 seconds (3.29s).
[0m14:57:47.283079 [debug] [MainThread]: Command end result
[0m14:57:47.292086 [info ] [MainThread]: 
[0m14:57:47.293084 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:57:47.294427 [info ] [MainThread]: 
[0m14:57:47.295430 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:57:47.297429 [debug] [MainThread]: Command `dbt snapshot` succeeded at 14:57:47.296429 after 3.87 seconds
[0m14:57:47.297429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1492550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDBA4F1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDBA7DFED0>]}
[0m14:57:47.298426 [debug] [MainThread]: Flushing usage events
[0m14:59:34.146827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB022B210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFD73050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFD721D0>]}


============================== 14:59:34.153672 | 43af5a71-87bc-4486-8586-30aa901cd0a6 ==============================
[0m14:59:34.153672 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:59:34.154671 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt snapshot', 'send_anonymous_usage_stats': 'True'}
[0m14:59:34.429336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFB01D10>]}
[0m14:59:34.530473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFB01D10>]}
[0m14:59:34.533474 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:59:34.543299 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:59:34.653466 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:59:34.654466 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:59:34.663077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB05E7B50>]}
[0m14:59:34.734858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB0340350>]}
[0m14:59:34.735376 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:59:34.736999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB0281350>]}
[0m14:59:34.739661 [info ] [MainThread]: 
[0m14:59:34.741761 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:59:34.744968 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:59:34.760322 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:59:34.762016 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:59:34.762537 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:35.064852 [debug] [ThreadPool]: SQL status: SELECT 21 in 0.0 seconds
[0m14:59:35.064852 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:59:35.075933 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:59:35.080113 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:35.082118 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:59:35.082118 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:35.283251 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:59:35.285250 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:35.286250 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:59:35.339895 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m14:59:35.341437 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:59:35.437453 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:59:35.444648 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:35.445648 [debug] [MainThread]: On master: BEGIN
[0m14:59:35.445648 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:59:35.655322 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:35.656330 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:35.657377 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:59:35.723382 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:59:35.724413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB05A8790>]}
[0m14:59:35.725919 [debug] [MainThread]: On master: ROLLBACK
[0m14:59:35.761662 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:35.762797 [debug] [MainThread]: On master: BEGIN
[0m14:59:35.831222 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:35.831222 [debug] [MainThread]: On master: COMMIT
[0m14:59:35.832222 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:35.832222 [debug] [MainThread]: On master: COMMIT
[0m14:59:35.867656 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:35.868462 [debug] [MainThread]: On master: Close
[0m14:59:35.868462 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:59:35.870001 [info ] [MainThread]: 
[0m14:59:35.875206 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m14:59:35.876205 [info ] [Thread-1 (]: 1 of 1 START snapshot test.scd_raw_listings .................................... [RUN]
[0m14:59:35.877206 [debug] [Thread-1 (]: Acquiring new postgres connection 'snapshot.dbtlearn.scd_raw_listings'
[0m14:59:35.878206 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m14:59:35.884868 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 14:59:35.879207 => 14:59:35.884868
[0m14:59:35.884868 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m14:59:35.932900 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:35.933882 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: BEGIN
[0m14:59:35.933882 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:59:36.132746 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:36.134252 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.134774 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:59:36.196371 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:59:36.227360 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.228360 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

        
  
    

  create temporary table "scd_raw_listings__dbt_tmp145936208956"
  
  
    as
  
  (
    with snapshot_query as (

        



SELECT
    *
FROM
    "inttegra_stage"."test"."raw_listings"


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "inttegra_stage"."test"."scd_raw_listings"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    deletes_source_data as (

        select
            *,
            id as dbt_unique_key
        from snapshot_query
    ),
    

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    ),

    deletes as (

        select
            'delete' as dbt_change_type,
            source_data.*,
            now()::timestamp without time zone as dbt_valid_from,
            now()::timestamp without time zone as dbt_updated_at,
            now()::timestamp without time zone as dbt_valid_to,
            snapshotted_data.dbt_scd_id

        from snapshotted_data
        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where source_data.dbt_unique_key is null
    )

    select * from insertions
    union all
    select * from updates
    union all
    select * from deletes

  );
  
    
[0m14:59:36.593932 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m14:59:36.596936 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.597943 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145936208956'
        
      order by ordinal_position

  
[0m14:59:36.642265 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:59:36.646295 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.646295 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:59:36.688673 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:59:36.692685 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.693672 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145936208956'
        
      order by ordinal_position

  
[0m14:59:36.733674 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:59:36.736696 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.737696 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:59:36.776898 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:59:36.783364 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.784460 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145936208956'
        
      order by ordinal_position

  
[0m14:59:36.829723 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:59:36.837698 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.840700 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.841700 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      update "inttegra_stage"."test"."scd_raw_listings"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "scd_raw_listings__dbt_tmp145936208956" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "inttegra_stage"."test"."scd_raw_listings".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "inttegra_stage"."test"."scd_raw_listings".dbt_valid_to is null;

    insert into "inttegra_stage"."test"."scd_raw_listings" ("id", "listing_url", "name", "room_type", "minimum_nights", "host_id", "price", "created_at", "updated_at", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."id",DBT_INTERNAL_SOURCE."listing_url",DBT_INTERNAL_SOURCE."name",DBT_INTERNAL_SOURCE."room_type",DBT_INTERNAL_SOURCE."minimum_nights",DBT_INTERNAL_SOURCE."host_id",DBT_INTERNAL_SOURCE."price",DBT_INTERNAL_SOURCE."created_at",DBT_INTERNAL_SOURCE."updated_at",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "scd_raw_listings__dbt_tmp145936208956" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
[0m14:59:36.874170 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m14:59:36.892198 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:59:36.893205 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.893205 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:59:36.927146 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:36.931919 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 14:59:35.884868 => 14:59:36.931387
[0m14:59:36.932974 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: Close
[0m14:59:36.934865 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB0281E50>]}
[0m14:59:36.936509 [info ] [Thread-1 (]: 1 of 1 OK snapshotted test.scd_raw_listings .................................... [[32mINSERT 0 0[0m in 1.06s]
[0m14:59:36.938108 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m14:59:36.940756 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:36.941815 [debug] [MainThread]: On master: BEGIN
[0m14:59:36.943507 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:59:37.146427 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:37.147431 [debug] [MainThread]: On master: COMMIT
[0m14:59:37.147431 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:37.148423 [debug] [MainThread]: On master: COMMIT
[0m14:59:37.175355 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:37.176118 [debug] [MainThread]: On master: Close
[0m14:59:37.177115 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:59:37.178114 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:59:37.178114 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:59:37.179114 [debug] [MainThread]: Connection 'snapshot.dbtlearn.scd_raw_listings' was properly closed.
[0m14:59:37.179114 [info ] [MainThread]: 
[0m14:59:37.180624 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 2.44 seconds (2.44s).
[0m14:59:37.181014 [debug] [MainThread]: Command end result
[0m14:59:37.190054 [info ] [MainThread]: 
[0m14:59:37.191020 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:59:37.192534 [info ] [MainThread]: 
[0m14:59:37.193051 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:59:37.194471 [debug] [MainThread]: Command `dbt snapshot` succeeded at 14:59:37.194471 after 3.15 seconds
[0m14:59:37.195473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAA8AB1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFA82150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAA8DAEF90>]}
[0m14:59:37.196471 [debug] [MainThread]: Flushing usage events
[0m15:01:23.607937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000217133591D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000217118CCA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021712E51D50>]}


============================== 15:01:23.612439 | eea3cbc2-1a36-4459-944e-f85e66c64459 ==============================
[0m15:01:23.612439 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:01:23.613383 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt snapshot', 'send_anonymous_usage_stats': 'True'}
[0m15:01:23.824843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713378390>]}
[0m15:01:23.902353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713058DD0>]}
[0m15:01:23.904031 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:01:23.913248 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:01:23.999472 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:01:23.999472 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:01:24.005477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002171335BFD0>]}
[0m15:01:24.057280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002171349F1D0>]}
[0m15:01:24.057835 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:01:24.058838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713433150>]}
[0m15:01:24.059838 [info ] [MainThread]: 
[0m15:01:24.060939 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:01:24.062609 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:01:24.074497 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:01:24.075495 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:01:24.076490 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:01:25.384502 [debug] [ThreadPool]: SQL status: SELECT 23 in 1.0 seconds
[0m15:01:25.389847 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:01:25.393662 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:01:25.403098 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:01:25.404075 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:01:25.404075 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:01:25.611872 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:01:25.613059 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:01:25.614042 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:01:25.663992 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:01:25.666084 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:01:25.696157 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:01:25.704724 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:25.704724 [debug] [MainThread]: On master: BEGIN
[0m15:01:25.704724 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:01:25.935057 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:01:25.935814 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:25.936809 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:01:25.992241 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:01:25.993511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713706C10>]}
[0m15:01:25.993511 [debug] [MainThread]: On master: ROLLBACK
[0m15:01:26.034364 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:26.035288 [debug] [MainThread]: On master: BEGIN
[0m15:01:26.097375 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:01:26.098387 [debug] [MainThread]: On master: COMMIT
[0m15:01:26.098387 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:26.099391 [debug] [MainThread]: On master: COMMIT
[0m15:01:26.126767 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:01:26.128274 [debug] [MainThread]: On master: Close
[0m15:01:26.129314 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:01:26.130280 [info ] [MainThread]: 
[0m15:01:26.133569 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m15:01:26.133569 [info ] [Thread-1 (]: 1 of 1 START snapshot test.scd_raw_listings .................................... [RUN]
[0m15:01:26.135573 [debug] [Thread-1 (]: Acquiring new postgres connection 'snapshot.dbtlearn.scd_raw_listings'
[0m15:01:26.136569 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m15:01:26.145750 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 15:01:26.136569 => 15:01:26.145750
[0m15:01:26.146740 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m15:01:26.193986 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.193986 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: BEGIN
[0m15:01:26.194990 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:01:26.388867 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:01:26.390310 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.390310 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:01:26.455599 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m15:01:26.485616 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.485616 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

        
  
    

  create temporary table "scd_raw_listings__dbt_tmp150126468360"
  
  
    as
  
  (
    with snapshot_query as (

        



SELECT
    *
FROM
    "inttegra_stage"."test"."raw_listings"


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "inttegra_stage"."test"."scd_raw_listings"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    deletes_source_data as (

        select
            *,
            id as dbt_unique_key
        from snapshot_query
    ),
    

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    ),

    deletes as (

        select
            'delete' as dbt_change_type,
            source_data.*,
            now()::timestamp without time zone as dbt_valid_from,
            now()::timestamp without time zone as dbt_updated_at,
            now()::timestamp without time zone as dbt_valid_to,
            snapshotted_data.dbt_scd_id

        from snapshotted_data
        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where source_data.dbt_unique_key is null
    )

    select * from insertions
    union all
    select * from updates
    union all
    select * from deletes

  );
  
    
[0m15:01:26.776747 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m15:01:26.780744 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.780744 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp150126468360'
        
      order by ordinal_position

  
[0m15:01:26.825849 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m15:01:26.831816 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.833331 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:01:26.873217 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m15:01:26.876347 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.877347 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp150126468360'
        
      order by ordinal_position

  
[0m15:01:26.922914 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m15:01:26.926914 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.926914 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:01:26.967288 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m15:01:26.974285 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.975285 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp150126468360'
        
      order by ordinal_position

  
[0m15:01:27.020712 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m15:01:27.027226 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:27.028227 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:27.029226 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      update "inttegra_stage"."test"."scd_raw_listings"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "scd_raw_listings__dbt_tmp150126468360" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "inttegra_stage"."test"."scd_raw_listings".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "inttegra_stage"."test"."scd_raw_listings".dbt_valid_to is null;

    insert into "inttegra_stage"."test"."scd_raw_listings" ("id", "listing_url", "name", "room_type", "minimum_nights", "host_id", "price", "created_at", "updated_at", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."id",DBT_INTERNAL_SOURCE."listing_url",DBT_INTERNAL_SOURCE."name",DBT_INTERNAL_SOURCE."room_type",DBT_INTERNAL_SOURCE."minimum_nights",DBT_INTERNAL_SOURCE."host_id",DBT_INTERNAL_SOURCE."price",DBT_INTERNAL_SOURCE."created_at",DBT_INTERNAL_SOURCE."updated_at",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "scd_raw_listings__dbt_tmp150126468360" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
[0m15:01:27.076295 [debug] [Thread-1 (]: SQL status: INSERT 0 1 in 0.0 seconds
[0m15:01:27.089000 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m15:01:27.090002 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:27.090986 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m15:01:27.121687 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:01:27.125149 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 15:01:26.146740 => 15:01:27.125149
[0m15:01:27.126149 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: Close
[0m15:01:27.127118 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002171354F850>]}
[0m15:01:27.128117 [info ] [Thread-1 (]: 1 of 1 OK snapshotted test.scd_raw_listings .................................... [[32mINSERT 0 1[0m in 0.99s]
[0m15:01:27.130002 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m15:01:27.131003 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:27.132005 [debug] [MainThread]: On master: BEGIN
[0m15:01:27.132005 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:01:27.341858 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:01:27.343045 [debug] [MainThread]: On master: COMMIT
[0m15:01:27.343045 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:27.344005 [debug] [MainThread]: On master: COMMIT
[0m15:01:27.376192 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:01:27.376192 [debug] [MainThread]: On master: Close
[0m15:01:27.376192 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:01:27.376192 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:01:27.376192 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:01:27.376192 [debug] [MainThread]: Connection 'snapshot.dbtlearn.scd_raw_listings' was properly closed.
[0m15:01:27.376192 [info ] [MainThread]: 
[0m15:01:27.382481 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 3.32 seconds (3.32s).
[0m15:01:27.382481 [debug] [MainThread]: Command end result
[0m15:01:27.387099 [info ] [MainThread]: 
[0m15:01:27.387099 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:01:27.395325 [info ] [MainThread]: 
[0m15:01:27.396099 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:01:27.398175 [debug] [MainThread]: Command `dbt snapshot` succeeded at 15:01:27.398175 after 3.85 seconds
[0m15:01:27.398690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002170BB81010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021712B484D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713606690>]}
[0m15:01:27.398690 [debug] [MainThread]: Flushing usage events
[0m15:17:47.363328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F5023D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F4FB110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69ED507D0>]}


============================== 15:17:47.363328 | e202945e-6920-412f-a248-e550b8e0caf3 ==============================
[0m15:17:47.363328 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:17:47.363328 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:17:47.602660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F716150>]}
[0m15:17:47.690833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69ED39190>]}
[0m15:17:47.690833 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:17:47.699126 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:17:47.795880 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m15:17:47.795880 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\schema.yml
[0m15:17:47.987238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F041010>]}
[0m15:17:48.000505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F8F9010>]}
[0m15:17:48.000505 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 2 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:17:48.000505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F041010>]}
[0m15:17:48.007326 [info ] [MainThread]: 
[0m15:17:48.007326 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:17:48.012719 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:17:48.020773 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:17:48.022778 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:17:48.023282 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:17:49.345993 [debug] [ThreadPool]: SQL status: SELECT 25 in 1.0 seconds
[0m15:17:49.353227 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:17:49.353227 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:17:49.361301 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:17:49.361301 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:17:49.361301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:17:49.566422 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:17:49.566422 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:17:49.567421 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:17:49.615645 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:17:49.619644 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:17:49.649511 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:17:49.658584 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:49.660099 [debug] [MainThread]: On master: BEGIN
[0m15:17:49.662099 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:17:49.878451 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:17:49.880474 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:49.881476 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:17:49.943917 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:17:49.946408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F9FB250>]}
[0m15:17:49.947542 [debug] [MainThread]: On master: ROLLBACK
[0m15:17:49.977658 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:49.978675 [debug] [MainThread]: On master: BEGIN
[0m15:17:50.037823 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:17:50.038503 [debug] [MainThread]: On master: COMMIT
[0m15:17:50.039528 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:50.039528 [debug] [MainThread]: On master: COMMIT
[0m15:17:50.072874 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:17:50.073877 [debug] [MainThread]: On master: Close
[0m15:17:50.074873 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:17:50.075873 [info ] [MainThread]: 
[0m15:17:50.078377 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:17:50.080055 [info ] [Thread-1 (]: 1 of 8 START sql view model test.src_hosts ..................................... [RUN]
[0m15:17:50.082063 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:17:50.083067 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:17:50.092141 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:17:50.095154 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:17:50.083067 => 15:17:50.094137
[0m15:17:50.096140 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:17:50.139372 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:17:50.140928 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.140928 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:17:50.141973 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:17:50.329250 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:50.330826 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.331778 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		"inttegra_stage"."test"."raw_hosts" rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:17:50.366703 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:17:50.373287 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.373287 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:17:50.411621 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:50.415140 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.416245 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:17:50.446756 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:50.462945 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:17:50.463485 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.463485 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:17:50.494710 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:50.500733 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:17:50.505733 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.506733 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:17:50.548514 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:17:50.550487 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:17:50.097143 => 15:17:50.549486
[0m15:17:50.550487 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:17:50.551486 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69EDD41D0>]}
[0m15:17:50.552487 [info ] [Thread-1 (]: 1 of 8 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.47s]
[0m15:17:50.553490 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:17:50.554489 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:17:50.555485 [info ] [Thread-1 (]: 2 of 8 START sql view model test.src_listings .................................. [RUN]
[0m15:17:50.556488 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:17:50.557487 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:17:50.560417 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:17:50.561924 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:17:50.557487 => 15:17:50.561924
[0m15:17:50.562924 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:17:50.566924 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:17:50.567925 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:50.568925 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:17:50.568925 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:50.968846 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:50.969358 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:50.970362 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."test"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:17:51.019318 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:17:51.026317 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:51.027822 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:17:51.059325 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.062325 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:51.063830 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:17:51.094916 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.096912 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:17:51.097912 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:51.097912 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:17:51.130128 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:51.133162 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:17:51.134162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:51.134162 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:17:51.167702 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:17:51.170163 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:17:50.562924 => 15:17:51.169157
[0m15:17:51.170163 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:17:51.171163 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F9B6B10>]}
[0m15:17:51.172163 [info ] [Thread-1 (]: 2 of 8 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.61s]
[0m15:17:51.173677 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:17:51.173677 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:17:51.174676 [info ] [Thread-1 (]: 3 of 8 START sql view model test.src_reviews ................................... [RUN]
[0m15:17:51.175676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:17:51.176679 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:17:51.179676 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:17:51.182185 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:17:51.176679 => 15:17:51.181679
[0m15:17:51.183193 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:17:51.190583 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:17:51.192580 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.193583 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:17:51.194580 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:51.400540 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:51.401752 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.402756 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT 
		*
	FROM
		"inttegra_stage"."test"."raw_reviews" rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:17:51.450956 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:17:51.454921 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.454921 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:17:51.486946 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.489943 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.490939 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:17:51.523873 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.525874 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:17:51.526873 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.527872 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:17:51.561019 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:51.564016 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:17:51.564978 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.564978 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:17:51.599294 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:17:51.601326 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:17:51.183193 => 15:17:51.600294
[0m15:17:51.601326 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:17:51.603326 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69FB5A990>]}
[0m15:17:51.603326 [info ] [Thread-1 (]: 3 of 8 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.43s]
[0m15:17:51.604832 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:17:51.604832 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:17:51.606233 [info ] [Thread-1 (]: 4 of 8 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:17:51.607233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:17:51.608232 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:17:51.611233 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.612232 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:17:51.608232 => 15:17:51.612232
[0m15:17:51.613232 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:17:51.639367 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.642413 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.643412 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:17:51.644411 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:51.847141 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:51.847141 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.848184 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:17:51.942512 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:17:51.945619 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.946617 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:17:51.978361 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.982371 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.983368 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:17:52.020101 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:52.027193 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:17:52.028195 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:52.028195 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:17:52.061451 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:52.064029 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:17:52.068030 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:52.069030 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:17:52.108381 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:17:52.110595 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:17:51.613232 => 15:17:52.109347
[0m15:17:52.110595 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:17:52.111597 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69FBE3590>]}
[0m15:17:52.112597 [info ] [Thread-1 (]: 4 of 8 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.50s]
[0m15:17:52.113597 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:17:52.114599 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:17:52.115596 [info ] [Thread-1 (]: 5 of 8 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:17:52.116597 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:17:52.116597 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:17:52.119595 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.121599 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:17:52.117596 => 15:17:52.120596
[0m15:17:52.121599 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:17:52.127092 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.131092 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.132093 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:17:52.133599 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:52.339610 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:52.340601 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.341608 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:17:52.496572 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:17:52.500606 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.501571 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:17:52.542003 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:52.546365 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.547365 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:17:52.577220 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:52.579641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:17:52.580641 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.581641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:17:52.611596 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:52.615102 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:17:52.616107 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.616107 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:17:52.659139 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:17:52.661147 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:17:52.122576 => 15:17:52.661147
[0m15:17:52.661147 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:17:52.662653 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69FBE2A90>]}
[0m15:17:52.663659 [info ] [Thread-1 (]: 5 of 8 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.55s]
[0m15:17:52.664665 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:17:52.665664 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:17:52.666664 [info ] [Thread-1 (]: 6 of 8 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:17:52.667665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m15:17:52.667665 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:17:52.676304 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:17:52.677982 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:17:52.667665 => 15:17:52.677982
[0m15:17:52.677982 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:17:52.713840 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:52.713840 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp151752706821"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m15:17:52.714847 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:53.924615 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m15:17:53.930807 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:53.931806 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:17:53.965018 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:53.966029 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:53.966029 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp151752706821'
        
      order by ordinal_position

  
[0m15:17:54.028753 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:17:54.036240 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.037212 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:17:54.079756 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:17:54.092770 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.093287 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp151752706821'
        
      order by ordinal_position

  
[0m15:17:54.133186 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:17:54.136178 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.137177 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:17:54.176964 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:17:54.185975 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m15:17:54.195748 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:17:54.197750 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.197750 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp151752706821"
    )


  
[0m15:17:54.230297 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m15:17:54.232303 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:17:54.233303 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.233303 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:17:54.266475 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:54.267516 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:17:52.678983 => 15:17:54.267516
[0m15:17:54.268507 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:17:54.269477 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F7F5E50>]}
[0m15:17:54.270475 [info ] [Thread-1 (]: 6 of 8 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.60s]
[0m15:17:54.271476 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:17:54.271476 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m15:17:54.273531 [info ] [Thread-1 (]: 7 of 8 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m15:17:54.275140 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m15:17:54.275140 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m15:17:54.278144 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.279146 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 15:17:54.276148 => 15:17:54.279146
[0m15:17:54.280146 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m15:17:54.284648 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.286015 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.287013 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m15:17:54.289016 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:54.541339 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:54.542348 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.543379 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m15:17:54.698575 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:17:54.701563 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.702568 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts" rename to "dim_listings_with_hosts__dbt_backup"
[0m15:17:54.733973 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:54.737013 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.738011 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m15:17:54.769020 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:54.771051 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m15:17:54.772051 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.773023 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m15:17:54.803133 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:54.806169 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m15:17:54.807168 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.808141 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m15:17:54.849975 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:17:54.851994 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 15:17:54.280146 => 15:17:54.851994
[0m15:17:54.852992 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m15:17:54.853992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69FB590D0>]}
[0m15:17:54.853992 [info ] [Thread-1 (]: 7 of 8 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 0.58s]
[0m15:17:54.854992 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m15:17:54.855993 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m15:17:54.856993 [info ] [Thread-1 (]: 8 of 8 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m15:17:54.857994 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m15:17:54.857994 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m15:17:54.861563 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:54.863003 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 15:17:54.859028 => 15:17:54.863003
[0m15:17:54.863003 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m15:17:54.868008 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:54.870010 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:54.870010 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m15:17:54.871015 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:55.063321 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:55.064115 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:55.065073 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_date IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m15:17:56.996701 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m15:17:56.999698 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:57.000700 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews" rename to "mart_fullmoon_reviews__dbt_backup"
[0m15:17:57.039173 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:57.042184 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:57.042184 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp" rename to "mart_fullmoon_reviews"
[0m15:17:57.073213 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:57.077343 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m15:17:57.077343 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:57.078308 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m15:17:57.127428 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:57.130463 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup"
[0m15:17:57.131461 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:57.132966 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
drop table if exists "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup" cascade
[0m15:17:57.220649 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:17:57.222688 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 15:17:54.864010 => 15:17:57.221657
[0m15:17:57.222688 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m15:17:57.223688 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69EDD41D0>]}
[0m15:17:57.224657 [info ] [Thread-1 (]: 8 of 8 OK created sql table model test.mart_fullmoon_reviews ................... [[32mSELECT 410284[0m in 2.37s]
[0m15:17:57.225656 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m15:17:57.227658 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:57.227658 [debug] [MainThread]: On master: BEGIN
[0m15:17:57.227658 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:17:57.435183 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:17:57.436413 [debug] [MainThread]: On master: COMMIT
[0m15:17:57.437459 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:57.437982 [debug] [MainThread]: On master: COMMIT
[0m15:17:57.467280 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:17:57.468323 [debug] [MainThread]: On master: Close
[0m15:17:57.469420 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:17:57.469946 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:17:57.470478 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:17:57.471029 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m15:17:57.472114 [info ] [MainThread]: 
[0m15:17:57.473756 [info ] [MainThread]: Finished running 3 view models, 4 table models, 1 incremental model in 0 hours 0 minutes and 9.46 seconds (9.46s).
[0m15:17:57.476436 [debug] [MainThread]: Command end result
[0m15:17:57.489498 [info ] [MainThread]: 
[0m15:17:57.491169 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:17:57.492832 [info ] [MainThread]: 
[0m15:17:57.494457 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m15:17:57.499321 [debug] [MainThread]: Command `dbt run` succeeded at 15:17:57.498796 after 10.20 seconds
[0m15:17:57.500427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69ED2F550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B697DE1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F0431D0>]}
[0m15:17:57.501478 [debug] [MainThread]: Flushing usage events
[0m15:18:07.608737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6DF44F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6D55A890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E360650>]}


============================== 15:18:07.618457 | 3238f417-bb71-4f51-9cfd-cb07d9f5638f ==============================
[0m15:18:07.618457 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:18:07.622222 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt test', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:18:07.964976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6DE72710>]}
[0m15:18:08.046806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E375510>]}
[0m15:18:08.058286 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:18:08.060428 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:18:08.171031 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:18:08.171031 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:18:08.174032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E73D8D0>]}
[0m15:18:08.238575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E3A1A10>]}
[0m15:18:08.239146 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 2 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:18:08.239146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E6D3E50>]}
[0m15:18:08.239146 [info ] [MainThread]: 
[0m15:18:08.239146 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:18:08.244437 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:18:08.257083 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:18:08.257083 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:18:08.257083 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:18:09.548906 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:18:09.548906 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:18:09.548906 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:18:09.597413 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:18:09.599476 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:18:09.628441 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:18:09.633103 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:09.633103 [debug] [MainThread]: On master: BEGIN
[0m15:18:09.633103 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:18:09.849002 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:09.849002 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:09.849002 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:18:09.908621 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:18:09.908621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E5D6D90>]}
[0m15:18:09.908621 [debug] [MainThread]: On master: ROLLBACK
[0m15:18:09.932478 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:09.932478 [debug] [MainThread]: On master: BEGIN
[0m15:18:09.992588 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:09.992588 [debug] [MainThread]: On master: COMMIT
[0m15:18:09.992588 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:10.002704 [debug] [MainThread]: On master: COMMIT
[0m15:18:10.028599 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:10.028599 [debug] [MainThread]: On master: Close
[0m15:18:10.034636 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:18:10.034636 [info ] [MainThread]: 
[0m15:18:10.040511 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9
[0m15:18:10.041487 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_listings_cleansed_listing_id .................... [RUN]
[0m15:18:10.041487 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9'
[0m15:18:10.041487 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9
[0m15:18:10.067442 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"
[0m15:18:10.071211 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9 (compile): 15:18:10.041487 => 15:18:10.071211
[0m15:18:10.071211 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9
[0m15:18:10.088572 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"
[0m15:18:10.090919 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"
[0m15:18:10.090919 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9: BEGIN
[0m15:18:10.090919 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:18:10.283796 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:10.283796 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"
[0m15:18:10.283796 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listing_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where listing_id is null



      
    ) dbt_internal_test
[0m15:18:10.317349 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "listing_id" does not exist
LINE 13: select listing_id
                ^

[0m15:18:10.317349 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9: ROLLBACK
[0m15:18:10.353730 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9 (execute): 15:18:10.071211 => 15:18:10.353730
[0m15:18:10.353730 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9: Close
[0m15:18:10.376962 [debug] [Thread-1 (]: Database Error in test not_null_dim_listings_cleansed_listing_id (dbtlearn/models\schema.yml)
  column "listing_id" does not exist
  LINE 13: select listing_id
                  ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\not_null_dim_listings_cleansed_listing_id.sql
[0m15:18:10.376962 [error] [Thread-1 (]: 1 of 2 ERROR not_null_dim_listings_cleansed_listing_id ......................... [[31mERROR[0m in 0.34s]
[0m15:18:10.376962 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9
[0m15:18:10.382550 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e
[0m15:18:10.382550 [info ] [Thread-1 (]: 2 of 2 START test unique_dim_listings_cleansed_listing_id ...................... [RUN]
[0m15:18:10.382550 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9, now test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e)
[0m15:18:10.382550 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e
[0m15:18:10.390024 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"
[0m15:18:10.393650 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e (compile): 15:18:10.382550 => 15:18:10.392728
[0m15:18:10.393650 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e
[0m15:18:10.398021 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"
[0m15:18:10.398021 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"
[0m15:18:10.401219 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e: BEGIN
[0m15:18:10.402158 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:18:10.594644 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:10.594644 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"
[0m15:18:10.594644 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    listing_id as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where listing_id is not null
group by listing_id
having count(*) > 1



      
    ) dbt_internal_test
[0m15:18:10.635137 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "listing_id" does not exist
LINE 12:     listing_id as unique_field,
             ^

[0m15:18:10.636176 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e: ROLLBACK
[0m15:18:10.665711 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e (execute): 15:18:10.395157 => 15:18:10.665711
[0m15:18:10.667477 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e: Close
[0m15:18:10.670745 [debug] [Thread-1 (]: Database Error in test unique_dim_listings_cleansed_listing_id (dbtlearn/models\schema.yml)
  column "listing_id" does not exist
  LINE 12:     listing_id as unique_field,
               ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\unique_dim_listings_cleansed_listing_id.sql
[0m15:18:10.671149 [error] [Thread-1 (]: 2 of 2 ERROR unique_dim_listings_cleansed_listing_id ........................... [[31mERROR[0m in 0.29s]
[0m15:18:10.672849 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e
[0m15:18:10.675960 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:10.675960 [debug] [MainThread]: On master: BEGIN
[0m15:18:10.679834 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:18:10.878550 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:10.878887 [debug] [MainThread]: On master: COMMIT
[0m15:18:10.878887 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:10.879911 [debug] [MainThread]: On master: COMMIT
[0m15:18:10.906125 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:10.906125 [debug] [MainThread]: On master: Close
[0m15:18:10.910343 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:18:10.910343 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:18:10.911514 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e' was properly closed.
[0m15:18:10.911514 [info ] [MainThread]: 
[0m15:18:10.912418 [info ] [MainThread]: Finished running 2 tests in 0 hours 0 minutes and 2.67 seconds (2.67s).
[0m15:18:10.913424 [debug] [MainThread]: Command end result
[0m15:18:10.925152 [info ] [MainThread]: 
[0m15:18:10.925152 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m15:18:10.925152 [info ] [MainThread]: 
[0m15:18:10.929727 [error] [MainThread]:   Database Error in test not_null_dim_listings_cleansed_listing_id (dbtlearn/models\schema.yml)
  column "listing_id" does not exist
  LINE 13: select listing_id
                  ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\not_null_dim_listings_cleansed_listing_id.sql
[0m15:18:10.930762 [info ] [MainThread]: 
[0m15:18:10.932774 [error] [MainThread]:   Database Error in test unique_dim_listings_cleansed_listing_id (dbtlearn/models\schema.yml)
  column "listing_id" does not exist
  LINE 12:     listing_id as unique_field,
               ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\unique_dim_listings_cleansed_listing_id.sql
[0m15:18:10.934142 [info ] [MainThread]: 
[0m15:18:10.937905 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=0 TOTAL=2
[0m15:18:10.940625 [debug] [MainThread]: Command `dbt test` failed at 15:18:10.939907 after 3.45 seconds
[0m15:18:10.940625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B66C21010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6DB36AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6DC27F50>]}
[0m15:18:10.942134 [debug] [MainThread]: Flushing usage events
[0m15:18:51.725151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0F36010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0FC5E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0E80C90>]}


============================== 15:18:51.730167 | ac8ab8d3-159f-417f-baa1-6dfb43beb8bb ==============================
[0m15:18:51.730167 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:18:51.731673 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt test', 'send_anonymous_usage_stats': 'True'}
[0m15:18:51.951587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0C61550>]}
[0m15:18:52.033040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F14585D0>]}
[0m15:18:52.033040 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:18:52.039591 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:18:52.132451 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:18:52.133451 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:18:52.483094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F16E0D50>]}
[0m15:18:52.498087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F17DC650>]}
[0m15:18:52.498087 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 2 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:18:52.499116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F1A0E710>]}
[0m15:18:52.501585 [info ] [MainThread]: 
[0m15:18:52.502180 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:18:52.504180 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:18:52.513008 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:18:52.513008 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:18:52.513008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:18:53.810737 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:18:53.812168 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:18:53.813168 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:18:53.864315 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:18:53.864315 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:18:53.895227 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:18:53.909833 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:53.910843 [debug] [MainThread]: On master: BEGIN
[0m15:18:53.911842 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:18:54.121521 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:54.123029 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:54.123545 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:18:54.184761 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:18:54.187525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F1947490>]}
[0m15:18:54.187525 [debug] [MainThread]: On master: ROLLBACK
[0m15:18:54.219261 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:54.219261 [debug] [MainThread]: On master: BEGIN
[0m15:18:54.289990 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:54.289990 [debug] [MainThread]: On master: COMMIT
[0m15:18:54.291498 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:54.292016 [debug] [MainThread]: On master: COMMIT
[0m15:18:54.316511 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:54.316511 [debug] [MainThread]: On master: Close
[0m15:18:54.316511 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:18:54.316511 [info ] [MainThread]: 
[0m15:18:54.316511 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:18:54.316511 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:18:54.328569 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485'
[0m15:18:54.329082 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:18:54.346446 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:18:54.353595 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:18:54.329082 => 15:18:54.352781
[0m15:18:54.353595 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:18:54.369730 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:18:54.371626 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:18:54.373050 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:18:54.373050 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:18:54.585081 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:54.585609 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:18:54.586129 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:18:54.639869 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:18:54.641811 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:18:54.355689 => 15:18:54.641811
[0m15:18:54.641811 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:18:54.671285 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:18:54.672292 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.34s]
[0m15:18:54.673281 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:18:54.674279 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:18:54.675246 [info ] [Thread-1 (]: 2 of 2 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:18:54.676246 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:18:54.676751 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:18:54.682760 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:18:54.685741 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:18:54.677240 => 15:18:54.685096
[0m15:18:54.686771 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:18:54.688895 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:18:54.692472 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:18:54.694480 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:18:54.694480 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:18:54.894923 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:54.895956 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:18:54.895956 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:18:54.955871 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:18:54.965012 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:18:54.686771 => 15:18:54.965012
[0m15:18:54.965527 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:18:55.000685 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:18:55.002288 [info ] [Thread-1 (]: 2 of 2 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.33s]
[0m15:18:55.003294 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:18:55.004290 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:55.005324 [debug] [MainThread]: On master: BEGIN
[0m15:18:55.005324 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:18:55.202281 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:55.202281 [debug] [MainThread]: On master: COMMIT
[0m15:18:55.203463 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:55.203463 [debug] [MainThread]: On master: COMMIT
[0m15:18:55.240733 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:55.240733 [debug] [MainThread]: On master: Close
[0m15:18:55.242087 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:18:55.243307 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:18:55.243307 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:18:55.244273 [info ] [MainThread]: 
[0m15:18:55.245274 [info ] [MainThread]: Finished running 2 tests in 0 hours 0 minutes and 2.74 seconds (2.74s).
[0m15:18:55.245835 [debug] [MainThread]: Command end result
[0m15:18:55.255371 [info ] [MainThread]: 
[0m15:18:55.256375 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:18:55.257375 [info ] [MainThread]: 
[0m15:18:55.258390 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:18:55.260372 [debug] [MainThread]: Command `dbt test` succeeded at 15:18:55.260372 after 3.61 seconds
[0m15:18:55.261376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0F65190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0C43E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267E9FDFED0>]}
[0m15:18:55.263375 [debug] [MainThread]: Flushing usage events
[0m15:22:55.988212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D63B9C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D498C890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D63BA3D0>]}


============================== 15:22:55.991842 | f59ba261-d304-49a6-be80-447cb96c77d2 ==============================
[0m15:22:55.991842 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:22:55.992841 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt test', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:22:56.211016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f59ba261-d304-49a6-be80-447cb96c77d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D63BA710>]}
[0m15:22:56.291911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f59ba261-d304-49a6-be80-447cb96c77d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D6520690>]}
[0m15:22:56.293911 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:22:56.302945 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:22:56.421493 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:22:56.422499 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:22:56.746912 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in dbtlearn/models\schema.yml:
  	test definition dictionary must have exactly one key, got [('relationships', None), ('to', "ref('dim_hosts_cleansed')"), ('field', 'host_id')] instead (3 keys)
  	@: UnparsedModelUpdate(original_file_path='dbtl...ne)
[0m15:22:56.748911 [debug] [MainThread]: Command `dbt test` failed at 15:22:56.748911 after 0.83 seconds
[0m15:22:56.749913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D5EDB110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7CECA1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D640BA10>]}
[0m15:22:56.750914 [debug] [MainThread]: Flushing usage events
[0m15:23:51.783931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35FC8ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35F7B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35FC8410>]}


============================== 15:23:51.786961 | b61cfff0-db09-4e62-b270-79fc89ec2201 ==============================
[0m15:23:51.786961 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:23:51.788471 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt test', 'send_anonymous_usage_stats': 'True'}
[0m15:23:52.011234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b61cfff0-db09-4e62-b270-79fc89ec2201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35CC9490>]}
[0m15:23:52.087454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b61cfff0-db09-4e62-b270-79fc89ec2201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE3525AC50>]}
[0m15:23:52.090136 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:23:52.098789 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:23:52.186321 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:23:52.186321 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:23:52.485306 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in dbtlearn/models\schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['Entire home/apt', 'Private room', 'Shared room', 'Hotel room'])] instead (2 keys)
  	@: UnparsedModelUpdate(original_file_path='dbtl...ne)
[0m15:23:52.487628 [debug] [MainThread]: Command `dbt test` failed at 15:23:52.486390 after 0.77 seconds
[0m15:23:52.487628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35A90990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE2E82E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35FD1B10>]}
[0m15:23:52.488662 [debug] [MainThread]: Flushing usage events
[0m15:24:42.483487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4993AAB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EC0910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EC0A50>]}


============================== 15:24:42.487486 | dd119fc9-218b-42f3-b78b-491579cbb5c7 ==============================
[0m15:24:42.487486 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:24:42.487486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt test', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:24:42.708415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EF26D0>]}
[0m15:24:42.782346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F499510B50>]}
[0m15:24:42.782346 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:24:42.794356 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:24:42.892333 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:24:42.893300 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:24:43.204409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49AA49F50>]}
[0m15:24:43.214071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49AA770D0>]}
[0m15:24:43.214071 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 5 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:24:43.214071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49A9C3690>]}
[0m15:24:43.222491 [info ] [MainThread]: 
[0m15:24:43.222491 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:24:43.226786 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:24:43.238214 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:24:43.240247 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:24:43.241939 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:24:44.568948 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:24:44.569949 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:24:44.570948 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:24:44.620945 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:24:44.621952 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:24:44.648786 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:24:44.656835 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:44.656835 [debug] [MainThread]: On master: BEGIN
[0m15:24:44.657850 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:24:44.849899 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:24:44.849899 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:44.849899 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:24:44.917284 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:24:44.919323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49AA80790>]}
[0m15:24:44.919323 [debug] [MainThread]: On master: ROLLBACK
[0m15:24:44.950941 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:44.951975 [debug] [MainThread]: On master: BEGIN
[0m15:24:45.015355 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:24:45.015355 [debug] [MainThread]: On master: COMMIT
[0m15:24:45.018449 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:45.018449 [debug] [MainThread]: On master: COMMIT
[0m15:24:45.045562 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:24:45.046562 [debug] [MainThread]: On master: Close
[0m15:24:45.048535 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:24:45.049531 [info ] [MainThread]: 
[0m15:24:45.054008 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502
[0m15:24:45.055197 [info ] [Thread-1 (]: 1 of 5 START test accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:24:45.057209 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502'
[0m15:24:45.058195 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502
[0m15:24:45.069233 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"
[0m15:24:45.071227 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502 (compile): 15:24:45.058195 => 15:24:45.071227
[0m15:24:45.072226 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502
[0m15:24:45.094098 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"
[0m15:24:45.096106 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"
[0m15:24:45.096106 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502: BEGIN
[0m15:24:45.096106 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:24:45.295871 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:45.295871 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"
[0m15:24:45.295871 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        romm_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by romm_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:24:45.347753 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "romm_type" does not exist
LINE 14:         romm_type as value_field,
                 ^
HINT:  Perhaps you meant to reference the column "dim_listings_cleansed.room_type".

[0m15:24:45.348779 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502: ROLLBACK
[0m15:24:45.379294 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502 (execute): 15:24:45.073226 => 15:24:45.378697
[0m15:24:45.380301 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502: Close
[0m15:24:45.384300 [debug] [Thread-1 (]: Database Error in test accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room (dbtlearn/models\schema.yml)
  column "romm_type" does not exist
  LINE 14:         romm_type as value_field,
                   ^
  HINT:  Perhaps you meant to reference the column "dim_listings_cleansed.room_type".
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\accepted_values_dim_listings_c_b00575739adcaecd53bcd93ce8f6c13a.sql
[0m15:24:45.385335 [error] [Thread-1 (]: 1 of 5 ERROR accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[31mERROR[0m in 0.33s]
[0m15:24:45.386330 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502
[0m15:24:45.387300 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:24:45.388300 [info ] [Thread-1 (]: 2 of 5 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:24:45.389808 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:24:45.389808 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:24:45.396809 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:24:45.397813 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:24:45.390810 => 15:24:45.397813
[0m15:24:45.398812 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:24:45.401357 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:24:45.403566 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:24:45.403566 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:24:45.404601 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:24:45.593903 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:45.593903 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:24:45.593903 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:24:45.656803 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:24:45.659846 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:24:45.399818 => 15:24:45.658814
[0m15:24:45.659846 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:24:45.692223 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:24:45.693384 [info ] [Thread-1 (]: 2 of 5 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.30s]
[0m15:24:45.694364 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:24:45.695374 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:24:45.696360 [info ] [Thread-1 (]: 3 of 5 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:24:45.697374 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:24:45.697374 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:24:45.701912 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:24:45.703987 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:24:45.698340 => 15:24:45.702981
[0m15:24:45.703987 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:24:45.706987 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:24:45.708986 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:24:45.709990 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:24:45.710987 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:24:45.934061 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:45.935023 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:24:45.936021 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:24:45.986561 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:24:45.987572 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:24:45.704988 => 15:24:45.987572
[0m15:24:45.988567 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:24:46.020273 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:24:46.021279 [info ] [Thread-1 (]: 3 of 5 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.32s]
[0m15:24:46.022278 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:24:46.023315 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:24:46.024068 [info ] [Thread-1 (]: 4 of 5 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:24:46.025073 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:24:46.025073 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:24:46.030106 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:24:46.032106 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:24:46.026578 => 15:24:46.032106
[0m15:24:46.033107 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:24:46.037106 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:24:46.038611 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:24:46.039170 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:24:46.040183 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:24:46.245648 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:46.246201 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:24:46.246753 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:24:46.320962 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:24:46.322604 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:24:46.033107 => 15:24:46.322604
[0m15:24:46.323604 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:24:46.354787 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:24:46.356577 [info ] [Thread-1 (]: 4 of 5 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.33s]
[0m15:24:46.357544 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:24:46.357544 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:24:46.358543 [info ] [Thread-1 (]: 5 of 5 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:24:46.359542 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:24:46.360543 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:24:46.365829 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:24:46.368179 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:24:46.360543 => 15:24:46.366828
[0m15:24:46.368179 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:24:46.371178 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:24:46.372179 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:24:46.373180 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:24:46.373180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:24:46.568234 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:46.569242 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:24:46.569242 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:24:46.639630 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:24:46.640978 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:24:46.369179 => 15:24:46.640978
[0m15:24:46.642028 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:24:46.667597 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:24:46.674043 [info ] [Thread-1 (]: 5 of 5 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.31s]
[0m15:24:46.676726 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:24:46.678545 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:46.678545 [debug] [MainThread]: On master: BEGIN
[0m15:24:46.679543 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:24:46.875018 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:24:46.876017 [debug] [MainThread]: On master: COMMIT
[0m15:24:46.877016 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:46.878016 [debug] [MainThread]: On master: COMMIT
[0m15:24:46.904890 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:24:46.905537 [debug] [MainThread]: On master: Close
[0m15:24:46.906555 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:24:46.906555 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:24:46.907578 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:24:46.908578 [info ] [MainThread]: 
[0m15:24:46.909544 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 3.69 seconds (3.69s).
[0m15:24:46.910548 [debug] [MainThread]: Command end result
[0m15:24:46.920062 [info ] [MainThread]: 
[0m15:24:46.921061 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:24:46.922061 [info ] [MainThread]: 
[0m15:24:46.924061 [error] [MainThread]:   Database Error in test accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room (dbtlearn/models\schema.yml)
  column "romm_type" does not exist
  LINE 14:         romm_type as value_field,
                   ^
  HINT:  Perhaps you meant to reference the column "dim_listings_cleansed.room_type".
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\accepted_values_dim_listings_c_b00575739adcaecd53bcd93ce8f6c13a.sql
[0m15:24:46.925059 [info ] [MainThread]: 
[0m15:24:46.926059 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m15:24:46.928631 [debug] [MainThread]: Command `dbt test` failed at 15:24:46.928212 after 4.51 seconds
[0m15:24:46.929643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F491C11010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EC0910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EC0A50>]}
[0m15:24:46.930642 [debug] [MainThread]: Flushing usage events
[0m15:25:21.392608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D2D2C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2CAE18D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D2EBFD0>]}


============================== 15:25:21.397607 | f0f2351d-9afc-4226-8124-fe7e4afd72a1 ==============================
[0m15:25:21.397607 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:25:21.398607 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt test', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:25:21.708143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2CDF8450>]}
[0m15:25:21.816150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D0D5090>]}
[0m15:25:21.818147 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:25:21.833141 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:25:21.982245 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:25:21.983244 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:25:22.359017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2E90B3D0>]}
[0m15:25:22.385592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D498150>]}
[0m15:25:22.385592 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 5 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:25:22.387831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2E8FA350>]}
[0m15:25:22.390958 [info ] [MainThread]: 
[0m15:25:22.393765 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:25:22.396774 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:25:22.414149 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:25:22.415348 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:25:22.416339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:25:22.719895 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:25:22.720900 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:25:22.721900 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:25:22.771526 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:25:22.775588 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:25:22.798492 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:25:22.811389 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:22.811389 [debug] [MainThread]: On master: BEGIN
[0m15:25:22.811389 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:25:23.016973 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:25:23.017995 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:23.018975 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:25:23.081923 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:25:23.086132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D7AC610>]}
[0m15:25:23.086643 [debug] [MainThread]: On master: ROLLBACK
[0m15:25:23.117882 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:23.118885 [debug] [MainThread]: On master: BEGIN
[0m15:25:23.181951 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:25:23.182494 [debug] [MainThread]: On master: COMMIT
[0m15:25:23.183540 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:23.184497 [debug] [MainThread]: On master: COMMIT
[0m15:25:23.213159 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:25:23.214161 [debug] [MainThread]: On master: Close
[0m15:25:23.215159 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:25:23.216159 [info ] [MainThread]: 
[0m15:25:23.221245 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:25:23.223241 [info ] [Thread-1 (]: 1 of 5 START test accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:25:23.224932 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af'
[0m15:25:23.226928 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:25:23.243488 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:25:23.259238 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 15:25:23.227930 => 15:25:23.251494
[0m15:25:23.267117 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:25:23.300762 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:25:23.305295 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:25:23.306292 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: BEGIN
[0m15:25:23.307293 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:25:23.535680 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:23.537236 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:25:23.538191 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        room_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by room_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:25:23.599024 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:23.602594 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 15:25:23.268311 => 15:25:23.602082
[0m15:25:23.603109 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: ROLLBACK
[0m15:25:23.636042 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: Close
[0m15:25:23.637043 [info ] [Thread-1 (]: 1 of 5 PASS accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[32mPASS[0m in 0.41s]
[0m15:25:23.638556 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:25:23.639747 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:25:23.639747 [info ] [Thread-1 (]: 2 of 5 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:25:23.641132 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:25:23.642132 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:25:23.648130 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:25:23.650642 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:25:23.642132 => 15:25:23.649133
[0m15:25:23.651722 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:25:23.653730 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:25:23.656255 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:25:23.657269 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:25:23.657269 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:25:23.856242 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:23.857126 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:25:23.858300 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:25:23.908648 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:23.911649 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:25:23.651722 => 15:25:23.911649
[0m15:25:23.913669 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:25:23.946047 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:25:23.949015 [info ] [Thread-1 (]: 2 of 5 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.31s]
[0m15:25:23.951521 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:25:23.952527 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:25:23.953528 [info ] [Thread-1 (]: 3 of 5 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:25:23.954529 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:25:23.955562 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:25:23.960704 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:25:23.965274 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:25:23.956669 => 15:25:23.965274
[0m15:25:23.967281 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:25:23.973286 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:25:23.979563 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:25:23.980565 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:25:23.982564 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:25:24.186733 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:24.187733 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:25:24.188734 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:25:24.242814 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:24.244805 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:25:23.968283 => 15:25:24.244805
[0m15:25:24.245804 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:25:24.278572 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:25:24.280573 [info ] [Thread-1 (]: 3 of 5 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.33s]
[0m15:25:24.281572 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:25:24.282574 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:25:24.283574 [info ] [Thread-1 (]: 4 of 5 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:25:24.285575 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:25:24.286573 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:25:24.293090 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:25:24.295091 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:25:24.286573 => 15:25:24.295091
[0m15:25:24.296090 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:25:24.305146 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:25:24.309146 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:25:24.310145 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:25:24.311656 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:25:24.513907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:24.515032 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:25:24.516241 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:25:24.592396 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:24.596389 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:25:24.297129 => 15:25:24.595391
[0m15:25:24.597390 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:25:24.630703 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:25:24.633704 [info ] [Thread-1 (]: 4 of 5 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.35s]
[0m15:25:24.637778 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:25:24.638778 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:25:24.639774 [info ] [Thread-1 (]: 5 of 5 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:25:24.641775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:25:24.642774 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:25:24.657360 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:25:24.662543 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:25:24.643777 => 15:25:24.662543
[0m15:25:24.664544 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:25:24.672049 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:25:24.674605 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:25:24.676607 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:25:24.678606 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:25:24.874951 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:24.876459 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:25:24.877994 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:25:24.945953 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:24.948989 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:25:24.666546 => 15:25:24.948462
[0m15:25:24.952999 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:25:24.985928 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:25:24.989449 [info ] [Thread-1 (]: 5 of 5 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.35s]
[0m15:25:24.991452 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:25:24.994451 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:24.995450 [debug] [MainThread]: On master: BEGIN
[0m15:25:24.996960 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:25:25.215002 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:25:25.216911 [debug] [MainThread]: On master: COMMIT
[0m15:25:25.217920 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:25.218920 [debug] [MainThread]: On master: COMMIT
[0m15:25:25.254616 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:25:25.254616 [debug] [MainThread]: On master: Close
[0m15:25:25.258161 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:25:25.262025 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:25:25.262791 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:25:25.264127 [info ] [MainThread]: 
[0m15:25:25.266136 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 2.87 seconds (2.87s).
[0m15:25:25.269571 [debug] [MainThread]: Command end result
[0m15:25:25.288373 [info ] [MainThread]: 
[0m15:25:25.290390 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:25:25.294386 [info ] [MainThread]: 
[0m15:25:25.298323 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m15:25:25.301496 [debug] [MainThread]: Command `dbt test` succeeded at 15:25:25.300497 after 3.99 seconds
[0m15:25:25.301496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D2C1E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D5AC1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE25B01010>]}
[0m15:25:25.302494 [debug] [MainThread]: Flushing usage events
[0m15:31:18.194309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7A4FBF10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7A11A050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7A54BF10>]}


============================== 15:31:18.199602 | 1fd74eef-094d-4cb3-bcec-aca9a0c033f7 ==============================
[0m15:31:18.199602 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:31:18.200602 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:31:18.453821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1fd74eef-094d-4cb3-bcec-aca9a0c033f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7A0475D0>]}
[0m15:31:18.558247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1fd74eef-094d-4cb3-bcec-aca9a0c033f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7A4FA4D0>]}
[0m15:31:18.562184 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:31:18.572962 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:31:18.725492 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m15:31:18.727081 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/tests\dim_listings_minimum_nights.sql
[0m15:31:18.910487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1fd74eef-094d-4cb3-bcec-aca9a0c033f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7A569F50>]}
[0m15:31:18.933312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1fd74eef-094d-4cb3-bcec-aca9a0c033f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7AA84690>]}
[0m15:31:18.933312 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 6 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:31:18.934786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1fd74eef-094d-4cb3-bcec-aca9a0c033f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7A7F7010>]}
[0m15:31:18.939896 [info ] [MainThread]: 
[0m15:31:18.941858 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:31:18.945860 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:31:18.959023 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:31:18.962104 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:31:18.963554 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:31:20.273812 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:31:20.275813 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:31:20.275813 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:31:20.324564 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:31:20.327565 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:31:20.354830 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:31:20.367535 [debug] [MainThread]: Using postgres connection "master"
[0m15:31:20.368547 [debug] [MainThread]: On master: BEGIN
[0m15:31:20.368547 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:31:20.566139 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:31:20.567145 [debug] [MainThread]: Using postgres connection "master"
[0m15:31:20.568133 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:31:20.629139 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:31:20.632244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1fd74eef-094d-4cb3-bcec-aca9a0c033f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7A7F7010>]}
[0m15:31:20.632244 [debug] [MainThread]: On master: ROLLBACK
[0m15:31:20.662623 [debug] [MainThread]: Using postgres connection "master"
[0m15:31:20.663592 [debug] [MainThread]: On master: BEGIN
[0m15:31:20.727719 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:31:20.728819 [debug] [MainThread]: On master: COMMIT
[0m15:31:20.728819 [debug] [MainThread]: Using postgres connection "master"
[0m15:31:20.729818 [debug] [MainThread]: On master: COMMIT
[0m15:31:20.754033 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:31:20.754033 [debug] [MainThread]: On master: Close
[0m15:31:20.754033 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:31:20.754033 [info ] [MainThread]: 
[0m15:31:20.762802 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:31:20.762802 [info ] [Thread-1 (]: 1 of 6 START test accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:31:20.766903 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af'
[0m15:31:20.766903 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:31:20.787957 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:31:20.791800 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 15:31:20.767909 => 15:31:20.790803
[0m15:31:20.793808 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:31:20.814618 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:31:20.816191 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:31:20.817304 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: BEGIN
[0m15:31:20.818354 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:31:21.006718 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:21.007728 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:31:21.007728 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        room_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by room_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:31:21.067936 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:21.069969 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 15:31:20.793808 => 15:31:21.069969
[0m15:31:21.070969 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: ROLLBACK
[0m15:31:21.096983 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: Close
[0m15:31:21.097983 [info ] [Thread-1 (]: 1 of 6 PASS accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[32mPASS[0m in 0.34s]
[0m15:31:21.099490 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:31:21.100015 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m15:31:21.100751 [info ] [Thread-1 (]: 2 of 6 START test dim_listings_minimum_nights .................................. [RUN]
[0m15:31:21.102130 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m15:31:21.103131 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m15:31:21.106129 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:31:21.110128 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 15:31:21.103131 => 15:31:21.110128
[0m15:31:21.111633 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m15:31:21.114236 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:31:21.119244 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:31:21.120247 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: BEGIN
[0m15:31:21.121242 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:21.323795 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:21.325803 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:31:21.325803 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dim_listings_minimum_nights"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
    *
FROM
    "inttegra_stage"."test"."dim_listings_cleansed"
WHERE
    minimum_nights < 1
LIMIT   
    10
      
    ) dbt_internal_test
[0m15:31:21.374028 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:21.376501 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 15:31:21.111633 => 15:31:21.375996
[0m15:31:21.377065 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: ROLLBACK
[0m15:31:21.407758 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: Close
[0m15:31:21.409749 [info ] [Thread-1 (]: 2 of 6 PASS dim_listings_minimum_nights ........................................ [[32mPASS[0m in 0.31s]
[0m15:31:21.410750 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m15:31:21.412259 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:31:21.413266 [info ] [Thread-1 (]: 3 of 6 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:31:21.414302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:31:21.414302 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:31:21.421266 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:31:21.423778 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:31:21.415266 => 15:31:21.422269
[0m15:31:21.424879 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:31:21.428340 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:31:21.430306 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:31:21.431305 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:31:21.431305 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:21.636929 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:21.638141 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:31:21.638141 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:31:21.686842 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:21.689493 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:31:21.425343 => 15:31:21.689493
[0m15:31:21.690498 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:31:21.715309 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:31:21.717320 [info ] [Thread-1 (]: 3 of 6 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.30s]
[0m15:31:21.718317 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:31:21.719317 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:31:21.719317 [info ] [Thread-1 (]: 4 of 6 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:31:21.721319 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:31:21.721319 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:31:21.725375 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:31:21.727383 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:31:21.722354 => 15:31:21.727383
[0m15:31:21.728382 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:31:21.730379 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:31:21.733022 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:31:21.734026 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:31:21.734026 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:21.935506 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:21.936506 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:31:21.936506 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:31:21.987507 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:21.990020 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:31:21.728382 => 15:31:21.989014
[0m15:31:21.990632 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:31:22.021269 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:31:22.022232 [info ] [Thread-1 (]: 4 of 6 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.30s]
[0m15:31:22.023232 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:31:22.024738 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:31:22.024738 [info ] [Thread-1 (]: 5 of 6 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:31:22.026402 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:31:22.027447 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:31:22.035442 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:31:22.036981 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:31:22.027447 => 15:31:22.036981
[0m15:31:22.038250 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:31:22.040293 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:31:22.042261 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:31:22.043260 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:31:22.043260 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:22.233665 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:22.234706 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:31:22.235718 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:31:22.311455 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:22.312457 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:31:22.038250 => 15:31:22.312457
[0m15:31:22.313455 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:31:22.346613 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:31:22.347609 [info ] [Thread-1 (]: 5 of 6 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.32s]
[0m15:31:22.349114 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:31:22.349114 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:31:22.350427 [info ] [Thread-1 (]: 6 of 6 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:31:22.351435 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:31:22.352439 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:31:22.360433 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:31:22.362959 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:31:22.352439 => 15:31:22.362509
[0m15:31:22.363944 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:31:22.367950 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:31:22.369943 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:31:22.370943 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:31:22.371944 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:22.559360 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:22.560374 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:31:22.561403 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:31:22.620989 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:22.626755 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:31:22.364954 => 15:31:22.626755
[0m15:31:22.626755 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:31:22.657284 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:31:22.658278 [info ] [Thread-1 (]: 6 of 6 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.31s]
[0m15:31:22.660288 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:31:22.661795 [debug] [MainThread]: Using postgres connection "master"
[0m15:31:22.661795 [debug] [MainThread]: On master: BEGIN
[0m15:31:22.663152 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:31:22.853115 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:31:22.854122 [debug] [MainThread]: On master: COMMIT
[0m15:31:22.854122 [debug] [MainThread]: Using postgres connection "master"
[0m15:31:22.854122 [debug] [MainThread]: On master: COMMIT
[0m15:31:22.885078 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:31:22.885078 [debug] [MainThread]: On master: Close
[0m15:31:22.885078 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:31:22.890300 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:31:22.890300 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:31:22.891300 [info ] [MainThread]: 
[0m15:31:22.891300 [info ] [MainThread]: Finished running 6 tests in 0 hours 0 minutes and 3.95 seconds (3.95s).
[0m15:31:22.891300 [debug] [MainThread]: Command end result
[0m15:31:22.907510 [info ] [MainThread]: 
[0m15:31:22.908510 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:31:22.910562 [info ] [MainThread]: 
[0m15:31:22.911509 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m15:31:22.914562 [debug] [MainThread]: Command `dbt test` succeeded at 15:31:22.914033 after 4.82 seconds
[0m15:31:22.914562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC79116C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC72D7E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC79D60310>]}
[0m15:31:22.915565 [debug] [MainThread]: Flushing usage events
[0m15:49:41.624237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4CE8BFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4C6A00D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4CC15F10>]}


============================== 15:49:41.629062 | a91a50b5-c285-45f8-8a36-78784ec5d048 ==============================
[0m15:49:41.629062 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:49:41.630572 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt test', 'send_anonymous_usage_stats': 'True'}
[0m15:49:41.866365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a91a50b5-c285-45f8-8a36-78784ec5d048', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4D05F750>]}
[0m15:49:41.959639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a91a50b5-c285-45f8-8a36-78784ec5d048', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4D04D090>]}
[0m15:49:41.962637 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:49:41.973283 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:49:42.092324 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m15:49:42.094310 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/tests\no_nulls_in_dim_listings.sql
[0m15:49:42.094310 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/macros\no_nulls_in_collumns.sql
[0m15:49:42.240220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a91a50b5-c285-45f8-8a36-78784ec5d048', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4C670610>]}
[0m15:49:42.247909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a91a50b5-c285-45f8-8a36-78784ec5d048', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4D259110>]}
[0m15:49:42.255649 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 7 tests, 3 sources, 0 exposures, 0 metrics, 402 macros, 0 groups, 0 semantic models
[0m15:49:42.256170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a91a50b5-c285-45f8-8a36-78784ec5d048', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4D137050>]}
[0m15:49:42.256170 [info ] [MainThread]: 
[0m15:49:42.256170 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:49:42.256170 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:49:42.274748 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:49:42.274748 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:49:42.274748 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:49:43.661779 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:49:43.663167 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:49:43.664166 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:49:43.721819 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:49:43.724387 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:49:43.762717 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:49:43.772837 [debug] [MainThread]: Using postgres connection "master"
[0m15:49:43.773833 [debug] [MainThread]: On master: BEGIN
[0m15:49:43.774836 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:49:44.033351 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:49:44.033351 [debug] [MainThread]: Using postgres connection "master"
[0m15:49:44.034351 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:49:44.104727 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:49:44.107478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a91a50b5-c285-45f8-8a36-78784ec5d048', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4D18F810>]}
[0m15:49:44.108484 [debug] [MainThread]: On master: ROLLBACK
[0m15:49:44.151553 [debug] [MainThread]: Using postgres connection "master"
[0m15:49:44.151553 [debug] [MainThread]: On master: BEGIN
[0m15:49:44.230564 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:49:44.230564 [debug] [MainThread]: On master: COMMIT
[0m15:49:44.231839 [debug] [MainThread]: Using postgres connection "master"
[0m15:49:44.232840 [debug] [MainThread]: On master: COMMIT
[0m15:49:44.264246 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:49:44.264246 [debug] [MainThread]: On master: Close
[0m15:49:44.264246 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:49:44.264246 [info ] [MainThread]: 
[0m15:49:44.264246 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:49:44.274994 [info ] [Thread-1 (]: 1 of 7 START test accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:49:44.276818 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af'
[0m15:49:44.278530 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:49:44.301796 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:49:44.304014 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 15:49:44.278530 => 15:49:44.304014
[0m15:49:44.305015 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:49:44.320967 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:49:44.324277 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:49:44.325284 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: BEGIN
[0m15:49:44.327289 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:49:44.578233 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:49:44.578233 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:49:44.579232 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        room_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by room_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:49:44.646510 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:49:44.648505 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 15:49:44.306028 => 15:49:44.648505
[0m15:49:44.649011 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: ROLLBACK
[0m15:49:44.680251 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: Close
[0m15:49:44.681258 [info ] [Thread-1 (]: 1 of 7 PASS accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[32mPASS[0m in 0.41s]
[0m15:49:44.682259 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:49:44.683292 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m15:49:44.684315 [info ] [Thread-1 (]: 2 of 7 START test dim_listings_minimum_nights .................................. [RUN]
[0m15:49:44.685528 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m15:49:44.685528 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m15:49:44.689529 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:49:44.692533 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 15:49:44.686528 => 15:49:44.691553
[0m15:49:44.692533 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m15:49:44.695532 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:49:44.698053 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:49:44.700051 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: BEGIN
[0m15:49:44.702059 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:49:44.946079 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:49:44.947594 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:49:44.949008 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dim_listings_minimum_nights"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
    *
FROM
    "inttegra_stage"."test"."dim_listings_cleansed"
WHERE
    minimum_nights < 1
LIMIT   
    10
      
    ) dbt_internal_test
[0m15:49:45.007611 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:49:45.009210 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 15:49:44.693534 => 15:49:45.009210
[0m15:49:45.010177 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: ROLLBACK
[0m15:49:45.050176 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: Close
[0m15:49:45.051143 [info ] [Thread-1 (]: 2 of 7 PASS dim_listings_minimum_nights ........................................ [[32mPASS[0m in 0.37s]
[0m15:49:45.052143 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m15:49:45.053176 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m15:49:45.054176 [info ] [Thread-1 (]: 3 of 7 START test no_nulls_in_dim_listings ..................................... [RUN]
[0m15:49:45.054176 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m15:49:45.055681 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m15:49:45.063860 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 15:49:45.055681 => 15:49:45.063860
[0m15:49:45.123691 [debug] [Thread-1 (]: Compilation Error in test no_nulls_in_dim_listings (dbtlearn/tests\no_nulls_in_dim_listings.sql)
  'no_nulls_in_columns' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:49:45.124691 [error] [Thread-1 (]: 3 of 7 ERROR no_nulls_in_dim_listings .......................................... [[31mERROR[0m in 0.07s]
[0m15:49:45.125195 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m15:49:45.126237 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:49:45.127201 [info ] [Thread-1 (]: 4 of 7 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:49:45.128202 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:49:45.128202 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:49:45.135369 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:49:45.137371 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:49:45.128202 => 15:49:45.137371
[0m15:49:45.138374 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:49:45.142039 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:49:45.144040 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:49:45.146079 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:49:45.147063 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:49:45.377018 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:49:45.378027 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:49:45.379025 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:49:45.438047 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:49:45.439045 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:49:45.138374 => 15:49:45.439045
[0m15:49:45.440550 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:49:45.479174 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:49:45.481175 [info ] [Thread-1 (]: 4 of 7 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.35s]
[0m15:49:45.482174 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:49:45.483211 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:49:45.484175 [info ] [Thread-1 (]: 5 of 7 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:49:45.485173 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:49:45.486173 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:49:45.492221 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:49:45.494220 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:49:45.486173 => 15:49:45.494220
[0m15:49:45.495221 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:49:45.495221 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:49:45.500576 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:49:45.501649 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:49:45.502007 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:49:45.722117 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:49:45.723108 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:49:45.723108 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:49:45.778279 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:49:45.780322 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:49:45.495221 => 15:49:45.779332
[0m15:49:45.780322 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:49:45.816354 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:49:45.818354 [info ] [Thread-1 (]: 5 of 7 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.33s]
[0m15:49:45.819354 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:49:45.819354 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:49:45.820353 [info ] [Thread-1 (]: 6 of 7 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:49:45.822354 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:49:45.823379 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:49:45.831209 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:49:45.833210 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:49:45.823379 => 15:49:45.833210
[0m15:49:45.835210 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:49:45.840734 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:49:45.843738 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:49:45.845734 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:49:45.846732 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:49:46.068105 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:49:46.069257 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:49:46.069257 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:49:46.155799 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:49:46.157992 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:49:45.835210 => 15:49:46.157476
[0m15:49:46.158508 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:49:46.196777 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:49:46.199419 [info ] [Thread-1 (]: 6 of 7 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.38s]
[0m15:49:46.201541 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:49:46.202608 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:49:46.203679 [info ] [Thread-1 (]: 7 of 7 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:49:46.205280 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:49:46.206905 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:49:46.215161 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:49:46.219373 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:49:46.207440 => 15:49:46.219373
[0m15:49:46.221891 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:49:46.226845 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:49:46.231141 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:49:46.232461 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:49:46.233748 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:49:46.453849 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:49:46.454600 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:49:46.455597 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:49:46.526455 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:49:46.528313 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:49:46.221891 => 15:49:46.528313
[0m15:49:46.529320 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:49:46.563463 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:49:46.565220 [info ] [Thread-1 (]: 7 of 7 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.36s]
[0m15:49:46.566220 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:49:46.567218 [debug] [MainThread]: Using postgres connection "master"
[0m15:49:46.568219 [debug] [MainThread]: On master: BEGIN
[0m15:49:46.568219 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:49:46.841962 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:49:46.842973 [debug] [MainThread]: On master: COMMIT
[0m15:49:46.842973 [debug] [MainThread]: Using postgres connection "master"
[0m15:49:46.843972 [debug] [MainThread]: On master: COMMIT
[0m15:49:46.879592 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:49:46.879592 [debug] [MainThread]: On master: Close
[0m15:49:46.880599 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:49:46.881597 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:49:46.882601 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:49:46.883110 [info ] [MainThread]: 
[0m15:49:46.883564 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 4.63 seconds (4.63s).
[0m15:49:46.885603 [debug] [MainThread]: Command end result
[0m15:49:46.897149 [info ] [MainThread]: 
[0m15:49:46.899117 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:49:46.899117 [info ] [MainThread]: 
[0m15:49:46.900117 [error] [MainThread]:   Compilation Error in test no_nulls_in_dim_listings (dbtlearn/tests\no_nulls_in_dim_listings.sql)
  'no_nulls_in_columns' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:49:46.901118 [info ] [MainThread]: 
[0m15:49:46.901118 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m15:49:46.903120 [debug] [MainThread]: Command `dbt test` failed at 15:49:46.903120 after 5.35 seconds
[0m15:49:46.903120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF45691010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4CA4FED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF4597FED0>]}
[0m15:49:46.904119 [debug] [MainThread]: Flushing usage events
[0m15:50:37.071510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243ED843D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243EA1FC1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243ED809310>]}


============================== 15:50:37.074512 | d62efce7-3712-4ed6-91d8-d1cdafa8497e ==============================
[0m15:50:37.074512 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:50:37.075510 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt test', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:50:37.293604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd62efce7-3712-4ed6-91d8-d1cdafa8497e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243ED841410>]}
[0m15:50:37.370904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd62efce7-3712-4ed6-91d8-d1cdafa8497e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243EDE1E090>]}
[0m15:50:37.372614 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:50:37.381237 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:50:37.485442 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m15:50:37.485442 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/macros\no_nulls_in_columns.sql
[0m15:50:37.486443 [debug] [MainThread]: Partial parsing: deleted file: dbtlearn://dbtlearn/macros\no_nulls_in_collumns.sql
[0m15:50:37.537148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd62efce7-3712-4ed6-91d8-d1cdafa8497e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243EDD23F50>]}
[0m15:50:37.550868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd62efce7-3712-4ed6-91d8-d1cdafa8497e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243EDF94290>]}
[0m15:50:37.551873 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 7 tests, 3 sources, 0 exposures, 0 metrics, 402 macros, 0 groups, 0 semantic models
[0m15:50:37.552734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd62efce7-3712-4ed6-91d8-d1cdafa8497e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243EDE6ED10>]}
[0m15:50:37.554743 [info ] [MainThread]: 
[0m15:50:37.555694 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:50:37.558839 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:50:37.570354 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:50:37.572355 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:50:37.573394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:50:37.927616 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:50:37.928620 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:50:37.928620 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:50:37.988942 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:50:37.989955 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:50:38.030465 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:50:38.037709 [debug] [MainThread]: Using postgres connection "master"
[0m15:50:38.038677 [debug] [MainThread]: On master: BEGIN
[0m15:50:38.038677 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:50:38.298172 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:50:38.299171 [debug] [MainThread]: Using postgres connection "master"
[0m15:50:38.300171 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:50:38.372822 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:50:38.374820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd62efce7-3712-4ed6-91d8-d1cdafa8497e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243EDFDDCD0>]}
[0m15:50:38.375819 [debug] [MainThread]: On master: ROLLBACK
[0m15:50:38.417498 [debug] [MainThread]: Using postgres connection "master"
[0m15:50:38.417498 [debug] [MainThread]: On master: BEGIN
[0m15:50:38.494668 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:50:38.495677 [debug] [MainThread]: On master: COMMIT
[0m15:50:38.496674 [debug] [MainThread]: Using postgres connection "master"
[0m15:50:38.496674 [debug] [MainThread]: On master: COMMIT
[0m15:50:38.541763 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:50:38.542769 [debug] [MainThread]: On master: Close
[0m15:50:38.543762 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:50:38.545759 [info ] [MainThread]: 
[0m15:50:38.550620 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:50:38.551619 [info ] [Thread-1 (]: 1 of 7 START test accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:50:38.552619 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af'
[0m15:50:38.553620 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:50:38.573702 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:50:38.575671 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 15:50:38.553620 => 15:50:38.575671
[0m15:50:38.577675 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:50:38.594283 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:50:38.595284 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:50:38.596285 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: BEGIN
[0m15:50:38.597578 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:50:38.811600 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:50:38.812104 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:50:38.813144 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        room_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by room_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:50:38.878832 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:50:38.881438 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 15:50:38.577675 => 15:50:38.881438
[0m15:50:38.882463 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: ROLLBACK
[0m15:50:38.910428 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: Close
[0m15:50:38.910428 [info ] [Thread-1 (]: 1 of 7 PASS accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[32mPASS[0m in 0.36s]
[0m15:50:38.910428 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:50:38.920923 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m15:50:38.920923 [info ] [Thread-1 (]: 2 of 7 START test dim_listings_minimum_nights .................................. [RUN]
[0m15:50:38.920923 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m15:50:38.920923 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m15:50:38.926047 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:50:38.927708 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 15:50:38.920923 => 15:50:38.927708
[0m15:50:38.928704 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m15:50:38.931130 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:50:38.933898 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:50:38.935908 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: BEGIN
[0m15:50:38.935908 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:50:39.161562 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:50:39.161562 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:50:39.161562 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dim_listings_minimum_nights"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
    *
FROM
    "inttegra_stage"."test"."dim_listings_cleansed"
WHERE
    minimum_nights < 1
LIMIT   
    10
      
    ) dbt_internal_test
[0m15:50:39.227964 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:50:39.229965 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 15:50:38.929388 => 15:50:39.228968
[0m15:50:39.229965 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: ROLLBACK
[0m15:50:39.266475 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: Close
[0m15:50:39.267285 [info ] [Thread-1 (]: 2 of 7 PASS dim_listings_minimum_nights ........................................ [[32mPASS[0m in 0.35s]
[0m15:50:39.269279 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m15:50:39.269821 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m15:50:39.270823 [info ] [Thread-1 (]: 3 of 7 START test no_nulls_in_dim_listings ..................................... [RUN]
[0m15:50:39.271832 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m15:50:39.271832 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m15:50:39.276187 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 15:50:39.272859 => 15:50:39.276187
[0m15:50:39.280192 [debug] [Thread-1 (]: Compilation Error in test no_nulls_in_dim_listings (dbtlearn/tests\no_nulls_in_dim_listings.sql)
  'no_nulls_in_columns' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:50:39.281197 [error] [Thread-1 (]: 3 of 7 ERROR no_nulls_in_dim_listings .......................................... [[31mERROR[0m in 0.01s]
[0m15:50:39.282286 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m15:50:39.283293 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:50:39.284298 [info ] [Thread-1 (]: 4 of 7 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:50:39.286296 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:50:39.287294 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:50:39.296840 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:50:39.298829 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:50:39.287294 => 15:50:39.297830
[0m15:50:39.299849 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:50:39.302828 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:50:39.303828 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:50:39.305333 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:50:39.305852 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:50:39.531317 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:50:39.532109 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:50:39.532109 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:50:39.587179 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:50:39.589185 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:50:39.299849 => 15:50:39.588188
[0m15:50:39.589185 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:50:39.628158 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:50:39.629665 [info ] [Thread-1 (]: 4 of 7 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.34s]
[0m15:50:39.630946 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:50:39.631946 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:50:39.631946 [info ] [Thread-1 (]: 5 of 7 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:50:39.632948 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:50:39.633945 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:50:39.637946 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:50:39.639946 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:50:39.633945 => 15:50:39.638945
[0m15:50:39.639946 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:50:39.642906 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:50:39.643454 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:50:39.644454 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:50:39.645456 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:50:39.881283 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:50:39.881283 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:50:39.882790 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:50:39.934865 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:50:39.936867 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:50:39.640947 => 15:50:39.936867
[0m15:50:39.936867 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:50:39.972281 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:50:39.973262 [info ] [Thread-1 (]: 5 of 7 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.34s]
[0m15:50:39.975266 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:50:39.975761 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:50:39.976558 [info ] [Thread-1 (]: 6 of 7 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:50:39.977610 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:50:39.978114 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:50:39.986880 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:50:39.986880 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:50:39.978114 => 15:50:39.986880
[0m15:50:39.986880 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:50:39.994144 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:50:39.996678 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:50:39.997691 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:50:39.998688 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:50:40.239715 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:50:40.240715 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:50:40.240715 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:50:40.334039 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:50:40.336021 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:50:39.990555 => 15:50:40.336021
[0m15:50:40.337018 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:50:40.374814 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:50:40.377210 [info ] [Thread-1 (]: 6 of 7 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.40s]
[0m15:50:40.379206 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:50:40.379206 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:50:40.380206 [info ] [Thread-1 (]: 7 of 7 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:50:40.382209 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:50:40.382209 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:50:40.388871 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:50:40.391870 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:50:40.383207 => 15:50:40.390876
[0m15:50:40.391870 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:50:40.397375 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:50:40.398880 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:50:40.399926 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:50:40.399926 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:50:40.660511 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:50:40.661518 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:50:40.662518 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:50:40.735480 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:50:40.737570 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:50:40.392871 => 15:50:40.737570
[0m15:50:40.738569 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:50:40.777848 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:50:40.780847 [info ] [Thread-1 (]: 7 of 7 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.40s]
[0m15:50:40.781848 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:50:40.784385 [debug] [MainThread]: Using postgres connection "master"
[0m15:50:40.784853 [debug] [MainThread]: On master: BEGIN
[0m15:50:40.785852 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:50:41.063601 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:50:41.064541 [debug] [MainThread]: On master: COMMIT
[0m15:50:41.065540 [debug] [MainThread]: Using postgres connection "master"
[0m15:50:41.065540 [debug] [MainThread]: On master: COMMIT
[0m15:50:41.103823 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:50:41.103823 [debug] [MainThread]: On master: Close
[0m15:50:41.104824 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:50:41.105825 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:50:41.105825 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:50:41.106824 [info ] [MainThread]: 
[0m15:50:41.107822 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 3.55 seconds (3.55s).
[0m15:50:41.109310 [debug] [MainThread]: Command end result
[0m15:50:41.118314 [info ] [MainThread]: 
[0m15:50:41.119820 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:50:41.121213 [info ] [MainThread]: 
[0m15:50:41.122214 [error] [MainThread]:   Compilation Error in test no_nulls_in_dim_listings (dbtlearn/tests\no_nulls_in_dim_listings.sql)
  'no_nulls_in_columns' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:50:41.123212 [info ] [MainThread]: 
[0m15:50:41.125219 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m15:50:41.127214 [debug] [MainThread]: Command `dbt test` failed at 15:50:41.127214 after 4.12 seconds
[0m15:50:41.128213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243E65A1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243EDFED690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243E689F210>]}
[0m15:50:41.128213 [debug] [MainThread]: Flushing usage events
[0m15:51:06.060734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00EC79CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00E4B0150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00ECA0490>]}


============================== 15:51:06.064732 | 25c22c26-3e27-4527-99e5-33799343630e ==============================
[0m15:51:06.064732 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:51:06.065734 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:51:06.403814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '25c22c26-3e27-4527-99e5-33799343630e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00EE8D450>]}
[0m15:51:06.636287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '25c22c26-3e27-4527-99e5-33799343630e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00EC91B50>]}
[0m15:51:06.639284 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:51:06.660859 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:51:06.908709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:51:06.909709 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:51:06.923434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '25c22c26-3e27-4527-99e5-33799343630e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00EF2D0D0>]}
[0m15:51:07.071300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '25c22c26-3e27-4527-99e5-33799343630e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00F0A2A90>]}
[0m15:51:07.071300 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 7 tests, 3 sources, 0 exposures, 0 metrics, 402 macros, 0 groups, 0 semantic models
[0m15:51:07.072299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25c22c26-3e27-4527-99e5-33799343630e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00E82AE10>]}
[0m15:51:07.075301 [info ] [MainThread]: 
[0m15:51:07.077298 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:51:07.085855 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:51:07.110960 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:51:07.112959 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:51:07.113955 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:51:08.526751 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:51:08.527826 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:51:08.527826 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:51:08.586721 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:51:08.587719 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:51:08.629704 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:51:08.641890 [debug] [MainThread]: Using postgres connection "master"
[0m15:51:08.642896 [debug] [MainThread]: On master: BEGIN
[0m15:51:08.643482 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:51:08.911299 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:51:08.912293 [debug] [MainThread]: Using postgres connection "master"
[0m15:51:08.912293 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:51:08.981667 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:51:08.983668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25c22c26-3e27-4527-99e5-33799343630e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00EFCE790>]}
[0m15:51:08.984667 [debug] [MainThread]: On master: ROLLBACK
[0m15:51:09.023484 [debug] [MainThread]: Using postgres connection "master"
[0m15:51:09.024483 [debug] [MainThread]: On master: BEGIN
[0m15:51:09.110519 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:51:09.110519 [debug] [MainThread]: On master: COMMIT
[0m15:51:09.110519 [debug] [MainThread]: Using postgres connection "master"
[0m15:51:09.110519 [debug] [MainThread]: On master: COMMIT
[0m15:51:09.151252 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:51:09.151252 [debug] [MainThread]: On master: Close
[0m15:51:09.152284 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:51:09.153251 [info ] [MainThread]: 
[0m15:51:09.157250 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:51:09.158754 [info ] [Thread-1 (]: 1 of 7 START test accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:51:09.160763 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af'
[0m15:51:09.161767 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:51:09.186808 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:51:09.188809 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 15:51:09.161767 => 15:51:09.187809
[0m15:51:09.189810 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:51:09.208688 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:51:09.210689 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:51:09.211722 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: BEGIN
[0m15:51:09.212724 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:51:09.475748 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:51:09.476749 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:51:09.477746 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        room_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by room_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:51:09.548238 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:51:09.550239 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 15:51:09.189810 => 15:51:09.550239
[0m15:51:09.551240 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: ROLLBACK
[0m15:51:09.583110 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: Close
[0m15:51:09.591299 [info ] [Thread-1 (]: 1 of 7 PASS accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[32mPASS[0m in 0.42s]
[0m15:51:09.592357 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:51:09.592357 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m15:51:09.592357 [info ] [Thread-1 (]: 2 of 7 START test dim_listings_minimum_nights .................................. [RUN]
[0m15:51:09.592357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m15:51:09.592357 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m15:51:09.598533 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:51:09.600010 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 15:51:09.592357 => 15:51:09.600010
[0m15:51:09.601040 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m15:51:09.605461 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:51:09.607462 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:51:09.609463 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: BEGIN
[0m15:51:09.609463 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:51:09.839229 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:51:09.839229 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:51:09.840257 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dim_listings_minimum_nights"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
    *
FROM
    "inttegra_stage"."test"."dim_listings_cleansed"
WHERE
    minimum_nights < 1
LIMIT   
    10
      
    ) dbt_internal_test
[0m15:51:09.896069 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:51:09.898087 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 15:51:09.602078 => 15:51:09.898087
[0m15:51:09.899086 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: ROLLBACK
[0m15:51:09.932441 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: Close
[0m15:51:09.933440 [info ] [Thread-1 (]: 2 of 7 PASS dim_listings_minimum_nights ........................................ [[32mPASS[0m in 0.34s]
[0m15:51:09.935446 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m15:51:09.935446 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m15:51:09.936440 [info ] [Thread-1 (]: 3 of 7 START test no_nulls_in_dim_listings ..................................... [RUN]
[0m15:51:09.937440 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m15:51:09.938456 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m15:51:09.943017 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 15:51:09.938456 => 15:51:09.943017
[0m15:51:09.947017 [debug] [Thread-1 (]: Compilation Error in test no_nulls_in_dim_listings (dbtlearn/tests\no_nulls_in_dim_listings.sql)
  'no_nulls_in_columns' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:51:09.948017 [error] [Thread-1 (]: 3 of 7 ERROR no_nulls_in_dim_listings .......................................... [[31mERROR[0m in 0.01s]
[0m15:51:09.949017 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m15:51:09.950016 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:51:09.950016 [info ] [Thread-1 (]: 4 of 7 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:51:09.951523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:51:09.952563 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:51:09.962788 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:51:09.967150 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:51:09.953780 => 15:51:09.966144
[0m15:51:09.968157 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:51:09.971143 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:51:09.974143 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:51:09.975651 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:51:09.975651 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:51:10.195866 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:51:10.196857 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:51:10.197856 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:51:10.253650 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:51:10.255441 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:51:09.969145 => 15:51:10.255441
[0m15:51:10.256424 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:51:10.295817 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:51:10.296792 [info ] [Thread-1 (]: 4 of 7 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.35s]
[0m15:51:10.297788 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:51:10.298790 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:51:10.298790 [info ] [Thread-1 (]: 5 of 7 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:51:10.301336 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:51:10.301922 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:51:10.305932 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:51:10.306933 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:51:10.301922 => 15:51:10.306933
[0m15:51:10.307934 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:51:10.309932 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:51:10.311932 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:51:10.312437 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:51:10.312437 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:51:10.564381 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:51:10.565381 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:51:10.565906 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:51:10.618576 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:51:10.620579 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:51:10.307934 => 15:51:10.620579
[0m15:51:10.621579 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:51:10.653973 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:51:10.655972 [info ] [Thread-1 (]: 5 of 7 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.35s]
[0m15:51:10.656973 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:51:10.656973 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:51:10.657971 [info ] [Thread-1 (]: 6 of 7 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:51:10.658973 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:51:10.658973 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:51:10.671013 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:51:10.674081 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:51:10.661005 => 15:51:10.673605
[0m15:51:10.675081 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:51:10.681086 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:51:10.683086 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:51:10.684599 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:51:10.685662 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:51:10.906256 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:51:10.907257 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:51:10.908253 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:51:10.987470 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:51:10.989510 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:51:10.677099 => 15:51:10.988475
[0m15:51:10.989510 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:51:11.025076 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:51:11.027108 [info ] [Thread-1 (]: 6 of 7 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.37s]
[0m15:51:11.028074 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:51:11.029113 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:51:11.029113 [info ] [Thread-1 (]: 7 of 7 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:51:11.030110 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:51:11.031106 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:51:11.039220 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:51:11.041219 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:51:11.031106 => 15:51:11.041219
[0m15:51:11.043187 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:51:11.048775 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:51:11.050773 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:51:11.051808 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:51:11.052775 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:51:11.336555 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:51:11.337554 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:51:11.338552 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:51:11.414026 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:51:11.416030 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:51:11.044185 => 15:51:11.416030
[0m15:51:11.417030 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:51:11.455259 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:51:11.457263 [info ] [Thread-1 (]: 7 of 7 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.43s]
[0m15:51:11.458266 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:51:11.459262 [debug] [MainThread]: Using postgres connection "master"
[0m15:51:11.460263 [debug] [MainThread]: On master: BEGIN
[0m15:51:11.460263 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:51:11.716731 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:51:11.716731 [debug] [MainThread]: On master: COMMIT
[0m15:51:11.718239 [debug] [MainThread]: Using postgres connection "master"
[0m15:51:11.718239 [debug] [MainThread]: On master: COMMIT
[0m15:51:11.752633 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:51:11.752633 [debug] [MainThread]: On master: Close
[0m15:51:11.754175 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:51:11.754175 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:51:11.755529 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:51:11.756528 [info ] [MainThread]: 
[0m15:51:11.756528 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 4.68 seconds (4.68s).
[0m15:51:11.758529 [debug] [MainThread]: Command end result
[0m15:51:11.770506 [info ] [MainThread]: 
[0m15:51:11.771509 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:51:11.772508 [info ] [MainThread]: 
[0m15:51:11.773509 [error] [MainThread]:   Compilation Error in test no_nulls_in_dim_listings (dbtlearn/tests\no_nulls_in_dim_listings.sql)
  'no_nulls_in_columns' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:51:11.774520 [info ] [MainThread]: 
[0m15:51:11.775507 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m15:51:11.777525 [debug] [MainThread]: Command `dbt test` failed at 15:51:11.777525 after 5.79 seconds
[0m15:51:11.780128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00746E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00F08D0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A00F08F9D0>]}
[0m15:51:11.781127 [debug] [MainThread]: Flushing usage events
[0m15:51:49.448396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FDA30050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FDA31390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FD748AD0>]}


============================== 15:51:49.452395 | 29239b01-6f9f-4d79-be30-44c7e707b4c4 ==============================
[0m15:51:49.452395 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:51:49.453395 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt test', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:51:49.659604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '29239b01-6f9f-4d79-be30-44c7e707b4c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FDB24DD0>]}
[0m15:51:49.736168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '29239b01-6f9f-4d79-be30-44c7e707b4c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FD5593D0>]}
[0m15:51:49.737938 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:51:49.746536 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:51:49.847778 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:51:49.847778 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/tests\no_nulls_in_dim_listings.sql
[0m15:51:49.964950 [error] [MainThread]: Encountered an error:
Compilation Error in test no_nulls_in_dim_listings (dbtlearn/tests\no_nulls_in_dim_listings.sql)
  'dbt.context.providers.ParseDatabaseWrapper object' has no attribute 'ger_columns_in_relation'
[0m15:51:49.966797 [debug] [MainThread]: Command `dbt test` failed at 15:51:49.966797 after 0.58 seconds
[0m15:51:49.967796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FDF07B50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FDD58D50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FDC86690>]}
[0m15:51:49.967796 [debug] [MainThread]: Flushing usage events
[0m15:52:09.612657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D90059E190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9007AB710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9007AB1D0>]}


============================== 15:52:09.616656 | 30480195-1f5f-45f8-a4d7-9e0d2fd0c09b ==============================
[0m15:52:09.616656 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:52:09.616656 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt test', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:52:09.814727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30480195-1f5f-45f8-a4d7-9e0d2fd0c09b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D900993610>]}
[0m15:52:09.898996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '30480195-1f5f-45f8-a4d7-9e0d2fd0c09b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D900A7E110>]}
[0m15:52:09.900350 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:52:09.907898 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:52:10.001972 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m15:52:10.003006 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/tests\no_nulls_in_dim_listings.sql
[0m15:52:10.003975 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/macros\no_nulls_in_columns.sql
[0m15:52:10.138587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30480195-1f5f-45f8-a4d7-9e0d2fd0c09b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D900801F50>]}
[0m15:52:10.153714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30480195-1f5f-45f8-a4d7-9e0d2fd0c09b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D900BAD810>]}
[0m15:52:10.153714 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 7 tests, 3 sources, 0 exposures, 0 metrics, 402 macros, 0 groups, 0 semantic models
[0m15:52:10.154715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30480195-1f5f-45f8-a4d7-9e0d2fd0c09b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9009B6AD0>]}
[0m15:52:10.156748 [info ] [MainThread]: 
[0m15:52:10.158714 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:52:10.160715 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:52:10.172105 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:52:10.173118 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:52:10.174630 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:52:11.558979 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:52:11.558979 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:52:11.559979 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:52:11.617981 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:52:11.617981 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:52:11.660864 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:52:11.669046 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:11.669046 [debug] [MainThread]: On master: BEGIN
[0m15:52:11.670044 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:52:11.945921 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:52:11.946921 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:11.947930 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:52:12.022841 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:52:12.025862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30480195-1f5f-45f8-a4d7-9e0d2fd0c09b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D900D00790>]}
[0m15:52:12.026344 [debug] [MainThread]: On master: ROLLBACK
[0m15:52:12.066952 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:12.067961 [debug] [MainThread]: On master: BEGIN
[0m15:52:12.146971 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:52:12.147562 [debug] [MainThread]: On master: COMMIT
[0m15:52:12.148571 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:12.148571 [debug] [MainThread]: On master: COMMIT
[0m15:52:12.195540 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:52:12.196548 [debug] [MainThread]: On master: Close
[0m15:52:12.197547 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:52:12.198548 [info ] [MainThread]: 
[0m15:52:12.202546 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:52:12.202546 [info ] [Thread-1 (]: 1 of 7 START test accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:52:12.204548 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af'
[0m15:52:12.206056 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:52:12.227863 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:52:12.229387 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 15:52:12.207064 => 15:52:12.227863
[0m15:52:12.230459 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:52:12.247985 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:52:12.249985 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:52:12.249985 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: BEGIN
[0m15:52:12.250984 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:52:12.486303 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:52:12.487302 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:52:12.487302 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        room_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by room_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:52:12.551432 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:52:12.552444 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 15:52:12.230459 => 15:52:12.552444
[0m15:52:12.553952 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: ROLLBACK
[0m15:52:12.588749 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: Close
[0m15:52:12.591518 [info ] [Thread-1 (]: 1 of 7 PASS accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[32mPASS[0m in 0.39s]
[0m15:52:12.593063 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:52:12.593063 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m15:52:12.594063 [info ] [Thread-1 (]: 2 of 7 START test dim_listings_minimum_nights .................................. [RUN]
[0m15:52:12.594755 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m15:52:12.595795 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m15:52:12.598794 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:52:12.599762 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 15:52:12.595795 => 15:52:12.599762
[0m15:52:12.600760 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m15:52:12.603469 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dim_listings_minimum_nights"
[0m15:52:12.606470 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:52:12.607485 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: BEGIN
[0m15:52:12.608470 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:52:12.826669 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:52:12.827193 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m15:52:12.827717 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dim_listings_minimum_nights"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
    *
FROM
    "inttegra_stage"."test"."dim_listings_cleansed"
WHERE
    minimum_nights < 1
LIMIT   
    10
      
    ) dbt_internal_test
[0m15:52:12.882094 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:52:12.884094 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 15:52:12.600760 => 15:52:12.884094
[0m15:52:12.885095 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: ROLLBACK
[0m15:52:12.929192 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: Close
[0m15:52:12.930192 [info ] [Thread-1 (]: 2 of 7 PASS dim_listings_minimum_nights ........................................ [[32mPASS[0m in 0.34s]
[0m15:52:12.932193 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m15:52:12.932193 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m15:52:12.933193 [info ] [Thread-1 (]: 3 of 7 START test no_nulls_in_dim_listings ..................................... [RUN]
[0m15:52:12.934192 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m15:52:12.935225 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m15:52:12.943167 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m15:52:12.943167 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m15:52:12.944169 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:52:13.203447 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:52:13.205452 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m15:52:13.206454 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:52:13.269558 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m15:52:13.273392 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m15:52:13.275359 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 15:52:12.935225 => 15:52:13.274379
[0m15:52:13.275359 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m15:52:13.277783 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m15:52:13.279802 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m15:52:13.280791 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
    WHERE
        id_listings IS NULL OR
        listing_name IS NULL OR
        room_type IS NULL OR
        minimum_nights IS NULL OR
        host_id IS NULL OR
        price IS NULL OR
        created_at IS NULL OR
        updated_at IS NULL OR
        
    FALSE

      
    ) dbt_internal_test
[0m15:52:13.332270 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:52:13.334424 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 15:52:13.275359 => 15:52:13.333399
[0m15:52:13.334424 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m15:52:13.369720 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m15:52:13.371365 [info ] [Thread-1 (]: 3 of 7 PASS no_nulls_in_dim_listings ........................................... [[32mPASS[0m in 0.44s]
[0m15:52:13.372443 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m15:52:13.373482 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:52:13.374451 [info ] [Thread-1 (]: 4 of 7 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:52:13.375472 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:52:13.375472 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:52:13.381452 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:52:13.383739 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:52:13.376452 => 15:52:13.382452
[0m15:52:13.384749 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:52:13.386349 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:52:13.387858 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:52:13.388865 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:52:13.389880 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:52:13.643563 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:52:13.644564 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:52:13.644564 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:52:13.700218 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:52:13.702018 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:52:13.385339 => 15:52:13.702018
[0m15:52:13.702980 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:52:13.736636 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:52:13.737646 [info ] [Thread-1 (]: 4 of 7 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.36s]
[0m15:52:13.739651 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:52:13.739651 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:52:13.740649 [info ] [Thread-1 (]: 5 of 7 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:52:13.741647 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:52:13.742680 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:52:13.746941 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:52:13.747943 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:52:13.742680 => 15:52:13.747943
[0m15:52:13.748944 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:52:13.750977 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:52:13.752960 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:52:13.752960 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:52:13.753943 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:52:14.000454 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:52:14.001497 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:52:14.001497 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:52:14.059536 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:52:14.061555 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:52:13.748944 => 15:52:14.060543
[0m15:52:14.061555 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:52:14.104190 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:52:14.105882 [info ] [Thread-1 (]: 5 of 7 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.36s]
[0m15:52:14.106887 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:52:14.107895 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:52:14.107895 [info ] [Thread-1 (]: 6 of 7 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:52:14.108921 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:52:14.108921 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:52:14.121114 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:52:14.123846 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:52:14.108921 => 15:52:14.121114
[0m15:52:14.123846 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:52:14.128978 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:52:14.128978 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:52:14.128978 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:52:14.128978 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:52:14.382467 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:52:14.382467 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:52:14.382467 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:52:14.476650 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:52:14.478282 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:52:14.123846 => 15:52:14.478282
[0m15:52:14.479305 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:52:14.522255 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:52:14.524249 [info ] [Thread-1 (]: 6 of 7 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.41s]
[0m15:52:14.525216 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:52:14.525758 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:52:14.526402 [info ] [Thread-1 (]: 7 of 7 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:52:14.527291 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:52:14.528436 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:52:14.537486 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:52:14.540500 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:52:14.528436 => 15:52:14.539494
[0m15:52:14.541490 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:52:14.544535 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:52:14.547487 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:52:14.548997 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:52:14.550080 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:52:14.796612 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:52:14.796612 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:52:14.798121 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:52:14.876314 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:52:14.878358 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:52:14.541490 => 15:52:14.878358
[0m15:52:14.878358 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:52:14.917641 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:52:14.917641 [info ] [Thread-1 (]: 7 of 7 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.39s]
[0m15:52:14.917641 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:52:14.921792 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:14.921792 [debug] [MainThread]: On master: BEGIN
[0m15:52:14.921792 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:52:15.170073 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:52:15.170073 [debug] [MainThread]: On master: COMMIT
[0m15:52:15.171073 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:15.171073 [debug] [MainThread]: On master: COMMIT
[0m15:52:15.207628 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:52:15.208635 [debug] [MainThread]: On master: Close
[0m15:52:15.208635 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:52:15.210141 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:52:15.211122 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:52:15.211479 [info ] [MainThread]: 
[0m15:52:15.212478 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 5.05 seconds (5.05s).
[0m15:52:15.213478 [debug] [MainThread]: Command end result
[0m15:52:15.226428 [info ] [MainThread]: 
[0m15:52:15.227411 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:52:15.228409 [info ] [MainThread]: 
[0m15:52:15.229410 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m15:52:15.230410 [debug] [MainThread]: Command `dbt test` succeeded at 15:52:15.230410 after 5.68 seconds
[0m15:52:15.231419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D900519990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D978F51010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9007E0710>]}
[0m15:52:15.231419 [debug] [MainThread]: Flushing usage events
[0m16:05:57.823898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DC8EAB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DC4A5E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DC142210>]}


============================== 16:05:57.828897 | 9d1f82c8-2a64-48aa-b9ac-c8b99bbe977a ==============================
[0m16:05:57.828897 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:05:57.829898 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:05:58.048455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9d1f82c8-2a64-48aa-b9ac-c8b99bbe977a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DCAFD550>]}
[0m16:05:58.139234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9d1f82c8-2a64-48aa-b9ac-c8b99bbe977a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DC4042D0>]}
[0m16:05:58.140235 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:05:58.149197 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:05:58.261618 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m16:05:58.262618 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/macros\positive_value.sql
[0m16:05:58.263620 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m16:05:58.600229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9d1f82c8-2a64-48aa-b9ac-c8b99bbe977a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DDFE40D0>]}
[0m16:05:58.614794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9d1f82c8-2a64-48aa-b9ac-c8b99bbe977a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DDF50E10>]}
[0m16:05:58.615834 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 8 tests, 3 sources, 0 exposures, 0 metrics, 403 macros, 0 groups, 0 semantic models
[0m16:05:58.616800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9d1f82c8-2a64-48aa-b9ac-c8b99bbe977a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DCCE29D0>]}
[0m16:05:58.618834 [info ] [MainThread]: 
[0m16:05:58.619799 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:05:58.621801 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:05:58.633912 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:05:58.634923 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:05:58.635897 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:06:00.020521 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m16:06:00.021107 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:06:00.021107 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:06:00.072808 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:06:00.074730 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:06:00.114735 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:06:00.122352 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:00.123353 [debug] [MainThread]: On master: BEGIN
[0m16:06:00.123353 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:06:00.353358 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:06:00.354370 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:00.354370 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:06:00.418201 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:06:00.420202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9d1f82c8-2a64-48aa-b9ac-c8b99bbe977a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DDF1C510>]}
[0m16:06:00.420202 [debug] [MainThread]: On master: ROLLBACK
[0m16:06:00.463103 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:00.464680 [debug] [MainThread]: On master: BEGIN
[0m16:06:00.531416 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:06:00.532406 [debug] [MainThread]: On master: COMMIT
[0m16:06:00.533406 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:00.533406 [debug] [MainThread]: On master: COMMIT
[0m16:06:00.565049 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:06:00.565049 [debug] [MainThread]: On master: Close
[0m16:06:00.566084 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:06:00.567350 [info ] [MainThread]: 
[0m16:06:00.571184 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:06:00.571184 [info ] [Thread-1 (]: 1 of 8 START test accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m16:06:00.572689 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af'
[0m16:06:00.572689 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:06:00.581885 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:06:00.584911 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 16:06:00.573884 => 16:06:00.582883
[0m16:06:00.585919 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:06:00.607059 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:06:00.608564 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:06:00.609119 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: BEGIN
[0m16:06:00.609535 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:06:00.864741 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:06:00.865736 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:06:00.866734 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        room_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by room_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m16:06:00.926993 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m16:06:00.929998 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 16:06:00.585919 => 16:06:00.929998
[0m16:06:00.931000 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: ROLLBACK
[0m16:06:00.966202 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: Close
[0m16:06:00.967973 [info ] [Thread-1 (]: 1 of 8 PASS accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[32mPASS[0m in 0.39s]
[0m16:06:00.968935 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:06:00.969954 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m16:06:00.970449 [info ] [Thread-1 (]: 2 of 8 START test dim_listings_minimum_nights .................................. [RUN]
[0m16:06:00.971447 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m16:06:00.971447 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m16:06:00.974479 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:06:00.975482 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 16:06:00.972480 => 16:06:00.975482
[0m16:06:00.976450 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m16:06:00.978447 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:06:00.979479 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m16:06:00.980984 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: BEGIN
[0m16:06:00.982223 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:06:01.256138 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:06:01.257647 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dim_listings_minimum_nights"
[0m16:06:01.257647 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dim_listings_minimum_nights"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT
    *
FROM
    "inttegra_stage"."test"."dim_listings_cleansed"
WHERE
    minimum_nights < 1
LIMIT   
    10
      
    ) dbt_internal_test
[0m16:06:01.319646 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m16:06:01.321647 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 16:06:00.976450 => 16:06:01.321647
[0m16:06:01.322646 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: ROLLBACK
[0m16:06:01.361820 [debug] [Thread-1 (]: On test.dbtlearn.dim_listings_minimum_nights: Close
[0m16:06:01.363429 [info ] [Thread-1 (]: 2 of 8 PASS dim_listings_minimum_nights ........................................ [[32mPASS[0m in 0.39s]
[0m16:06:01.364426 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m16:06:01.365489 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:06:01.366004 [info ] [Thread-1 (]: 3 of 8 START test no_nulls_in_dim_listings ..................................... [RUN]
[0m16:06:01.367013 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m16:06:01.368013 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m16:06:01.380926 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:06:01.381976 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m16:06:01.383065 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:06:01.635244 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:06:01.636289 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:06:01.637259 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:06:01.710252 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m16:06:01.714006 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:06:01.715266 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 16:06:01.368013 => 16:06:01.715266
[0m16:06:01.716229 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m16:06:01.718227 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:06:01.720228 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:06:01.720228 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
    WHERE
        id_listings IS NULL OR
        listing_name IS NULL OR
        room_type IS NULL OR
        minimum_nights IS NULL OR
        host_id IS NULL OR
        price IS NULL OR
        created_at IS NULL OR
        updated_at IS NULL OR
        
    FALSE

      
    ) dbt_internal_test
[0m16:06:01.777528 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m16:06:01.778528 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 16:06:01.716229 => 16:06:01.778528
[0m16:06:01.779561 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m16:06:01.817811 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m16:06:01.819609 [info ] [Thread-1 (]: 3 of 8 PASS no_nulls_in_dim_listings ........................................... [[32mPASS[0m in 0.45s]
[0m16:06:01.820573 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:06:01.820573 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:06:01.821572 [info ] [Thread-1 (]: 4 of 8 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m16:06:01.823084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m16:06:01.823648 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:06:01.830162 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:06:01.832163 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 16:06:01.824157 => 16:06:01.832163
[0m16:06:01.833160 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:06:01.835673 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:06:01.836670 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:06:01.837670 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m16:06:01.837670 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:06:02.065738 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:06:02.066242 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:06:02.067244 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m16:06:02.120264 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m16:06:02.121272 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 16:06:01.833160 => 16:06:02.121272
[0m16:06:02.122779 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m16:06:02.160205 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m16:06:02.161212 [info ] [Thread-1 (]: 4 of 8 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.34s]
[0m16:06:02.162213 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:06:02.163245 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:06:02.164212 [info ] [Thread-1 (]: 5 of 8 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m16:06:02.164212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m16:06:02.165718 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:06:02.169725 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:06:02.171731 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 16:06:02.165718 => 16:06:02.171230
[0m16:06:02.172238 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:06:02.174243 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:06:02.176243 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:06:02.176243 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m16:06:02.177244 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:06:02.402882 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:06:02.402882 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:06:02.403882 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m16:06:02.458279 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m16:06:02.459310 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 16:06:02.172238 => 16:06:02.459310
[0m16:06:02.460282 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m16:06:02.495354 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m16:06:02.496428 [info ] [Thread-1 (]: 5 of 8 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.33s]
[0m16:06:02.497559 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:06:02.498562 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:06:02.499562 [info ] [Thread-1 (]: 6 of 8 START test positive_value_dim_listings_cleansed_minimum_nights .......... [RUN]
[0m16:06:02.500561 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m16:06:02.500561 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:06:02.504560 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:06:02.506560 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 16:06:02.501561 => 16:06:02.506560
[0m16:06:02.508067 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:06:02.511111 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:06:02.514080 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:06:02.515076 [debug] [Thread-1 (]: On test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313: BEGIN
[0m16:06:02.516080 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:06:02.749070 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:06:02.750037 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:06:02.750037 [debug] [Thread-1 (]: On test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
SELECT
    *
FROM
    "inttegra_stage"."test"."dim_listings_cleansed"
WHERE
    minimum_nights < 1

      
    ) dbt_internal_test
[0m16:06:02.799152 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m16:06:02.802152 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 16:06:02.508067 => 16:06:02.801154
[0m16:06:02.802152 [debug] [Thread-1 (]: On test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313: ROLLBACK
[0m16:06:02.836341 [debug] [Thread-1 (]: On test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313: Close
[0m16:06:02.838341 [info ] [Thread-1 (]: 6 of 8 PASS positive_value_dim_listings_cleansed_minimum_nights ................ [[32mPASS[0m in 0.34s]
[0m16:06:02.839342 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:06:02.839342 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:06:02.840380 [info ] [Thread-1 (]: 7 of 8 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m16:06:02.841343 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m16:06:02.842342 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:06:02.846367 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:06:02.848367 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 16:06:02.842342 => 16:06:02.847365
[0m16:06:02.848367 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:06:02.851365 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:06:02.852367 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:06:02.852367 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m16:06:02.853368 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:06:03.088857 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:06:03.090137 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:06:03.091166 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m16:06:03.173104 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m16:06:03.175093 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 16:06:02.849367 => 16:06:03.175093
[0m16:06:03.175093 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m16:06:03.210985 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m16:06:03.211994 [info ] [Thread-1 (]: 7 of 8 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.37s]
[0m16:06:03.212994 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:06:03.213994 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:06:03.214994 [info ] [Thread-1 (]: 8 of 8 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m16:06:03.214994 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m16:06:03.216500 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:06:03.222023 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:06:03.223022 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 16:06:03.216500 => 16:06:03.223022
[0m16:06:03.224020 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:06:03.226020 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:06:03.227020 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:06:03.227020 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m16:06:03.229066 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:06:03.491042 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:06:03.492044 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:06:03.493043 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m16:06:03.574191 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m16:06:03.576412 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 16:06:03.224020 => 16:06:03.576412
[0m16:06:03.577529 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m16:06:03.617097 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m16:06:03.618653 [info ] [Thread-1 (]: 8 of 8 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.40s]
[0m16:06:03.619689 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:06:03.621252 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:03.621771 [debug] [MainThread]: On master: BEGIN
[0m16:06:03.622287 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:06:03.874983 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:06:03.875991 [debug] [MainThread]: On master: COMMIT
[0m16:06:03.875991 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:03.875991 [debug] [MainThread]: On master: COMMIT
[0m16:06:03.913452 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:06:03.913452 [debug] [MainThread]: On master: Close
[0m16:06:03.914568 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:06:03.915574 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:06:03.915574 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m16:06:03.916574 [info ] [MainThread]: 
[0m16:06:03.917574 [info ] [MainThread]: Finished running 8 tests in 0 hours 0 minutes and 5.30 seconds (5.30s).
[0m16:06:03.918573 [debug] [MainThread]: Command end result
[0m16:06:03.931085 [info ] [MainThread]: 
[0m16:06:03.933083 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:06:03.934082 [info ] [MainThread]: 
[0m16:06:03.935092 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m16:06:03.939018 [debug] [MainThread]: Command `dbt test` succeeded at 16:06:03.938125 after 6.19 seconds
[0m16:06:03.939018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199D51F1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199D54DFE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199DC404110>]}
[0m16:06:03.940132 [debug] [MainThread]: Flushing usage events
[0m16:15:19.508309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9AE9F6050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9AE4D5750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9AE4D7B50>]}


============================== 16:15:19.512342 | a8739cbf-6794-4cc7-bfb7-d054e1a692a7 ==============================
[0m16:15:19.512342 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:15:19.513308 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:15:19.643626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a8739cbf-6794-4cc7-bfb7-d054e1a692a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9AE9AAE10>]}
[0m16:15:19.646630 [debug] [MainThread]: Set downloads directory='C:\Users\marco\AppData\Local\Temp\dbt-downloads-9nh7mhif'
[0m16:15:19.647630 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m16:15:21.382518 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m16:15:21.384513 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m16:15:21.833669 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m16:15:21.844089 [info ] [MainThread]: Updating lock file in file path: C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1/package-lock.yml
[0m16:15:21.858393 [debug] [MainThread]: Set downloads directory='C:\Users\marco\AppData\Local\Temp\dbt-downloads-ryg5ydsg'
[0m16:15:21.863132 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m16:15:23.303391 [info ] [MainThread]: Installed from version 1.3.0
[0m16:15:23.304894 [info ] [MainThread]: Up to date!
[0m16:15:23.306893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'a8739cbf-6794-4cc7-bfb7-d054e1a692a7', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9AEA29410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9AE9B39D0>]}
[0m16:15:23.311878 [debug] [MainThread]: Command `dbt deps` succeeded at 16:15:23.311878 after 3.88 seconds
[0m16:15:23.314878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9AE27C990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9A7291010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9A7290FD0>]}
[0m16:15:23.316174 [debug] [MainThread]: Flushing usage events
[0m16:17:25.442348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C675752850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C67496AA50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C675274490>]}


============================== 16:17:25.446862 | dc928ee6-58ec-41d4-966e-fe6a1c08e477 ==============================
[0m16:17:25.446862 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:17:25.447863 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select fact_reviews', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:17:25.686654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dc928ee6-58ec-41d4-966e-fe6a1c08e477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C675946310>]}
[0m16:17:25.778952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dc928ee6-58ec-41d4-966e-fe6a1c08e477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C6757627D0>]}
[0m16:17:25.781178 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:17:25.807371 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:17:25.828145 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m16:17:25.829154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'dc928ee6-58ec-41d4-966e-fe6a1c08e477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C675B6C750>]}
[0m16:17:28.284188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dc928ee6-58ec-41d4-966e-fe6a1c08e477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C6770F98D0>]}
[0m16:17:28.301204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc928ee6-58ec-41d4-966e-fe6a1c08e477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C677001D50>]}
[0m16:17:28.302204 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:17:28.303716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc928ee6-58ec-41d4-966e-fe6a1c08e477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C670A1F590>]}
[0m16:17:28.305889 [info ] [MainThread]: 
[0m16:17:28.306923 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:17:28.308890 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:17:28.318991 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:17:28.318991 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:17:28.320497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:17:29.682338 [debug] [ThreadPool]: SQL status: SELECT 25 in 1.0 seconds
[0m16:17:29.684351 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:17:29.687374 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:17:29.693373 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:17:29.694371 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:17:29.695373 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:17:29.924020 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:17:29.925025 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:17:29.926025 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:17:29.978520 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:17:29.980516 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:17:30.014461 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:17:30.022451 [debug] [MainThread]: Using postgres connection "master"
[0m16:17:30.022451 [debug] [MainThread]: On master: BEGIN
[0m16:17:30.023592 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:17:30.241858 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:17:30.242872 [debug] [MainThread]: Using postgres connection "master"
[0m16:17:30.242872 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:17:30.309522 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:17:30.311746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc928ee6-58ec-41d4-966e-fe6a1c08e477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C6771E1790>]}
[0m16:17:30.311746 [debug] [MainThread]: On master: ROLLBACK
[0m16:17:30.338920 [debug] [MainThread]: Using postgres connection "master"
[0m16:17:30.338920 [debug] [MainThread]: On master: BEGIN
[0m16:17:30.414672 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:17:30.414672 [debug] [MainThread]: On master: COMMIT
[0m16:17:30.415672 [debug] [MainThread]: Using postgres connection "master"
[0m16:17:30.415672 [debug] [MainThread]: On master: COMMIT
[0m16:17:30.447041 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:17:30.448058 [debug] [MainThread]: On master: Close
[0m16:17:30.449063 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:17:30.451060 [info ] [MainThread]: 
[0m16:17:30.453058 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:17:30.455158 [info ] [Thread-1 (]: 1 of 1 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:17:30.456719 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.fact_reviews'
[0m16:17:30.458236 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:17:30.480189 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:17:30.484924 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:17:30.459237 => 16:17:30.484924
[0m16:17:30.484924 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:17:30.547572 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:17:30.549528 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp161730517273"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    md5(cast(coalesce(cast(listing_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(review_date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(reviewer_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(review_text as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as review_id,
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:17:30.549528 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:17:30.773330 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "review_text" does not exist
LINE 21: ...ils_surrogate_key_null_') || '-' || coalesce(cast(review_tex...
                                                              ^
HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".

[0m16:17:30.774398 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:17:30.484924 => 16:17:30.774398
[0m16:17:30.775352 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:17:30.780725 [debug] [Thread-1 (]: Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  column "review_text" does not exist
  LINE 21: ...ils_surrogate_key_null_') || '-' || coalesce(cast(review_tex...
                                                                ^
  HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".
[0m16:17:30.781725 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dc928ee6-58ec-41d4-966e-fe6a1c08e477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C676DF6A90>]}
[0m16:17:30.782726 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model test.fact_reviews .................. [[31mERROR[0m in 0.33s]
[0m16:17:30.783727 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:17:30.785725 [debug] [MainThread]: Using postgres connection "master"
[0m16:17:30.785725 [debug] [MainThread]: On master: BEGIN
[0m16:17:30.786724 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:17:31.010234 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:17:31.011201 [debug] [MainThread]: On master: COMMIT
[0m16:17:31.011201 [debug] [MainThread]: Using postgres connection "master"
[0m16:17:31.012201 [debug] [MainThread]: On master: COMMIT
[0m16:17:31.044462 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:17:31.045470 [debug] [MainThread]: On master: Close
[0m16:17:31.046469 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:17:31.046469 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:17:31.047764 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:17:31.047764 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m16:17:31.048765 [info ] [MainThread]: 
[0m16:17:31.048765 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 2.74 seconds (2.74s).
[0m16:17:31.050732 [debug] [MainThread]: Command end result
[0m16:17:31.065266 [info ] [MainThread]: 
[0m16:17:31.066271 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:17:31.066271 [info ] [MainThread]: 
[0m16:17:31.067782 [error] [MainThread]:   Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  column "review_text" does not exist
  LINE 21: ...ils_surrogate_key_null_') || '-' || coalesce(cast(review_tex...
                                                                ^
  HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".
[0m16:17:31.068870 [info ] [MainThread]: 
[0m16:17:31.070011 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:17:31.072012 [debug] [MainThread]: Command `dbt run` failed at 16:17:31.071012 after 5.70 seconds
[0m16:17:31.073018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C675798110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C66DFC1050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C66DFC1B90>]}
[0m16:17:31.074049 [debug] [MainThread]: Flushing usage events
[0m16:19:14.507203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9E27DE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9B218E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9E197A90>]}


============================== 16:19:14.511204 | 5bc14ffe-f959-4716-8db4-eb778be06924 ==============================
[0m16:19:14.511204 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:19:14.512205 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select fact_reviews', 'send_anonymous_usage_stats': 'True'}
[0m16:19:14.721912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5bc14ffe-f959-4716-8db4-eb778be06924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9E875E50>]}
[0m16:19:14.801202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5bc14ffe-f959-4716-8db4-eb778be06924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9E6E2350>]}
[0m16:19:14.802960 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:19:14.818587 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:19:15.012943 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:19:15.013946 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\fact\fact_reviews.sql
[0m16:19:15.155599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5bc14ffe-f959-4716-8db4-eb778be06924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9FBE7110>]}
[0m16:19:15.172681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5bc14ffe-f959-4716-8db4-eb778be06924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9FA60D90>]}
[0m16:19:15.173605 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:19:15.174608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5bc14ffe-f959-4716-8db4-eb778be06924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9E143E90>]}
[0m16:19:15.177120 [info ] [MainThread]: 
[0m16:19:15.178138 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:19:15.179644 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:19:15.189148 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:19:15.190383 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:19:15.190383 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:19:16.528742 [debug] [ThreadPool]: SQL status: SELECT 25 in 1.0 seconds
[0m16:19:16.530551 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:19:16.535645 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:19:16.547038 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:19:16.548427 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:19:16.550006 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:19:16.764728 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:19:16.769415 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:19:16.769751 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:19:16.816326 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:19:16.816326 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:19:16.849591 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:19:16.864686 [debug] [MainThread]: Using postgres connection "master"
[0m16:19:16.865719 [debug] [MainThread]: On master: BEGIN
[0m16:19:16.865719 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:19:17.107932 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:19:17.107932 [debug] [MainThread]: Using postgres connection "master"
[0m16:19:17.108941 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:19:17.308499 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:19:17.310525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5bc14ffe-f959-4716-8db4-eb778be06924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9DE76D50>]}
[0m16:19:17.311524 [debug] [MainThread]: On master: ROLLBACK
[0m16:19:17.350097 [debug] [MainThread]: Using postgres connection "master"
[0m16:19:17.350097 [debug] [MainThread]: On master: BEGIN
[0m16:19:17.424628 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:19:17.424628 [debug] [MainThread]: On master: COMMIT
[0m16:19:17.424628 [debug] [MainThread]: Using postgres connection "master"
[0m16:19:17.424628 [debug] [MainThread]: On master: COMMIT
[0m16:19:17.465122 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:19:17.466127 [debug] [MainThread]: On master: Close
[0m16:19:17.467128 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:19:17.468130 [info ] [MainThread]: 
[0m16:19:17.471128 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:19:17.473149 [info ] [Thread-1 (]: 1 of 1 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:19:17.475160 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.fact_reviews'
[0m16:19:17.476162 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:19:17.489199 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:19:17.493204 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:19:17.477159 => 16:19:17.492209
[0m16:19:17.493204 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:19:17.551916 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:19:17.552949 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp161917528567"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    md5(cast(coalesce(cast(listing_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(review_date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(reviewer_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(review_txt as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as review_id,
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:19:17.552949 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:19:18.795453 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:19:18.803646 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:19:18.804647 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:19:18.844977 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:19:18.845978 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:19:18.846984 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp161917528567'
        
      order by ordinal_position

  
[0m16:19:18.919782 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m16:19:18.924818 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:19:18.924818 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:19:18.973269 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:19:18.985877 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:19:18.986842 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp161917528567'
        
      order by ordinal_position

  
[0m16:19:19.033459 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m16:19:19.037684 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:19:19.038712 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:19:19.084446 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:19:19.093117 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: True
        Source columns not in target: [<Column review_id (text)>]
        Target columns not in source: []
        New column types: []
  
[0m16:19:19.094117 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:19:17.494198 => 16:19:19.094117
[0m16:19:19.095097 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: ROLLBACK
[0m16:19:19.134175 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:19:19.152376 [debug] [Thread-1 (]: Compilation Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  
                The source and target schemas on this incremental model are out of sync!
                They can be reconciled in several ways:
                  - set the `on_schema_change` config to either append_new_columns or sync_all_columns, depending on your situation.
                  - Re-run the incremental model with `full_refresh: True` to update the target schema.
                  - update the schema manually and re-run the process.
  
                Additional troubleshooting context:
                   Source columns not in target: [<Column review_id (text)>]
                   Target columns not in source: []
                   New column types: []
            
  
  > in macro process_schema_changes (macros\materializations\models\incremental\on_schema_change.sql)
  > called by macro materialization_incremental_default (macros\materializations\models\incremental\incremental.sql)
  > called by model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
[0m16:19:19.153375 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5bc14ffe-f959-4716-8db4-eb778be06924', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9FB2B150>]}
[0m16:19:19.154879 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model test.fact_reviews .................. [[31mERROR[0m in 1.68s]
[0m16:19:19.156354 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:19:19.158369 [debug] [MainThread]: Using postgres connection "master"
[0m16:19:19.158369 [debug] [MainThread]: On master: BEGIN
[0m16:19:19.159371 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:19:19.423067 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:19:19.424054 [debug] [MainThread]: On master: COMMIT
[0m16:19:19.424054 [debug] [MainThread]: Using postgres connection "master"
[0m16:19:19.425049 [debug] [MainThread]: On master: COMMIT
[0m16:19:19.455675 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:19:19.455675 [debug] [MainThread]: On master: Close
[0m16:19:19.455675 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:19:19.455675 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:19:19.455675 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:19:19.455675 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m16:19:19.455675 [info ] [MainThread]: 
[0m16:19:19.455675 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.28 seconds (4.28s).
[0m16:19:19.467403 [debug] [MainThread]: Command end result
[0m16:19:19.479845 [info ] [MainThread]: 
[0m16:19:19.480880 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:19:19.481886 [info ] [MainThread]: 
[0m16:19:19.483885 [error] [MainThread]:   Compilation Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  
                The source and target schemas on this incremental model are out of sync!
                They can be reconciled in several ways:
                  - set the `on_schema_change` config to either append_new_columns or sync_all_columns, depending on your situation.
                  - Re-run the incremental model with `full_refresh: True` to update the target schema.
                  - update the schema manually and re-run the process.
  
                Additional troubleshooting context:
                   Source columns not in target: [<Column review_id (text)>]
                   Target columns not in source: []
                   New column types: []
            
  
  > in macro process_schema_changes (macros\materializations\models\incremental\on_schema_change.sql)
  > called by macro materialization_incremental_default (macros\materializations\models\incremental\incremental.sql)
  > called by model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
[0m16:19:19.484887 [info ] [MainThread]: 
[0m16:19:19.485923 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:19:19.487843 [debug] [MainThread]: Command `dbt run` failed at 16:19:19.487843 after 5.04 seconds
[0m16:19:19.487843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC96FC1050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9E220450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC9E997B10>]}
[0m16:19:19.488810 [debug] [MainThread]: Flushing usage events
[0m16:20:24.457195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A8DC6790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A88E5E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A89DB2D0>]}


============================== 16:20:24.461698 | 96500520-3c96-41ea-a8d4-7cdc2b8d4617 ==============================
[0m16:20:24.461698 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:20:24.463188 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select fact_reviews --full-refresh', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:20:24.691166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96500520-3c96-41ea-a8d4-7cdc2b8d4617', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A8E31910>]}
[0m16:20:24.776420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '96500520-3c96-41ea-a8d4-7cdc2b8d4617', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A85ED910>]}
[0m16:20:24.780094 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:20:24.797104 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:20:25.003166 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:20:25.003166 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:20:25.020215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96500520-3c96-41ea-a8d4-7cdc2b8d4617', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A91CA110>]}
[0m16:20:25.038767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96500520-3c96-41ea-a8d4-7cdc2b8d4617', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A91038D0>]}
[0m16:20:25.038767 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:20:25.040615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96500520-3c96-41ea-a8d4-7cdc2b8d4617', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A900A650>]}
[0m16:20:25.042622 [info ] [MainThread]: 
[0m16:20:25.042622 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:20:25.042622 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:20:25.055693 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:20:25.055693 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:20:25.060411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:20:25.413800 [debug] [ThreadPool]: SQL status: SELECT 25 in 0.0 seconds
[0m16:20:25.414800 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:20:25.417800 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:20:25.424313 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:20:25.426317 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:20:25.426317 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:20:25.667395 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:20:25.668361 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:20:25.668361 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:20:25.722417 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:20:25.723451 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:20:25.758030 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:20:25.766641 [debug] [MainThread]: Using postgres connection "master"
[0m16:20:25.767610 [debug] [MainThread]: On master: BEGIN
[0m16:20:25.767610 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:20:26.022038 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:20:26.022923 [debug] [MainThread]: Using postgres connection "master"
[0m16:20:26.023919 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:20:26.095277 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:20:26.097583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96500520-3c96-41ea-a8d4-7cdc2b8d4617', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A8FE9C50>]}
[0m16:20:26.098581 [debug] [MainThread]: On master: ROLLBACK
[0m16:20:26.136997 [debug] [MainThread]: Using postgres connection "master"
[0m16:20:26.138036 [debug] [MainThread]: On master: BEGIN
[0m16:20:26.216162 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:20:26.216709 [debug] [MainThread]: On master: COMMIT
[0m16:20:26.217746 [debug] [MainThread]: Using postgres connection "master"
[0m16:20:26.217746 [debug] [MainThread]: On master: COMMIT
[0m16:20:26.252478 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:20:26.253598 [debug] [MainThread]: On master: Close
[0m16:20:26.254637 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:20:26.255605 [info ] [MainThread]: 
[0m16:20:26.258602 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:20:26.260604 [info ] [Thread-1 (]: 1 of 1 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:20:26.262616 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.fact_reviews'
[0m16:20:26.263602 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:20:26.296978 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:20:26.298962 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:20:26.263602 => 16:20:26.297967
[0m16:20:26.298962 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:20:26.352218 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:20:26.354175 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:20:26.355176 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:20:26.356182 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:20:26.602356 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:20:26.603351 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:20:26.603351 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      
  
    

  create  table "inttegra_stage"."test"."fact_reviews__dbt_tmp"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    md5(cast(coalesce(cast(listing_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(review_date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(reviewer_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(review_txt as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as review_id,
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

  );
  
  
[0m16:20:28.969723 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m16:20:28.980944 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:20:28.980944 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */
alter table "inttegra_stage"."test"."fact_reviews" rename to "fact_reviews__dbt_backup"
[0m16:20:29.017704 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:20:29.028723 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:20:29.029900 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */
alter table "inttegra_stage"."test"."fact_reviews__dbt_tmp" rename to "fact_reviews"
[0m16:20:29.070027 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:20:29.093003 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:20:29.094027 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:20:29.096001 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:20:29.137696 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:20:29.146764 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."fact_reviews__dbt_backup"
[0m16:20:29.151299 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:20:29.153304 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */
drop table if exists "inttegra_stage"."test"."fact_reviews__dbt_backup" cascade
[0m16:20:29.239217 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:20:29.241217 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:20:26.300471 => 16:20:29.241217
[0m16:20:29.242215 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:20:29.243216 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96500520-3c96-41ea-a8d4-7cdc2b8d4617', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A8EDCB50>]}
[0m16:20:29.243216 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model test.fact_reviews ...................... [[32mSELECT 410284[0m in 2.98s]
[0m16:20:29.245239 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:20:29.247246 [debug] [MainThread]: Using postgres connection "master"
[0m16:20:29.248246 [debug] [MainThread]: On master: BEGIN
[0m16:20:29.249247 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:20:29.467466 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:20:29.468463 [debug] [MainThread]: On master: COMMIT
[0m16:20:29.469463 [debug] [MainThread]: Using postgres connection "master"
[0m16:20:29.469463 [debug] [MainThread]: On master: COMMIT
[0m16:20:29.500808 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:20:29.500808 [debug] [MainThread]: On master: Close
[0m16:20:29.502019 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:20:29.503024 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:20:29.504026 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:20:29.505025 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m16:20:29.505025 [info ] [MainThread]: 
[0m16:20:29.506023 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.46 seconds (4.46s).
[0m16:20:29.507024 [debug] [MainThread]: Command end result
[0m16:20:29.521517 [info ] [MainThread]: 
[0m16:20:29.523357 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:20:29.525369 [info ] [MainThread]: 
[0m16:20:29.526372 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:20:29.529376 [debug] [MainThread]: Command `dbt run` succeeded at 16:20:29.529376 after 5.14 seconds
[0m16:20:29.530371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A8E13F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A1661210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A4A195F410>]}
[0m16:20:29.531404 [debug] [MainThread]: Flushing usage events
[0m16:40:37.811161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024676A1D550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467A2692D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467A044F90>]}


============================== 16:40:37.816821 | 523f14eb-c040-4957-821a-912adfece67a ==============================
[0m16:40:37.816821 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:40:37.817826 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:40:38.057563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '523f14eb-c040-4957-821a-912adfece67a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467A720190>]}
[0m16:40:38.139887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '523f14eb-c040-4957-821a-912adfece67a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467A66E4D0>]}
[0m16:40:38.141376 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:40:38.155462 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:40:38.337250 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:40:38.338249 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m16:40:38.629436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '523f14eb-c040-4957-821a-912adfece67a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467BB591D0>]}
[0m16:40:38.633469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '523f14eb-c040-4957-821a-912adfece67a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467A92FE50>]}
[0m16:40:38.633469 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:40:38.634469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '523f14eb-c040-4957-821a-912adfece67a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467BBA7D10>]}
[0m16:40:38.637501 [info ] [MainThread]: 
[0m16:40:38.638468 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:40:38.640470 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:40:38.649948 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:40:38.651456 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:40:38.652466 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:40:40.028952 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m16:40:40.029953 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:40:40.030954 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:40:40.079378 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:40:40.081360 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:40:40.118344 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:40:40.126852 [debug] [MainThread]: Using postgres connection "master"
[0m16:40:40.127854 [debug] [MainThread]: On master: BEGIN
[0m16:40:40.128852 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:40:40.392271 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:40:40.393250 [debug] [MainThread]: Using postgres connection "master"
[0m16:40:40.393250 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:40:40.461020 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:40:40.463019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '523f14eb-c040-4957-821a-912adfece67a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467A762810>]}
[0m16:40:40.464017 [debug] [MainThread]: On master: ROLLBACK
[0m16:40:40.499227 [debug] [MainThread]: On master: Close
[0m16:40:40.500236 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:40:40.501232 [info ] [MainThread]: 
[0m16:40:40.505246 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:40:40.506751 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:40:40.506751 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:40:40.519375 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:40:40.521585 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:40:40.508325 => 16:40:40.521585
[0m16:40:40.523587 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:40:40.524587 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:40:40.524587 => 16:40:40.524587
[0m16:40:40.525584 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:40:40.526584 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:40:40.527585 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:40:40.528585 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:40:40.533844 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:40:40.535834 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:40:40.528585 => 16:40:40.535834
[0m16:40:40.536831 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:40:40.537864 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:40:40.537864 => 16:40:40.537864
[0m16:40:40.539829 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:40:40.539829 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:40:40.541830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:40:40.541830 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:40:40.545348 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:40:40.547346 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:40:40.542833 => 16:40:40.546345
[0m16:40:40.548348 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:40:40.549349 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:40:40.549349 => 16:40:40.549349
[0m16:40:40.551346 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:40:40.552352 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m16:40:40.553354 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m16:40:40.554895 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m16:40:40.557771 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 16:40:40.554895 => 16:40:40.557771
[0m16:40:40.558783 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m16:40:40.559773 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 16:40:40.559773 => 16:40:40.559773
[0m16:40:40.560774 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m16:40:40.561772 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m16:40:40.561772 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m16:40:40.562772 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m16:40:40.571304 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 16:40:40.563769 => 16:40:40.571304
[0m16:40:40.572302 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m16:40:40.573302 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 16:40:40.573302 => 16:40:40.573302
[0m16:40:40.574303 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m16:40:40.575301 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:40:40.575301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m16:40:40.576301 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:40:40.579301 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:40:40.581320 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:40:40.576301 => 16:40:40.580314
[0m16:40:40.581320 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:40:40.582320 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:40:40.582320 => 16:40:40.582320
[0m16:40:40.583318 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:40:40.584321 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:40:40.585319 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:40:40.585319 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:40:40.588319 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:40:40.590829 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:40:40.586319 => 16:40:40.590829
[0m16:40:40.593293 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:40:40.594272 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:40:40.594272 => 16:40:40.594272
[0m16:40:40.596271 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:40:40.597271 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:40:40.599271 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:40:40.600270 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:40:40.620811 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:40:40.621811 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:40:40.600270 => 16:40:40.621811
[0m16:40:40.622811 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:40:40.623811 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:40:40.622811 => 16:40:40.622811
[0m16:40:40.624811 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:40:40.624811 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:40:40.625810 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:40:40.625810 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:40:40.629834 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:40:40.631832 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:40:40.627316 => 16:40:40.631832
[0m16:40:40.632835 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:40:40.633834 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:40:40.633834 => 16:40:40.633834
[0m16:40:40.634834 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:40:40.635839 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:40:40.636841 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m16:40:40.636841 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:40:40.640993 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:40:40.642999 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 16:40:40.637834 => 16:40:40.642999
[0m16:40:40.642999 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:40:40.644034 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 16:40:40.644034 => 16:40:40.644034
[0m16:40:40.645033 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:40:40.645999 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m16:40:40.647017 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m16:40:40.648037 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m16:40:40.651033 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:40:40.653009 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 16:40:40.649045 => 16:40:40.653009
[0m16:40:40.653009 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m16:40:40.654022 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 16:40:40.654022 => 16:40:40.654022
[0m16:40:40.655064 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m16:40:40.656028 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:40:40.656028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m16:40:40.657062 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m16:40:40.666785 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:40:40.667751 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m16:40:40.667751 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:40:40.924030 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:40:40.925034 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:40:40.927540 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:40:40.994026 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m16:40:40.998057 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:40:40.999564 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 16:40:40.657062 => 16:40:40.999564
[0m16:40:41.000561 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m16:40:41.000561 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 16:40:41.000561 => 16:40:41.000561
[0m16:40:41.001800 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m16:40:41.041074 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m16:40:41.043001 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:40:41.043001 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:40:41.044000 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m16:40:41.045000 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:40:41.054025 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:40:41.055025 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 16:40:41.045000 => 16:40:41.055025
[0m16:40:41.056026 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:40:41.057026 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 16:40:41.056026 => 16:40:41.056026
[0m16:40:41.057026 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:40:41.058530 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:40:41.059536 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m16:40:41.060041 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:40:41.066052 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:40:41.068051 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 16:40:41.060525 => 16:40:41.067052
[0m16:40:41.069058 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:40:41.069058 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 16:40:41.069058 => 16:40:41.069058
[0m16:40:41.070051 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:40:41.071556 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:40:41.072073 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m16:40:41.072073 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:40:41.076079 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:40:41.078079 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 16:40:41.073078 => 16:40:41.077078
[0m16:40:41.078079 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:40:41.079079 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 16:40:41.079079 => 16:40:41.079079
[0m16:40:41.080079 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:40:41.080079 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:40:41.081079 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m16:40:41.082079 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:40:41.087718 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:40:41.089684 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 16:40:41.082079 => 16:40:41.088719
[0m16:40:41.089684 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:40:41.090719 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 16:40:41.090719 => 16:40:41.090719
[0m16:40:41.091689 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:40:41.092690 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:40:41.093689 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m16:40:41.093689 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:40:41.099937 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:40:41.101899 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 16:40:41.094688 => 16:40:41.101899
[0m16:40:41.102899 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:40:41.102899 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 16:40:41.102899 => 16:40:41.102899
[0m16:40:41.103899 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:40:41.104933 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m16:40:41.105936 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m16:40:41.105936 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m16:40:41.109447 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m16:40:41.111454 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 16:40:41.105936 => 16:40:41.111454
[0m16:40:41.113449 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m16:40:41.113449 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 16:40:41.113449 => 16:40:41.113449
[0m16:40:41.114486 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m16:40:41.115484 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:40:41.116483 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:40:41.116483 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m16:40:41.120023 [debug] [MainThread]: Command end result
[0m16:40:41.340015 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m16:40:41.340541 [info ] [MainThread]: Building catalog
[0m16:40:41.344550 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m16:40:41.356987 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:40:41.358200 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m16:40:41.359351 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:40:41.610989 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:40:41.610989 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:40:41.612497 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m16:40:41.813986 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m16:40:41.821112 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m16:40:41.852575 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m16:40:41.869266 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m16:40:41.871267 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:40:41.871267 after 4.13 seconds
[0m16:40:41.872264 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:40:41.872264 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m16:40:41.873266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467A13CB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002467BC6B4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024679746790>]}
[0m16:40:41.873266 [debug] [MainThread]: Flushing usage events
[0m16:43:00.974756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6872EF1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6858BCC90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E686B44790>]}


============================== 16:43:00.979222 | f4cee8fd-020e-4c35-b229-7a66395d8e11 ==============================
[0m16:43:00.979222 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:43:00.980224 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:43:01.223709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f4cee8fd-020e-4c35-b229-7a66395d8e11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E686EA2050>]}
[0m16:43:01.305719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f4cee8fd-020e-4c35-b229-7a66395d8e11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6873355D0>]}
[0m16:50:14.992396 [error] [MainThread]: Encountered an error:

[0m16:50:15.058541 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 90, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 75, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 168, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 197, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 244, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\main.py", line 324, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\task\serve.py", line 28, in run
    httpd.serve_forever()
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\socketserver.py", line 233, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m16:50:15.061081 [debug] [MainThread]: Command `dbt docs serve` failed at 16:50:15.061081 after 434.15 seconds
[0m16:50:15.061634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6872FC850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E686E32150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E686AF6790>]}
[0m16:50:15.061634 [debug] [MainThread]: Flushing usage events
[0m16:50:22.656359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA0595B3D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA0608F790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA0608ECD0>]}


============================== 16:50:22.660903 | 1cb88e26-df21-4028-9846-fc3720ec97a8 ==============================
[0m16:50:22.660903 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:50:22.662900 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m16:50:22.911849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1cb88e26-df21-4028-9846-fc3720ec97a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA05C42050>]}
[0m16:50:22.993112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1cb88e26-df21-4028-9846-fc3720ec97a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA058959D0>]}
[0m16:50:22.995736 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:50:23.008979 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:50:23.193816 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m16:50:23.194816 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\docs.md
[0m16:50:23.195816 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m16:50:23.485727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1cb88e26-df21-4028-9846-fc3720ec97a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA07747090>]}
[0m16:50:23.490783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1cb88e26-df21-4028-9846-fc3720ec97a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA0649FD90>]}
[0m16:50:23.491784 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:50:23.492792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1cb88e26-df21-4028-9846-fc3720ec97a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA062FD450>]}
[0m16:50:23.495781 [info ] [MainThread]: 
[0m16:50:23.496783 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:50:23.499280 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:50:23.508285 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:50:23.509793 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:50:23.510361 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:23.897793 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:50:23.897793 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:50:23.898801 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:50:23.956506 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:50:23.958503 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:50:23.996952 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:50:24.004452 [debug] [MainThread]: Using postgres connection "master"
[0m16:50:24.005421 [debug] [MainThread]: On master: BEGIN
[0m16:50:24.005421 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:50:24.242825 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:50:24.244177 [debug] [MainThread]: Using postgres connection "master"
[0m16:50:24.245146 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:50:24.312792 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:50:24.315259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1cb88e26-df21-4028-9846-fc3720ec97a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA0651D050>]}
[0m16:50:24.315701 [debug] [MainThread]: On master: ROLLBACK
[0m16:50:24.350965 [debug] [MainThread]: On master: Close
[0m16:50:24.352197 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:50:24.352708 [info ] [MainThread]: 
[0m16:50:24.355711 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:50:24.356710 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:50:24.357710 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:50:24.365163 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:50:24.366129 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:50:24.358714 => 16:50:24.366129
[0m16:50:24.367129 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:50:24.368129 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:50:24.368129 => 16:50:24.368129
[0m16:50:24.370163 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:50:24.371129 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:50:24.372128 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:50:24.373133 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:50:24.378726 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:50:24.382660 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:50:24.374154 => 16:50:24.381665
[0m16:50:24.383665 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:50:24.385661 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:50:24.384659 => 16:50:24.384659
[0m16:50:24.388182 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:50:24.389188 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:50:24.390189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:50:24.391193 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:50:24.395196 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:50:24.397188 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:50:24.392190 => 16:50:24.397188
[0m16:50:24.398221 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:50:24.398221 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:50:24.398221 => 16:50:24.398221
[0m16:50:24.399188 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:50:24.400164 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m16:50:24.402401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m16:50:24.403428 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m16:50:24.405394 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 16:50:24.403428 => 16:50:24.405394
[0m16:50:24.406433 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m16:50:24.407396 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 16:50:24.406433 => 16:50:24.406433
[0m16:50:24.408399 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m16:50:24.409448 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m16:50:24.410955 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m16:50:24.411472 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m16:50:24.415476 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 16:50:24.412018 => 16:50:24.415476
[0m16:50:24.416477 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m16:50:24.416477 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 16:50:24.416477 => 16:50:24.416477
[0m16:50:24.417478 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m16:50:24.418478 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:50:24.419478 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m16:50:24.420480 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:50:24.424628 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:50:24.426635 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:50:24.420480 => 16:50:24.425639
[0m16:50:24.427634 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:50:24.428634 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:50:24.428634 => 16:50:24.428634
[0m16:50:24.430635 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:50:24.431632 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:50:24.432633 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:50:24.432633 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:50:24.436132 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:50:24.437660 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:50:24.432633 => 16:50:24.437660
[0m16:50:24.438660 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:50:24.438660 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:50:24.438660 => 16:50:24.438660
[0m16:50:24.439660 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:50:24.440659 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:50:24.441977 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:50:24.441977 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:50:24.462507 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:50:24.464508 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:50:24.442976 => 16:50:24.463508
[0m16:50:24.464508 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:50:24.465508 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:50:24.465508 => 16:50:24.465508
[0m16:50:24.466508 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:50:24.466508 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:50:24.467508 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:50:24.468507 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:50:24.472162 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:50:24.473761 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:50:24.468507 => 16:50:24.473761
[0m16:50:24.473761 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:50:24.474801 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:50:24.474801 => 16:50:24.474801
[0m16:50:24.475767 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:50:24.476765 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:50:24.477771 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m16:50:24.478770 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:50:24.483306 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:50:24.484631 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 16:50:24.478770 => 16:50:24.484631
[0m16:50:24.485611 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:50:24.486595 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 16:50:24.485611 => 16:50:24.485611
[0m16:50:24.487629 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:50:24.487629 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m16:50:24.488629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m16:50:24.489639 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m16:50:24.493629 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:50:24.495137 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 16:50:24.490596 => 16:50:24.493629
[0m16:50:24.495696 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m16:50:24.496731 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 16:50:24.496207 => 16:50:24.496207
[0m16:50:24.497700 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m16:50:24.497700 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:50:24.498731 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m16:50:24.499732 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m16:50:24.510772 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:50:24.511739 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m16:50:24.511739 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:50:24.741091 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:50:24.742098 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:50:24.742098 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:50:24.807585 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m16:50:24.811144 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:50:24.812145 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 16:50:24.499732 => 16:50:24.812145
[0m16:50:24.813178 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m16:50:24.813178 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 16:50:24.813178 => 16:50:24.813178
[0m16:50:24.814144 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m16:50:24.847454 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m16:50:24.848460 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:50:24.849459 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:50:24.850462 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m16:50:24.850462 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:50:24.859641 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:50:24.861623 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 16:50:24.851461 => 16:50:24.861623
[0m16:50:24.862622 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:50:24.863622 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 16:50:24.863622 => 16:50:24.863622
[0m16:50:24.864621 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:50:24.865622 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:50:24.866623 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m16:50:24.867622 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:50:24.874052 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:50:24.876051 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 16:50:24.867622 => 16:50:24.875052
[0m16:50:24.877053 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:50:24.878052 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 16:50:24.877053 => 16:50:24.877053
[0m16:50:24.878052 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:50:24.880084 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:50:24.881090 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m16:50:24.882092 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:50:24.886093 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:50:24.888091 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 16:50:24.882092 => 16:50:24.888091
[0m16:50:24.889091 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:50:24.890091 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 16:50:24.889091 => 16:50:24.889091
[0m16:50:24.890091 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:50:24.891597 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:50:24.893811 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m16:50:24.894808 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:50:24.900675 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:50:24.903330 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 16:50:24.895811 => 16:50:24.902807
[0m16:50:24.903842 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:50:24.904885 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 16:50:24.904365 => 16:50:24.904365
[0m16:50:24.905940 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:50:24.906456 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:50:24.907564 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m16:50:24.908560 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:50:24.915427 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:50:24.917669 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 16:50:24.909070 => 16:50:24.917113
[0m16:50:24.918255 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:50:24.919269 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 16:50:24.918255 => 16:50:24.918255
[0m16:50:24.920272 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:50:24.921262 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m16:50:24.923261 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m16:50:24.924026 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m16:50:24.927469 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m16:50:24.929058 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 16:50:24.924590 => 16:50:24.928494
[0m16:50:24.929587 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m16:50:24.930104 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 16:50:24.930104 => 16:50:24.930104
[0m16:50:24.931878 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m16:50:24.933027 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:50:24.933591 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:50:24.934106 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m16:50:24.937761 [debug] [MainThread]: Command end result
[0m16:50:24.955205 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m16:50:24.956314 [info ] [MainThread]: Building catalog
[0m16:50:24.960444 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m16:50:24.968149 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:50:24.969187 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m16:50:24.970406 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:25.200703 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:50:25.201718 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:50:25.201718 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m16:50:25.254529 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m16:50:25.261488 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m16:50:25.298902 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m16:50:25.315825 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m16:50:25.317826 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:50:25.317826 after 2.73 seconds
[0m16:50:25.318859 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:50:25.318859 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m16:50:25.319825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA05F9CE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA058E4650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AA058C0E10>]}
[0m16:50:25.319825 [debug] [MainThread]: Flushing usage events
[0m16:50:32.779848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026692034250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266956E5B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026695776190>]}


============================== 16:50:32.783847 | ffc11740-2186-437f-b31f-fdcf397d90f7 ==============================
[0m16:50:32.783847 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:50:32.784847 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt docs serve', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:50:33.002860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ffc11740-2186-437f-b31f-fdcf397d90f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026695702050>]}
[0m16:50:33.083529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ffc11740-2186-437f-b31f-fdcf397d90f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026695BC0C10>]}
[0m16:53:00.483056 [error] [MainThread]: Encountered an error:

[0m16:53:00.486060 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 90, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 75, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 168, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 197, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 244, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\main.py", line 324, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\task\serve.py", line 28, in run
    httpd.serve_forever()
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\socketserver.py", line 233, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m16:53:00.489057 [debug] [MainThread]: Command `dbt docs serve` failed at 16:53:00.488061 after 147.77 seconds
[0m16:53:00.489057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026695775D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266956CBD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266956C8090>]}
[0m16:53:00.490060 [debug] [MainThread]: Flushing usage events
[0m16:53:09.554798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016939733090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169396E5910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016939F28790>]}


============================== 16:53:09.560464 | e27b6b57-22e5-4ee7-8151-84e24f7bd00a ==============================
[0m16:53:09.560464 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:53:09.561486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:53:09.787274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e27b6b57-22e5-4ee7-8151-84e24f7bd00a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016939F50490>]}
[0m16:53:09.867122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e27b6b57-22e5-4ee7-8151-84e24f7bd00a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001693979F690>]}
[0m16:53:09.868089 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:53:09.882073 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:53:10.063741 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:53:10.064743 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\overview.md
[0m16:53:10.075480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e27b6b57-22e5-4ee7-8151-84e24f7bd00a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001693970F610>]}
[0m16:53:10.080517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e27b6b57-22e5-4ee7-8151-84e24f7bd00a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001693A307F90>]}
[0m16:53:10.080517 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:53:10.081512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e27b6b57-22e5-4ee7-8151-84e24f7bd00a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001693A154E50>]}
[0m16:53:10.084479 [info ] [MainThread]: 
[0m16:53:10.085522 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:53:10.087999 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:53:10.100860 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:53:10.101982 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:53:10.102894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:53:11.505373 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m16:53:11.506388 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:53:11.506388 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:53:11.564960 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:53:11.566968 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:53:11.607133 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:53:11.616957 [debug] [MainThread]: Using postgres connection "master"
[0m16:53:11.616957 [debug] [MainThread]: On master: BEGIN
[0m16:53:11.617993 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:53:11.918516 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:53:11.919523 [debug] [MainThread]: Using postgres connection "master"
[0m16:53:11.919523 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:53:11.994554 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:53:11.997014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e27b6b57-22e5-4ee7-8151-84e24f7bd00a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001693970C350>]}
[0m16:53:11.997014 [debug] [MainThread]: On master: ROLLBACK
[0m16:53:12.034590 [debug] [MainThread]: On master: Close
[0m16:53:12.035629 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:53:12.036587 [info ] [MainThread]: 
[0m16:53:12.039585 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:53:12.040586 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:53:12.042590 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:53:12.052900 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:53:12.055950 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:53:12.042590 => 16:53:12.053901
[0m16:53:12.056755 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:53:12.057970 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:53:12.057970 => 16:53:12.057970
[0m16:53:12.060957 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:53:12.061959 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:53:12.063961 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:53:12.064958 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:53:12.071826 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:53:12.074313 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:53:12.067486 => 16:53:12.073796
[0m16:53:12.076323 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:53:12.077333 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:53:12.076323 => 16:53:12.076323
[0m16:53:12.079833 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:53:12.080839 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:53:12.081839 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:53:12.081839 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:53:12.085873 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:53:12.086838 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:53:12.082838 => 16:53:12.086838
[0m16:53:12.087841 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:53:12.088839 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:53:12.087841 => 16:53:12.087841
[0m16:53:12.089839 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:53:12.089839 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m16:53:12.091910 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m16:53:12.092854 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m16:53:12.094906 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 16:53:12.092854 => 16:53:12.094906
[0m16:53:12.095906 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m16:53:12.097908 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 16:53:12.096909 => 16:53:12.096909
[0m16:53:12.098907 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m16:53:12.099906 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m16:53:12.100906 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m16:53:12.100906 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m16:53:12.106770 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 16:53:12.101907 => 16:53:12.104769
[0m16:53:12.107772 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m16:53:12.108824 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 16:53:12.108824 => 16:53:12.108824
[0m16:53:12.110771 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m16:53:12.111768 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:53:12.112769 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m16:53:12.112769 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:53:12.116440 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:53:12.117897 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:53:12.113802 => 16:53:12.116929
[0m16:53:12.117897 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:53:12.118897 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:53:12.118897 => 16:53:12.118897
[0m16:53:12.119894 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:53:12.120929 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:53:12.121931 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:53:12.121931 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:53:12.124928 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:53:12.125895 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:53:12.121931 => 16:53:12.125895
[0m16:53:12.127400 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:53:12.127400 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:53:12.127400 => 16:53:12.127400
[0m16:53:12.128608 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:53:12.129610 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:53:12.130607 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:53:12.131609 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:53:12.153115 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:53:12.154115 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:53:12.132611 => 16:53:12.154115
[0m16:53:12.155115 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:53:12.156114 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:53:12.155115 => 16:53:12.155115
[0m16:53:12.157117 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:53:12.158125 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:53:12.159116 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:53:12.161113 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:53:12.164796 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:53:12.166154 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:53:12.161113 => 16:53:12.166154
[0m16:53:12.167152 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:53:12.167152 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:53:12.167152 => 16:53:12.167152
[0m16:53:12.168181 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:53:12.169185 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:53:12.169185 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m16:53:12.170152 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:53:12.182230 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:53:12.184249 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 16:53:12.170152 => 16:53:12.184249
[0m16:53:12.185246 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:53:12.186209 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 16:53:12.185246 => 16:53:12.185246
[0m16:53:12.186209 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:53:12.187714 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m16:53:12.187714 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m16:53:12.188946 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m16:53:12.193950 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:53:12.196279 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 16:53:12.188946 => 16:53:12.196279
[0m16:53:12.196279 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m16:53:12.197286 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 16:53:12.197286 => 16:53:12.197286
[0m16:53:12.198284 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m16:53:12.198284 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:53:12.199789 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m16:53:12.199789 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m16:53:12.211843 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:53:12.211843 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m16:53:12.213078 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:53:12.493453 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:53:12.494452 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:53:12.495453 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:53:12.569141 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m16:53:12.572171 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:53:12.574276 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 16:53:12.200837 => 16:53:12.574276
[0m16:53:12.574276 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m16:53:12.575284 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 16:53:12.575284 => 16:53:12.575284
[0m16:53:12.576282 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m16:53:12.614242 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m16:53:12.615232 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:53:12.616233 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:53:12.617233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m16:53:12.617233 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:53:12.625699 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:53:12.627702 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 16:53:12.618233 => 16:53:12.627702
[0m16:53:12.628703 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:53:12.628703 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 16:53:12.628703 => 16:53:12.628703
[0m16:53:12.629703 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:53:12.630703 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:53:12.630703 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m16:53:12.632211 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:53:12.636401 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:53:12.637400 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 16:53:12.632211 => 16:53:12.637400
[0m16:53:12.638399 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:53:12.640397 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 16:53:12.639398 => 16:53:12.639398
[0m16:53:12.642397 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:53:12.643397 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:53:12.643397 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m16:53:12.644399 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:53:12.649013 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:53:12.651014 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 16:53:12.644911 => 16:53:12.650012
[0m16:53:12.651014 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:53:12.652013 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 16:53:12.652013 => 16:53:12.652013
[0m16:53:12.653045 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:53:12.654011 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:53:12.654011 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m16:53:12.655013 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:53:12.663050 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:53:12.665051 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 16:53:12.655013 => 16:53:12.664051
[0m16:53:12.665051 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:53:12.666048 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 16:53:12.666048 => 16:53:12.666048
[0m16:53:12.667048 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:53:12.667048 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:53:12.668552 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m16:53:12.669105 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:53:12.675140 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:53:12.676172 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 16:53:12.669588 => 16:53:12.676172
[0m16:53:12.677172 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:53:12.677172 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 16:53:12.677172 => 16:53:12.677172
[0m16:53:12.679173 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:53:12.679173 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m16:53:12.680141 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m16:53:12.681121 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m16:53:12.684182 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m16:53:12.686152 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 16:53:12.681121 => 16:53:12.686152
[0m16:53:12.687149 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m16:53:12.687149 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 16:53:12.687149 => 16:53:12.687149
[0m16:53:12.688182 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m16:53:12.689187 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:53:12.690182 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:53:12.690182 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m16:53:12.694383 [debug] [MainThread]: Command end result
[0m16:53:12.712012 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m16:53:12.713012 [info ] [MainThread]: Building catalog
[0m16:53:12.715391 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m16:53:12.722739 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:53:12.722739 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m16:53:12.723741 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:53:12.986059 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:53:12.987008 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:53:12.988010 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m16:53:13.051594 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m16:53:13.058770 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m16:53:13.098036 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m16:53:13.114224 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m16:53:13.115753 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:53:13.115753 after 3.64 seconds
[0m16:53:13.116720 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:53:13.116720 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m16:53:13.117719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169329B4490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016939A957D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169399B7F90>]}
[0m16:53:13.117719 [debug] [MainThread]: Flushing usage events
[0m16:53:22.646601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000130726C3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013072695FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013072735550>]}


============================== 16:53:22.650923 | dcc13a53-107a-4d02-bcb3-8f8d9cea5004 ==============================
[0m16:53:22.650923 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:53:22.652015 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:53:22.886018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dcc13a53-107a-4d02-bcb3-8f8d9cea5004', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000130726C2050>]}
[0m16:53:22.966502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dcc13a53-107a-4d02-bcb3-8f8d9cea5004', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013072B8FB10>]}
[0m16:54:20.660868 [error] [MainThread]: Encountered an error:

[0m16:54:20.664626 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 90, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 75, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 168, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 197, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 244, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\main.py", line 324, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\task\serve.py", line 28, in run
    httpd.serve_forever()
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\socketserver.py", line 233, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m16:54:20.667624 [debug] [MainThread]: Command `dbt docs serve` failed at 16:54:20.666626 after 58.09 seconds
[0m16:54:20.667624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000130723D3750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000130726B8A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001306B446810>]}
[0m16:54:20.668624 [debug] [MainThread]: Flushing usage events
[0m16:54:27.629392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000141309F0F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000141304F51D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000141304F6790>]}


============================== 16:54:27.635388 | 3db6bf52-1a24-4530-ad65-d62b26618349 ==============================
[0m16:54:27.635388 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:54:27.637390 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m16:54:28.030894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3db6bf52-1a24-4530-ad65-d62b26618349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014130BDDD90>]}
[0m16:54:28.145608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3db6bf52-1a24-4530-ad65-d62b26618349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014130B0F910>]}
[0m16:54:28.148072 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:54:28.170001 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:54:28.565707 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:54:28.567730 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\overview.md
[0m16:54:28.614763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3db6bf52-1a24-4530-ad65-d62b26618349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014130510E10>]}
[0m16:54:28.632008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3db6bf52-1a24-4530-ad65-d62b26618349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014130E05150>]}
[0m16:54:28.634012 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:54:28.638624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3db6bf52-1a24-4530-ad65-d62b26618349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014130201450>]}
[0m16:54:28.643179 [info ] [MainThread]: 
[0m16:54:28.647337 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:54:28.655345 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:54:28.689949 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:54:28.705001 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:54:28.710036 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:54:30.111774 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m16:54:30.111774 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:54:30.112773 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:54:30.168320 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:54:30.171285 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:54:30.205493 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:54:30.217568 [debug] [MainThread]: Using postgres connection "master"
[0m16:54:30.218535 [debug] [MainThread]: On master: BEGIN
[0m16:54:30.218535 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:54:30.482031 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:54:30.483036 [debug] [MainThread]: Using postgres connection "master"
[0m16:54:30.484033 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:54:30.550922 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:54:30.555887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3db6bf52-1a24-4530-ad65-d62b26618349', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014130201450>]}
[0m16:54:30.556883 [debug] [MainThread]: On master: ROLLBACK
[0m16:54:30.596457 [debug] [MainThread]: On master: Close
[0m16:54:30.597923 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:54:30.598924 [info ] [MainThread]: 
[0m16:54:30.602923 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:54:30.605929 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:54:30.605929 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:54:30.623788 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:54:30.627816 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:54:30.606925 => 16:54:30.626820
[0m16:54:30.630816 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:54:30.632844 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:54:30.632324 => 16:54:30.632844
[0m16:54:30.634851 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:54:30.635851 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:54:30.637852 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:54:30.638855 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:54:30.646883 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:54:30.652894 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:54:30.640862 => 16:54:30.649880
[0m16:54:30.654882 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:54:30.656923 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:54:30.656394 => 16:54:30.656394
[0m16:54:30.658929 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:54:30.659925 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:54:30.660927 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:54:30.661927 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:54:30.666926 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:54:30.672074 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:54:30.661927 => 16:54:30.672074
[0m16:54:30.674082 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:54:30.676071 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:54:30.675073 => 16:54:30.675073
[0m16:54:30.677076 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:54:30.680631 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m16:54:30.683191 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m16:54:30.685190 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m16:54:30.687188 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 16:54:30.685190 => 16:54:30.687188
[0m16:54:30.688193 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m16:54:30.689191 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 16:54:30.689191 => 16:54:30.689191
[0m16:54:30.691192 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m16:54:30.691192 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m16:54:30.694119 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m16:54:30.695131 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m16:54:30.703118 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 16:54:30.697122 => 16:54:30.703118
[0m16:54:30.705176 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m16:54:30.709249 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 16:54:30.709249 => 16:54:30.709249
[0m16:54:30.712247 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m16:54:30.713246 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:54:30.719426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m16:54:30.720421 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:54:30.724925 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:54:30.728441 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:54:30.722423 => 16:54:30.726931
[0m16:54:30.729973 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:54:30.730980 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:54:30.730980 => 16:54:30.730980
[0m16:54:30.734017 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:54:30.734975 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:54:30.735973 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:54:30.736971 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:54:30.738970 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:54:30.740995 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:54:30.736971 => 16:54:30.740995
[0m16:54:30.742000 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:54:30.742999 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:54:30.742000 => 16:54:30.742000
[0m16:54:30.743999 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:54:30.743999 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:54:30.747004 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:54:30.750008 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:54:30.808315 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:54:30.816212 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:54:30.751003 => 16:54:30.816212
[0m16:54:30.818230 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:54:30.821220 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:54:30.820223 => 16:54:30.820223
[0m16:54:30.823220 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:54:30.824728 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:54:30.826264 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:54:30.827263 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:54:30.840310 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:54:30.847309 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:54:30.829265 => 16:54:30.845308
[0m16:54:30.848817 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:54:30.850345 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:54:30.849856 => 16:54:30.849856
[0m16:54:30.854354 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:54:30.857348 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:54:30.859346 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m16:54:30.861389 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:54:30.901123 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:54:30.903121 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 16:54:30.862398 => 16:54:30.903121
[0m16:54:30.904135 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:54:30.905132 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 16:54:30.905132 => 16:54:30.905132
[0m16:54:30.907139 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:54:30.908122 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m16:54:30.909641 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m16:54:30.910444 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m16:54:30.918807 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:54:30.923341 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 16:54:30.911804 => 16:54:30.922343
[0m16:54:30.924342 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m16:54:30.925342 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 16:54:30.925342 => 16:54:30.925342
[0m16:54:30.926848 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m16:54:30.927846 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:54:30.929849 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m16:54:30.930849 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m16:54:30.943365 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:54:30.944874 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m16:54:30.946177 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:54:31.228567 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:54:31.230480 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:54:31.232783 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:54:31.305260 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m16:54:31.308773 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:54:31.313806 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 16:54:30.930849 => 16:54:31.312782
[0m16:54:31.315776 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m16:54:31.316773 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 16:54:31.315776 => 16:54:31.315776
[0m16:54:31.317773 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m16:54:31.356255 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m16:54:31.358255 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:54:31.359256 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:54:31.360227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m16:54:31.361236 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:54:31.368982 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:54:31.370954 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 16:54:31.361236 => 16:54:31.370954
[0m16:54:31.371955 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:54:31.371955 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 16:54:31.371955 => 16:54:31.371955
[0m16:54:31.373496 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:54:31.374500 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:54:31.375500 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m16:54:31.375500 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:54:31.380014 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:54:31.382015 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 16:54:31.376500 => 16:54:31.382015
[0m16:54:31.383015 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:54:31.384015 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 16:54:31.384015 => 16:54:31.384015
[0m16:54:31.385015 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:54:31.386015 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:54:31.387015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m16:54:31.387015 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:54:31.392038 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:54:31.393038 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 16:54:31.388014 => 16:54:31.393038
[0m16:54:31.394037 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:54:31.395038 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 16:54:31.394037 => 16:54:31.394037
[0m16:54:31.396038 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:54:31.396038 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:54:31.397038 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m16:54:31.397038 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:54:31.405061 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:54:31.406067 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 16:54:31.398038 => 16:54:31.406067
[0m16:54:31.407061 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:54:31.408062 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 16:54:31.407061 => 16:54:31.407061
[0m16:54:31.409062 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:54:31.409062 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:54:31.410062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m16:54:31.411062 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:54:31.416087 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:54:31.418087 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 16:54:31.411062 => 16:54:31.418087
[0m16:54:31.419088 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:54:31.419088 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 16:54:31.419088 => 16:54:31.419088
[0m16:54:31.420087 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:54:31.421087 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m16:54:31.421087 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m16:54:31.422086 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m16:54:31.425590 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m16:54:31.427151 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 16:54:31.422086 => 16:54:31.426568
[0m16:54:31.427151 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m16:54:31.428156 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 16:54:31.428156 => 16:54:31.428156
[0m16:54:31.429154 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m16:54:31.431155 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:54:31.431155 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:54:31.432155 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m16:54:31.435153 [debug] [MainThread]: Command end result
[0m16:54:31.453030 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m16:54:31.454031 [info ] [MainThread]: Building catalog
[0m16:54:31.456742 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m16:54:31.462811 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:54:31.464014 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m16:54:31.464984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:54:31.742406 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:54:31.744423 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:54:31.745407 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m16:54:31.809510 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m16:54:31.820031 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m16:54:31.862603 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m16:54:31.884654 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m16:54:31.887655 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:54:31.886654 after 4.36 seconds
[0m16:54:31.888654 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:54:31.889660 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m16:54:31.891657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000141301FEF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001412DAEE750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014130C18810>]}
[0m16:54:31.892654 [debug] [MainThread]: Flushing usage events
[0m16:54:38.064072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA394A0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA3909E310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA38CA6810>]}


============================== 16:54:38.068070 | e729c025-f5e4-4ab2-aa6c-5b6b15ef05da ==============================
[0m16:54:38.068070 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:54:38.069071 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt docs serve', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:54:38.286411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e729c025-f5e4-4ab2-aa6c-5b6b15ef05da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA39615D50>]}
[0m16:54:38.364514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e729c025-f5e4-4ab2-aa6c-5b6b15ef05da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA396AEC50>]}
[0m16:55:26.262573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020984B30550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209837051D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209849167D0>]}


============================== 16:55:26.266709 | 96322ed4-2391-4eed-91d0-c095b3431766 ==============================
[0m16:55:26.266709 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:55:26.267708 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:55:26.485756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96322ed4-2391-4eed-91d0-c095b3431766', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020984BE7550>]}
[0m16:55:26.563310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '96322ed4-2391-4eed-91d0-c095b3431766', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020985132B10>]}
[0m16:55:26.564818 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:55:26.577032 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:55:26.740128 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:55:26.741161 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\overview.md
[0m16:55:26.752349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96322ed4-2391-4eed-91d0-c095b3431766', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209851E1B90>]}
[0m16:55:26.757300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96322ed4-2391-4eed-91d0-c095b3431766', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209864E3990>]}
[0m16:55:26.757804 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:55:26.758622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96322ed4-2391-4eed-91d0-c095b3431766', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209850BBF10>]}
[0m16:55:26.760663 [info ] [MainThread]: 
[0m16:55:26.761628 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:55:26.764471 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:55:26.776568 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:55:26.777568 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:55:26.778567 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:55:28.218897 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m16:55:28.219909 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:55:28.220897 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:55:28.278101 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:55:28.280101 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:55:28.320054 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:55:28.332202 [debug] [MainThread]: Using postgres connection "master"
[0m16:55:28.333242 [debug] [MainThread]: On master: BEGIN
[0m16:55:28.333762 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:55:28.585383 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:55:28.586166 [debug] [MainThread]: Using postgres connection "master"
[0m16:55:28.587126 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:55:28.658172 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:55:28.660211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96322ed4-2391-4eed-91d0-c095b3431766', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209852D9ED0>]}
[0m16:55:28.661210 [debug] [MainThread]: On master: ROLLBACK
[0m16:55:28.700305 [debug] [MainThread]: On master: Close
[0m16:55:28.701324 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:55:28.702308 [info ] [MainThread]: 
[0m16:55:28.705679 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:55:28.706687 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:55:28.707680 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:55:28.714677 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:55:28.716181 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:55:28.707680 => 16:55:28.716181
[0m16:55:28.717259 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:55:28.718544 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:55:28.717259 => 16:55:28.717259
[0m16:55:28.720538 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:55:28.721537 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:55:28.722547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:55:28.723538 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:55:28.728040 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:55:28.730577 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:55:28.724534 => 16:55:28.729568
[0m16:55:28.730577 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:55:28.731569 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:55:28.731569 => 16:55:28.731569
[0m16:55:28.733568 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:55:28.734568 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:55:28.735571 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:55:28.735571 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:55:28.741104 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:55:28.742643 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:55:28.736571 => 16:55:28.742643
[0m16:55:28.743636 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:55:28.743636 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:55:28.743636 => 16:55:28.743636
[0m16:55:28.745635 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:55:28.745635 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m16:55:28.746635 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m16:55:28.747633 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m16:55:28.750640 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 16:55:28.748634 => 16:55:28.749635
[0m16:55:28.750640 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m16:55:28.752155 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 16:55:28.752155 => 16:55:28.752155
[0m16:55:28.753675 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m16:55:28.753675 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m16:55:28.754675 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m16:55:28.755696 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m16:55:28.759676 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 16:55:28.755696 => 16:55:28.758680
[0m16:55:28.760679 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m16:55:28.761676 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 16:55:28.760679 => 16:55:28.760679
[0m16:55:28.762693 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m16:55:28.762693 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:55:28.764741 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m16:55:28.765746 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:55:28.768746 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:55:28.770542 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:55:28.765746 => 16:55:28.770542
[0m16:55:28.771583 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:55:28.771583 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:55:28.771583 => 16:55:28.771583
[0m16:55:28.772552 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:55:28.773552 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:55:28.774559 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:55:28.774559 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:55:28.777845 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:55:28.779950 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:55:28.774559 => 16:55:28.779950
[0m16:55:28.779950 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:55:28.780989 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:55:28.780989 => 16:55:28.780989
[0m16:55:28.781957 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:55:28.782954 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:55:28.783955 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:55:28.784955 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:55:28.803765 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:55:28.804733 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:55:28.784955 => 16:55:28.804733
[0m16:55:28.805732 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:55:28.806732 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:55:28.805732 => 16:55:28.805732
[0m16:55:28.807767 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:55:28.807767 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:55:28.808757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:55:28.809734 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:55:28.812302 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:55:28.814123 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:55:28.809734 => 16:55:28.814123
[0m16:55:28.814123 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:55:28.815163 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:55:28.815163 => 16:55:28.815163
[0m16:55:28.816162 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:55:28.817130 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:55:28.817130 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m16:55:28.818162 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:55:28.829370 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:55:28.831341 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 16:55:28.818162 => 16:55:28.830372
[0m16:55:28.831341 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:55:28.832371 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 16:55:28.832371 => 16:55:28.832371
[0m16:55:28.833373 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:55:28.833373 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m16:55:28.834337 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m16:55:28.835371 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m16:55:28.839478 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:55:28.841443 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 16:55:28.835371 => 16:55:28.840441
[0m16:55:28.841443 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m16:55:28.842441 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 16:55:28.842441 => 16:55:28.842441
[0m16:55:28.843183 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m16:55:28.844224 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:55:28.845223 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m16:55:28.845223 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m16:55:28.854385 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:55:28.854385 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m16:55:28.855348 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:55:29.084210 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:55:29.085259 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:55:29.085259 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:55:29.152323 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m16:55:29.156365 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:55:29.157765 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 16:55:28.845223 => 16:55:29.157765
[0m16:55:29.158380 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m16:55:29.159387 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 16:55:29.158380 => 16:55:29.158380
[0m16:55:29.159387 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m16:55:29.194337 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m16:55:29.195346 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:55:29.196886 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:55:29.197428 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m16:55:29.198443 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:55:29.206429 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:55:29.208934 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 16:55:29.198443 => 16:55:29.207430
[0m16:55:29.209470 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:55:29.210106 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 16:55:29.210106 => 16:55:29.210106
[0m16:55:29.211475 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:55:29.211475 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:55:29.212475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m16:55:29.212475 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:55:29.217475 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:55:29.218475 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 16:55:29.213479 => 16:55:29.218475
[0m16:55:29.219476 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:55:29.219476 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 16:55:29.219476 => 16:55:29.219476
[0m16:55:29.221515 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:55:29.222533 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:55:29.222533 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m16:55:29.223521 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:55:29.227520 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:55:29.229534 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 16:55:29.223521 => 16:55:29.228521
[0m16:55:29.229534 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:55:29.230521 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 16:55:29.230521 => 16:55:29.230521
[0m16:55:29.231521 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:55:29.233031 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:55:29.233556 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m16:55:29.234561 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:55:29.241560 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:55:29.243561 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 16:55:29.234561 => 16:55:29.242574
[0m16:55:29.243561 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:55:29.243561 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 16:55:29.243561 => 16:55:29.243561
[0m16:55:29.245597 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:55:29.246796 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:55:29.247797 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m16:55:29.247797 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:55:29.253797 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:55:29.254797 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 16:55:29.248797 => 16:55:29.254797
[0m16:55:29.255813 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:55:29.256797 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 16:55:29.255813 => 16:55:29.255813
[0m16:55:29.257301 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:55:29.258305 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m16:55:29.259305 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m16:55:29.260307 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m16:55:29.263306 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m16:55:29.265112 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 16:55:29.260307 => 16:55:29.265112
[0m16:55:29.265112 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m16:55:29.266152 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 16:55:29.266152 => 16:55:29.266152
[0m16:55:29.267151 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m16:55:29.269117 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:55:29.269624 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:55:29.270361 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m16:55:29.273365 [debug] [MainThread]: Command end result
[0m16:55:29.289393 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m16:55:29.290391 [info ] [MainThread]: Building catalog
[0m16:55:29.292914 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m16:55:29.300454 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:55:29.300454 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m16:55:29.301452 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:55:29.533714 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:55:29.534728 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:55:29.535329 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m16:55:29.597065 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m16:55:29.603070 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m16:55:29.641760 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m16:55:29.657070 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m16:55:29.659186 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:55:29.657919 after 3.46 seconds
[0m16:55:29.659186 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:55:29.660184 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m16:55:29.660184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002098498EB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209FDC6EFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020984C07950>]}
[0m16:55:29.661186 [debug] [MainThread]: Flushing usage events
[0m16:55:35.870121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EDAB0DD90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EDADB7FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023ED77DD310>]}


============================== 16:55:35.873722 | c0fdaff7-8d4a-4132-9c65-e214d5d28987 ==============================
[0m16:55:35.873722 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:55:35.874722 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt docs serve', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:55:36.095226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c0fdaff7-8d4a-4132-9c65-e214d5d28987', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EDAB32050>]}
[0m16:55:36.170489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c0fdaff7-8d4a-4132-9c65-e214d5d28987', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EDB3E3850>]}
[0m16:56:54.468855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BB55C250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BB55C290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BEE73110>]}


============================== 16:56:54.472858 | 23c3dd74-478a-4d8e-b133-35134284a299 ==============================
[0m16:56:54.472858 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:56:54.474866 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m16:56:54.697246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '23c3dd74-478a-4d8e-b133-35134284a299', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BF552750>]}
[0m16:56:54.777993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '23c3dd74-478a-4d8e-b133-35134284a299', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BF46FCD0>]}
[0m16:56:54.779009 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:56:54.791533 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:56:54.967283 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:56:54.968286 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\overview.md
[0m16:56:54.981124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23c3dd74-478a-4d8e-b133-35134284a299', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BF5C1B90>]}
[0m16:56:54.985189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '23c3dd74-478a-4d8e-b133-35134284a299', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BF72E850>]}
[0m16:56:54.986190 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:56:54.986948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23c3dd74-478a-4d8e-b133-35134284a299', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BF5D5990>]}
[0m16:56:54.988987 [info ] [MainThread]: 
[0m16:56:54.989987 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:56:54.992659 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:56:55.003378 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:56:55.004379 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:56:55.005381 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:56.356760 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m16:56:56.356760 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:56:56.357762 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:56:56.411800 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:56:56.413934 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:56:56.450074 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:56:56.457809 [debug] [MainThread]: Using postgres connection "master"
[0m16:56:56.458331 [debug] [MainThread]: On master: BEGIN
[0m16:56:56.459385 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:56:56.709129 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:56:56.709129 [debug] [MainThread]: Using postgres connection "master"
[0m16:56:56.710132 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:56:56.807771 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:56:56.810816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23c3dd74-478a-4d8e-b133-35134284a299', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BDFEBB10>]}
[0m16:56:56.811812 [debug] [MainThread]: On master: ROLLBACK
[0m16:56:56.852543 [debug] [MainThread]: On master: Close
[0m16:56:56.853534 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:56:56.854533 [info ] [MainThread]: 
[0m16:56:56.858100 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:56:56.860272 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:56:56.861276 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:56:56.872820 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:56:56.875795 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:56:56.862282 => 16:56:56.875795
[0m16:56:56.876788 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:56:56.877821 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:56:56.877821 => 16:56:56.877821
[0m16:56:56.879813 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:56:56.882629 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:56:56.884637 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:56:56.884637 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:56:56.890628 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:56:56.891627 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:56:56.886630 => 16:56:56.891627
[0m16:56:56.895377 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:56:56.897387 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:56:56.896387 => 16:56:56.896387
[0m16:56:56.898387 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:56:56.898387 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:56:56.900423 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:56:56.901395 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:56:56.904389 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:56:56.906902 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:56:56.902389 => 16:56:56.905899
[0m16:56:56.907902 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:56:56.908902 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:56:56.907902 => 16:56:56.907902
[0m16:56:56.909935 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:56:56.909935 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m16:56:56.910935 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m16:56:56.911902 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m16:56:56.914902 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 16:56:56.911902 => 16:56:56.914902
[0m16:56:56.915901 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m16:56:56.915901 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 16:56:56.915901 => 16:56:56.915901
[0m16:56:56.917406 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m16:56:56.918333 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m16:56:56.919513 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m16:56:56.919513 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m16:56:56.924512 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 16:56:56.920513 => 16:56:56.923523
[0m16:56:56.925512 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m16:56:56.926518 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 16:56:56.926518 => 16:56:56.926518
[0m16:56:56.928521 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m16:56:56.930021 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:56:56.931027 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m16:56:56.932028 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:56:56.935028 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:56:56.937037 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:56:56.932028 => 16:56:56.937037
[0m16:56:56.938028 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:56:56.939030 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:56:56.938028 => 16:56:56.938028
[0m16:56:56.940028 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:56:56.940028 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:56:56.943553 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:56:56.944568 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:56:56.950616 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:56:56.953550 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:56:56.945549 => 16:56:56.952550
[0m16:56:56.956158 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:56:56.961158 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:56:56.959158 => 16:56:56.959158
[0m16:56:56.977721 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:56:56.979861 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:56:56.984876 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:56:56.985871 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:56:57.035732 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:56:57.038241 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:56:56.986872 => 16:56:57.036735
[0m16:56:57.040251 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:56:57.041255 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:56:57.041255 => 16:56:57.041255
[0m16:56:57.045259 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:56:57.048248 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:56:57.049757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:56:57.051780 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:56:57.057762 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:56:57.064283 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:56:57.052765 => 16:56:57.063045
[0m16:56:57.065284 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:56:57.066280 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:56:57.065284 => 16:56:57.065284
[0m16:56:57.069283 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:56:57.070281 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:56:57.072285 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m16:56:57.072285 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:56:57.107969 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:56:57.112016 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 16:56:57.074796 => 16:56:57.111015
[0m16:56:57.113014 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:56:57.114014 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 16:56:57.114014 => 16:56:57.114014
[0m16:56:57.116014 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:56:57.117015 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m16:56:57.119014 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m16:56:57.119014 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m16:56:57.125060 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:56:57.127059 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 16:56:57.120014 => 16:56:57.127059
[0m16:56:57.128059 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m16:56:57.129058 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 16:56:57.129058 => 16:56:57.129058
[0m16:56:57.132078 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m16:56:57.135124 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:56:57.137123 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m16:56:57.138138 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m16:56:57.153155 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:56:57.155155 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m16:56:57.156156 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:56:57.423034 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:56:57.424162 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:56:57.425161 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:56:57.496717 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m16:56:57.501413 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:56:57.503513 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 16:56:57.139121 => 16:56:57.502985
[0m16:56:57.504574 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m16:56:57.505703 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 16:56:57.505123 => 16:56:57.505123
[0m16:56:57.506731 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m16:56:57.548843 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m16:56:57.549843 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:56:57.550842 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:56:57.551844 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m16:56:57.552844 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:56:57.562873 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:56:57.563872 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 16:56:57.552844 => 16:56:57.563872
[0m16:56:57.564876 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:56:57.566904 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 16:56:57.566382 => 16:56:57.566382
[0m16:56:57.568917 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:56:57.569913 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:56:57.570912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m16:56:57.570912 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:56:57.576910 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:56:57.578415 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 16:56:57.571911 => 16:56:57.576910
[0m16:56:57.578930 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:56:57.578930 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 16:56:57.578930 => 16:56:57.578930
[0m16:56:57.580436 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:56:57.581442 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:56:57.582444 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m16:56:57.583443 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:56:57.587442 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:56:57.589442 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 16:56:57.583443 => 16:56:57.588441
[0m16:56:57.589442 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:56:57.590442 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 16:56:57.590442 => 16:56:57.590442
[0m16:56:57.591952 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:56:57.591952 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:56:57.592957 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m16:56:57.593956 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:56:57.604991 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:56:57.609012 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 16:56:57.593956 => 16:56:57.609012
[0m16:56:57.609996 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:56:57.610993 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 16:56:57.610993 => 16:56:57.610993
[0m16:56:57.611991 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:56:57.613005 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:56:57.614512 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m16:56:57.615518 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:56:57.620517 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:56:57.622517 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 16:56:57.615518 => 16:56:57.622517
[0m16:56:57.622517 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:56:57.623517 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 16:56:57.623517 => 16:56:57.623517
[0m16:56:57.624518 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:56:57.625518 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m16:56:57.626516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m16:56:57.627022 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m16:56:57.630509 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m16:56:57.632507 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 16:56:57.627501 => 16:56:57.632507
[0m16:56:57.633508 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m16:56:57.633508 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 16:56:57.633508 => 16:56:57.633508
[0m16:56:57.635506 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m16:56:57.636506 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:56:57.636506 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:56:57.637512 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m16:56:57.640669 [debug] [MainThread]: Command end result
[0m16:56:57.658631 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m16:56:57.659630 [info ] [MainThread]: Building catalog
[0m16:56:57.662630 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m16:56:57.669730 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:56:57.670731 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m16:56:57.671732 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:57.942927 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:56:57.942927 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:56:57.943962 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m16:56:58.006765 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m16:56:58.014082 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m16:56:58.056364 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m16:56:58.072162 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m16:56:58.074172 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:56:58.074172 after 3.67 seconds
[0m16:56:58.075168 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:56:58.075168 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m16:56:58.076168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BEE57E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253BEE40E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000253B7F6F250>]}
[0m16:56:58.077169 [debug] [MainThread]: Flushing usage events
[0m16:57:04.576543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA7C7F7D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA7B965150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA7C525550>]}


============================== 16:57:04.582542 | e89850b5-6003-4c5a-8ecf-95ae4201c34e ==============================
[0m16:57:04.582542 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:57:04.583543 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt docs serve', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:57:04.832743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e89850b5-6003-4c5a-8ecf-95ae4201c34e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA7CD884D0>]}
[0m16:57:04.960698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e89850b5-6003-4c5a-8ecf-95ae4201c34e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA7CF2EB50>]}
[0m16:57:41.730040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F49D251D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F49D53790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F49D516D0>]}


============================== 16:57:41.734550 | 35ec34a1-80ca-48e1-a2fb-8bd7ac396311 ==============================
[0m16:57:41.734550 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:57:41.736553 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:57:41.961291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35ec34a1-80ca-48e1-a2fb-8bd7ac396311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F4A718110>]}
[0m16:57:42.047801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35ec34a1-80ca-48e1-a2fb-8bd7ac396311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F49D77250>]}
[0m16:57:42.049418 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:57:42.064704 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:57:42.247398 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:57:42.248394 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\overview.md
[0m16:57:42.262419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35ec34a1-80ca-48e1-a2fb-8bd7ac396311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F4A0D2410>]}
[0m16:57:42.267428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35ec34a1-80ca-48e1-a2fb-8bd7ac396311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F4B917650>]}
[0m16:57:42.268427 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m16:57:42.269428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35ec34a1-80ca-48e1-a2fb-8bd7ac396311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F4A51B210>]}
[0m16:57:42.271459 [info ] [MainThread]: 
[0m16:57:42.272425 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:57:42.274942 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:57:42.288070 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:57:42.290102 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:57:42.292071 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:43.648643 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m16:57:43.649800 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:57:43.650807 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:57:43.702477 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m16:57:43.705479 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:57:43.738433 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:57:43.747263 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:43.748263 [debug] [MainThread]: On master: BEGIN
[0m16:57:43.748263 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:57:44.026242 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:57:44.026242 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:44.027490 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:57:44.097015 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:57:44.098820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35ec34a1-80ca-48e1-a2fb-8bd7ac396311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F491DB810>]}
[0m16:57:44.100881 [debug] [MainThread]: On master: ROLLBACK
[0m16:57:44.139268 [debug] [MainThread]: On master: Close
[0m16:57:44.140273 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:57:44.141274 [info ] [MainThread]: 
[0m16:57:44.144772 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:57:44.145805 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:57:44.146774 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:57:44.157349 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:57:44.159288 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:57:44.147773 => 16:57:44.159288
[0m16:57:44.161327 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:57:44.163328 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:57:44.162334 => 16:57:44.162334
[0m16:57:44.166338 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:57:44.166338 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:57:44.168328 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:57:44.169330 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:57:44.171361 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:57:44.174596 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:57:44.169330 => 16:57:44.173950
[0m16:57:44.174596 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:57:44.176608 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:57:44.175603 => 16:57:44.175603
[0m16:57:44.177601 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:57:44.177601 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:57:44.178635 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:57:44.179602 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:57:44.183604 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:57:44.185124 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:57:44.180603 => 16:57:44.185124
[0m16:57:44.186126 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:57:44.186126 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:57:44.186126 => 16:57:44.186126
[0m16:57:44.187159 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:57:44.188161 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m16:57:44.189125 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m16:57:44.191130 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m16:57:44.194134 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 16:57:44.191130 => 16:57:44.193135
[0m16:57:44.195129 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m16:57:44.195129 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 16:57:44.195129 => 16:57:44.195129
[0m16:57:44.197161 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m16:57:44.198164 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m16:57:44.199162 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m16:57:44.199162 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m16:57:44.203162 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 16:57:44.200197 => 16:57:44.203162
[0m16:57:44.204164 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m16:57:44.205163 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 16:57:44.205163 => 16:57:44.205163
[0m16:57:44.207166 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m16:57:44.208692 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:57:44.210520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m16:57:44.211527 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:57:44.215526 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:57:44.216526 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:57:44.212536 => 16:57:44.216526
[0m16:57:44.217560 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:57:44.218527 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:57:44.217560 => 16:57:44.217560
[0m16:57:44.218527 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:57:44.219564 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:57:44.221046 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:57:44.221046 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:57:44.223553 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:57:44.225558 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:57:44.221046 => 16:57:44.225558
[0m16:57:44.226560 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:57:44.226560 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:57:44.226560 => 16:57:44.226560
[0m16:57:44.227559 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:57:44.228558 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:57:44.229543 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:57:44.229543 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:57:44.251106 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:57:44.253108 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:57:44.230548 => 16:57:44.252107
[0m16:57:44.253108 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:57:44.254107 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:57:44.254107 => 16:57:44.254107
[0m16:57:44.255107 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:57:44.255107 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:57:44.257166 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:57:44.257644 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:57:44.260176 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:57:44.262176 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:57:44.258172 => 16:57:44.261176
[0m16:57:44.262176 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:57:44.263177 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:57:44.263177 => 16:57:44.263177
[0m16:57:44.264176 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:57:44.264176 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:57:44.265176 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m16:57:44.266178 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:57:44.279208 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m16:57:44.281231 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 16:57:44.267178 => 16:57:44.280715
[0m16:57:44.281231 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:57:44.282236 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 16:57:44.282236 => 16:57:44.282236
[0m16:57:44.283238 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m16:57:44.284237 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m16:57:44.284237 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m16:57:44.285237 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m16:57:44.289241 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m16:57:44.291238 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 16:57:44.285237 => 16:57:44.290241
[0m16:57:44.291238 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m16:57:44.291238 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 16:57:44.291238 => 16:57:44.291238
[0m16:57:44.293828 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m16:57:44.294263 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:57:44.294263 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m16:57:44.295263 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m16:57:44.304766 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:57:44.305311 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m16:57:44.306317 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:57:44.579597 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:57:44.579597 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:57:44.579597 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:57:44.655648 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m16:57:44.658649 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m16:57:44.660649 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 16:57:44.295263 => 16:57:44.659649
[0m16:57:44.660649 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m16:57:44.661650 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 16:57:44.661650 => 16:57:44.661650
[0m16:57:44.662650 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m16:57:44.701001 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m16:57:44.702685 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m16:57:44.703237 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:57:44.704244 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m16:57:44.705244 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:57:44.713241 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m16:57:44.715559 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 16:57:44.705244 => 16:57:44.715559
[0m16:57:44.716561 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:57:44.716561 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 16:57:44.716561 => 16:57:44.716561
[0m16:57:44.717558 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m16:57:44.718558 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:57:44.719558 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m16:57:44.719558 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:57:44.723558 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m16:57:44.725558 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 16:57:44.720557 => 16:57:44.724558
[0m16:57:44.726062 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:57:44.726565 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 16:57:44.726565 => 16:57:44.726565
[0m16:57:44.727109 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m16:57:44.728114 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:57:44.729120 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m16:57:44.729120 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:57:44.734119 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m16:57:44.736120 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 16:57:44.730119 => 16:57:44.735119
[0m16:57:44.736120 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:57:44.736120 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 16:57:44.736120 => 16:57:44.736120
[0m16:57:44.738688 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m16:57:44.739146 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:57:44.740146 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m16:57:44.741145 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:57:44.750165 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m16:57:44.751171 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 16:57:44.742149 => 16:57:44.751171
[0m16:57:44.752171 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:57:44.753171 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 16:57:44.752171 => 16:57:44.752171
[0m16:57:44.754170 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m16:57:44.754170 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:57:44.755170 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m16:57:44.756170 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:57:44.762189 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m16:57:44.763195 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 16:57:44.756170 => 16:57:44.763195
[0m16:57:44.764199 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:57:44.764199 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 16:57:44.764199 => 16:57:44.764199
[0m16:57:44.765199 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m16:57:44.767201 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m16:57:44.767201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m16:57:44.768233 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m16:57:44.771233 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m16:57:44.772233 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 16:57:44.768233 => 16:57:44.772233
[0m16:57:44.773739 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m16:57:44.774780 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 16:57:44.774780 => 16:57:44.774780
[0m16:57:44.775745 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m16:57:44.777746 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:57:44.777746 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:57:44.778745 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m16:57:44.781744 [debug] [MainThread]: Command end result
[0m16:57:44.799837 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m16:57:44.799837 [info ] [MainThread]: Building catalog
[0m16:57:44.803837 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m16:57:44.810861 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:57:44.811863 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m16:57:44.812861 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:45.072346 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:57:45.073854 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m16:57:45.073854 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m16:57:45.138110 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m16:57:45.145114 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m16:57:45.185408 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m16:57:45.200823 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m16:57:45.203817 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:57:45.203817 after 3.54 seconds
[0m16:57:45.204815 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:57:45.204815 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m16:57:45.207350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F4A552750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F43094410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F4A13E210>]}
[0m16:57:45.209081 [debug] [MainThread]: Flushing usage events
[0m16:57:54.359955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018AF53B16D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018AF53B17D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018AF53F51D0>]}


============================== 16:57:54.365462 | f14d13f8-052b-4759-aacb-ab22565c0e58 ==============================
[0m16:57:54.365462 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:57:54.366466 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:57:54.588327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f14d13f8-052b-4759-aacb-ab22565c0e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018AF54EDC10>]}
[0m16:57:54.668832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f14d13f8-052b-4759-aacb-ab22565c0e58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018AF53BE710>]}
[0m17:00:05.669910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658CDC9650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658D03AC50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658C1E7050>]}


============================== 17:00:05.674403 | 4b883091-1a79-44d1-bd83-e2349f23f83e ==============================
[0m17:00:05.674403 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:00:05.675410 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:00:05.905775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b883091-1a79-44d1-bd83-e2349f23f83e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658D097F90>]}
[0m17:00:05.987317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4b883091-1a79-44d1-bd83-e2349f23f83e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658D5BAD10>]}
[0m17:00:05.988813 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m17:00:06.005510 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m17:00:06.077123 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m17:00:06.078090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4b883091-1a79-44d1-bd83-e2349f23f83e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658D612A10>]}
[0m17:00:07.857921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4b883091-1a79-44d1-bd83-e2349f23f83e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658EE262D0>]}
[0m17:00:07.861425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4b883091-1a79-44d1-bd83-e2349f23f83e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658D73DA10>]}
[0m17:00:07.862437 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m17:00:07.862949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b883091-1a79-44d1-bd83-e2349f23f83e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658DB79710>]}
[0m17:00:07.865947 [info ] [MainThread]: 
[0m17:00:07.867952 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:00:07.869949 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m17:00:07.881064 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m17:00:07.882066 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m17:00:07.883064 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:00:09.253948 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m17:00:09.255487 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m17:00:09.255487 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m17:00:09.308197 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:00:09.309195 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m17:00:09.349037 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m17:00:09.356103 [debug] [MainThread]: Using postgres connection "master"
[0m17:00:09.357095 [debug] [MainThread]: On master: BEGIN
[0m17:00:09.358098 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:00:09.581962 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:00:09.581962 [debug] [MainThread]: Using postgres connection "master"
[0m17:00:09.582968 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:00:09.640656 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m17:00:09.643190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b883091-1a79-44d1-bd83-e2349f23f83e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658D811BD0>]}
[0m17:00:09.644189 [debug] [MainThread]: On master: ROLLBACK
[0m17:00:09.679454 [debug] [MainThread]: On master: Close
[0m17:00:09.680453 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:00:09.681450 [info ] [MainThread]: 
[0m17:00:09.685192 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m17:00:09.686230 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m17:00:09.686230 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m17:00:09.694706 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m17:00:09.696703 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 17:00:09.687226 => 17:00:09.695703
[0m17:00:09.697707 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m17:00:09.698704 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 17:00:09.697707 => 17:00:09.697707
[0m17:00:09.698704 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m17:00:09.700209 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m17:00:09.701500 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m17:00:09.702499 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m17:00:09.706039 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m17:00:09.709073 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 17:00:09.702499 => 17:00:09.708057
[0m17:00:09.711053 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m17:00:09.712564 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 17:00:09.711053 => 17:00:09.711053
[0m17:00:09.714317 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m17:00:09.715330 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m17:00:09.716330 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m17:00:09.718333 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m17:00:09.725647 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m17:00:09.726852 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 17:00:09.720333 => 17:00:09.726852
[0m17:00:09.727855 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m17:00:09.728853 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 17:00:09.727855 => 17:00:09.727855
[0m17:00:09.729885 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m17:00:09.729885 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m17:00:09.731887 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m17:00:09.732852 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m17:00:09.734885 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 17:00:09.732852 => 17:00:09.734885
[0m17:00:09.734885 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m17:00:09.734885 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 17:00:09.734885 => 17:00:09.734885
[0m17:00:09.736424 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m17:00:09.738634 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m17:00:09.739627 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m17:00:09.740626 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m17:00:09.743624 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 17:00:09.740626 => 17:00:09.743624
[0m17:00:09.744627 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m17:00:09.745633 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 17:00:09.745633 => 17:00:09.745633
[0m17:00:09.746626 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m17:00:09.746626 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m17:00:09.748131 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m17:00:09.749176 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m17:00:09.752334 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m17:00:09.756338 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 17:00:09.749176 => 17:00:09.755346
[0m17:00:09.757335 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m17:00:09.758337 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 17:00:09.758337 => 17:00:09.758337
[0m17:00:09.759339 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m17:00:09.760333 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m17:00:09.761569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m17:00:09.761569 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m17:00:09.764570 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m17:00:09.766039 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 17:00:09.762568 => 17:00:09.766039
[0m17:00:09.767044 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m17:00:09.767044 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 17:00:09.767044 => 17:00:09.767044
[0m17:00:09.768045 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m17:00:09.769043 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m17:00:09.770078 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m17:00:09.770078 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m17:00:09.778245 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m17:00:09.780196 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 17:00:09.771080 => 17:00:09.779198
[0m17:00:09.780196 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m17:00:09.781235 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 17:00:09.781235 => 17:00:09.781235
[0m17:00:09.782196 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m17:00:09.782196 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m17:00:09.783231 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m17:00:09.784231 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m17:00:09.787782 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m17:00:09.789540 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 17:00:09.784776 => 17:00:09.789540
[0m17:00:09.789540 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m17:00:09.790547 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 17:00:09.790547 => 17:00:09.790547
[0m17:00:09.791546 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m17:00:09.792546 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:00:09.793547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m17:00:09.793547 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:00:09.797832 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m17:00:09.799798 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 17:00:09.794580 => 17:00:09.798801
[0m17:00:09.799798 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:00:09.800832 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 17:00:09.800832 => 17:00:09.800832
[0m17:00:09.801832 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:00:09.801832 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m17:00:09.803801 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m17:00:09.803801 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m17:00:09.808313 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m17:00:09.809410 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 17:00:09.804803 => 17:00:09.809410
[0m17:00:09.810431 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m17:00:09.810431 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 17:00:09.810431 => 17:00:09.810431
[0m17:00:09.811428 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m17:00:09.812427 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m17:00:09.813431 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m17:00:09.813431 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m17:00:09.822938 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:00:09.823939 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m17:00:09.823939 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:00:10.066879 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:00:10.068882 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:00:10.069879 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m17:00:10.133171 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m17:00:10.136494 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:00:10.138503 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 17:00:09.814428 => 17:00:10.138503
[0m17:00:10.139461 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m17:00:10.140502 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 17:00:10.140502 => 17:00:10.140502
[0m17:00:10.141494 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m17:00:10.176315 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m17:00:10.177310 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m17:00:10.178310 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:00:10.179309 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m17:00:10.179309 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:00:10.187234 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m17:00:10.189241 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 17:00:10.179309 => 17:00:10.188236
[0m17:00:10.190238 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:00:10.190238 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 17:00:10.190238 => 17:00:10.190238
[0m17:00:10.191236 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:00:10.192235 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:00:10.193237 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m17:00:10.193740 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:00:10.197744 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m17:00:10.199745 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 17:00:10.194315 => 17:00:10.198744
[0m17:00:10.199745 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:00:10.200746 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 17:00:10.200746 => 17:00:10.200746
[0m17:00:10.201745 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:00:10.202746 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:00:10.202746 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m17:00:10.203746 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:00:10.207781 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m17:00:10.209785 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 17:00:10.203746 => 17:00:10.209785
[0m17:00:10.210782 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:00:10.211790 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 17:00:10.211790 => 17:00:10.211790
[0m17:00:10.212781 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:00:10.213783 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:00:10.214783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m17:00:10.214783 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:00:10.219978 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m17:00:10.221983 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 17:00:10.214783 => 17:00:10.220984
[0m17:00:10.221983 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:00:10.222982 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 17:00:10.222982 => 17:00:10.222982
[0m17:00:10.223985 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:00:10.224983 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:00:10.225984 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m17:00:10.225984 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:00:10.232493 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m17:00:10.233493 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 17:00:10.226984 => 17:00:10.233493
[0m17:00:10.234492 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:00:10.235497 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 17:00:10.234492 => 17:00:10.234492
[0m17:00:10.236493 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:00:10.237501 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m17:00:10.238493 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m17:00:10.238493 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m17:00:10.242518 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m17:00:10.243523 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 17:00:10.239494 => 17:00:10.243523
[0m17:00:10.244524 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m17:00:10.244524 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 17:00:10.244524 => 17:00:10.244524
[0m17:00:10.245523 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m17:00:10.246523 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:00:10.247557 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m17:00:10.247557 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m17:00:10.250560 [debug] [MainThread]: Command end result
[0m17:00:10.268292 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m17:00:10.269324 [info ] [MainThread]: Building catalog
[0m17:00:10.273292 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m17:00:10.279795 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m17:00:10.279795 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m17:00:10.280794 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:00:10.544927 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:00:10.547923 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m17:00:10.547923 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m17:00:10.596385 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m17:00:10.604895 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m17:00:10.640322 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m17:00:10.657962 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m17:00:10.658967 [debug] [MainThread]: Command `dbt docs generate` succeeded at 17:00:10.658967 after 5.07 seconds
[0m17:00:10.660503 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:00:10.660503 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m17:00:10.661510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658D115650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658EF8DAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001658CE17F10>]}
[0m17:00:10.662503 [debug] [MainThread]: Flushing usage events
[0m17:00:19.009284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023DB6982290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023DB61B0AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023DB6982150>]}


============================== 17:00:19.013284 | 970e313e-7480-427a-b178-bc51f8a3e6c5 ==============================
[0m17:00:19.013284 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:00:19.014286 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt docs serve', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:00:19.233700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '970e313e-7480-427a-b178-bc51f8a3e6c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023DB64DA050>]}
[0m17:00:19.314815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '970e313e-7480-427a-b178-bc51f8a3e6c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023DB6AA54D0>]}
[0m17:02:14.691294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E19AE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E19AE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136D9CE110>]}


============================== 17:02:14.697524 | c69f1191-6fd6-4442-859d-6374982e42d1 ==============================
[0m17:02:14.697524 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:02:14.699088 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt docs generate', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:02:14.999718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c69f1191-6fd6-4442-859d-6374982e42d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E351890>]}
[0m17:02:15.107090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c69f1191-6fd6-4442-859d-6374982e42d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E1E93D0>]}
[0m17:02:15.110081 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m17:02:15.128658 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m17:02:15.409348 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:02:15.410365 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\overview.md
[0m17:02:15.426339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c69f1191-6fd6-4442-859d-6374982e42d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E4962D0>]}
[0m17:02:15.430367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c69f1191-6fd6-4442-859d-6374982e42d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E5D7090>]}
[0m17:02:15.431363 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m17:02:15.432234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c69f1191-6fd6-4442-859d-6374982e42d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E2B5E10>]}
[0m17:02:15.434240 [info ] [MainThread]: 
[0m17:02:15.436241 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:02:15.438240 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m17:02:15.448758 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m17:02:15.448758 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m17:02:15.450267 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:02:16.930618 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m17:02:16.931146 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m17:02:16.931673 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m17:02:16.983661 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:02:16.985786 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m17:02:17.023224 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m17:02:17.030923 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:17.030923 [debug] [MainThread]: On master: BEGIN
[0m17:02:17.031928 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:02:17.245956 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:02:17.246962 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:17.246962 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:02:17.314923 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m17:02:17.316926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c69f1191-6fd6-4442-859d-6374982e42d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E5067D0>]}
[0m17:02:17.317927 [debug] [MainThread]: On master: ROLLBACK
[0m17:02:17.352581 [debug] [MainThread]: On master: Close
[0m17:02:17.353584 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:02:17.354583 [info ] [MainThread]: 
[0m17:02:17.358582 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m17:02:17.359581 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m17:02:17.360583 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m17:02:17.367699 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m17:02:17.369700 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 17:02:17.361583 => 17:02:17.369700
[0m17:02:17.370703 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m17:02:17.370703 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 17:02:17.370703 => 17:02:17.370703
[0m17:02:17.373736 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m17:02:17.374357 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m17:02:17.375786 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m17:02:17.376786 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m17:02:17.380790 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m17:02:17.382787 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 17:02:17.376786 => 17:02:17.382787
[0m17:02:17.382787 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m17:02:17.383792 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 17:02:17.383792 => 17:02:17.383792
[0m17:02:17.386840 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m17:02:17.389394 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m17:02:17.391374 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m17:02:17.392374 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m17:02:17.396371 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m17:02:17.399889 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 17:02:17.393372 => 17:02:17.398891
[0m17:02:17.400887 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m17:02:17.401897 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 17:02:17.401897 => 17:02:17.401897
[0m17:02:17.404905 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m17:02:17.407889 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m17:02:17.413939 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m17:02:17.414940 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m17:02:17.418942 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 17:02:17.415939 => 17:02:17.417941
[0m17:02:17.419939 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m17:02:17.421447 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 17:02:17.419939 => 17:02:17.419939
[0m17:02:17.423908 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m17:02:17.425815 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m17:02:17.427821 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m17:02:17.428818 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m17:02:17.431833 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 17:02:17.428818 => 17:02:17.431833
[0m17:02:17.433337 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m17:02:17.436503 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 17:02:17.435498 => 17:02:17.435498
[0m17:02:17.438495 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m17:02:17.438495 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m17:02:17.439494 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m17:02:17.440494 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m17:02:17.443494 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m17:02:17.445524 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 17:02:17.440494 => 17:02:17.445524
[0m17:02:17.445524 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m17:02:17.446761 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 17:02:17.446761 => 17:02:17.446761
[0m17:02:17.447728 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m17:02:17.448729 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m17:02:17.449729 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m17:02:17.450728 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m17:02:17.453731 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m17:02:17.455728 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 17:02:17.450728 => 17:02:17.455728
[0m17:02:17.456727 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m17:02:17.457728 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 17:02:17.457728 => 17:02:17.457728
[0m17:02:17.458682 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m17:02:17.459798 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m17:02:17.460472 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m17:02:17.461480 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m17:02:17.488404 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m17:02:17.492412 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 17:02:17.461480 => 17:02:17.491412
[0m17:02:17.493409 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m17:02:17.493915 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 17:02:17.493915 => 17:02:17.493915
[0m17:02:17.494920 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m17:02:17.494920 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m17:02:17.495920 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m17:02:17.501924 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m17:02:17.509968 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m17:02:17.513969 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 17:02:17.502924 => 17:02:17.513969
[0m17:02:17.514968 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m17:02:17.515971 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 17:02:17.515971 => 17:02:17.515971
[0m17:02:17.519015 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m17:02:17.520018 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:02:17.521016 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m17:02:17.522017 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:02:17.537887 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m17:02:17.539891 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 17:02:17.523017 => 17:02:17.539891
[0m17:02:17.541398 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:02:17.542370 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 17:02:17.541916 => 17:02:17.541916
[0m17:02:17.542922 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:02:17.543922 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m17:02:17.544925 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m17:02:17.545924 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m17:02:17.549921 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m17:02:17.551921 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 17:02:17.545924 => 17:02:17.550921
[0m17:02:17.551921 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m17:02:17.551921 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 17:02:17.551921 => 17:02:17.551921
[0m17:02:17.554444 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m17:02:17.555450 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m17:02:17.555450 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m17:02:17.556451 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m17:02:17.566957 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:02:17.566957 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m17:02:17.567958 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:02:17.834252 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:02:17.836258 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:02:17.838256 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m17:02:17.911370 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m17:02:17.917572 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:02:17.918614 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 17:02:17.556451 => 17:02:17.918614
[0m17:02:17.920574 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m17:02:17.921576 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 17:02:17.921576 => 17:02:17.921576
[0m17:02:17.922599 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m17:02:17.962348 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m17:02:17.964926 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m17:02:17.965912 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:02:17.967918 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m17:02:17.968915 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:02:17.984488 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m17:02:17.986490 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 17:02:17.969919 => 17:02:17.986490
[0m17:02:17.988213 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:02:17.989756 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 17:02:17.988748 => 17:02:17.988748
[0m17:02:17.991757 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:02:17.992755 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:02:17.994759 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m17:02:17.994759 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:02:18.001922 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m17:02:18.003923 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 17:02:17.995764 => 17:02:18.003923
[0m17:02:18.005926 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:02:18.007941 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 17:02:18.007941 => 17:02:18.007941
[0m17:02:18.010435 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:02:18.011622 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:02:18.013628 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m17:02:18.015631 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:02:18.023234 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m17:02:18.025242 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 17:02:18.016631 => 17:02:18.025242
[0m17:02:18.026240 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:02:18.027242 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 17:02:18.027242 => 17:02:18.027242
[0m17:02:18.029240 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:02:18.030243 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:02:18.032247 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m17:02:18.034281 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:02:18.050837 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m17:02:18.053838 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 17:02:18.035800 => 17:02:18.053838
[0m17:02:18.055840 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:02:18.056846 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 17:02:18.055840 => 17:02:18.055840
[0m17:02:18.059903 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:02:18.059903 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:02:18.061902 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m17:02:18.062902 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:02:18.071498 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m17:02:18.073755 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 17:02:18.062902 => 17:02:18.073755
[0m17:02:18.075754 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:02:18.076754 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 17:02:18.076754 => 17:02:18.076754
[0m17:02:18.078755 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:02:18.078755 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m17:02:18.080789 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m17:02:18.082298 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m17:02:18.087362 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m17:02:18.089875 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 17:02:18.082298 => 17:02:18.089875
[0m17:02:18.090909 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m17:02:18.091908 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 17:02:18.090909 => 17:02:18.090909
[0m17:02:18.092908 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m17:02:18.092908 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:02:18.094415 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m17:02:18.094415 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m17:02:18.098828 [debug] [MainThread]: Command end result
[0m17:02:18.132723 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m17:02:18.133723 [info ] [MainThread]: Building catalog
[0m17:02:18.137727 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m17:02:18.145413 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m17:02:18.145413 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m17:02:18.146413 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:02:18.422157 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:02:18.423148 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m17:02:18.423148 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m17:02:18.503603 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m17:02:18.517763 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m17:02:18.560031 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m17:02:18.627709 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m17:02:18.631706 [debug] [MainThread]: Command `dbt docs generate` succeeded at 17:02:18.631706 after 4.05 seconds
[0m17:02:18.632704 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:02:18.633709 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m17:02:18.636666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136D9F4410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136D9CF350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002136E30CDD0>]}
[0m17:02:18.637847 [debug] [MainThread]: Flushing usage events
[0m17:02:27.927997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A82EF3210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A82F30110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A82FA2B50>]}


============================== 17:02:27.932668 | 0d45b4a4-4439-47c9-9ed1-7c80cf0d4c71 ==============================
[0m17:02:27.932668 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:02:27.933655 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt docs serve', 'send_anonymous_usage_stats': 'True'}
[0m17:02:28.193174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0d45b4a4-4439-47c9-9ed1-7c80cf0d4c71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A82F22050>]}
[0m17:02:28.279126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0d45b4a4-4439-47c9-9ed1-7c80cf0d4c71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A83066ED0>]}
[0m17:02:49.663127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023167D73A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002316833EAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023164BD4150>]}


============================== 17:02:49.667599 | 924d1367-aa07-4f47-8ab4-6f6bd61291ab ==============================
[0m17:02:49.667599 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:02:49.668604 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m17:02:49.873731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '924d1367-aa07-4f47-8ab4-6f6bd61291ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023168591B90>]}
[0m17:02:49.951949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '924d1367-aa07-4f47-8ab4-6f6bd61291ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023167746BD0>]}
[0m17:02:49.952927 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m17:02:49.966847 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m17:02:50.131129 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:02:50.131129 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:02:50.140161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '924d1367-aa07-4f47-8ab4-6f6bd61291ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002316994BD90>]}
[0m17:02:50.145162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '924d1367-aa07-4f47-8ab4-6f6bd61291ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231698FF950>]}
[0m17:02:50.145162 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m17:02:50.147191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '924d1367-aa07-4f47-8ab4-6f6bd61291ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231698A8210>]}
[0m17:02:50.149844 [info ] [MainThread]: 
[0m17:02:50.150844 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:02:50.152816 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m17:02:50.165744 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m17:02:50.166798 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m17:02:50.167902 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:02:51.554815 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m17:02:51.554815 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m17:02:51.555822 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m17:02:51.614973 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:02:51.616979 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m17:02:51.654743 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m17:02:51.662556 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:51.662556 [debug] [MainThread]: On master: BEGIN
[0m17:02:51.663555 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:02:51.929835 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:02:51.930842 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:51.930842 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:02:52.004763 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m17:02:52.006803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '924d1367-aa07-4f47-8ab4-6f6bd61291ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231698ECCD0>]}
[0m17:02:52.007770 [debug] [MainThread]: On master: ROLLBACK
[0m17:02:52.046427 [debug] [MainThread]: On master: Close
[0m17:02:52.047428 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:02:52.048143 [info ] [MainThread]: 
[0m17:02:52.051151 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m17:02:52.053150 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m17:02:52.053150 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m17:02:52.061174 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m17:02:52.063177 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 17:02:52.054149 => 17:02:52.062173
[0m17:02:52.064172 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m17:02:52.065173 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 17:02:52.065173 => 17:02:52.065173
[0m17:02:52.067173 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m17:02:52.068176 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m17:02:52.070211 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m17:02:52.071243 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m17:02:52.076215 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m17:02:52.077245 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 17:02:52.071243 => 17:02:52.077245
[0m17:02:52.078244 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m17:02:52.079213 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 17:02:52.078244 => 17:02:52.079213
[0m17:02:52.080212 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m17:02:52.082281 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m17:02:52.084057 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m17:02:52.085055 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m17:02:52.090047 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m17:02:52.092045 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 17:02:52.086050 => 17:02:52.091045
[0m17:02:52.092045 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m17:02:52.092045 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 17:02:52.092045 => 17:02:52.092045
[0m17:02:52.094564 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m17:02:52.095571 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m17:02:52.096513 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m17:02:52.097519 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m17:02:52.099518 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 17:02:52.097519 => 17:02:52.098519
[0m17:02:52.099518 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m17:02:52.100518 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 17:02:52.100518 => 17:02:52.100518
[0m17:02:52.101523 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m17:02:52.102531 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m17:02:52.103524 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m17:02:52.104564 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m17:02:52.110063 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 17:02:52.105519 => 17:02:52.109065
[0m17:02:52.110063 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m17:02:52.111065 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 17:02:52.111065 => 17:02:52.111065
[0m17:02:52.112063 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m17:02:52.113063 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m17:02:52.113063 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m17:02:52.114064 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m17:02:52.117062 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m17:02:52.118064 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 17:02:52.114064 => 17:02:52.118064
[0m17:02:52.118945 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m17:02:52.119443 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 17:02:52.119443 => 17:02:52.119443
[0m17:02:52.120444 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m17:02:52.121443 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m17:02:52.122443 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m17:02:52.122443 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m17:02:52.125443 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m17:02:52.127444 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 17:02:52.123443 => 17:02:52.126443
[0m17:02:52.127444 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m17:02:52.128443 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 17:02:52.128443 => 17:02:52.128443
[0m17:02:52.128443 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m17:02:52.129947 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m17:02:52.130463 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m17:02:52.131474 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m17:02:52.150587 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m17:02:52.152079 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 17:02:52.131474 => 17:02:52.152079
[0m17:02:52.152079 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m17:02:52.153086 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 17:02:52.153086 => 17:02:52.153086
[0m17:02:52.154085 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m17:02:52.155186 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m17:02:52.156195 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m17:02:52.157196 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m17:02:52.160197 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m17:02:52.162193 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 17:02:52.157196 => 17:02:52.161196
[0m17:02:52.162193 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m17:02:52.163192 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 17:02:52.163192 => 17:02:52.163192
[0m17:02:52.164196 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m17:02:52.164196 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:02:52.165705 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m17:02:52.166955 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:02:52.179495 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m17:02:52.181501 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 17:02:52.166955 => 17:02:52.180501
[0m17:02:52.181501 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:02:52.182500 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 17:02:52.182500 => 17:02:52.182500
[0m17:02:52.183501 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:02:52.184501 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m17:02:52.185501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m17:02:52.186502 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m17:02:52.188501 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m17:02:52.191538 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 17:02:52.186502 => 17:02:52.191538
[0m17:02:52.192533 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m17:02:52.193532 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 17:02:52.192533 => 17:02:52.192533
[0m17:02:52.194532 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m17:02:52.195531 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m17:02:52.195531 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m17:02:52.196532 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m17:02:52.207564 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:02:52.207564 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m17:02:52.208565 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:02:52.435430 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:02:52.435430 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:02:52.436463 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m17:02:52.502371 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m17:02:52.506691 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:02:52.508660 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 17:02:52.197532 => 17:02:52.507659
[0m17:02:52.508660 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m17:02:52.509660 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 17:02:52.509660 => 17:02:52.509660
[0m17:02:52.510663 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m17:02:52.543925 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m17:02:52.545892 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m17:02:52.546900 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:02:52.547926 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m17:02:52.547926 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:02:52.557723 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m17:02:52.560695 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 17:02:52.548925 => 17:02:52.559728
[0m17:02:52.560695 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:02:52.561695 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 17:02:52.561695 => 17:02:52.561695
[0m17:02:52.563201 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:02:52.563757 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:02:52.564207 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m17:02:52.565206 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:02:52.570208 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m17:02:52.572207 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 17:02:52.566207 => 17:02:52.572207
[0m17:02:52.572207 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:02:52.574264 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 17:02:52.574264 => 17:02:52.574264
[0m17:02:52.575481 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:02:52.576481 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:02:52.577514 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m17:02:52.577514 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:02:52.582514 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m17:02:52.584483 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 17:02:52.578481 => 17:02:52.583482
[0m17:02:52.585481 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:02:52.586496 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 17:02:52.585481 => 17:02:52.585481
[0m17:02:52.587545 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:02:52.588004 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:02:52.589004 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m17:02:52.590004 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:02:52.597004 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m17:02:52.599022 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 17:02:52.590004 => 17:02:52.598508
[0m17:02:52.600026 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:02:52.600026 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 17:02:52.600026 => 17:02:52.600026
[0m17:02:52.601027 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:02:52.602025 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:02:52.603026 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m17:02:52.604026 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:02:52.609061 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m17:02:52.612031 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 17:02:52.604026 => 17:02:52.611634
[0m17:02:52.612031 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:02:52.613067 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 17:02:52.613067 => 17:02:52.613067
[0m17:02:52.614068 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:02:52.614068 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m17:02:52.615033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m17:02:52.616067 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m17:02:52.620031 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m17:02:52.621030 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 17:02:52.617036 => 17:02:52.621030
[0m17:02:52.622535 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m17:02:52.623052 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 17:02:52.623052 => 17:02:52.623052
[0m17:02:52.624056 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m17:02:52.625056 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:02:52.626056 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m17:02:52.626056 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m17:02:52.629056 [debug] [MainThread]: Command end result
[0m17:02:52.652006 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m17:02:52.653004 [info ] [MainThread]: Building catalog
[0m17:02:52.655003 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m17:02:52.663039 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m17:02:52.664039 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m17:02:52.664039 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:02:52.903313 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:02:52.904312 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m17:02:52.904312 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m17:02:52.965246 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m17:02:52.971795 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m17:02:53.008728 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m17:02:53.023825 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m17:02:53.025793 [debug] [MainThread]: Command `dbt docs generate` succeeded at 17:02:53.025793 after 3.42 seconds
[0m17:02:53.026825 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:02:53.026825 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m17:02:53.027791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023168021610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023169968DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231687C4890>]}
[0m17:02:53.028791 [debug] [MainThread]: Flushing usage events
[0m17:03:00.323627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D70625AE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D706038050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D706287C50>]}


============================== 17:03:00.327394 | 6076ca67-d369-49a0-8d49-66bbebf90fb9 ==============================
[0m17:03:00.327394 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:03:00.329395 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:03:00.599103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6076ca67-d369-49a0-8d49-66bbebf90fb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7063EA790>]}
[0m17:03:00.791845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6076ca67-d369-49a0-8d49-66bbebf90fb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D705FA8E50>]}
[0m17:09:17.132962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022FA85F4910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022FA7E12E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022FA7ED7D10>]}


============================== 17:09:17.139115 | c1733eb4-d7c1-47dd-bd36-3902359a8736 ==============================
[0m17:09:17.139115 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:09:17.140113 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:09:17.454885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c1733eb4-d7c1-47dd-bd36-3902359a8736', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022FA7E32050>]}
[0m17:09:17.563987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c1733eb4-d7c1-47dd-bd36-3902359a8736', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022FA86E3ED0>]}
[0m17:13:22.590140 [error] [MainThread]: Encountered an error:

[0m17:13:22.593935 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 90, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 75, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 168, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 197, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\requires.py", line 244, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\cli\main.py", line 324, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\site-packages\dbt\task\serve.py", line 28, in run
    httpd.serve_forever()
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\socketserver.py", line 233, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marco\AppData\Local\Programs\Python\Python311\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m17:13:22.595935 [debug] [MainThread]: Command `dbt docs serve` failed at 17:13:22.595935 after 245.53 seconds
[0m17:13:22.596968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022FA7E117D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022FA8624B90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022FA85DBE90>]}
[0m17:13:22.596968 [debug] [MainThread]: Flushing usage events
[0m17:13:34.736343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A3120072D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A312308050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A31252B710>]}


============================== 17:13:34.742959 | f1a6507c-dcdb-4830-a806-2ce808a8062b ==============================
[0m17:13:34.742959 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:13:34.743960 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m17:13:35.030458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f1a6507c-dcdb-4830-a806-2ce808a8062b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A312579790>]}
[0m17:13:35.137369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f1a6507c-dcdb-4830-a806-2ce808a8062b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A311E341D0>]}
[0m17:13:35.138796 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m17:13:35.154662 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m17:13:35.363988 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:13:35.365139 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\overview.md
[0m17:13:35.380168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f1a6507c-dcdb-4830-a806-2ce808a8062b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A312278850>]}
[0m17:13:35.388211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f1a6507c-dcdb-4830-a806-2ce808a8062b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A312880050>]}
[0m17:13:35.389212 [info ] [MainThread]: Found 8 models, 1 snapshot, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 519 macros, 0 groups, 0 semantic models
[0m17:13:35.390214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f1a6507c-dcdb-4830-a806-2ce808a8062b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A312056C90>]}
[0m17:13:35.394247 [info ] [MainThread]: 
[0m17:13:35.397214 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:13:35.401296 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m17:13:35.423855 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m17:13:35.424257 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m17:13:35.425257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:13:36.832240 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m17:13:36.833239 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m17:13:36.833239 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m17:13:36.890566 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m17:13:36.893593 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m17:13:36.936089 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m17:13:36.943490 [debug] [MainThread]: Using postgres connection "master"
[0m17:13:36.943490 [debug] [MainThread]: On master: BEGIN
[0m17:13:36.944493 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:13:37.188521 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:13:37.189280 [debug] [MainThread]: Using postgres connection "master"
[0m17:13:37.189280 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:13:37.259774 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m17:13:37.261776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f1a6507c-dcdb-4830-a806-2ce808a8062b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A312877A10>]}
[0m17:13:37.262890 [debug] [MainThread]: On master: ROLLBACK
[0m17:13:37.300933 [debug] [MainThread]: On master: Close
[0m17:13:37.301933 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:13:37.302935 [info ] [MainThread]: 
[0m17:13:37.306935 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m17:13:37.307932 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m17:13:37.307932 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m17:13:37.317670 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m17:13:37.320671 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 17:13:37.309438 => 17:13:37.319674
[0m17:13:37.320671 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m17:13:37.321667 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 17:13:37.321667 => 17:13:37.321667
[0m17:13:37.324991 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m17:13:37.326996 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m17:13:37.329981 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m17:13:37.330983 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m17:13:37.340140 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m17:13:37.344136 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 17:13:37.333555 => 17:13:37.343135
[0m17:13:37.346177 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m17:13:37.347215 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 17:13:37.347215 => 17:13:37.347215
[0m17:13:37.348181 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m17:13:37.349180 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m17:13:37.351180 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m17:13:37.352181 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m17:13:37.356180 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m17:13:37.358263 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 17:13:37.353181 => 17:13:37.358263
[0m17:13:37.359274 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m17:13:37.360271 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 17:13:37.360271 => 17:13:37.360271
[0m17:13:37.362270 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m17:13:37.362270 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m17:13:37.363271 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m17:13:37.364776 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m17:13:37.368783 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 17:13:37.364776 => 17:13:37.367786
[0m17:13:37.369786 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m17:13:37.370873 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 17:13:37.370292 => 17:13:37.370292
[0m17:13:37.372335 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m17:13:37.373300 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m17:13:37.374333 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now snapshot.dbtlearn.scd_raw_listings)
[0m17:13:37.375300 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m17:13:37.380350 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 17:13:37.375300 => 17:13:37.380350
[0m17:13:37.381864 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m17:13:37.383403 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 17:13:37.382394 => 17:13:37.382394
[0m17:13:37.385402 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m17:13:37.386403 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m17:13:37.388402 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.dbtlearn.scd_raw_listings, now model.dbtlearn.dim_hosts_cleansed)
[0m17:13:37.389401 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m17:13:37.397452 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m17:13:37.400452 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 17:13:37.389401 => 17:13:37.400452
[0m17:13:37.402453 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m17:13:37.403452 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 17:13:37.403452 => 17:13:37.403452
[0m17:13:37.405963 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m17:13:37.406484 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m17:13:37.408495 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m17:13:37.408495 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m17:13:37.414494 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m17:13:37.418001 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 17:13:37.409495 => 17:13:37.416493
[0m17:13:37.419497 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m17:13:37.421498 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 17:13:37.420497 => 17:13:37.420497
[0m17:13:37.423499 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m17:13:37.424498 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m17:13:37.426499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m17:13:37.427498 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m17:13:37.451682 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m17:13:37.453683 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 17:13:37.428496 => 17:13:37.453683
[0m17:13:37.454786 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m17:13:37.456060 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 17:13:37.456060 => 17:13:37.456060
[0m17:13:37.457061 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m17:13:37.458064 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m17:13:37.459060 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m17:13:37.460094 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m17:13:37.463094 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m17:13:37.464635 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 17:13:37.460094 => 17:13:37.463094
[0m17:13:37.464635 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m17:13:37.464635 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 17:13:37.464635 => 17:13:37.464635
[0m17:13:37.466184 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m17:13:37.467223 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:13:37.468191 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af)
[0m17:13:37.468191 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:13:37.480207 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m17:13:37.482214 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 17:13:37.469190 => 17:13:37.481208
[0m17:13:37.483213 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:13:37.485211 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 17:13:37.484212 => 17:13:37.484212
[0m17:13:37.486210 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m17:13:37.487210 [debug] [Thread-1 (]: Began running node test.dbtlearn.dim_listings_minimum_nights
[0m17:13:37.488208 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.dim_listings_minimum_nights)
[0m17:13:37.488208 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dim_listings_minimum_nights
[0m17:13:37.494238 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dim_listings_minimum_nights"
[0m17:13:37.495233 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (compile): 17:13:37.488208 => 17:13:37.495233
[0m17:13:37.496235 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dim_listings_minimum_nights
[0m17:13:37.497234 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dim_listings_minimum_nights (execute): 17:13:37.496235 => 17:13:37.496235
[0m17:13:37.498234 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dim_listings_minimum_nights
[0m17:13:37.498234 [debug] [Thread-1 (]: Began running node test.dbtlearn.no_nulls_in_dim_listings
[0m17:13:37.499235 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dim_listings_minimum_nights, now test.dbtlearn.no_nulls_in_dim_listings)
[0m17:13:37.500234 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.no_nulls_in_dim_listings
[0m17:13:37.509125 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:13:37.510126 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: BEGIN
[0m17:13:37.510126 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:13:37.748873 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:13:37.749392 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:13:37.750424 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.no_nulls_in_dim_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_cleansed'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m17:13:37.824032 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m17:13:37.828029 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.no_nulls_in_dim_listings"
[0m17:13:37.830609 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (compile): 17:13:37.500234 => 17:13:37.829617
[0m17:13:37.831609 [debug] [Thread-1 (]: Began executing node test.dbtlearn.no_nulls_in_dim_listings
[0m17:13:37.831609 [debug] [Thread-1 (]: Timing info for test.dbtlearn.no_nulls_in_dim_listings (execute): 17:13:37.831609 => 17:13:37.831609
[0m17:13:37.832607 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: ROLLBACK
[0m17:13:37.868921 [debug] [Thread-1 (]: On test.dbtlearn.no_nulls_in_dim_listings: Close
[0m17:13:37.870918 [debug] [Thread-1 (]: Finished running node test.dbtlearn.no_nulls_in_dim_listings
[0m17:13:37.871916 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:13:37.872916 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.no_nulls_in_dim_listings, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m17:13:37.872916 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:13:37.881992 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m17:13:37.883989 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 17:13:37.872916 => 17:13:37.883989
[0m17:13:37.884991 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:13:37.886500 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 17:13:37.886500 => 17:13:37.886500
[0m17:13:37.888608 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m17:13:37.889606 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:13:37.890606 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m17:13:37.891606 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:13:37.897605 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m17:13:37.899695 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 17:13:37.892612 => 17:13:37.899695
[0m17:13:37.900700 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:13:37.900700 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 17:13:37.900700 => 17:13:37.900700
[0m17:13:37.901701 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m17:13:37.902700 [debug] [Thread-1 (]: Began running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:13:37.903708 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313)
[0m17:13:37.904700 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:13:37.909700 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313"
[0m17:13:37.910701 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (compile): 17:13:37.904700 => 17:13:37.910701
[0m17:13:37.912154 [debug] [Thread-1 (]: Began executing node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:13:37.914172 [debug] [Thread-1 (]: Timing info for test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313 (execute): 17:13:37.913155 => 17:13:37.913155
[0m17:13:37.916201 [debug] [Thread-1 (]: Finished running node test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313
[0m17:13:37.917152 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:13:37.918152 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.positive_value_dim_listings_cleansed_minimum_nights.78fa6fc313, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m17:13:37.919153 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:13:37.930212 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m17:13:37.932211 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 17:13:37.920155 => 17:13:37.931210
[0m17:13:37.933210 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:13:37.933210 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 17:13:37.933210 => 17:13:37.933210
[0m17:13:37.935231 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m17:13:37.935231 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:13:37.936236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m17:13:37.937239 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:13:37.943270 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m17:13:37.944237 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 17:13:37.937239 => 17:13:37.944237
[0m17:13:37.945237 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:13:37.945237 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 17:13:37.945237 => 17:13:37.945237
[0m17:13:37.947796 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m17:13:37.948989 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m17:13:37.951014 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066, now model.dbtlearn.mart_fullmoon_reviews)
[0m17:13:37.951974 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m17:13:37.957009 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m17:13:37.958550 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 17:13:37.951974 => 17:13:37.958550
[0m17:13:37.959678 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m17:13:37.959678 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 17:13:37.959678 => 17:13:37.959678
[0m17:13:37.960687 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m17:13:37.963686 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:13:37.965194 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m17:13:37.966201 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m17:13:37.969202 [debug] [MainThread]: Command end result
[0m17:13:37.999895 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m17:13:37.999895 [info ] [MainThread]: Building catalog
[0m17:13:38.004390 [debug] [ThreadPool]: Acquiring new postgres connection 'inttegra_stage.information_schema'
[0m17:13:38.013527 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m17:13:38.014491 [debug] [ThreadPool]: On inttegra_stage.information_schema: BEGIN
[0m17:13:38.014491 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:13:38.281674 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:13:38.281674 [debug] [ThreadPool]: Using postgres connection "inttegra_stage.information_schema"
[0m17:13:38.283182 [debug] [ThreadPool]: On inttegra_stage.information_schema: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "inttegra_stage.information_schema"} */

    
    

    select
        'inttegra_stage' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('seed_full_moon_dates')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('fact_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('mart_fullmoon_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_hosts_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('scd_raw_listings')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('src_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_cleansed')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('dim_listings_with_hosts')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_reviews')) or (upper(sch.nspname) = upper('test') and
           upper(tbl.relname) = upper('raw_hosts')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m17:13:38.345837 [debug] [ThreadPool]: SQL status: SELECT 87 in 0.0 seconds
[0m17:13:38.352885 [debug] [ThreadPool]: On inttegra_stage.information_schema: ROLLBACK
[0m17:13:38.393536 [debug] [ThreadPool]: On inttegra_stage.information_schema: Close
[0m17:13:38.409811 [info ] [MainThread]: Catalog written to C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\target\catalog.json
[0m17:13:38.411751 [debug] [MainThread]: Command `dbt docs generate` succeeded at 17:13:38.411751 after 3.77 seconds
[0m17:13:38.412717 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:13:38.412717 [debug] [MainThread]: Connection 'inttegra_stage.information_schema' was properly closed.
[0m17:13:38.413717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A311D36B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A311D5F590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A31264A710>]}
[0m17:13:38.413717 [debug] [MainThread]: Flushing usage events
[0m17:13:48.354644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D45BE1D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D457DE210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D45BE1A10>]}


============================== 17:13:48.359650 | 387c2577-d482-4d9a-94a4-9e2b585861fb ==============================
[0m17:13:48.359650 [info ] [MainThread]: Running with dbt=1.7.3
[0m17:13:48.361661 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:13:48.605726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '387c2577-d482-4d9a-94a4-9e2b585861fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D45C47F10>]}
[0m17:13:48.708190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '387c2577-d482-4d9a-94a4-9e2b585861fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D45BED210>]}
[0m10:04:42.819983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A252B48D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A2574B0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A25524D10>]}


============================== 10:04:42.825126 | 257bf24c-931b-4c80-8ec3-9523c3355f41 ==============================
[0m10:04:42.825126 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:04:42.826268 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:04:43.074812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '257bf24c-931b-4c80-8ec3-9523c3355f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A24F2E790>]}
[0m10:04:43.085394 [debug] [MainThread]: Set downloads directory='C:\Users\marco\AppData\Local\Temp\dbt-downloads-z_c_1j4d'
[0m10:04:43.086393 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m10:04:43.798865 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m10:04:43.801046 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m10:04:44.281707 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m10:04:44.286744 [error] [MainThread]: Encountered an error:
Package catalogica/dbt_expactations was not found in the package index
[0m10:04:44.288674 [debug] [MainThread]: Command `dbt deps` failed at 10:04:44.288674 after 1.57 seconds
[0m10:04:44.289624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A24F2C3D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A1DFC1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015A1E2BF210>]}
[0m10:04:44.291167 [debug] [MainThread]: Flushing usage events
[0m10:05:21.973999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED430F850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3B29110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3BF1250>]}


============================== 10:05:21.978000 | 1389cb83-2a3a-4d8c-a3eb-a8fee83e44f2 ==============================
[0m10:05:21.978000 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:05:21.978998 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m10:05:22.111320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1389cb83-2a3a-4d8c-a3eb-a8fee83e44f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3E16CD0>]}
[0m10:05:22.115732 [debug] [MainThread]: Set downloads directory='C:\Users\marco\AppData\Local\Temp\dbt-downloads-04_cq91c'
[0m10:05:22.116733 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m10:05:22.523133 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m10:05:22.524677 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m10:05:22.931403 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m10:05:22.936443 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json
[0m10:05:23.393000 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_expectations.json 200
[0m10:05:23.394664 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `calogica/dbt_expectations` package is deprecated in favor of
`metaplane/dbt_expectations`. Please update your `packages.yml` configuration to
use `metaplane/dbt_expectations` instead.
[0m10:05:23.395260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '1389cb83-2a3a-4d8c-a3eb-a8fee83e44f2', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3EEAA50>]}
[0m10:05:23.398362 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json
[0m10:05:23.829790 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/calogica/dbt_date.json 200
[0m10:05:23.842887 [info ] [MainThread]: Updating lock file in file path: C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1/package-lock.yml
[0m10:05:24.057077 [debug] [MainThread]: Set downloads directory='C:\Users\marco\AppData\Local\Temp\dbt-downloads-oxt5pqv9'
[0m10:05:24.064577 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m10:05:25.263944 [info ] [MainThread]: Installed from version 1.3.0
[0m10:05:25.264944 [info ] [MainThread]: Up to date!
[0m10:05:25.265945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '1389cb83-2a3a-4d8c-a3eb-a8fee83e44f2', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3B35A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED433D450>]}
[0m10:05:25.265945 [info ] [MainThread]: Installing calogica/dbt_expectations
[0m10:05:26.753201 [info ] [MainThread]: Installed from version 0.10.4
[0m10:05:26.755206 [info ] [MainThread]: Up to date!
[0m10:05:26.756202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '1389cb83-2a3a-4d8c-a3eb-a8fee83e44f2', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3B37390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3EEAA50>]}
[0m10:05:26.757202 [info ] [MainThread]: Installing calogica/dbt_date
[0m10:05:27.637656 [info ] [MainThread]: Installed from version 0.10.1
[0m10:05:27.638656 [info ] [MainThread]: Up to date!
[0m10:05:27.639659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '1389cb83-2a3a-4d8c-a3eb-a8fee83e44f2', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED4369510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED4789010>]}
[0m10:05:27.643179 [debug] [MainThread]: Command `dbt deps` succeeded at 10:05:27.643179 after 5.74 seconds
[0m10:05:27.645177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3BC44D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FED3EA3210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FECCDC4390>]}
[0m10:05:27.646182 [debug] [MainThread]: Flushing usage events
[0m10:16:52.306278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002014F47F790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002014F47F090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002014EE76490>]}


============================== 10:16:52.310267 | 497cac70-bcef-44cd-9f53-f8cd7085f9dc ==============================
[0m10:16:52.310267 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:16:52.311267 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt test --select dim_listings_w_hosts', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:16:52.578927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '497cac70-bcef-44cd-9f53-f8cd7085f9dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002014FE01DD0>]}
[0m10:16:52.656533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '497cac70-bcef-44cd-9f53-f8cd7085f9dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002014FDB0250>]}
[0m10:16:52.658716 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:16:52.723661 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:16:52.781414 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m10:16:52.782158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '497cac70-bcef-44cd-9f53-f8cd7085f9dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000201500C5350>]}
[0m10:16:56.985823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '497cac70-bcef-44cd-9f53-f8cd7085f9dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000201514EC150>]}
[0m10:16:57.018435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '497cac70-bcef-44cd-9f53-f8cd7085f9dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000201518E7E10>]}
[0m10:16:57.019433 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:16:57.020433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '497cac70-bcef-44cd-9f53-f8cd7085f9dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000201514EFC90>]}
[0m10:16:57.021438 [warn ] [MainThread]: The selection criterion 'dim_listings_w_hosts' does not match any nodes
[0m10:16:57.023294 [info ] [MainThread]: 
[0m10:16:57.023717 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:16:57.024724 [debug] [MainThread]: Command end result
[0m10:16:57.043798 [debug] [MainThread]: Command `dbt test` succeeded at 10:16:57.043273 after 4.80 seconds
[0m10:16:57.043798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002014FC99190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020148561090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002014F790590>]}
[0m10:16:57.045798 [debug] [MainThread]: Flushing usage events
[0m10:17:17.360651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018393B4DE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018393C788D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018393A57C50>]}


============================== 10:17:17.365200 | fc57e1e2-1e41-4932-bf34-1e405191d846 ==============================
[0m10:17:17.365200 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:17:17.366206 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test --select dim_listings_w_hosts', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:17:17.575744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fc57e1e2-1e41-4932-bf34-1e405191d846', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183940A3790>]}
[0m10:17:17.651848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fc57e1e2-1e41-4932-bf34-1e405191d846', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001839404DB90>]}
[0m10:17:17.654358 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:17:17.678390 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:17:17.913397 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:17:17.914403 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m10:17:18.092014 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'dim_listings_w_hosts' in the 'models' section of file 'dbtlearn/models\schema.yml'
[0m10:17:18.261069 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_w_hosts_price__number.6e17061c8a' (dbtlearn/models\schema.yml) depends on a node named 'dim_listings_w_hosts' in package '' which was not found
[0m10:17:18.262036 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_w_hosts_price__500__50__0_99.71a0bfb970' (dbtlearn/models\schema.yml) depends on a node named 'dim_listings_w_hosts' in package '' which was not found
[0m10:17:18.263321 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_w_hosts_price__5000.5218138b75' (dbtlearn/models\schema.yml) depends on a node named 'dim_listings_w_hosts' in package '' which was not found
[0m10:17:18.264454 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_w_hosts_source_airbnb_listings_.637b6229da' (dbtlearn/models\schema.yml) depends on a node named 'dim_listings_w_hosts' in package '' which was not found
[0m10:17:18.280988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fc57e1e2-1e41-4932-bf34-1e405191d846', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018395711590>]}
[0m10:17:18.347239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fc57e1e2-1e41-4932-bf34-1e405191d846', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183953CB090>]}
[0m10:17:18.347239 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:17:18.348218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc57e1e2-1e41-4932-bf34-1e405191d846', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183955B35D0>]}
[0m10:17:18.349252 [warn ] [MainThread]: The selection criterion 'dim_listings_w_hosts' does not match any nodes
[0m10:17:18.350220 [info ] [MainThread]: 
[0m10:17:18.351232 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:17:18.352219 [debug] [MainThread]: Command end result
[0m10:17:18.367308 [debug] [MainThread]: Command `dbt test` succeeded at 10:17:18.367308 after 1.07 seconds
[0m10:17:18.368317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018393762450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838C7E1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018393AE1C10>]}
[0m10:17:18.369309 [debug] [MainThread]: Flushing usage events
[0m10:18:41.543754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CBB08050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205C8BC5A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CBAF1290>]}


============================== 10:18:41.547265 | f04a2c78-d849-4a82-8cca-8f46a8e6ef82 ==============================
[0m10:18:41.547265 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:18:41.549270 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt test --select dim_listings_w_hosts', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:18:41.755533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f04a2c78-d849-4a82-8cca-8f46a8e6ef82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CBC9E690>]}
[0m10:18:41.830837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f04a2c78-d849-4a82-8cca-8f46a8e6ef82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CBBC4550>]}
[0m10:18:41.832815 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:18:41.859477 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:18:42.086917 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:18:42.087922 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:18:42.093955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f04a2c78-d849-4a82-8cca-8f46a8e6ef82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CCF1EA90>]}
[0m10:18:42.112114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f04a2c78-d849-4a82-8cca-8f46a8e6ef82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CBE1FE10>]}
[0m10:18:42.113081 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:18:42.113998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f04a2c78-d849-4a82-8cca-8f46a8e6ef82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CBD0D050>]}
[0m10:18:42.115006 [warn ] [MainThread]: The selection criterion 'dim_listings_w_hosts' does not match any nodes
[0m10:18:42.116489 [info ] [MainThread]: 
[0m10:18:42.117500 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:18:42.118516 [debug] [MainThread]: Command end result
[0m10:18:42.133109 [debug] [MainThread]: Command `dbt test` succeeded at 10:18:42.133109 after 0.65 seconds
[0m10:18:42.133109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CB2F1E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205CB5D40D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000205C43A1090>]}
[0m10:18:42.134075 [debug] [MainThread]: Flushing usage events
[0m10:18:54.939234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0F53AD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0F0F65D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0ED6FB90>]}


============================== 10:18:54.942232 | cf7cd5d0-c800-4d47-ae55-600490b061be ==============================
[0m10:18:54.942232 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:18:54.943542 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt test --select dim_listings_w_hosts', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:18:55.164434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cf7cd5d0-c800-4d47-ae55-600490b061be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0F6F1DD0>]}
[0m10:18:55.244077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cf7cd5d0-c800-4d47-ae55-600490b061be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0F589A10>]}
[0m10:18:55.245672 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:18:55.275284 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:18:55.490713 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:18:55.491713 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:18:55.498291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf7cd5d0-c800-4d47-ae55-600490b061be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0ED85950>]}
[0m10:18:55.516954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cf7cd5d0-c800-4d47-ae55-600490b061be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0F89FDD0>]}
[0m10:18:55.516954 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:18:55.517991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf7cd5d0-c800-4d47-ae55-600490b061be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0F74DFD0>]}
[0m10:18:55.519957 [warn ] [MainThread]: The selection criterion 'dim_listings_w_hosts' does not match any nodes
[0m10:18:55.520957 [info ] [MainThread]: 
[0m10:18:55.521956 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:18:55.522956 [debug] [MainThread]: Command end result
[0m10:18:55.536465 [debug] [MainThread]: Command `dbt test` succeeded at 10:18:55.536465 after 0.66 seconds
[0m10:18:55.537639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0E766F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B07E21090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016B0EE415D0>]}
[0m10:18:55.537639 [debug] [MainThread]: Flushing usage events
[0m10:20:20.677710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267896D0150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267894188D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026788EFC9D0>]}


============================== 10:20:20.682210 | 40ee83e7-f663-4061-ad96-70268e67db10 ==============================
[0m10:20:20.682210 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:20:20.682210 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --select dim_listings_w_hosts', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:20:20.893228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '40ee83e7-f663-4061-ad96-70268e67db10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267898D34D0>]}
[0m10:20:20.985152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '40ee83e7-f663-4061-ad96-70268e67db10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026789830050>]}
[0m10:20:20.986901 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:20:21.010295 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:20:21.224304 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:20:21.225303 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:20:21.231303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40ee83e7-f663-4061-ad96-70268e67db10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002678AB73790>]}
[0m10:20:21.249413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40ee83e7-f663-4061-ad96-70268e67db10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026789A27E90>]}
[0m10:20:21.250411 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:20:21.251412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40ee83e7-f663-4061-ad96-70268e67db10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002678999A210>]}
[0m10:20:21.252458 [warn ] [MainThread]: The selection criterion 'dim_listings_w_hosts' does not match any nodes
[0m10:20:21.253481 [info ] [MainThread]: 
[0m10:20:21.254482 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:20:21.255480 [debug] [MainThread]: Command end result
[0m10:20:21.270061 [debug] [MainThread]: Command `dbt test` succeeded at 10:20:21.270061 after 0.65 seconds
[0m10:20:21.271054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026782001090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267822EFE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026789956690>]}
[0m10:20:21.272072 [debug] [MainThread]: Flushing usage events
[0m10:21:45.948170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1C5D6FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1C6CDE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1C5D7C50>]}


============================== 10:21:45.952603 | 8dd04b1a-d43b-40f6-baad-966524a6bbd1 ==============================
[0m10:21:45.952603 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:21:45.953661 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt list', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:21:46.206112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8dd04b1a-d43b-40f6-baad-966524a6bbd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1CAE0550>]}
[0m10:21:46.282055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8dd04b1a-d43b-40f6-baad-966524a6bbd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1CCC3A10>]}
[0m10:21:46.283597 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:21:46.306775 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:21:46.537295 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:21:46.537811 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:21:46.545282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8dd04b1a-d43b-40f6-baad-966524a6bbd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1DF52AD0>]}
[0m10:21:46.564242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8dd04b1a-d43b-40f6-baad-966524a6bbd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1DDF7D90>]}
[0m10:21:46.564242 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 8 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:21:46.565240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8dd04b1a-d43b-40f6-baad-966524a6bbd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1CC62ED0>]}
[0m10:21:46.570241 [debug] [MainThread]: Command `dbt list` succeeded at 10:21:46.570241 after 0.69 seconds
[0m10:21:46.571240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA1C3A7CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA156AEF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA156AFD50>]}
[0m10:21:46.571240 [debug] [MainThread]: Flushing usage events
[0m10:25:51.076176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AFA60A410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AFA1203D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AFA633F50>]}


============================== 10:25:51.080174 | 5ac19bf9-fc3c-443e-97d6-34cbd8a4b34a ==============================
[0m10:25:51.080174 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:25:51.081386 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt test --select dim_listings_w_hosts', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:25:51.290909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ac19bf9-fc3c-443e-97d6-34cbd8a4b34a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AFA81C450>]}
[0m10:25:51.373593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ac19bf9-fc3c-443e-97d6-34cbd8a4b34a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AFA753890>]}
[0m10:25:51.375758 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:25:51.401385 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:25:51.632779 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:25:51.633780 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m10:25:51.798775 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'fct_reviews' in the 'models' section of file 'dbtlearn/models\schema.yml'
[0m10:25:51.929440 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbtlearn.relationships_fct_reviews_listing_id__listing_id__ref_dim_listings_cleansed_.7dd9ef05fe' (dbtlearn/models\schema.yml) depends on a node named 'fct_reviews' in package '' which was not found
[0m10:25:51.930440 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbtlearn.not_null_fct_reviews_reviewer_name.8204e43c88' (dbtlearn/models\schema.yml) depends on a node named 'fct_reviews' in package '' which was not found
[0m10:25:51.931444 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbtlearn.accepted_values_fct_reviews_review_sentiment__positive__neutral__negative.7309aafcef' (dbtlearn/models\schema.yml) depends on a node named 'fct_reviews' in package '' which was not found
[0m10:25:51.947425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ac19bf9-fc3c-443e-97d6-34cbd8a4b34a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AFBD28C90>]}
[0m10:25:51.976861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ac19bf9-fc3c-443e-97d6-34cbd8a4b34a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AFBAB04D0>]}
[0m10:25:51.977875 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 12 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:25:51.978861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ac19bf9-fc3c-443e-97d6-34cbd8a4b34a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AFA22D510>]}
[0m10:25:51.979895 [warn ] [MainThread]: The selection criterion 'dim_listings_w_hosts' does not match any nodes
[0m10:25:51.981858 [info ] [MainThread]: 
[0m10:25:51.982860 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:25:51.983860 [debug] [MainThread]: Command end result
[0m10:25:52.002481 [debug] [MainThread]: Command `dbt test` succeeded at 10:25:52.002481 after 0.99 seconds
[0m10:25:52.003480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AF9E32450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AF2F31090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AF8CFA250>]}
[0m10:25:52.003480 [debug] [MainThread]: Flushing usage events
[0m10:27:41.854076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0A5DB310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0A864F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0A565450>]}


============================== 10:27:41.858073 | 0aeef221-2996-4aac-9823-4aef202921d3 ==============================
[0m10:27:41.858073 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:27:41.859075 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test --select dim_listings_w_hosts', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:27:42.065514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0aeef221-2996-4aac-9823-4aef202921d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0AEE55D0>]}
[0m10:27:42.150777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0aeef221-2996-4aac-9823-4aef202921d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0AD23C50>]}
[0m10:27:42.152419 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:27:42.174994 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:27:42.425561 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:27:42.426562 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m10:27:42.623397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0aeef221-2996-4aac-9823-4aef202921d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0C4408D0>]}
[0m10:27:42.643138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0aeef221-2996-4aac-9823-4aef202921d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0A566550>]}
[0m10:27:42.643138 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 16 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:27:42.645106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0aeef221-2996-4aac-9823-4aef202921d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0AF99450>]}
[0m10:27:42.645106 [warn ] [MainThread]: The selection criterion 'dim_listings_w_hosts' does not match any nodes
[0m10:27:42.647105 [info ] [MainThread]: 
[0m10:27:42.647765 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:27:42.649149 [debug] [MainThread]: Command end result
[0m10:27:42.667797 [debug] [MainThread]: Command `dbt test` succeeded at 10:27:42.667797 after 0.88 seconds
[0m10:27:42.670356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A0A851810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A038CFE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A035E1090>]}
[0m10:27:42.671334 [debug] [MainThread]: Flushing usage events
[0m10:28:09.383161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BA253190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BA30C510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BA2C2210>]}


============================== 10:28:09.386734 | fb2f6b85-d93e-4285-aea2-0cca6ca2f937 ==============================
[0m10:28:09.386734 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:28:09.387733 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:28:09.596218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BA269790>]}
[0m10:28:09.686146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1B9F33F10>]}
[0m10:28:09.688211 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:28:09.719335 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:28:09.954344 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:28:09.955344 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:28:09.961958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BA9F1E90>]}
[0m10:28:09.983072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BAA87CD0>]}
[0m10:28:09.983072 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 16 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:28:09.984088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BA237350>]}
[0m10:28:09.986598 [info ] [MainThread]: 
[0m10:28:09.987599 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:28:09.991360 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m10:28:10.003894 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m10:28:10.004882 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m10:28:10.005882 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:28:11.324686 [debug] [ThreadPool]: SQL status: SELECT 25 in 1.0 seconds
[0m10:28:11.325696 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m10:28:11.327696 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m10:28:11.334207 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:28:11.334207 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m10:28:11.335210 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:28:11.561948 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:28:11.562971 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:28:11.562971 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m10:28:11.617902 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m10:28:11.619409 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m10:28:11.652790 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m10:28:11.660341 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:11.661308 [debug] [MainThread]: On master: BEGIN
[0m10:28:11.661308 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:28:11.896945 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:28:11.897472 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:11.898003 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:28:11.969380 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m10:28:11.971468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BAB104D0>]}
[0m10:28:11.972467 [debug] [MainThread]: On master: ROLLBACK
[0m10:28:12.008980 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:12.009486 [debug] [MainThread]: On master: BEGIN
[0m10:28:12.080412 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:28:12.081376 [debug] [MainThread]: On master: COMMIT
[0m10:28:12.082381 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:12.082381 [debug] [MainThread]: On master: COMMIT
[0m10:28:12.123489 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:28:12.123489 [debug] [MainThread]: On master: Close
[0m10:28:12.125493 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:28:12.125776 [info ] [MainThread]: 
[0m10:28:12.131554 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m10:28:12.132554 [info ] [Thread-1 (]: 1 of 8 START sql view model test.src_hosts ..................................... [RUN]
[0m10:28:12.134554 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m10:28:12.134554 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m10:28:12.145064 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m10:28:12.147065 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 10:28:12.135554 => 10:28:12.147065
[0m10:28:12.149065 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m10:28:12.187133 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m10:28:12.190185 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m10:28:12.191187 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m10:28:12.191187 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:28:12.437258 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:12.438218 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m10:28:12.438218 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		"inttegra_stage"."test"."raw_hosts" rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m10:28:12.503787 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m10:28:12.510518 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m10:28:12.511522 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m10:28:12.547398 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:12.550913 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m10:28:12.551917 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m10:28:12.587392 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:12.602432 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m10:28:12.603940 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m10:28:12.604950 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m10:28:12.640385 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:28:12.648348 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m10:28:12.652818 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m10:28:12.653817 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m10:28:12.705122 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m10:28:12.707087 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 10:28:12.149600 => 10:28:12.707087
[0m10:28:12.708089 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m10:28:12.709615 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BA236C90>]}
[0m10:28:12.710618 [info ] [Thread-1 (]: 1 of 8 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.58s]
[0m10:28:12.712625 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m10:28:12.713631 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m10:28:12.714346 [info ] [Thread-1 (]: 2 of 8 START sql view model test.src_listings .................................. [RUN]
[0m10:28:12.714961 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m10:28:12.715968 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m10:28:12.719469 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m10:28:12.722561 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 10:28:12.716967 => 10:28:12.721551
[0m10:28:12.722561 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m10:28:12.729093 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m10:28:12.733106 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m10:28:12.734111 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m10:28:12.735106 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:12.977062 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:12.977062 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m10:28:12.978062 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."test"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m10:28:13.032213 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m10:28:13.036229 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m10:28:13.036229 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m10:28:13.072422 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:13.076422 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m10:28:13.077423 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m10:28:13.112621 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:13.114660 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m10:28:13.115665 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m10:28:13.115665 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m10:28:13.150342 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:28:13.153373 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m10:28:13.154372 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m10:28:13.155385 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m10:28:13.187350 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m10:28:13.189601 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 10:28:12.723587 => 10:28:13.189601
[0m10:28:13.189601 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m10:28:13.190607 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BAADC790>]}
[0m10:28:13.191611 [info ] [Thread-1 (]: 2 of 8 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.48s]
[0m10:28:13.192613 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m10:28:13.193648 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m10:28:13.194612 [info ] [Thread-1 (]: 3 of 8 START sql view model test.src_reviews ................................... [RUN]
[0m10:28:13.195122 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m10:28:13.196161 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m10:28:13.199700 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m10:28:13.200703 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 10:28:13.196161 => 10:28:13.200703
[0m10:28:13.201737 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m10:28:13.207214 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m10:28:13.211086 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m10:28:13.212122 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m10:28:13.213114 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:13.441137 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:13.442124 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m10:28:13.442124 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT 
		*
	FROM
		"inttegra_stage"."test"."raw_reviews" rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m10:28:13.490370 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m10:28:13.494402 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m10:28:13.495398 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m10:28:13.533049 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:13.536059 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m10:28:13.537059 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m10:28:13.573403 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:13.575413 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m10:28:13.576412 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m10:28:13.577411 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m10:28:13.611697 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:28:13.614737 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m10:28:13.615734 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m10:28:13.616740 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m10:28:13.652101 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m10:28:13.654102 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 10:28:13.202707 => 10:28:13.654102
[0m10:28:13.655102 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m10:28:13.656104 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BAC62110>]}
[0m10:28:13.657103 [info ] [Thread-1 (]: 3 of 8 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.46s]
[0m10:28:13.658101 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m10:28:13.659100 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m10:28:13.659606 [info ] [Thread-1 (]: 4 of 8 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m10:28:13.661645 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m10:28:13.661645 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m10:28:13.665645 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m10:28:13.667616 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 10:28:13.662612 => 10:28:13.667616
[0m10:28:13.667616 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m10:28:13.697129 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m10:28:13.699369 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m10:28:13.699369 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m10:28:13.700376 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:13.917893 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:13.919438 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m10:28:13.920475 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m10:28:14.019717 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m10:28:14.024005 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m10:28:14.025066 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m10:28:14.058114 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:14.062924 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m10:28:14.063452 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m10:28:14.097390 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:14.101908 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m10:28:14.102907 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m10:28:14.103908 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m10:28:14.138743 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:28:14.142328 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m10:28:14.145328 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m10:28:14.145328 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m10:28:14.190630 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:28:14.191673 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 10:28:13.669124 => 10:28:14.191673
[0m10:28:14.192669 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m10:28:14.193669 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BBEC2810>]}
[0m10:28:14.194635 [info ] [Thread-1 (]: 4 of 8 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.53s]
[0m10:28:14.195636 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m10:28:14.196656 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m10:28:14.196656 [info ] [Thread-1 (]: 5 of 8 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m10:28:14.197634 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m10:28:14.199138 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m10:28:14.202148 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m10:28:14.204150 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 10:28:14.199138 => 10:28:14.204150
[0m10:28:14.205149 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m10:28:14.209652 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m10:28:14.211157 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m10:28:14.212164 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m10:28:14.213197 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:14.446470 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:14.447257 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m10:28:14.448239 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m10:28:14.610159 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m10:28:14.613981 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m10:28:14.614982 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m10:28:14.649229 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:14.653270 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m10:28:14.654270 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m10:28:14.688840 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:14.691360 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m10:28:14.691360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m10:28:14.692361 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m10:28:14.732754 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:28:14.735735 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m10:28:14.736738 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m10:28:14.737736 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m10:28:14.779237 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:28:14.781277 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 10:28:14.205149 => 10:28:14.781277
[0m10:28:14.782245 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m10:28:14.782245 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1B96B8A90>]}
[0m10:28:14.783278 [info ] [Thread-1 (]: 5 of 8 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.58s]
[0m10:28:14.784243 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m10:28:14.785280 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m10:28:14.786185 [info ] [Thread-1 (]: 6 of 8 START sql incremental model test.fact_reviews ........................... [RUN]
[0m10:28:14.787189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m10:28:14.788190 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m10:28:14.808345 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m10:28:14.812614 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 10:28:14.788190 => 10:28:14.812032
[0m10:28:14.813698 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m10:28:14.844640 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m10:28:14.845633 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp102814839061"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    md5(cast(coalesce(cast(listing_id as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(review_date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(reviewer_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(review_txt as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as review_id,
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m10:28:14.845633 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:16.444105 [debug] [Thread-1 (]: SQL status: SELECT 0 in 2.0 seconds
[0m10:28:16.455150 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m10:28:16.455150 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m10:28:16.499094 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:16.500106 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m10:28:16.501101 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp102814839061'
        
      order by ordinal_position

  
[0m10:28:16.571128 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m10:28:16.576121 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m10:28:16.577121 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m10:28:16.624782 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m10:28:16.649840 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m10:28:16.650847 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp102814839061'
        
      order by ordinal_position

  
[0m10:28:16.696984 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m10:28:16.702503 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m10:28:16.702503 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m10:28:16.744670 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m10:28:16.753292 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m10:28:16.762868 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m10:28:16.765885 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m10:28:16.766925 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("review_id", "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "review_id", "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp102814839061"
    )


  
[0m10:28:16.802363 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m10:28:16.803405 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m10:28:16.804394 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m10:28:16.805399 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m10:28:16.839693 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:28:16.840702 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 10:28:14.814225 => 10:28:16.840702
[0m10:28:16.841707 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m10:28:16.842708 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BBEF3150>]}
[0m10:28:16.843708 [info ] [Thread-1 (]: 6 of 8 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 2.06s]
[0m10:28:16.844604 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m10:28:16.845610 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m10:28:16.846616 [info ] [Thread-1 (]: 7 of 8 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m10:28:16.848080 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m10:28:16.848080 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m10:28:16.851684 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m10:28:16.854659 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 10:28:16.849109 => 10:28:16.853655
[0m10:28:16.854659 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m10:28:16.860171 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m10:28:16.863171 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m10:28:16.864169 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m10:28:16.865169 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:18.189121 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m10:28:18.190135 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m10:28:18.191140 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m10:28:18.351806 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m10:28:18.355644 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m10:28:18.356160 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts" rename to "dim_listings_with_hosts__dbt_backup"
[0m10:28:18.389066 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:18.392681 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m10:28:18.393708 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m10:28:18.428655 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:18.432428 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m10:28:18.433604 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m10:28:18.434200 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m10:28:18.473331 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:28:18.476329 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m10:28:18.477329 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m10:28:18.478329 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m10:28:18.530303 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:28:18.532301 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 10:28:16.855654 => 10:28:18.531303
[0m10:28:18.532301 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m10:28:18.533303 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BBEBB4D0>]}
[0m10:28:18.534302 [info ] [Thread-1 (]: 7 of 8 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 1.69s]
[0m10:28:18.535303 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m10:28:18.535303 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m10:28:18.536302 [info ] [Thread-1 (]: 8 of 8 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m10:28:18.537302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m10:28:18.538302 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m10:28:18.541310 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m10:28:18.543187 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 10:28:18.538302 => 10:28:18.543187
[0m10:28:18.543187 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m10:28:18.549696 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m10:28:18.553176 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m10:28:18.554180 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m10:28:18.554180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:18.761827 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:18.762786 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m10:28:18.763787 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_date IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m10:28:20.539146 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m10:28:20.542750 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m10:28:20.543717 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews" rename to "mart_fullmoon_reviews__dbt_backup"
[0m10:28:20.575689 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:20.579369 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m10:28:20.580378 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp" rename to "mart_fullmoon_reviews"
[0m10:28:20.613033 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:28:20.615074 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m10:28:20.616040 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m10:28:20.616040 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m10:28:20.655561 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:28:20.657564 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup"
[0m10:28:20.659107 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m10:28:20.660113 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
drop table if exists "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup" cascade
[0m10:28:20.702347 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:28:20.704352 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 10:28:18.544193 => 10:28:20.704352
[0m10:28:20.704352 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m10:28:20.705353 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb2f6b85-d93e-4285-aea2-0cca6ca2f937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BBE68810>]}
[0m10:28:20.706352 [info ] [Thread-1 (]: 8 of 8 OK created sql table model test.mart_fullmoon_reviews ................... [[32mSELECT 410284[0m in 2.17s]
[0m10:28:20.707359 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m10:28:20.709353 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:20.709353 [debug] [MainThread]: On master: BEGIN
[0m10:28:20.710885 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:28:20.913471 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:28:20.914470 [debug] [MainThread]: On master: COMMIT
[0m10:28:20.915483 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:20.915483 [debug] [MainThread]: On master: COMMIT
[0m10:28:20.953611 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:28:20.954562 [debug] [MainThread]: On master: Close
[0m10:28:20.955555 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:28:20.955555 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m10:28:20.956555 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m10:28:20.956555 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m10:28:20.957554 [info ] [MainThread]: 
[0m10:28:20.957554 [info ] [MainThread]: Finished running 3 view models, 4 table models, 1 incremental model in 0 hours 0 minutes and 10.97 seconds (10.97s).
[0m10:28:20.961096 [debug] [MainThread]: Command end result
[0m10:28:20.979080 [info ] [MainThread]: 
[0m10:28:20.980087 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:28:20.982099 [info ] [MainThread]: 
[0m10:28:20.983090 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m10:28:20.986107 [debug] [MainThread]: Command `dbt run` succeeded at 10:28:20.986107 after 11.67 seconds
[0m10:28:20.987088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1B2F91010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1B98A2E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1BA2C2350>]}
[0m10:28:20.988087 [debug] [MainThread]: Flushing usage events
[0m10:28:27.353587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DF1ACAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DF6C8B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DF1AFC50>]}


============================== 10:28:27.357587 | 7dffba00-55aa-43f0-9178-4cf6c9b8dcaa ==============================
[0m10:28:27.357587 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:28:27.359093 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt test --select dim_listings_w_hosts', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:28:27.560556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7dffba00-55aa-43f0-9178-4cf6c9b8dcaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DF1AC550>]}
[0m10:28:27.643345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7dffba00-55aa-43f0-9178-4cf6c9b8dcaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DFB02ED0>]}
[0m10:28:27.645331 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:28:27.668073 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:28:27.901350 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:28:27.902351 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:28:27.915876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7dffba00-55aa-43f0-9178-4cf6c9b8dcaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DFB4C2D0>]}
[0m10:28:27.942155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7dffba00-55aa-43f0-9178-4cf6c9b8dcaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DFCBFD10>]}
[0m10:28:27.943188 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 16 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:28:27.944157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7dffba00-55aa-43f0-9178-4cf6c9b8dcaa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DFC2F0D0>]}
[0m10:28:27.945155 [warn ] [MainThread]: The selection criterion 'dim_listings_w_hosts' does not match any nodes
[0m10:28:27.946180 [info ] [MainThread]: 
[0m10:28:27.947190 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:28:27.948811 [debug] [MainThread]: Command end result
[0m10:28:27.966997 [debug] [MainThread]: Command `dbt test` succeeded at 10:28:27.965998 after 0.68 seconds
[0m10:28:27.966997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DF1B3790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232DF1860D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232D8519E50>]}
[0m10:28:27.967997 [debug] [MainThread]: Flushing usage events
[0m10:28:37.201274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F7DBF490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F7DBCE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F7E71D90>]}


============================== 10:28:37.205281 | af3b1afd-fed5-42a2-b121-1ef5a2ed6734 ==============================
[0m10:28:37.205281 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:28:37.206279 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test --select dim_listings_with_hosts', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:28:37.410084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'af3b1afd-fed5-42a2-b121-1ef5a2ed6734', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F7DBC450>]}
[0m10:28:37.495065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'af3b1afd-fed5-42a2-b121-1ef5a2ed6734', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F8193E90>]}
[0m10:28:37.496065 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:28:37.522502 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:28:37.739123 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:28:37.740653 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:28:37.747666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af3b1afd-fed5-42a2-b121-1ef5a2ed6734', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F9A37990>]}
[0m10:28:37.767796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af3b1afd-fed5-42a2-b121-1ef5a2ed6734', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F98DFE50>]}
[0m10:28:37.768797 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 16 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:28:37.768797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'af3b1afd-fed5-42a2-b121-1ef5a2ed6734', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F8758410>]}
[0m10:28:37.771230 [info ] [MainThread]: 
[0m10:28:37.772195 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:28:37.774289 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m10:28:37.784813 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:28:37.785844 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m10:28:37.785844 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:28:39.102271 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m10:28:39.102271 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:28:39.103273 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m10:28:39.153448 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m10:28:39.154458 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m10:28:39.186342 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m10:28:39.193935 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:39.193935 [debug] [MainThread]: On master: BEGIN
[0m10:28:39.194903 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:28:39.410606 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:28:39.411609 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:39.412607 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:28:39.477251 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m10:28:39.479761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'af3b1afd-fed5-42a2-b121-1ef5a2ed6734', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F88BA810>]}
[0m10:28:39.479761 [debug] [MainThread]: On master: ROLLBACK
[0m10:28:39.512745 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:39.513754 [debug] [MainThread]: On master: BEGIN
[0m10:28:39.575521 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:28:39.575521 [debug] [MainThread]: On master: COMMIT
[0m10:28:39.576521 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:39.576521 [debug] [MainThread]: On master: COMMIT
[0m10:28:39.613138 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:28:39.614143 [debug] [MainThread]: On master: Close
[0m10:28:39.615108 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:28:39.616105 [info ] [MainThread]: 
[0m10:28:39.620611 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:28:39.621612 [info ] [Thread-1 (]: 1 of 4 START test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [RUN]
[0m10:28:39.623611 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba'
[0m10:28:39.624612 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:28:39.652005 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:28:39.653974 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (compile): 10:28:39.624612 => 10:28:39.653974
[0m10:28:39.654985 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:28:39.672082 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:28:39.674083 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:28:39.675083 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: BEGIN
[0m10:28:39.676083 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:28:39.887305 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:39.888314 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:28:39.888314 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  
( 1=1 and max(price) <= 5000
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:28:39.953434 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:28:39.955465 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (execute): 10:28:39.655973 => 10:28:39.955465
[0m10:28:39.956464 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: ROLLBACK
[0m10:28:39.986657 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: Close
[0m10:28:39.987658 [warn ] [Thread-1 (]: 1 of 4 WARN 1 dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [[33mWARN 1[0m in 0.37s]
[0m10:28:39.989166 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:28:39.990174 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:28:39.991173 [info ] [Thread-1 (]: 2 of 4 START test dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [RUN]
[0m10:28:39.992173 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba, now test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b)
[0m10:28:39.992173 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:28:40.004689 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:28:40.007697 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (compile): 10:28:39.993171 => 10:28:40.007697
[0m10:28:40.009215 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:28:40.016227 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:28:40.019727 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:28:40.019727 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: BEGIN
[0m10:28:40.020734 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:40.217507 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:40.217507 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:28:40.219048 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      





    with grouped_expression as (
    select
        
        
    
  
( 1=1 and percentile_cont(0.99) within group (order by price) >= 50 and percentile_cont(0.99) within group (order by price) <= 500
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:28:40.292338 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:28:40.294333 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (execute): 10:28:40.010228 => 10:28:40.293333
[0m10:28:40.294333 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: ROLLBACK
[0m10:28:40.335708 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: Close
[0m10:28:40.336716 [info ] [Thread-1 (]: 2 of 4 PASS dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [[32mPASS[0m in 0.35s]
[0m10:28:40.337714 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:28:40.337714 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8
[0m10:28:40.339256 [info ] [Thread-1 (]: 3 of 4 START test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number  [RUN]
[0m10:28:40.340264 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b, now test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8)
[0m10:28:40.341299 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8
[0m10:28:40.355846 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:28:40.355846 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: BEGIN
[0m10:28:40.356844 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:40.584562 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:40.585561 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:28:40.585561 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_with_hosts'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m10:28:40.651027 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m10:28:40.663637 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:28:40.665602 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8 (compile): 10:28:40.341299 => 10:28:40.665602
[0m10:28:40.666603 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8
[0m10:28:40.670115 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:28:40.672247 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:28:40.673278 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      with relation_columns as (

        
        select
            cast('ID_LISTINGS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('LISTING_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('ROOM_TYPE' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('MINIMUM_NIGHTS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('PRICE' as TEXT) as relation_column,
            cast('NUMERIC' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_ID' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_IS_SUPERHOST' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('CREATED_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        union all
        
        select
            cast('UPDATE_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        
        
    ),
    test_data as (

        select
            *
        from
            relation_columns
        where
            relation_column = 'PRICE'
            and
            relation_column_type not in ('NUMBER')

    )
    select *
    from test_data
      
    ) dbt_internal_test
[0m10:28:40.711087 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:28:40.713059 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8 (execute): 10:28:40.667603 => 10:28:40.713059
[0m10:28:40.714055 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: ROLLBACK
[0m10:28:40.745300 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: Close
[0m10:28:40.746306 [error] [Thread-1 (]: 3 of 4 FAIL 1 dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number  [[31mFAIL 1[0m in 0.41s]
[0m10:28:40.747308 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8
[0m10:28:40.748814 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:28:40.749820 [info ] [Thread-1 (]: 4 of 4 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m10:28:40.750820 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8, now test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214)
[0m10:28:40.751819 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:28:40.776431 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:28:40.779949 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 10:28:40.751819 => 10:28:40.779949
[0m10:28:40.780952 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:28:40.785950 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:28:40.787948 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:28:40.789454 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m10:28:40.789454 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:41.011834 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:28:41.012836 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:28:41.013832 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m10:28:41.080319 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:28:41.082351 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 10:28:40.781957 => 10:28:41.081315
[0m10:28:41.082351 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m10:28:41.112218 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m10:28:41.113109 [info ] [Thread-1 (]: 4 of 4 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.36s]
[0m10:28:41.115063 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:28:41.116066 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:41.117064 [debug] [MainThread]: On master: BEGIN
[0m10:28:41.117064 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:28:41.344436 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:28:41.345443 [debug] [MainThread]: On master: COMMIT
[0m10:28:41.345443 [debug] [MainThread]: Using postgres connection "master"
[0m10:28:41.346476 [debug] [MainThread]: On master: COMMIT
[0m10:28:41.386584 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:28:41.387094 [debug] [MainThread]: On master: Close
[0m10:28:41.388104 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:28:41.389102 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m10:28:41.389606 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214' was properly closed.
[0m10:28:41.389606 [info ] [MainThread]: 
[0m10:28:41.390612 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 3.62 seconds (3.62s).
[0m10:28:41.392651 [debug] [MainThread]: Command end result
[0m10:28:41.407196 [info ] [MainThread]: 
[0m10:28:41.407566 [info ] [MainThread]: [31mCompleted with 1 error and 1 warning:[0m
[0m10:28:41.409079 [info ] [MainThread]: 
[0m10:28:41.410089 [error] [MainThread]: [31mFailure in test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number (dbtlearn/models\schema.yml)[0m
[0m10:28:41.411094 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:28:41.412085 [info ] [MainThread]: 
[0m10:28:41.413110 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_195c26ad485e7df4f2484c541ab30c07.sql
[0m10:28:41.416090 [info ] [MainThread]: 
[0m10:28:41.417090 [warn ] [MainThread]: [33mWarning in test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000 (dbtlearn/models\schema.yml)[0m
[0m10:28:41.418089 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m10:28:41.419117 [info ] [MainThread]: 
[0m10:28:41.420263 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_468e4de3f229fa6ad450d64ec382bdcb.sql
[0m10:28:41.421263 [info ] [MainThread]: 
[0m10:28:41.422261 [info ] [MainThread]: Done. PASS=2 WARN=1 ERROR=1 SKIP=0 TOTAL=4
[0m10:28:41.423259 [debug] [MainThread]: Command `dbt test` failed at 10:28:41.423259 after 4.28 seconds
[0m10:28:41.424259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F7FE7B50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F0EE1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000279F7D06790>]}
[0m10:28:41.425260 [debug] [MainThread]: Flushing usage events
[0m10:31:07.548383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001816776A7D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001816731FB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018167066550>]}


============================== 10:31:07.552439 | e4695e82-a428-4af2-814a-238303443c0b ==============================
[0m10:31:07.552439 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:31:07.553437 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt test --select dim_listings_with_hosts', 'send_anonymous_usage_stats': 'True'}
[0m10:31:07.758027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e4695e82-a428-4af2-814a-238303443c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181672B2050>]}
[0m10:31:07.834444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e4695e82-a428-4af2-814a-238303443c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000181677B9750>]}
[0m10:31:07.836603 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:31:07.863980 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:31:08.094306 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:31:08.095306 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m10:31:08.400494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4695e82-a428-4af2-814a-238303443c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018168FC79D0>]}
[0m10:31:08.421283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4695e82-a428-4af2-814a-238303443c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018167E9E990>]}
[0m10:31:08.422280 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 16 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:31:08.422664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4695e82-a428-4af2-814a-238303443c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018167C35E10>]}
[0m10:31:08.424703 [info ] [MainThread]: 
[0m10:31:08.425668 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:31:08.429021 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m10:31:08.438540 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:31:08.439552 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m10:31:08.440057 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:31:09.737735 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m10:31:09.739242 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:31:09.740249 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m10:31:09.789636 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m10:31:09.792015 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m10:31:09.823806 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m10:31:09.831381 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:09.832390 [debug] [MainThread]: On master: BEGIN
[0m10:31:09.832390 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:31:10.039620 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:31:10.040160 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:10.041197 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:31:10.106919 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m10:31:10.109478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4695e82-a428-4af2-814a-238303443c0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018167CB44D0>]}
[0m10:31:10.109478 [debug] [MainThread]: On master: ROLLBACK
[0m10:31:10.140763 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:10.141414 [debug] [MainThread]: On master: BEGIN
[0m10:31:10.203786 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:31:10.204831 [debug] [MainThread]: On master: COMMIT
[0m10:31:10.204831 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:10.205831 [debug] [MainThread]: On master: COMMIT
[0m10:31:10.240386 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:31:10.241187 [debug] [MainThread]: On master: Close
[0m10:31:10.242195 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:31:10.243201 [info ] [MainThread]: 
[0m10:31:10.247236 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:31:10.248204 [info ] [Thread-1 (]: 1 of 4 START test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [RUN]
[0m10:31:10.248204 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba'
[0m10:31:10.249714 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:31:10.260794 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:31:10.262790 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (compile): 10:31:10.249714 => 10:31:10.262790
[0m10:31:10.263788 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:31:10.282724 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:31:10.285256 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:31:10.286263 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: BEGIN
[0m10:31:10.287264 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:31:10.518020 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:31:10.519524 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:31:10.520529 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  
( 1=1 and max(price) <= 5000
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:31:10.580633 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:31:10.582663 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (execute): 10:31:10.264785 => 10:31:10.582663
[0m10:31:10.583665 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: ROLLBACK
[0m10:31:10.618973 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: Close
[0m10:31:10.620706 [warn ] [Thread-1 (]: 1 of 4 WARN 1 dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [[33mWARN 1[0m in 0.37s]
[0m10:31:10.621703 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:31:10.622735 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:31:10.622735 [info ] [Thread-1 (]: 2 of 4 START test dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [RUN]
[0m10:31:10.623702 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba, now test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b)
[0m10:31:10.624703 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:31:10.629204 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:31:10.631244 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (compile): 10:31:10.624703 => 10:31:10.631244
[0m10:31:10.631244 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:31:10.634208 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:31:10.635207 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:31:10.636211 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: BEGIN
[0m10:31:10.637208 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:31:10.867834 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:31:10.867834 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:31:10.869375 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      





    with grouped_expression as (
    select
        
        
    
  
( 1=1 and percentile_cont(0.99) within group (order by price) >= 50 and percentile_cont(0.99) within group (order by price) <= 500
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:31:10.945125 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:31:10.947167 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (execute): 10:31:10.632210 => 10:31:10.946180
[0m10:31:10.947167 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: ROLLBACK
[0m10:31:10.980624 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: Close
[0m10:31:10.981622 [info ] [Thread-1 (]: 2 of 4 PASS dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [[32mPASS[0m in 0.36s]
[0m10:31:10.982624 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:31:10.983621 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e
[0m10:31:10.983621 [info ] [Thread-1 (]: 3 of 4 START test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic  [RUN]
[0m10:31:10.984654 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b, now test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e)
[0m10:31:10.985655 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e
[0m10:31:10.995236 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e"
[0m10:31:10.996237 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e: BEGIN
[0m10:31:10.996237 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:31:11.229466 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:31:11.230475 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e"
[0m10:31:11.231473 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_with_hosts'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m10:31:11.297225 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m10:31:11.310398 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e"
[0m10:31:11.312399 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e (compile): 10:31:10.985655 => 10:31:11.312399
[0m10:31:11.313400 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e
[0m10:31:11.316432 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e"
[0m10:31:11.318406 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e"
[0m10:31:11.319433 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      with relation_columns as (

        
        select
            cast('ID_LISTINGS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('LISTING_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('ROOM_TYPE' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('MINIMUM_NIGHTS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('PRICE' as TEXT) as relation_column,
            cast('NUMERIC' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_ID' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_IS_SUPERHOST' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('CREATED_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        union all
        
        select
            cast('UPDATE_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        
        
    ),
    test_data as (

        select
            *
        from
            relation_columns
        where
            relation_column = 'PRICE'
            and
            relation_column_type not in ('NUMBERIC')

    )
    select *
    from test_data
      
    ) dbt_internal_test
[0m10:31:11.363540 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:31:11.364541 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e (execute): 10:31:11.313400 => 10:31:11.364541
[0m10:31:11.365540 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e: ROLLBACK
[0m10:31:11.399341 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e: Close
[0m10:31:11.401849 [error] [Thread-1 (]: 3 of 4 FAIL 1 dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic  [[31mFAIL 1[0m in 0.42s]
[0m10:31:11.402847 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e
[0m10:31:11.403882 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:31:11.404847 [info ] [Thread-1 (]: 4 of 4 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m10:31:11.405868 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic.ec7934ec9e, now test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214)
[0m10:31:11.406880 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:31:11.413392 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:31:11.415393 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 10:31:11.406880 => 10:31:11.414391
[0m10:31:11.415393 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:31:11.418391 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:31:11.420723 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:31:11.422730 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m10:31:11.423730 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:31:11.657881 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:31:11.659418 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:31:11.659418 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m10:31:11.727645 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:31:11.729233 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 10:31:11.416392 => 10:31:11.729233
[0m10:31:11.730260 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m10:31:11.765127 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m10:31:11.766133 [info ] [Thread-1 (]: 4 of 4 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.36s]
[0m10:31:11.768133 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:31:11.769671 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:11.769671 [debug] [MainThread]: On master: BEGIN
[0m10:31:11.770677 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:31:11.977783 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:31:11.977783 [debug] [MainThread]: On master: COMMIT
[0m10:31:11.979383 [debug] [MainThread]: Using postgres connection "master"
[0m10:31:11.979383 [debug] [MainThread]: On master: COMMIT
[0m10:31:12.019041 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:31:12.019552 [debug] [MainThread]: On master: Close
[0m10:31:12.020583 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:31:12.021588 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m10:31:12.021588 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214' was properly closed.
[0m10:31:12.022587 [info ] [MainThread]: 
[0m10:31:12.023608 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 3.60 seconds (3.60s).
[0m10:31:12.025587 [debug] [MainThread]: Command end result
[0m10:31:12.039605 [info ] [MainThread]: 
[0m10:31:12.040613 [info ] [MainThread]: [31mCompleted with 1 error and 1 warning:[0m
[0m10:31:12.041613 [info ] [MainThread]: 
[0m10:31:12.042615 [error] [MainThread]: [31mFailure in test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__numberic (dbtlearn/models\schema.yml)[0m
[0m10:31:12.043613 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:31:12.044614 [info ] [MainThread]: 
[0m10:31:12.045614 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_607b07aa5f2a20c22f36b7fb16c8d91c.sql
[0m10:31:12.045614 [info ] [MainThread]: 
[0m10:31:12.046612 [warn ] [MainThread]: [33mWarning in test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000 (dbtlearn/models\schema.yml)[0m
[0m10:31:12.047613 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m10:31:12.048616 [info ] [MainThread]: 
[0m10:31:12.049612 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_468e4de3f229fa6ad450d64ec382bdcb.sql
[0m10:31:12.049612 [info ] [MainThread]: 
[0m10:31:12.051061 [info ] [MainThread]: Done. PASS=2 WARN=1 ERROR=1 SKIP=0 TOTAL=4
[0m10:31:12.053071 [debug] [MainThread]: Command `dbt test` failed at 10:31:12.052071 after 4.57 seconds
[0m10:31:12.054071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001815FFE1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018160025C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018160025BD0>]}
[0m10:31:12.054071 [debug] [MainThread]: Flushing usage events
[0m10:38:59.070612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E878982E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87C272390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87BFB0790>]}


============================== 10:38:59.075114 | e0f9f132-ef74-4f07-8a2e-8d0c3b17c4c8 ==============================
[0m10:38:59.075114 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:38:59.076120 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test --select dim_listings_with_hosts', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:38:59.283581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e0f9f132-ef74-4f07-8a2e-8d0c3b17c4c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87C75FE90>]}
[0m10:38:59.375637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e0f9f132-ef74-4f07-8a2e-8d0c3b17c4c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87C01BCD0>]}
[0m10:38:59.377602 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:38:59.404627 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:38:59.663181 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:38:59.664684 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m10:38:59.969630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0f9f132-ef74-4f07-8a2e-8d0c3b17c4c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87DF56810>]}
[0m10:38:59.989756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0f9f132-ef74-4f07-8a2e-8d0c3b17c4c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87DF09890>]}
[0m10:38:59.989756 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 16 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:38:59.990786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0f9f132-ef74-4f07-8a2e-8d0c3b17c4c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87CCAFD50>]}
[0m10:38:59.992753 [info ] [MainThread]: 
[0m10:38:59.993828 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:38:59.996874 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m10:39:00.005981 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:39:00.007011 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m10:39:00.008011 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:39:01.321662 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m10:39:01.322664 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:39:01.323661 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m10:39:01.369172 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m10:39:01.371166 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m10:39:01.400677 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m10:39:01.408266 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:01.409265 [debug] [MainThread]: On master: BEGIN
[0m10:39:01.409265 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:39:01.618650 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:39:01.619693 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:01.619693 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:39:01.684377 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m10:39:01.686962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0f9f132-ef74-4f07-8a2e-8d0c3b17c4c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87CA18990>]}
[0m10:39:01.686962 [debug] [MainThread]: On master: ROLLBACK
[0m10:39:01.719922 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:01.720474 [debug] [MainThread]: On master: BEGIN
[0m10:39:01.786911 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:39:01.787957 [debug] [MainThread]: On master: COMMIT
[0m10:39:01.788481 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:01.789007 [debug] [MainThread]: On master: COMMIT
[0m10:39:01.825550 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:39:01.826559 [debug] [MainThread]: On master: Close
[0m10:39:01.826559 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:39:01.827861 [info ] [MainThread]: 
[0m10:39:01.831866 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:39:01.832869 [info ] [Thread-1 (]: 1 of 4 START test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [RUN]
[0m10:39:01.833870 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba'
[0m10:39:01.833870 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:39:01.844915 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:39:01.846926 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (compile): 10:39:01.834872 => 10:39:01.846926
[0m10:39:01.847926 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:39:01.862438 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:39:01.863438 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:39:01.864947 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: BEGIN
[0m10:39:01.865955 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:39:02.296566 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:39:02.297567 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:39:02.297567 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  
( 1=1 and max(price) <= 5000
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:39:02.378109 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:39:02.380898 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (execute): 10:39:01.847926 => 10:39:02.379897
[0m10:39:02.380898 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: ROLLBACK
[0m10:39:02.446414 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: Close
[0m10:39:02.447424 [warn ] [Thread-1 (]: 1 of 4 WARN 1 dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [[33mWARN 1[0m in 0.61s]
[0m10:39:02.448441 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:39:02.449469 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:39:02.450429 [info ] [Thread-1 (]: 2 of 4 START test dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [RUN]
[0m10:39:02.451431 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba, now test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b)
[0m10:39:02.452463 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:39:02.457042 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:39:02.458043 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (compile): 10:39:02.452463 => 10:39:02.458043
[0m10:39:02.459010 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:39:02.462041 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:39:02.463012 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:39:02.464006 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: BEGIN
[0m10:39:02.465018 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:39:02.785938 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:39:02.786929 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:39:02.787889 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      





    with grouped_expression as (
    select
        
        
    
  
( 1=1 and percentile_cont(0.99) within group (order by price) >= 50 and percentile_cont(0.99) within group (order by price) <= 500
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:39:02.859136 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:39:02.861142 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (execute): 10:39:02.460041 => 10:39:02.860145
[0m10:39:02.861142 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: ROLLBACK
[0m10:39:02.924576 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: Close
[0m10:39:02.926097 [info ] [Thread-1 (]: 2 of 4 PASS dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [[32mPASS[0m in 0.48s]
[0m10:39:02.927616 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:39:02.927616 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901
[0m10:39:02.928615 [info ] [Thread-1 (]: 3 of 4 START test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal  [RUN]
[0m10:39:02.929614 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b, now test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901)
[0m10:39:02.930616 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901
[0m10:39:02.941138 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901"
[0m10:39:02.942139 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901: BEGIN
[0m10:39:02.943149 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:39:03.338199 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:39:03.339239 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901"
[0m10:39:03.340238 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_with_hosts'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m10:39:03.408575 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m10:39:03.422882 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901"
[0m10:39:03.424888 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901 (compile): 10:39:02.930616 => 10:39:03.423884
[0m10:39:03.424888 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901
[0m10:39:03.428208 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901"
[0m10:39:03.430210 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901"
[0m10:39:03.431209 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      with relation_columns as (

        
        select
            cast('ID_LISTINGS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('LISTING_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('ROOM_TYPE' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('MINIMUM_NIGHTS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('PRICE' as TEXT) as relation_column,
            cast('NUMERIC' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_ID' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_IS_SUPERHOST' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('CREATED_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        union all
        
        select
            cast('UPDATE_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        
        
    ),
    test_data as (

        select
            *
        from
            relation_columns
        where
            relation_column = 'PRICE'
            and
            relation_column_type not in ('DECIMAL')

    )
    select *
    from test_data
      
    ) dbt_internal_test
[0m10:39:03.541967 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:39:03.543973 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901 (execute): 10:39:03.426208 => 10:39:03.542984
[0m10:39:03.543973 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901: ROLLBACK
[0m10:39:03.610135 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901: Close
[0m10:39:03.611085 [error] [Thread-1 (]: 3 of 4 FAIL 1 dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal  [[31mFAIL 1[0m in 0.68s]
[0m10:39:03.613080 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901
[0m10:39:03.613080 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:39:03.614079 [info ] [Thread-1 (]: 4 of 4 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m10:39:03.614984 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal.98aec1b901, now test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214)
[0m10:39:03.615994 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:39:03.623990 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:39:03.627141 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 10:39:03.615994 => 10:39:03.626141
[0m10:39:03.628138 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:39:03.632141 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:39:03.635142 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:39:03.635142 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m10:39:03.636295 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:39:04.024899 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:39:04.024899 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:39:04.027215 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m10:39:04.097328 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:39:04.099361 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 10:39:03.628138 => 10:39:04.098329
[0m10:39:04.099361 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m10:39:04.150113 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m10:39:04.151114 [info ] [Thread-1 (]: 4 of 4 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.54s]
[0m10:39:04.152122 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:39:04.154624 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:04.155631 [debug] [MainThread]: On master: BEGIN
[0m10:39:04.156632 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:39:04.557307 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:39:04.558306 [debug] [MainThread]: On master: COMMIT
[0m10:39:04.559308 [debug] [MainThread]: Using postgres connection "master"
[0m10:39:04.559308 [debug] [MainThread]: On master: COMMIT
[0m10:39:04.597642 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:39:04.598640 [debug] [MainThread]: On master: Close
[0m10:39:04.599641 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:39:04.599641 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m10:39:04.600793 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214' was properly closed.
[0m10:39:04.600793 [info ] [MainThread]: 
[0m10:39:04.601640 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 4.61 seconds (4.61s).
[0m10:39:04.603643 [debug] [MainThread]: Command end result
[0m10:39:04.621695 [info ] [MainThread]: 
[0m10:39:04.622695 [info ] [MainThread]: [31mCompleted with 1 error and 1 warning:[0m
[0m10:39:04.622695 [info ] [MainThread]: 
[0m10:39:04.624696 [error] [MainThread]: [31mFailure in test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__decimal (dbtlearn/models\schema.yml)[0m
[0m10:39:04.624696 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:39:04.627201 [info ] [MainThread]: 
[0m10:39:04.628198 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_204798d13356cebe5408f07fc173b99a.sql
[0m10:39:04.629200 [info ] [MainThread]: 
[0m10:39:04.630199 [warn ] [MainThread]: [33mWarning in test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000 (dbtlearn/models\schema.yml)[0m
[0m10:39:04.631201 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m10:39:04.632202 [info ] [MainThread]: 
[0m10:39:04.632202 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_468e4de3f229fa6ad450d64ec382bdcb.sql
[0m10:39:04.634710 [info ] [MainThread]: 
[0m10:39:04.634710 [info ] [MainThread]: Done. PASS=2 WARN=1 ERROR=1 SKIP=0 TOTAL=4
[0m10:39:04.636717 [debug] [MainThread]: Command `dbt test` failed at 10:39:04.636717 after 5.63 seconds
[0m10:39:04.637723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87C7A1510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E874FE1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E87C36B6D0>]}
[0m10:39:04.638724 [debug] [MainThread]: Flushing usage events
[0m10:42:56.947461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35A9F0450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35A9CE990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35A582490>]}


============================== 10:42:56.951467 | a72153ef-e473-4169-8890-160996b8334f ==============================
[0m10:42:56.951467 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:42:56.951467 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt test --select dim_listings_with_hosts', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:42:57.160676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a72153ef-e473-4169-8890-160996b8334f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35AA394D0>]}
[0m10:42:57.237876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a72153ef-e473-4169-8890-160996b8334f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35A5EE510>]}
[0m10:42:57.239572 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:42:57.262210 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:42:57.499557 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:42:57.500557 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m10:42:57.805944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a72153ef-e473-4169-8890-160996b8334f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35C207B90>]}
[0m10:42:57.825528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a72153ef-e473-4169-8890-160996b8334f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35BE67750>]}
[0m10:42:57.826281 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 16 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:42:57.826740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a72153ef-e473-4169-8890-160996b8334f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35BF05490>]}
[0m10:42:57.828780 [info ] [MainThread]: 
[0m10:42:57.829749 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:42:57.831746 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m10:42:57.842760 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:42:57.843769 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m10:42:57.844772 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:42:58.166409 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:42:58.167574 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:42:58.167574 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m10:42:58.220124 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m10:42:58.222131 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m10:42:58.262536 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m10:42:58.270670 [debug] [MainThread]: Using postgres connection "master"
[0m10:42:58.270670 [debug] [MainThread]: On master: BEGIN
[0m10:42:58.271643 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:42:58.472339 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:42:58.473646 [debug] [MainThread]: Using postgres connection "master"
[0m10:42:58.473646 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:42:58.537191 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m10:42:58.539191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a72153ef-e473-4169-8890-160996b8334f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35C016B90>]}
[0m10:42:58.540190 [debug] [MainThread]: On master: ROLLBACK
[0m10:42:58.570575 [debug] [MainThread]: Using postgres connection "master"
[0m10:42:58.571128 [debug] [MainThread]: On master: BEGIN
[0m10:42:58.632837 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:42:58.633417 [debug] [MainThread]: On master: COMMIT
[0m10:42:58.633934 [debug] [MainThread]: Using postgres connection "master"
[0m10:42:58.634450 [debug] [MainThread]: On master: COMMIT
[0m10:42:58.672385 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:42:58.673636 [debug] [MainThread]: On master: Close
[0m10:42:58.674642 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:42:58.675834 [info ] [MainThread]: 
[0m10:42:58.681367 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:42:58.681890 [info ] [Thread-1 (]: 1 of 4 START test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [RUN]
[0m10:42:58.683471 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba'
[0m10:42:58.684546 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:42:58.695190 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:42:58.698190 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (compile): 10:42:58.685069 => 10:42:58.697192
[0m10:42:58.699206 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:42:58.715209 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:42:58.717209 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:42:58.718211 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: BEGIN
[0m10:42:58.718211 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:42:58.921005 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:42:58.922011 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:42:58.923018 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  
( 1=1 and max(price) <= 5000
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:42:58.980658 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:42:58.983049 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (execute): 10:42:58.700190 => 10:42:58.983049
[0m10:42:58.984093 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: ROLLBACK
[0m10:42:59.014796 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: Close
[0m10:42:59.015762 [warn ] [Thread-1 (]: 1 of 4 WARN 1 dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [[33mWARN 1[0m in 0.33s]
[0m10:42:59.016639 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:42:59.017674 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:42:59.018645 [info ] [Thread-1 (]: 2 of 4 START test dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [RUN]
[0m10:42:59.019645 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba, now test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b)
[0m10:42:59.019645 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:42:59.025242 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:42:59.027227 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (compile): 10:42:59.020673 => 10:42:59.026240
[0m10:42:59.027227 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:42:59.030242 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:42:59.032215 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:42:59.033215 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: BEGIN
[0m10:42:59.034413 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:42:59.238225 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:42:59.239221 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:42:59.240222 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      





    with grouped_expression as (
    select
        
        
    
  
( 1=1 and percentile_cont(0.99) within group (order by price) >= 50 and percentile_cont(0.99) within group (order by price) <= 500
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:42:59.308354 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:42:59.310350 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (execute): 10:42:59.028244 => 10:42:59.310350
[0m10:42:59.311356 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: ROLLBACK
[0m10:42:59.344489 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: Close
[0m10:42:59.345524 [info ] [Thread-1 (]: 2 of 4 PASS dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [[32mPASS[0m in 0.33s]
[0m10:42:59.346489 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:42:59.347489 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904
[0m10:42:59.347489 [info ] [Thread-1 (]: 3 of 4 START test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer  [RUN]
[0m10:42:59.348491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b, now test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904)
[0m10:42:59.349523 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904
[0m10:42:59.359071 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904"
[0m10:42:59.360070 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904: BEGIN
[0m10:42:59.361069 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:42:59.564131 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:42:59.564131 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904"
[0m10:42:59.565128 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_with_hosts'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m10:42:59.629956 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m10:42:59.643027 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904"
[0m10:42:59.645034 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904 (compile): 10:42:59.349523 => 10:42:59.645034
[0m10:42:59.646034 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904
[0m10:42:59.649066 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904"
[0m10:42:59.651034 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904"
[0m10:42:59.651034 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      with relation_columns as (

        
        select
            cast('ID_LISTINGS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('LISTING_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('ROOM_TYPE' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('MINIMUM_NIGHTS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('PRICE' as TEXT) as relation_column,
            cast('NUMERIC' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_ID' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_IS_SUPERHOST' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('CREATED_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        union all
        
        select
            cast('UPDATE_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        
        
    ),
    test_data as (

        select
            *
        from
            relation_columns
        where
            relation_column = 'PRICE'
            and
            relation_column_type not in ('INTEGER')

    )
    select *
    from test_data
      
    ) dbt_internal_test
[0m10:42:59.683381 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:42:59.685424 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904 (execute): 10:42:59.646034 => 10:42:59.684401
[0m10:42:59.685424 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904: ROLLBACK
[0m10:42:59.716395 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904: Close
[0m10:42:59.717403 [error] [Thread-1 (]: 3 of 4 FAIL 1 dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer  [[31mFAIL 1[0m in 0.37s]
[0m10:42:59.718401 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904
[0m10:42:59.719435 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:42:59.720437 [info ] [Thread-1 (]: 4 of 4 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m10:42:59.721415 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer.a206e79904, now test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214)
[0m10:42:59.721415 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:42:59.727930 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:42:59.729938 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 10:42:59.722920 => 10:42:59.728931
[0m10:42:59.730933 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:42:59.735418 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:42:59.738411 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:42:59.738411 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m10:42:59.740408 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:42:59.964710 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:42:59.965712 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:42:59.965712 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m10:43:00.031642 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:43:00.033147 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 10:42:59.730933 => 10:43:00.031642
[0m10:43:00.034152 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m10:43:00.069746 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m10:43:00.070757 [info ] [Thread-1 (]: 4 of 4 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.35s]
[0m10:43:00.071895 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:00.074941 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:00.074941 [debug] [MainThread]: On master: BEGIN
[0m10:43:00.076449 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:43:00.313266 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:43:00.313266 [debug] [MainThread]: On master: COMMIT
[0m10:43:00.314567 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:00.315598 [debug] [MainThread]: On master: COMMIT
[0m10:43:00.356402 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:43:00.357440 [debug] [MainThread]: On master: Close
[0m10:43:00.358440 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:43:00.358440 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m10:43:00.359402 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214' was properly closed.
[0m10:43:00.359402 [info ] [MainThread]: 
[0m10:43:00.360401 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 2.53 seconds (2.53s).
[0m10:43:00.362326 [debug] [MainThread]: Command end result
[0m10:43:00.380415 [info ] [MainThread]: 
[0m10:43:00.381417 [info ] [MainThread]: [31mCompleted with 1 error and 1 warning:[0m
[0m10:43:00.381417 [info ] [MainThread]: 
[0m10:43:00.383943 [error] [MainThread]: [31mFailure in test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__integer (dbtlearn/models\schema.yml)[0m
[0m10:43:00.384936 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:43:00.386946 [info ] [MainThread]: 
[0m10:43:00.387966 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_bed4c6fd0b2e3f29034a921fd639b16c.sql
[0m10:43:00.388935 [info ] [MainThread]: 
[0m10:43:00.389940 [warn ] [MainThread]: [33mWarning in test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000 (dbtlearn/models\schema.yml)[0m
[0m10:43:00.390933 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m10:43:00.391932 [info ] [MainThread]: 
[0m10:43:00.392933 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_468e4de3f229fa6ad450d64ec382bdcb.sql
[0m10:43:00.394482 [info ] [MainThread]: 
[0m10:43:00.394482 [info ] [MainThread]: Done. PASS=2 WARN=1 ERROR=1 SKIP=0 TOTAL=4
[0m10:43:00.396480 [debug] [MainThread]: Command `dbt test` failed at 10:43:00.396480 after 3.51 seconds
[0m10:43:00.397480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F353231090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F35351FE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F3532768D0>]}
[0m10:43:00.397480 [debug] [MainThread]: Flushing usage events
[0m10:43:16.231966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186871B1310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018687252DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001868725BC90>]}


============================== 10:43:16.235111 | 386cbe96-c254-4a4f-892b-053ecec6d41b ==============================
[0m10:43:16.235111 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:43:16.236614 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test --select dim_listings_with_hosts', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:43:16.448380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '386cbe96-c254-4a4f-892b-053ecec6d41b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186879E8F50>]}
[0m10:43:16.525635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '386cbe96-c254-4a4f-892b-053ecec6d41b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018686BA6290>]}
[0m10:43:16.527033 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:43:16.551660 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:43:16.775106 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:43:16.777140 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m10:43:17.081996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '386cbe96-c254-4a4f-892b-053ecec6d41b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186891D7B90>]}
[0m10:43:17.102033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '386cbe96-c254-4a4f-892b-053ecec6d41b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018687E4C510>]}
[0m10:43:17.102033 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 16 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:43:17.103215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '386cbe96-c254-4a4f-892b-053ecec6d41b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018687EDFCD0>]}
[0m10:43:17.105225 [info ] [MainThread]: 
[0m10:43:17.106225 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:43:17.109563 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m10:43:17.119080 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:43:17.120080 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m10:43:17.121092 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:43:18.444549 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m10:43:18.444549 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:43:18.445556 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m10:43:18.500589 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m10:43:18.501620 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m10:43:18.537358 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m10:43:18.545321 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:18.546355 [debug] [MainThread]: On master: BEGIN
[0m10:43:18.547339 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:43:18.779789 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:43:18.780592 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:18.781599 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:43:18.846794 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m10:43:18.848759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '386cbe96-c254-4a4f-892b-053ecec6d41b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186890B1710>]}
[0m10:43:18.849757 [debug] [MainThread]: On master: ROLLBACK
[0m10:43:18.893060 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:18.894487 [debug] [MainThread]: On master: BEGIN
[0m10:43:18.962900 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:43:18.963446 [debug] [MainThread]: On master: COMMIT
[0m10:43:18.964457 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:18.964457 [debug] [MainThread]: On master: COMMIT
[0m10:43:19.003505 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:43:19.003505 [debug] [MainThread]: On master: Close
[0m10:43:19.005755 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:43:19.006755 [info ] [MainThread]: 
[0m10:43:19.010000 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:43:19.010998 [info ] [Thread-1 (]: 1 of 4 START test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [RUN]
[0m10:43:19.012001 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba'
[0m10:43:19.013001 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:43:19.024057 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:43:19.027055 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (compile): 10:43:19.013505 => 10:43:19.026062
[0m10:43:19.028057 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:43:19.044844 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:43:19.047378 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:43:19.047378 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: BEGIN
[0m10:43:19.048380 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:43:19.254566 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:43:19.255568 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:43:19.255568 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  
( 1=1 and max(price) <= 5000
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:43:19.314884 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:43:19.316829 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (execute): 10:43:19.028057 => 10:43:19.316829
[0m10:43:19.317828 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: ROLLBACK
[0m10:43:19.350216 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: Close
[0m10:43:19.351722 [warn ] [Thread-1 (]: 1 of 4 WARN 1 dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [[33mWARN 1[0m in 0.34s]
[0m10:43:19.353218 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:43:19.353218 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:43:19.354236 [info ] [Thread-1 (]: 2 of 4 START test dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [RUN]
[0m10:43:19.355226 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba, now test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b)
[0m10:43:19.356224 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:43:19.361224 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:43:19.363225 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (compile): 10:43:19.356224 => 10:43:19.363225
[0m10:43:19.364326 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:43:19.368328 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:43:19.370324 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:43:19.371328 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: BEGIN
[0m10:43:19.373342 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:43:19.572410 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:43:19.572954 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:43:19.573962 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      





    with grouped_expression as (
    select
        
        
    
  
( 1=1 and percentile_cont(0.99) within group (order by price) >= 50 and percentile_cont(0.99) within group (order by price) <= 500
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:43:19.644073 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:43:19.646323 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (execute): 10:43:19.364326 => 10:43:19.646323
[0m10:43:19.646323 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: ROLLBACK
[0m10:43:19.677586 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: Close
[0m10:43:19.679581 [info ] [Thread-1 (]: 2 of 4 PASS dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [[32mPASS[0m in 0.32s]
[0m10:43:19.680548 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:43:19.681548 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8
[0m10:43:19.681548 [info ] [Thread-1 (]: 3 of 4 START test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number  [RUN]
[0m10:43:19.683054 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b, now test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8)
[0m10:43:19.684059 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8
[0m10:43:19.694580 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:43:19.695584 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: BEGIN
[0m10:43:19.696585 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:43:19.903037 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:43:19.904124 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:43:19.905096 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'dim_listings_with_hosts'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m10:43:19.969653 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m10:43:19.984462 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:43:19.986463 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8 (compile): 10:43:19.684059 => 10:43:19.986463
[0m10:43:19.987477 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8
[0m10:43:19.989462 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:43:19.991462 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"
[0m10:43:19.991462 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      with relation_columns as (

        
        select
            cast('ID_LISTINGS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('LISTING_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('ROOM_TYPE' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('MINIMUM_NIGHTS' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('PRICE' as TEXT) as relation_column,
            cast('NUMERIC' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_ID' as TEXT) as relation_column,
            cast('INTEGER' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_NAME' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('HOST_IS_SUPERHOST' as TEXT) as relation_column,
            cast('TEXT' as TEXT) as relation_column_type
        union all
        
        select
            cast('CREATED_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        union all
        
        select
            cast('UPDATE_AT' as TEXT) as relation_column,
            cast('TIMESTAMP WITHOUT TIME ZONE' as TEXT) as relation_column_type
        
        
    ),
    test_data as (

        select
            *
        from
            relation_columns
        where
            relation_column = 'PRICE'
            and
            relation_column_type not in ('NUMBER')

    )
    select *
    from test_data
      
    ) dbt_internal_test
[0m10:43:20.035014 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:43:20.036014 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8 (execute): 10:43:19.987477 => 10:43:20.036014
[0m10:43:20.037013 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: ROLLBACK
[0m10:43:20.067947 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8: Close
[0m10:43:20.068950 [error] [Thread-1 (]: 3 of 4 FAIL 1 dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number  [[31mFAIL 1[0m in 0.39s]
[0m10:43:20.070949 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8
[0m10:43:20.070949 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:20.071966 [info ] [Thread-1 (]: 4 of 4 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m10:43:20.074464 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number.fd59f68aa8, now test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214)
[0m10:43:20.075463 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:20.082999 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:43:20.085006 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 10:43:20.076463 => 10:43:20.084006
[0m10:43:20.086005 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:20.089007 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:43:20.091008 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:43:20.092014 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m10:43:20.093539 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:43:20.305037 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:43:20.305037 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:43:20.306034 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m10:43:20.369441 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:43:20.371470 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 10:43:20.086005 => 10:43:20.371470
[0m10:43:20.371470 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m10:43:20.404036 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m10:43:20.406070 [info ] [Thread-1 (]: 4 of 4 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.33s]
[0m10:43:20.407037 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:20.409072 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:20.409072 [debug] [MainThread]: On master: BEGIN
[0m10:43:20.410070 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:43:20.654124 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:43:20.655128 [debug] [MainThread]: On master: COMMIT
[0m10:43:20.655128 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:20.656343 [debug] [MainThread]: On master: COMMIT
[0m10:43:20.697295 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:43:20.698345 [debug] [MainThread]: On master: Close
[0m10:43:20.699302 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:43:20.699302 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m10:43:20.700335 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214' was properly closed.
[0m10:43:20.700335 [info ] [MainThread]: 
[0m10:43:20.701334 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 3.59 seconds (3.59s).
[0m10:43:20.702842 [debug] [MainThread]: Command end result
[0m10:43:20.719364 [info ] [MainThread]: 
[0m10:43:20.720393 [info ] [MainThread]: [31mCompleted with 1 error and 1 warning:[0m
[0m10:43:20.722858 [info ] [MainThread]: 
[0m10:43:20.723867 [error] [MainThread]: [31mFailure in test dbt_expectations_expect_column_values_to_be_of_type_dim_listings_with_hosts_price__number (dbtlearn/models\schema.yml)[0m
[0m10:43:20.725877 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:43:20.726867 [info ] [MainThread]: 
[0m10:43:20.727868 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_195c26ad485e7df4f2484c541ab30c07.sql
[0m10:43:20.729893 [info ] [MainThread]: 
[0m10:43:20.731906 [warn ] [MainThread]: [33mWarning in test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000 (dbtlearn/models\schema.yml)[0m
[0m10:43:20.732892 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m10:43:20.735257 [info ] [MainThread]: 
[0m10:43:20.737235 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_468e4de3f229fa6ad450d64ec382bdcb.sql
[0m10:43:20.738234 [info ] [MainThread]: 
[0m10:43:20.739295 [info ] [MainThread]: Done. PASS=2 WARN=1 ERROR=1 SKIP=0 TOTAL=4
[0m10:43:20.741234 [debug] [MainThread]: Command `dbt test` failed at 10:43:20.741234 after 4.58 seconds
[0m10:43:20.743235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018687991550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018680221090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018687252DD0>]}
[0m10:43:20.743742 [debug] [MainThread]: Flushing usage events
[0m10:43:33.944720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D435487D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D41FBC910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D43221010>]}


============================== 10:43:33.950018 | 4471bd9b-7d99-43bb-b1b5-1a4c6d20f358 ==============================
[0m10:43:33.950018 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:43:33.951016 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt test --select dim_listings_with_hosts', 'send_anonymous_usage_stats': 'True'}
[0m10:43:34.177473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4471bd9b-7d99-43bb-b1b5-1a4c6d20f358', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D43A61D50>]}
[0m10:43:34.262631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4471bd9b-7d99-43bb-b1b5-1a4c6d20f358', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D43B33C50>]}
[0m10:43:34.263637 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:43:34.291880 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:43:34.542711 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:43:34.544717 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m10:43:34.860365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4471bd9b-7d99-43bb-b1b5-1a4c6d20f358', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D451E3010>]}
[0m10:43:34.881051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4471bd9b-7d99-43bb-b1b5-1a4c6d20f358', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D43EC7950>]}
[0m10:43:34.882051 [info ] [MainThread]: Found 8 models, 1 snapshot, 1 analysis, 15 tests, 1 seed, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:43:34.883050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4471bd9b-7d99-43bb-b1b5-1a4c6d20f358', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D43CEB090>]}
[0m10:43:34.884264 [info ] [MainThread]: 
[0m10:43:34.886263 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:43:34.887652 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m10:43:34.899914 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:43:34.901911 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m10:43:34.902915 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:43:35.193222 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:43:35.194225 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:43:35.194225 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m10:43:35.244080 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m10:43:35.246084 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m10:43:35.278175 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m10:43:35.285796 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:35.286800 [debug] [MainThread]: On master: BEGIN
[0m10:43:35.287765 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:43:35.506922 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:43:35.507929 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:35.507929 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:43:35.578403 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m10:43:35.580982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4471bd9b-7d99-43bb-b1b5-1a4c6d20f358', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D451F7490>]}
[0m10:43:35.581984 [debug] [MainThread]: On master: ROLLBACK
[0m10:43:35.615937 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:35.615937 [debug] [MainThread]: On master: BEGIN
[0m10:43:35.687076 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:43:35.689082 [debug] [MainThread]: On master: COMMIT
[0m10:43:35.690123 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:35.690123 [debug] [MainThread]: On master: COMMIT
[0m10:43:35.728492 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:43:35.729489 [debug] [MainThread]: On master: Close
[0m10:43:35.730500 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:43:35.731155 [info ] [MainThread]: 
[0m10:43:35.735670 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:43:35.735670 [info ] [Thread-1 (]: 1 of 3 START test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [RUN]
[0m10:43:35.737679 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba'
[0m10:43:35.738672 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:43:35.750196 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:43:35.752710 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (compile): 10:43:35.738672 => 10:43:35.751199
[0m10:43:35.753730 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:43:35.771296 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:43:35.774980 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:43:35.775989 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: BEGIN
[0m10:43:35.777216 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:43:36.014249 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:43:36.014777 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"
[0m10:43:36.015858 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  
( 1=1 and max(price) <= 5000
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:43:36.073804 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:43:36.076806 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba (execute): 10:43:35.754718 => 10:43:36.076806
[0m10:43:36.077802 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: ROLLBACK
[0m10:43:36.116369 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba: Close
[0m10:43:36.117370 [warn ] [Thread-1 (]: 1 of 3 WARN 1 dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000  [[33mWARN 1[0m in 0.38s]
[0m10:43:36.119370 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba
[0m10:43:36.119370 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:43:36.120399 [info ] [Thread-1 (]: 2 of 3 START test dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [RUN]
[0m10:43:36.121371 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000.3f951930ba, now test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b)
[0m10:43:36.121371 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:43:36.128921 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:43:36.130917 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (compile): 10:43:36.121371 => 10:43:36.129915
[0m10:43:36.130917 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:43:36.135428 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:43:36.137427 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:43:36.138427 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: BEGIN
[0m10:43:36.138427 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:43:36.372990 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:43:36.372990 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"
[0m10:43:36.374007 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      





    with grouped_expression as (
    select
        
        
    
  
( 1=1 and percentile_cont(0.99) within group (order by price) >= 50 and percentile_cont(0.99) within group (order by price) <= 500
)
 as expression


    from "inttegra_stage"."test"."dim_listings_with_hosts"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors






      
    ) dbt_internal_test
[0m10:43:36.448989 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:43:36.450999 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b (execute): 10:43:36.131916 => 10:43:36.450999
[0m10:43:36.451999 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: ROLLBACK
[0m10:43:36.486208 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b: Close
[0m10:43:36.488293 [info ] [Thread-1 (]: 2 of 3 PASS dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99  [[32mPASS[0m in 0.37s]
[0m10:43:36.489291 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b
[0m10:43:36.490812 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:36.491824 [info ] [Thread-1 (]: 3 of 3 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m10:43:36.494062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_column_quantile_values_to_be_between_dim_listings_with_hosts_price__500__50__0_99.2ef2227c8b, now test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214)
[0m10:43:36.496063 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:36.505596 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:43:36.506601 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 10:43:36.496063 => 10:43:36.506601
[0m10:43:36.507601 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:36.513122 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:43:36.515133 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:43:36.515133 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m10:43:36.516134 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:43:36.744243 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:43:36.745236 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:43:36.746236 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m10:43:36.814158 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:43:36.816157 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 10:43:36.508599 => 10:43:36.816157
[0m10:43:36.817155 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m10:43:36.847697 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m10:43:36.848703 [info ] [Thread-1 (]: 3 of 3 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.36s]
[0m10:43:36.849703 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:43:36.851703 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:36.851703 [debug] [MainThread]: On master: BEGIN
[0m10:43:36.852703 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:43:37.059954 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:43:37.059954 [debug] [MainThread]: On master: COMMIT
[0m10:43:37.060993 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:37.061963 [debug] [MainThread]: On master: COMMIT
[0m10:43:37.096383 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:43:37.097340 [debug] [MainThread]: On master: Close
[0m10:43:37.098339 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:43:37.098339 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m10:43:37.099339 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214' was properly closed.
[0m10:43:37.099339 [info ] [MainThread]: 
[0m10:43:37.100202 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 2.21 seconds (2.21s).
[0m10:43:37.101225 [debug] [MainThread]: Command end result
[0m10:43:37.118289 [info ] [MainThread]: 
[0m10:43:37.119289 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m10:43:37.120292 [info ] [MainThread]: 
[0m10:43:37.121289 [warn ] [MainThread]: [33mWarning in test dbt_expectations_expect_column_max_to_be_between_dim_listings_with_hosts_price__5000 (dbtlearn/models\schema.yml)[0m
[0m10:43:37.123810 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m10:43:37.126822 [info ] [MainThread]: 
[0m10:43:37.128822 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\schema.yml\dbt_expectations_expect_column_468e4de3f229fa6ad450d64ec382bdcb.sql
[0m10:43:37.129821 [info ] [MainThread]: 
[0m10:43:37.131916 [info ] [MainThread]: Done. PASS=2 WARN=1 ERROR=0 SKIP=0 TOTAL=3
[0m10:43:37.134404 [debug] [MainThread]: Command `dbt test` succeeded at 10:43:37.134404 after 3.26 seconds
[0m10:43:37.135415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D43516F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D3C261090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012D435A5690>]}
[0m10:43:37.136450 [debug] [MainThread]: Flushing usage events
[0m10:58:41.346125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028154801410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002815487E110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281547E8150>]}


============================== 10:58:41.350633 | 8a97b6fc-6c2d-4b34-b291-6bbf8d01f9ef ==============================
[0m10:58:41.350633 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:58:41.351639 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt test --select dbt_expectations.expect_column_distinct_count_to_equal', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:58:41.575926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8a97b6fc-6c2d-4b34-b291-6bbf8d01f9ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028154802050>]}
[0m10:58:41.657310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8a97b6fc-6c2d-4b34-b291-6bbf8d01f9ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281550CE310>]}
[0m10:58:41.659889 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:58:41.687134 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:58:41.952494 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:58:41.953493 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m10:58:42.835951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8a97b6fc-6c2d-4b34-b291-6bbf8d01f9ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028156B5BBD0>]}
[0m10:58:42.860587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8a97b6fc-6c2d-4b34-b291-6bbf8d01f9ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028155476450>]}
[0m10:58:42.861627 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:58:42.862593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a97b6fc-6c2d-4b34-b291-6bbf8d01f9ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028154AD6A10>]}
[0m10:58:42.863614 [warn ] [MainThread]: The selection criterion 'dbt_expectations.expect_column_distinct_count_to_equal' does not match any nodes
[0m10:58:42.867164 [info ] [MainThread]: 
[0m10:58:42.868127 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:58:42.869131 [debug] [MainThread]: Command end result
[0m10:58:42.958022 [debug] [MainThread]: Command `dbt test` succeeded at 10:58:42.958022 after 1.68 seconds
[0m10:58:42.959055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002814D8D1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028154BCE150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002814DB79ED0>]}
[0m10:58:42.959055 [debug] [MainThread]: Flushing usage events
[0m10:59:11.913472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215FA164C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F9DB2550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215FA1F2250>]}


============================== 10:59:11.917985 | 554e5d6e-87e4-49cf-be6f-067192f594d8 ==============================
[0m10:59:11.917985 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:59:11.918990 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt test --select listings', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:59:12.146058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '554e5d6e-87e4-49cf-be6f-067192f594d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215FA85F8D0>]}
[0m10:59:12.228777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '554e5d6e-87e4-49cf-be6f-067192f594d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215FA7A0650>]}
[0m10:59:12.230811 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:59:12.259746 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:59:12.499694 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:59:12.499694 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:59:12.506766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '554e5d6e-87e4-49cf-be6f-067192f594d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215FBB5C4D0>]}
[0m10:59:12.531293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '554e5d6e-87e4-49cf-be6f-067192f594d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215FB97BDD0>]}
[0m10:59:12.532297 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:59:12.533329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '554e5d6e-87e4-49cf-be6f-067192f594d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215FA90BF10>]}
[0m10:59:12.534835 [warn ] [MainThread]: The selection criterion 'listings' does not match any nodes
[0m10:59:12.535840 [info ] [MainThread]: 
[0m10:59:12.536840 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m10:59:12.537839 [debug] [MainThread]: Command end result
[0m10:59:12.554953 [debug] [MainThread]: Command `dbt test` succeeded at 10:59:12.553377 after 0.70 seconds
[0m10:59:12.555997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F2F81050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F9E46AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215F31F4450>]}
[0m10:59:12.556996 [debug] [MainThread]: Flushing usage events
[0m10:59:56.787745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB419C2250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB41A62C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4218DD10>]}


============================== 10:59:56.792253 | b6211760-24df-409b-b1fe-3c2d5b35ce11 ==============================
[0m10:59:56.792253 [info ] [MainThread]: Running with dbt=1.7.3
[0m10:59:56.793254 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --select source:airbnb.listings', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:59:57.016697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b6211760-24df-409b-b1fe-3c2d5b35ce11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB41CE9DD0>]}
[0m10:59:57.108673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b6211760-24df-409b-b1fe-3c2d5b35ce11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB421F8E10>]}
[0m10:59:57.109674 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m10:59:57.136931 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m10:59:57.365594 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:59:57.366593 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:59:57.373775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b6211760-24df-409b-b1fe-3c2d5b35ce11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB43637550>]}
[0m10:59:57.396840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b6211760-24df-409b-b1fe-3c2d5b35ce11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB434D3DD0>]}
[0m10:59:57.397842 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m10:59:57.398850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b6211760-24df-409b-b1fe-3c2d5b35ce11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4245FB10>]}
[0m10:59:57.401382 [info ] [MainThread]: 
[0m10:59:57.403363 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:59:57.405883 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m10:59:57.416917 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:59:57.417920 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m10:59:57.418920 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:59:58.746837 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m10:59:58.747841 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m10:59:58.747841 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m10:59:58.793863 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m10:59:58.795899 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m10:59:58.826972 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m10:59:58.835090 [debug] [MainThread]: Using postgres connection "master"
[0m10:59:58.836097 [debug] [MainThread]: On master: BEGIN
[0m10:59:58.837097 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:59:59.045662 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:59:59.046624 [debug] [MainThread]: Using postgres connection "master"
[0m10:59:59.046624 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:59:59.105201 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m10:59:59.107243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b6211760-24df-409b-b1fe-3c2d5b35ce11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4231EED0>]}
[0m10:59:59.107243 [debug] [MainThread]: On master: ROLLBACK
[0m10:59:59.139196 [debug] [MainThread]: Using postgres connection "master"
[0m10:59:59.140742 [debug] [MainThread]: On master: BEGIN
[0m10:59:59.201768 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:59:59.202774 [debug] [MainThread]: On master: COMMIT
[0m10:59:59.203768 [debug] [MainThread]: Using postgres connection "master"
[0m10:59:59.203768 [debug] [MainThread]: On master: COMMIT
[0m10:59:59.231043 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:59:59.232050 [debug] [MainThread]: On master: Close
[0m10:59:59.233053 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:59:59.234061 [info ] [MainThread]: 
[0m10:59:59.239055 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:59:59.240566 [info ] [Thread-1 (]: 1 of 3 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m10:59:59.243575 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m10:59:59.245084 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:59:59.288954 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:59:59.291473 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 10:59:59.246093 => 10:59:59.290465
[0m10:59:59.292472 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:59:59.309018 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:59:59.313536 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:59:59.313536 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m10:59:59.315046 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:59:59.510501 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:59:59.511510 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m10:59:59.512507 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m10:59:59.578071 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:59:59.581598 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 10:59:59.292472 => 10:59:59.580586
[0m10:59:59.581598 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m10:59:59.613261 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m10:59:59.615785 [info ] [Thread-1 (]: 1 of 3 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.37s]
[0m10:59:59.616792 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m10:59:59.617784 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m10:59:59.618787 [info ] [Thread-1 (]: 2 of 3 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m10:59:59.619783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m10:59:59.620783 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m10:59:59.634967 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m10:59:59.637974 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 10:59:59.620783 => 10:59:59.637974
[0m10:59:59.638974 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m10:59:59.642488 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m10:59:59.646004 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m10:59:59.647004 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m10:59:59.648003 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:59:59.869628 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:59:59.871131 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m10:59:59.872144 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m10:59:59.942212 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:59:59.944721 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 10:59:59.638974 => 10:59:59.944721
[0m10:59:59.945727 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m10:59:59.977037 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m10:59:59.978035 [info ] [Thread-1 (]: 2 of 3 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.36s]
[0m10:59:59.979035 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m10:59:59.979035 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m10:59:59.980541 [info ] [Thread-1 (]: 3 of 3 START test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [RUN]
[0m10:59:59.981546 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65, now test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9)
[0m10:59:59.982548 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m10:59:59.997696 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:00:00.000692 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9 (compile): 10:59:59.982548 => 10:59:59.999727
[0m11:00:00.001946 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:00:00.007003 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:00:00.010507 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:00:00.011522 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: BEGIN
[0m11:00:00.011522 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:00:00.236970 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:00:00.237969 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:00:00.237969 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  


    

coalesce(array_length((select regexp_matches(price, '^\\$[0-9][0-9\\.]+$', '')), 1), 0)


 > 0
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors





      
    ) dbt_internal_test
[0m11:00:00.329190 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:00:00.331876 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9 (execute): 11:00:00.002954 => 11:00:00.331322
[0m11:00:00.332937 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: ROLLBACK
[0m11:00:00.365048 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: Close
[0m11:00:00.366049 [error] [Thread-1 (]: 3 of 3 FAIL 17499 dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [[31mFAIL 17499[0m in 0.38s]
[0m11:00:00.368556 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:00:00.370695 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:00.371763 [debug] [MainThread]: On master: BEGIN
[0m11:00:00.371763 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:00:00.584642 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:00:00.585655 [debug] [MainThread]: On master: COMMIT
[0m11:00:00.586657 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:00.587660 [debug] [MainThread]: On master: COMMIT
[0m11:00:00.625673 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:00:00.626679 [debug] [MainThread]: On master: Close
[0m11:00:00.628646 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:00:00.629655 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:00:00.632222 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9' was properly closed.
[0m11:00:00.633250 [info ] [MainThread]: 
[0m11:00:00.634766 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 3.23 seconds (3.23s).
[0m11:00:00.637774 [debug] [MainThread]: Command end result
[0m11:00:00.659625 [info ] [MainThread]: 
[0m11:00:00.661129 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:00:00.662138 [info ] [MainThread]: 
[0m11:00:00.664677 [error] [MainThread]: [31mFailure in test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_ (dbtlearn/models\sources.yml)[0m
[0m11:00:00.666687 [error] [MainThread]:   Got 17499 results, configured to fail if != 0
[0m11:00:00.667692 [info ] [MainThread]: 
[0m11:00:00.668689 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\sources.yml\dbt_expectations_source_expect_a60b59a84fbc4577a11df360c50013bb.sql
[0m11:00:00.670699 [info ] [MainThread]: 
[0m11:00:00.673219 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m11:00:00.675792 [debug] [MainThread]: Command `dbt test` failed at 11:00:00.675792 after 3.95 seconds
[0m11:00:00.676760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB3A9E1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB41A94350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB41DA7F10>]}
[0m11:00:00.678782 [debug] [MainThread]: Flushing usage events
[0m11:00:30.982787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D3B6BD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D21C5490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D378E790>]}


============================== 11:00:30.987003 | acd5562b-939e-432e-bb91-4556400f9b6a ==============================
[0m11:00:30.987003 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:00:30.988615 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt test --select source:airbnb.listings', 'send_anonymous_usage_stats': 'True'}
[0m11:00:31.240392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'acd5562b-939e-432e-bb91-4556400f9b6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D3D225D0>]}
[0m11:00:31.321097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'acd5562b-939e-432e-bb91-4556400f9b6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D33934D0>]}
[0m11:00:31.322915 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:00:31.345712 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:00:31.644388 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:00:31.646525 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m11:00:32.828533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'acd5562b-939e-432e-bb91-4556400f9b6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D5828FD0>]}
[0m11:00:32.869505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'acd5562b-939e-432e-bb91-4556400f9b6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D4034B90>]}
[0m11:00:32.870501 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 16 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m11:00:32.871935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'acd5562b-939e-432e-bb91-4556400f9b6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D40D1F90>]}
[0m11:00:32.875532 [info ] [MainThread]: 
[0m11:00:32.876535 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:00:32.881063 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m11:00:32.898878 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:00:32.902406 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m11:00:32.903405 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:00:34.213379 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m11:00:34.214925 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:00:34.214925 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m11:00:34.262399 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m11:00:34.263398 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m11:00:34.293050 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m11:00:34.303076 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:34.305596 [debug] [MainThread]: On master: BEGIN
[0m11:00:34.305596 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:00:34.564394 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:00:34.565892 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:34.566893 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:00:34.631200 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m11:00:34.635733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'acd5562b-939e-432e-bb91-4556400f9b6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D4016B90>]}
[0m11:00:34.636733 [debug] [MainThread]: On master: ROLLBACK
[0m11:00:34.667847 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:34.668850 [debug] [MainThread]: On master: BEGIN
[0m11:00:34.758651 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:00:34.759607 [debug] [MainThread]: On master: COMMIT
[0m11:00:34.760609 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:34.761115 [debug] [MainThread]: On master: COMMIT
[0m11:00:34.789547 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:00:34.790547 [debug] [MainThread]: On master: Close
[0m11:00:34.791051 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:00:34.793057 [info ] [MainThread]: 
[0m11:00:34.797574 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:00:34.797574 [info ] [Thread-1 (]: 1 of 2 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m11:00:34.799577 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m11:00:34.800596 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:00:34.821221 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:00:34.823219 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 11:00:34.801623 => 11:00:34.823219
[0m11:00:34.825739 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:00:34.949443 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:00:34.952539 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:00:34.954538 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m11:00:34.955541 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:00:35.178551 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:00:35.179558 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:00:35.181579 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m11:00:35.248733 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:00:35.251246 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 11:00:34.826743 => 11:00:35.251246
[0m11:00:35.252246 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m11:00:35.283068 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m11:00:35.284575 [info ] [Thread-1 (]: 1 of 2 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.49s]
[0m11:00:35.286583 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:00:35.287582 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:00:35.288585 [info ] [Thread-1 (]: 2 of 2 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m11:00:35.291099 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m11:00:35.292103 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:00:35.298617 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:00:35.301122 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 11:00:35.292103 => 11:00:35.301122
[0m11:00:35.303134 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:00:35.308651 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:00:35.314703 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:00:35.316716 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m11:00:35.317713 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:00:35.520511 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:00:35.521578 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:00:35.523455 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m11:00:35.595540 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:00:35.598915 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 11:00:35.303134 => 11:00:35.597906
[0m11:00:35.602433 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m11:00:35.638788 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m11:00:35.640294 [info ] [Thread-1 (]: 2 of 2 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.35s]
[0m11:00:35.642305 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:00:35.644820 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:35.645832 [debug] [MainThread]: On master: BEGIN
[0m11:00:35.645832 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:00:35.868645 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:00:35.870152 [debug] [MainThread]: On master: COMMIT
[0m11:00:35.871159 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:35.872160 [debug] [MainThread]: On master: COMMIT
[0m11:00:35.905849 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:00:35.906848 [debug] [MainThread]: On master: Close
[0m11:00:35.907847 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:00:35.908853 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:00:35.908853 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65' was properly closed.
[0m11:00:35.910360 [info ] [MainThread]: 
[0m11:00:35.911366 [info ] [MainThread]: Finished running 2 tests in 0 hours 0 minutes and 3.03 seconds (3.03s).
[0m11:00:35.912366 [debug] [MainThread]: Command end result
[0m11:00:35.945480 [info ] [MainThread]: 
[0m11:00:35.948486 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:00:35.950496 [info ] [MainThread]: 
[0m11:00:35.952777 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:00:35.956775 [debug] [MainThread]: Command `dbt test` succeeded at 11:00:35.956775 after 5.06 seconds
[0m11:00:35.957775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D2797050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282D3470CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282CC401090>]}
[0m11:00:35.958793 [debug] [MainThread]: Flushing usage events
[0m11:09:01.271267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D2419D590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D241EF750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D23C7AF10>]}


============================== 11:09:01.275778 | 7c2345a5-0e7f-4eba-bf6a-80907a61ee92 ==============================
[0m11:09:01.275778 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:09:01.276779 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --select source:airbnb.listings', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:09:01.496997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7c2345a5-0e7f-4eba-bf6a-80907a61ee92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D2420F510>]}
[0m11:09:01.592679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7c2345a5-0e7f-4eba-bf6a-80907a61ee92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D23B35C50>]}
[0m11:09:01.594621 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:09:01.623638 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:09:01.875112 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:09:01.877113 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m11:09:02.620697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7c2345a5-0e7f-4eba-bf6a-80907a61ee92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D25807B90>]}
[0m11:09:02.642929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7c2345a5-0e7f-4eba-bf6a-80907a61ee92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D2466C050>]}
[0m11:09:02.643936 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m11:09:02.644321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7c2345a5-0e7f-4eba-bf6a-80907a61ee92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D25D2F450>]}
[0m11:09:02.646890 [info ] [MainThread]: 
[0m11:09:02.647897 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:09:02.649919 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m11:09:02.661446 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:09:02.662952 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m11:09:02.662952 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:09:03.044446 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:09:03.045528 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:09:03.045528 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m11:09:03.099052 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m11:09:03.100844 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m11:09:03.137527 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m11:09:03.146116 [debug] [MainThread]: Using postgres connection "master"
[0m11:09:03.147121 [debug] [MainThread]: On master: BEGIN
[0m11:09:03.147121 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:09:03.406256 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:09:03.407259 [debug] [MainThread]: Using postgres connection "master"
[0m11:09:03.407259 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:09:03.475692 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m11:09:03.477922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7c2345a5-0e7f-4eba-bf6a-80907a61ee92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D25DA7F50>]}
[0m11:09:03.478921 [debug] [MainThread]: On master: ROLLBACK
[0m11:09:03.514254 [debug] [MainThread]: Using postgres connection "master"
[0m11:09:03.515308 [debug] [MainThread]: On master: BEGIN
[0m11:09:03.587381 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:09:03.587381 [debug] [MainThread]: On master: COMMIT
[0m11:09:03.588886 [debug] [MainThread]: Using postgres connection "master"
[0m11:09:03.588886 [debug] [MainThread]: On master: COMMIT
[0m11:09:03.629782 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:09:03.630791 [debug] [MainThread]: On master: Close
[0m11:09:03.631790 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:09:03.633331 [info ] [MainThread]: 
[0m11:09:03.637270 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:09:03.637270 [info ] [Thread-1 (]: 1 of 3 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m11:09:03.638775 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m11:09:03.639811 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:09:03.714029 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:09:03.716031 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 11:09:03.640783 => 11:09:03.716031
[0m11:09:03.718039 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:09:03.739295 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:09:03.741532 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:09:03.742058 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m11:09:03.742058 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:09:03.969427 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:09:03.970433 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:09:03.970433 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m11:09:04.036983 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:09:04.039510 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 11:09:03.719036 => 11:09:04.038990
[0m11:09:04.040516 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m11:09:04.076029 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m11:09:04.077054 [info ] [Thread-1 (]: 1 of 3 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.44s]
[0m11:09:04.078032 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:09:04.079049 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:09:04.079589 [info ] [Thread-1 (]: 2 of 3 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m11:09:04.080596 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m11:09:04.081628 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:09:04.086181 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:09:04.088721 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 11:09:04.081628 => 11:09:04.087212
[0m11:09:04.088721 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:09:04.091726 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:09:04.093234 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:09:04.093234 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m11:09:04.094240 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:09:04.295460 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:09:04.296981 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:09:04.296981 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m11:09:04.362059 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:09:04.364083 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 11:09:04.088721 => 11:09:04.364083
[0m11:09:04.365048 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m11:09:04.399155 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m11:09:04.400159 [info ] [Thread-1 (]: 2 of 3 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.32s]
[0m11:09:04.401208 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:09:04.402247 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0
[0m11:09:04.403252 [info ] [Thread-1 (]: 3 of 3 START test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [RUN]
[0m11:09:04.404258 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65, now test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0)
[0m11:09:04.404258 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0
[0m11:09:04.410773 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"
[0m11:09:04.411774 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0 (compile): 11:09:04.405258 => 11:09:04.411774
[0m11:09:04.413279 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0
[0m11:09:04.417294 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"
[0m11:09:04.420354 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"
[0m11:09:04.421880 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0: BEGIN
[0m11:09:04.422886 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:09:04.640151 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:09:04.641114 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"
[0m11:09:04.642112 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  


    

coalesce(array_length((select regexp_matches(price, '^\\$[0-9][0-9]\\.]+$', '')), 1), 0)


 > 0
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors





      
    ) dbt_internal_test
[0m11:09:04.737025 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:09:04.739035 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0 (execute): 11:09:04.414287 => 11:09:04.739035
[0m11:09:04.739546 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0: ROLLBACK
[0m11:09:04.771708 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0: Close
[0m11:09:04.773083 [error] [Thread-1 (]: 3 of 3 FAIL 17499 dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [[31mFAIL 17499[0m in 0.37s]
[0m11:09:04.774089 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0
[0m11:09:04.776107 [debug] [MainThread]: Using postgres connection "master"
[0m11:09:04.776107 [debug] [MainThread]: On master: BEGIN
[0m11:09:04.777112 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:09:05.008695 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:09:05.008695 [debug] [MainThread]: On master: COMMIT
[0m11:09:05.009704 [debug] [MainThread]: Using postgres connection "master"
[0m11:09:05.010703 [debug] [MainThread]: On master: COMMIT
[0m11:09:05.043739 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:09:05.043739 [debug] [MainThread]: On master: Close
[0m11:09:05.045744 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:09:05.045744 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:09:05.045744 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0' was properly closed.
[0m11:09:05.047250 [info ] [MainThread]: 
[0m11:09:05.047250 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 2.40 seconds (2.40s).
[0m11:09:05.049827 [debug] [MainThread]: Command end result
[0m11:09:05.067885 [info ] [MainThread]: 
[0m11:09:05.069421 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:09:05.070421 [info ] [MainThread]: 
[0m11:09:05.071420 [error] [MainThread]: [31mFailure in test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_ (dbtlearn/models\sources.yml)[0m
[0m11:09:05.072927 [error] [MainThread]:   Got 17499 results, configured to fail if != 0
[0m11:09:05.073940 [info ] [MainThread]: 
[0m11:09:05.075938 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\sources.yml\dbt_expectations_source_expect_a60b59a84fbc4577a11df360c50013bb.sql
[0m11:09:05.077949 [info ] [MainThread]: 
[0m11:09:05.079457 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m11:09:05.081459 [debug] [MainThread]: Command `dbt test` failed at 11:09:05.081459 after 3.89 seconds
[0m11:09:05.082995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D1CA71090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D239CFCD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D239CC1D0>]}
[0m11:09:05.084004 [debug] [MainThread]: Flushing usage events
[0m11:12:38.094015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8B9692ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8B7CD5790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8B96D98D0>]}


============================== 11:12:38.098028 | 07ee2849-b33c-4ff6-a771-bce38519667e ==============================
[0m11:12:38.098028 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:12:38.099034 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --select source:airbnb.listings', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:12:38.368363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '07ee2849-b33c-4ff6-a771-bce38519667e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8B968AE50>]}
[0m11:12:38.478701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '07ee2849-b33c-4ff6-a771-bce38519667e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8B96A39D0>]}
[0m11:12:38.481487 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:12:38.511016 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:12:38.784147 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:12:38.785147 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m11:12:39.600829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '07ee2849-b33c-4ff6-a771-bce38519667e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8BB240890>]}
[0m11:12:39.625455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '07ee2849-b33c-4ff6-a771-bce38519667e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8BAB20050>]}
[0m11:12:39.625455 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m11:12:39.626461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07ee2849-b33c-4ff6-a771-bce38519667e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8BB240D90>]}
[0m11:12:39.628972 [info ] [MainThread]: 
[0m11:12:39.629974 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:12:39.632484 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m11:12:39.643508 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:12:39.643508 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m11:12:39.644508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:12:40.982588 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m11:12:40.983525 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:12:40.983525 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m11:12:41.035393 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m11:12:41.038371 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m11:12:41.076107 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m11:12:41.084722 [debug] [MainThread]: Using postgres connection "master"
[0m11:12:41.086266 [debug] [MainThread]: On master: BEGIN
[0m11:12:41.086266 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:12:41.336206 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:12:41.337165 [debug] [MainThread]: Using postgres connection "master"
[0m11:12:41.338172 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:12:41.402733 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m11:12:41.404775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07ee2849-b33c-4ff6-a771-bce38519667e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8BB17AC10>]}
[0m11:12:41.406282 [debug] [MainThread]: On master: ROLLBACK
[0m11:12:41.446270 [debug] [MainThread]: Using postgres connection "master"
[0m11:12:41.447312 [debug] [MainThread]: On master: BEGIN
[0m11:12:41.523746 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:12:41.524608 [debug] [MainThread]: On master: COMMIT
[0m11:12:41.525569 [debug] [MainThread]: Using postgres connection "master"
[0m11:12:41.525569 [debug] [MainThread]: On master: COMMIT
[0m11:12:41.566555 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:12:41.566555 [debug] [MainThread]: On master: Close
[0m11:12:41.568061 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:12:41.569075 [info ] [MainThread]: 
[0m11:12:41.574487 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:12:41.574991 [info ] [Thread-1 (]: 1 of 3 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m11:12:41.574991 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m11:12:41.576549 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:12:41.660108 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:12:41.661141 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 11:12:41.576549 => 11:12:41.661141
[0m11:12:41.662665 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:12:41.678954 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:12:41.680953 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:12:41.680953 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m11:12:41.682487 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:12:41.925100 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:12:41.926618 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:12:41.926618 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m11:12:41.993567 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:12:41.996314 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 11:12:41.663670 => 11:12:41.995317
[0m11:12:41.996314 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m11:12:42.032474 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m11:12:42.033519 [info ] [Thread-1 (]: 1 of 3 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.46s]
[0m11:12:42.034485 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:12:42.035483 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:12:42.036483 [info ] [Thread-1 (]: 2 of 3 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m11:12:42.038022 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m11:12:42.038022 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:12:42.043609 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:12:42.046639 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 11:12:42.039029 => 11:12:42.046639
[0m11:12:42.048148 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:12:42.051155 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:12:42.052661 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:12:42.053670 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m11:12:42.054669 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:42.296203 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:12:42.297233 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:12:42.297233 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m11:12:42.367303 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:12:42.368880 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 11:12:42.048148 => 11:12:42.368880
[0m11:12:42.369883 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m11:12:42.403174 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m11:12:42.404184 [info ] [Thread-1 (]: 2 of 3 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.37s]
[0m11:12:42.406163 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:12:42.407161 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4
[0m11:12:42.407161 [info ] [Thread-1 (]: 3 of 3 START test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_  [RUN]
[0m11:12:42.408161 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65, now test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4)
[0m11:12:42.409488 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4
[0m11:12:42.414487 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4"
[0m11:12:42.415925 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4 (compile): 11:12:42.409488 => 11:12:42.415925
[0m11:12:42.416931 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4
[0m11:12:42.420030 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4"
[0m11:12:42.422549 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4"
[0m11:12:42.423557 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4: BEGIN
[0m11:12:42.423557 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:42.670907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:12:42.670907 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4"
[0m11:12:42.672413 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  


    

coalesce(array_length((select regexp_matches(price, '^\$\d{1,3}\.\d{2}$', '')), 1), 0)


 > 0
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors





      
    ) dbt_internal_test
[0m11:12:42.816649 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:12:42.818761 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4 (execute): 11:12:42.417937 => 11:12:42.818244
[0m11:12:42.819277 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4: ROLLBACK
[0m11:12:42.853108 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4: Close
[0m11:12:42.855160 [error] [Thread-1 (]: 3 of 3 FAIL 21 dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_  [[31mFAIL 21[0m in 0.45s]
[0m11:12:42.856125 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4
[0m11:12:42.858628 [debug] [MainThread]: Using postgres connection "master"
[0m11:12:42.859640 [debug] [MainThread]: On master: BEGIN
[0m11:12:42.861327 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:12:43.076756 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:12:43.078265 [debug] [MainThread]: On master: COMMIT
[0m11:12:43.079273 [debug] [MainThread]: Using postgres connection "master"
[0m11:12:43.080274 [debug] [MainThread]: On master: COMMIT
[0m11:12:43.116277 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:12:43.117293 [debug] [MainThread]: On master: Close
[0m11:12:43.119858 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:12:43.120819 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:12:43.120819 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_.8e0f1388c4' was properly closed.
[0m11:12:43.122329 [info ] [MainThread]: 
[0m11:12:43.122329 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 3.49 seconds (3.49s).
[0m11:12:43.124337 [debug] [MainThread]: Command end result
[0m11:12:43.148957 [info ] [MainThread]: 
[0m11:12:43.149958 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:12:43.150960 [info ] [MainThread]: 
[0m11:12:43.153482 [error] [MainThread]: [31mFailure in test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___d_1_3_d_2_ (dbtlearn/models\sources.yml)[0m
[0m11:12:43.155479 [error] [MainThread]:   Got 21 results, configured to fail if != 0
[0m11:12:43.160037 [info ] [MainThread]: 
[0m11:12:43.163636 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\sources.yml\dbt_expectations_source_expect_91356c3a2c84b7e880e428c38083e5dc.sql
[0m11:12:43.168143 [info ] [MainThread]: 
[0m11:12:43.170668 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m11:12:43.175694 [debug] [MainThread]: Command `dbt test` failed at 11:12:43.175694 after 5.16 seconds
[0m11:12:43.176712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8B1EF1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8B62D4A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8B21EF210>]}
[0m11:12:43.178226 [debug] [MainThread]: Flushing usage events
[0m11:16:15.499470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F309DDDD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F30DAFC50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F30CC0910>]}


============================== 11:16:15.503470 | 1864ed82-45ad-472f-be37-5a18cbf0e2ae ==============================
[0m11:16:15.503470 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:16:15.504472 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt test --select source:airbnb.listings', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:16:15.749149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1864ed82-45ad-472f-be37-5a18cbf0e2ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F313B7390>]}
[0m11:16:15.832788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1864ed82-45ad-472f-be37-5a18cbf0e2ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F313BE110>]}
[0m11:16:15.834207 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:16:15.861847 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:16:16.111444 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:16:16.112450 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m11:16:16.936563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1864ed82-45ad-472f-be37-5a18cbf0e2ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F32BB9DD0>]}
[0m11:16:16.958878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1864ed82-45ad-472f-be37-5a18cbf0e2ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F32E6B250>]}
[0m11:16:16.959878 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m11:16:16.959878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1864ed82-45ad-472f-be37-5a18cbf0e2ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F30A7EB90>]}
[0m11:16:16.962457 [info ] [MainThread]: 
[0m11:16:16.963426 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:16:16.966425 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m11:16:16.977951 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:16:16.978958 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m11:16:16.979959 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:16:18.326441 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m11:16:18.326441 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:16:18.327947 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m11:16:18.378187 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m11:16:18.379189 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m11:16:18.405745 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m11:16:18.414914 [debug] [MainThread]: Using postgres connection "master"
[0m11:16:18.415470 [debug] [MainThread]: On master: BEGIN
[0m11:16:18.415470 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:16:18.652512 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:16:18.653545 [debug] [MainThread]: Using postgres connection "master"
[0m11:16:18.654519 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:16:18.718173 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m11:16:18.720216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1864ed82-45ad-472f-be37-5a18cbf0e2ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F32663350>]}
[0m11:16:18.721721 [debug] [MainThread]: On master: ROLLBACK
[0m11:16:18.750552 [debug] [MainThread]: Using postgres connection "master"
[0m11:16:18.751603 [debug] [MainThread]: On master: BEGIN
[0m11:16:18.806168 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:16:18.807716 [debug] [MainThread]: On master: COMMIT
[0m11:16:18.808749 [debug] [MainThread]: Using postgres connection "master"
[0m11:16:18.808749 [debug] [MainThread]: On master: COMMIT
[0m11:16:18.837631 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:16:18.838868 [debug] [MainThread]: On master: Close
[0m11:16:18.839872 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:16:18.840877 [info ] [MainThread]: 
[0m11:16:18.845875 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:16:18.845875 [info ] [Thread-1 (]: 1 of 3 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m11:16:18.848393 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m11:16:18.849425 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:16:18.932688 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:16:18.934675 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 11:16:18.850438 => 11:16:18.933675
[0m11:16:18.934675 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:16:18.949822 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:16:18.950823 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:16:18.951823 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m11:16:18.951823 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:16:19.168556 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:16:19.169554 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:16:19.170553 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m11:16:19.238556 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:16:19.240552 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 11:16:18.935676 => 11:16:19.240552
[0m11:16:19.241555 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m11:16:19.274155 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m11:16:19.275161 [info ] [Thread-1 (]: 1 of 3 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.43s]
[0m11:16:19.276168 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:16:19.277202 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:16:19.278476 [info ] [Thread-1 (]: 2 of 3 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m11:16:19.279475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m11:16:19.280476 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:16:19.286522 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:16:19.289033 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 11:16:19.280476 => 11:16:19.289033
[0m11:16:19.291569 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:16:19.294611 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:16:19.296578 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:16:19.297577 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m11:16:19.300745 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:16:19.537532 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:16:19.538540 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:16:19.539539 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m11:16:19.612564 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:16:19.613565 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 11:16:19.292579 => 11:16:19.613565
[0m11:16:19.614567 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m11:16:19.656575 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m11:16:19.659088 [info ] [Thread-1 (]: 2 of 3 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.38s]
[0m11:16:19.661608 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:16:19.662615 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:16:19.662615 [info ] [Thread-1 (]: 3 of 3 START test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [RUN]
[0m11:16:19.663616 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65, now test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9)
[0m11:16:19.664614 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:16:19.670130 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:16:19.671635 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9 (compile): 11:16:19.665618 => 11:16:19.671635
[0m11:16:19.672641 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:16:19.675647 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:16:19.677152 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:16:19.678157 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: BEGIN
[0m11:16:19.679161 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:16:19.902759 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:16:19.904758 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:16:19.905767 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  


    

coalesce(array_length((select regexp_matches(price, '^\\$[0-9][0-9\\.]+$', '')), 1), 0)


 > 0
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors





      
    ) dbt_internal_test
[0m11:16:20.000397 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:16:20.002707 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9 (execute): 11:16:19.672641 => 11:16:20.002143
[0m11:16:20.003237 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: ROLLBACK
[0m11:16:20.039297 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: Close
[0m11:16:20.041435 [error] [Thread-1 (]: 3 of 3 FAIL 17499 dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [[31mFAIL 17499[0m in 0.38s]
[0m11:16:20.043015 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:16:20.045215 [debug] [MainThread]: Using postgres connection "master"
[0m11:16:20.046829 [debug] [MainThread]: On master: BEGIN
[0m11:16:20.047881 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:16:20.293772 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:16:20.293772 [debug] [MainThread]: On master: COMMIT
[0m11:16:20.294740 [debug] [MainThread]: Using postgres connection "master"
[0m11:16:20.295742 [debug] [MainThread]: On master: COMMIT
[0m11:16:20.331380 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:16:20.332388 [debug] [MainThread]: On master: Close
[0m11:16:20.335388 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:16:20.335388 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:16:20.336396 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9' was properly closed.
[0m11:16:20.336396 [info ] [MainThread]: 
[0m11:16:20.337395 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 3.37 seconds (3.37s).
[0m11:16:20.338663 [debug] [MainThread]: Command end result
[0m11:16:20.358207 [info ] [MainThread]: 
[0m11:16:20.360210 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:16:20.360210 [info ] [MainThread]: 
[0m11:16:20.361720 [error] [MainThread]: [31mFailure in test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_ (dbtlearn/models\sources.yml)[0m
[0m11:16:20.362726 [error] [MainThread]:   Got 17499 results, configured to fail if != 0
[0m11:16:20.362726 [info ] [MainThread]: 
[0m11:16:20.363726 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\sources.yml\dbt_expectations_source_expect_a60b59a84fbc4577a11df360c50013bb.sql
[0m11:16:20.364727 [info ] [MainThread]: 
[0m11:16:20.365734 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m11:16:20.367242 [debug] [MainThread]: Command `dbt test` failed at 11:16:20.367242 after 4.94 seconds
[0m11:16:20.369250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F309E0F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F29A01090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F311C2790>]}
[0m11:16:20.369250 [debug] [MainThread]: Flushing usage events
[0m11:17:02.217787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D263E2D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D268BB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D263E510>]}


============================== 11:17:02.223311 | e6eac93a-0630-4c62-9e81-932dab3c8538 ==============================
[0m11:17:02.223311 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:17:02.225311 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt test --select source:airbnb.listings', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:17:02.559743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e6eac93a-0630-4c62-9e81-932dab3c8538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D2856D10>]}
[0m11:17:02.649041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e6eac93a-0630-4c62-9e81-932dab3c8538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D1F37F10>]}
[0m11:17:02.650043 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:17:02.679970 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:17:03.354166 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:17:03.355673 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m11:17:04.339965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6eac93a-0630-4c62-9e81-932dab3c8538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D42F8F10>]}
[0m11:17:04.361545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6eac93a-0630-4c62-9e81-932dab3c8538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D2B16B10>]}
[0m11:17:04.362556 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 16 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m11:17:04.363160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6eac93a-0630-4c62-9e81-932dab3c8538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D27CED90>]}
[0m11:17:04.365167 [info ] [MainThread]: 
[0m11:17:04.366166 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:17:04.369077 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m11:17:04.381308 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:17:04.382314 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m11:17:04.382314 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:17:04.715534 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:17:04.715534 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:17:04.717042 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m11:17:04.770092 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m11:17:04.772645 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m11:17:04.804318 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m11:17:04.813434 [debug] [MainThread]: Using postgres connection "master"
[0m11:17:04.814431 [debug] [MainThread]: On master: BEGIN
[0m11:17:04.815431 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:17:05.042170 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:17:05.043198 [debug] [MainThread]: Using postgres connection "master"
[0m11:17:05.044150 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:17:05.113678 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m11:17:05.115726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6eac93a-0630-4c62-9e81-932dab3c8538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D3F8D8D0>]}
[0m11:17:05.115726 [debug] [MainThread]: On master: ROLLBACK
[0m11:17:05.154513 [debug] [MainThread]: Using postgres connection "master"
[0m11:17:05.155317 [debug] [MainThread]: On master: BEGIN
[0m11:17:05.220367 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:17:05.221373 [debug] [MainThread]: On master: COMMIT
[0m11:17:05.222389 [debug] [MainThread]: Using postgres connection "master"
[0m11:17:05.222389 [debug] [MainThread]: On master: COMMIT
[0m11:17:05.261853 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:17:05.262854 [debug] [MainThread]: On master: Close
[0m11:17:05.263853 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:17:05.265359 [info ] [MainThread]: 
[0m11:17:05.269889 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:17:05.271396 [info ] [Thread-1 (]: 1 of 2 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m11:17:05.273406 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m11:17:05.273406 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:17:05.287469 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:17:05.289791 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 11:17:05.274405 => 11:17:05.289791
[0m11:17:05.292347 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:17:05.383713 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:17:05.387094 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:17:05.388106 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m11:17:05.389103 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:17:05.580206 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:17:05.581718 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:17:05.581718 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m11:17:05.644257 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:17:05.646242 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 11:17:05.293356 => 11:17:05.646242
[0m11:17:05.647275 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m11:17:05.677328 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m11:17:05.679434 [info ] [Thread-1 (]: 1 of 2 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.41s]
[0m11:17:05.680433 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:17:05.680433 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:17:05.681433 [info ] [Thread-1 (]: 2 of 2 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m11:17:05.682384 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m11:17:05.683424 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:17:05.688998 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:17:05.691509 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 11:17:05.684392 => 11:17:05.691509
[0m11:17:05.693551 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:17:05.699120 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:17:05.701625 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:17:05.702635 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m11:17:05.703665 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:17:05.901521 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:17:05.902576 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:17:05.902576 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m11:17:05.971539 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:17:05.973539 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 11:17:05.694529 => 11:17:05.972540
[0m11:17:05.973539 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m11:17:06.002705 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m11:17:06.004708 [info ] [Thread-1 (]: 2 of 2 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.32s]
[0m11:17:06.005717 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:17:06.008230 [debug] [MainThread]: Using postgres connection "master"
[0m11:17:06.009231 [debug] [MainThread]: On master: BEGIN
[0m11:17:06.009231 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:17:06.194073 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:17:06.195583 [debug] [MainThread]: On master: COMMIT
[0m11:17:06.195583 [debug] [MainThread]: Using postgres connection "master"
[0m11:17:06.197091 [debug] [MainThread]: On master: COMMIT
[0m11:17:06.232839 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:17:06.233838 [debug] [MainThread]: On master: Close
[0m11:17:06.233838 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:17:06.235344 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:17:06.235344 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65' was properly closed.
[0m11:17:06.236350 [info ] [MainThread]: 
[0m11:17:06.237349 [info ] [MainThread]: Finished running 2 tests in 0 hours 0 minutes and 1.87 seconds (1.87s).
[0m11:17:06.238366 [debug] [MainThread]: Command end result
[0m11:17:06.260626 [info ] [MainThread]: 
[0m11:17:06.262634 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:17:06.263667 [info ] [MainThread]: 
[0m11:17:06.264730 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:17:06.267238 [debug] [MainThread]: Command `dbt test` succeeded at 11:17:06.265730 after 4.13 seconds
[0m11:17:06.269248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4CAEE1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4D2462150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C4CB1CFE50>]}
[0m11:17:06.271247 [debug] [MainThread]: Flushing usage events
[0m11:45:00.831790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD19B4E390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD19B4CF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD1A354D90>]}


============================== 11:45:00.837307 | d5d6218a-23f5-42cd-848d-4f9d5277cbea ==============================
[0m11:45:00.837307 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:45:00.838305 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --select source:airbnb.listings', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:45:01.091955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd5d6218a-23f5-42cd-848d-4f9d5277cbea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD19F1C450>]}
[0m11:45:01.178285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd5d6218a-23f5-42cd-848d-4f9d5277cbea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD1A483ED0>]}
[0m11:45:01.179790 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:45:01.204339 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:45:01.452304 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:45:01.454818 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m11:45:02.177403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5d6218a-23f5-42cd-848d-4f9d5277cbea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD1BD74590>]}
[0m11:45:02.198465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5d6218a-23f5-42cd-848d-4f9d5277cbea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD1B76EDD0>]}
[0m11:45:02.199433 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m11:45:02.200432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5d6218a-23f5-42cd-848d-4f9d5277cbea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD1A627590>]}
[0m11:45:02.202435 [info ] [MainThread]: 
[0m11:45:02.203430 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:45:02.205846 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m11:45:02.218324 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:45:02.219323 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m11:45:02.220322 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:45:02.626199 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:45:02.627172 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:45:02.627172 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m11:45:02.677330 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m11:45:02.678336 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m11:45:02.714375 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m11:45:02.721935 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:02.723443 [debug] [MainThread]: On master: BEGIN
[0m11:45:02.723443 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:45:02.963071 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:45:02.963614 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:02.963614 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:45:03.030657 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m11:45:03.032659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5d6218a-23f5-42cd-848d-4f9d5277cbea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD1BF55A10>]}
[0m11:45:03.033657 [debug] [MainThread]: On master: ROLLBACK
[0m11:45:03.071467 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:03.072481 [debug] [MainThread]: On master: BEGIN
[0m11:45:03.149552 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:45:03.150552 [debug] [MainThread]: On master: COMMIT
[0m11:45:03.151563 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:03.151563 [debug] [MainThread]: On master: COMMIT
[0m11:45:03.191918 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:45:03.191918 [debug] [MainThread]: On master: Close
[0m11:45:03.193458 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:45:03.194462 [info ] [MainThread]: 
[0m11:45:03.199509 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:45:03.200544 [info ] [Thread-1 (]: 1 of 3 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m11:45:03.201515 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m11:45:03.202517 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:45:03.276609 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:45:03.278151 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 11:45:03.202517 => 11:45:03.277149
[0m11:45:03.278151 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:45:03.293730 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:45:03.295274 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:45:03.295274 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m11:45:03.296274 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:45:03.518322 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:45:03.518322 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:45:03.519362 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m11:45:03.587958 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:45:03.589957 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 11:45:03.279152 => 11:45:03.589957
[0m11:45:03.590957 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m11:45:03.626507 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m11:45:03.628505 [info ] [Thread-1 (]: 1 of 3 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.43s]
[0m11:45:03.629505 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:45:03.630505 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:45:03.630505 [info ] [Thread-1 (]: 2 of 3 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m11:45:03.631506 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m11:45:03.632509 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:45:03.638828 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:45:03.641818 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 11:45:03.632509 => 11:45:03.640821
[0m11:45:03.641818 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:45:03.647362 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:45:03.649377 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:45:03.651383 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m11:45:03.652387 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:03.860032 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:45:03.861033 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:45:03.861033 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m11:45:03.928684 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:45:03.929684 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 11:45:03.643328 => 11:45:03.929684
[0m11:45:03.930682 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m11:45:03.961557 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m11:45:03.963563 [info ] [Thread-1 (]: 2 of 3 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.33s]
[0m11:45:03.964598 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:45:03.965607 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:45:03.965607 [info ] [Thread-1 (]: 3 of 3 START test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [RUN]
[0m11:45:03.968155 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65, now test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9)
[0m11:45:03.969133 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:45:03.974668 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:45:03.976676 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9 (compile): 11:45:03.970121 => 11:45:03.976676
[0m11:45:03.977671 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:45:03.981667 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:45:03.983702 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:45:03.984855 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: BEGIN
[0m11:45:03.984855 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:04.190291 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:45:04.191292 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"
[0m11:45:04.192282 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  


    

coalesce(array_length((select regexp_matches(price, '^\\$[0-9][0-9\\.]+$', '')), 1), 0)


 > 0
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors





      
    ) dbt_internal_test
[0m11:45:04.285644 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:45:04.289016 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9 (execute): 11:45:03.978670 => 11:45:04.288038
[0m11:45:04.289016 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: ROLLBACK
[0m11:45:04.319811 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9: Close
[0m11:45:04.320814 [error] [Thread-1 (]: 3 of 3 FAIL 17499 dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [[31mFAIL 17499[0m in 0.35s]
[0m11:45:04.323346 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9
[0m11:45:04.325356 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:04.326356 [debug] [MainThread]: On master: BEGIN
[0m11:45:04.326356 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:45:04.524226 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:45:04.525229 [debug] [MainThread]: On master: COMMIT
[0m11:45:04.526228 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:04.526228 [debug] [MainThread]: On master: COMMIT
[0m11:45:04.560031 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:45:04.561032 [debug] [MainThread]: On master: Close
[0m11:45:04.562029 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:45:04.562029 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:45:04.562029 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.09375076a9' was properly closed.
[0m11:45:04.563534 [info ] [MainThread]: 
[0m11:45:04.564544 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 2.36 seconds (2.36s).
[0m11:45:04.566550 [debug] [MainThread]: Command end result
[0m11:45:04.590572 [info ] [MainThread]: 
[0m11:45:04.591574 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:45:04.592573 [info ] [MainThread]: 
[0m11:45:04.595101 [error] [MainThread]: [31mFailure in test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_ (dbtlearn/models\sources.yml)[0m
[0m11:45:04.596100 [error] [MainThread]:   Got 17499 results, configured to fail if != 0
[0m11:45:04.597102 [info ] [MainThread]: 
[0m11:45:04.597102 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\sources.yml\dbt_expectations_source_expect_a60b59a84fbc4577a11df360c50013bb.sql
[0m11:45:04.599103 [info ] [MainThread]: 
[0m11:45:04.601116 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m11:45:04.603611 [debug] [MainThread]: Command `dbt test` failed at 11:45:04.602103 after 3.85 seconds
[0m11:45:04.604628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD19E597D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD12C41090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AD19C12B50>]}
[0m11:45:04.605621 [debug] [MainThread]: Flushing usage events
[0m11:48:32.589003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAF73F60D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAF78D3B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAF78D2190>]}


============================== 11:48:32.593726 | 844e636e-971f-4ff9-9bcf-b7d7064ba22a ==============================
[0m11:48:32.593726 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:48:32.594727 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt test --select source:airbnb.listings', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:48:32.802918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '844e636e-971f-4ff9-9bcf-b7d7064ba22a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAF7AB7F50>]}
[0m11:48:32.880962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '844e636e-971f-4ff9-9bcf-b7d7064ba22a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAF79403D0>]}
[0m11:48:32.883366 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:48:32.911048 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:48:33.000710 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbtlearn: sources.yml - Runtime Error
    Syntax error near line 17
    ------------------------------
    14 |           - name: price
    15 |             tests:
    16 |               - dbt_expectations.expect_column_values_to_match_regex:
    17 |                   regex: "^\$[0-9][0-9\.]+$"
    18 |       
    19 |       - name: hosts
    20 |         identifier: raw_hosts
    
    Raw Error:
    ------------------------------
    while parsing a quoted scalar
      in "<unicode string>", line 17, column 26
    found unknown escape character
      in "<unicode string>", line 17, column 28
[0m11:48:33.002835 [debug] [MainThread]: Command `dbt test` failed at 11:48:33.002835 after 0.48 seconds
[0m11:48:33.002835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAF7101250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAF0121090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAF78C31D0>]}
[0m11:48:33.003843 [debug] [MainThread]: Flushing usage events
[0m11:50:36.507896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018615EAACD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186156DF150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018615EAAAD0>]}


============================== 11:50:36.512627 | 622837c2-9293-4e83-b7d7-bdc98f9825aa ==============================
[0m11:50:36.512627 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:50:36.513632 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt test --select source:airbnb.listings', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:50:36.725492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '622837c2-9293-4e83-b7d7-bdc98f9825aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018615F214D0>]}
[0m11:50:36.817685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '622837c2-9293-4e83-b7d7-bdc98f9825aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018615EF8DD0>]}
[0m11:50:36.819652 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:50:36.844196 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:50:36.924506 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbtlearn: sources.yml - Runtime Error
    Syntax error near line 17
    ------------------------------
    14 |           - name: price
    15 |             tests:
    16 |               - dbt_expectations.expect_column_values_to_match_regex:
    17 |                   regex: "^\\\$[0-9][0-9]\\\.]+$"
    18 |       
    19 |       - name: hosts
    20 |         identifier: raw_hosts
    
    Raw Error:
    ------------------------------
    while parsing a quoted scalar
      in "<unicode string>", line 17, column 26
    found unknown escape character
      in "<unicode string>", line 17, column 30
[0m11:50:36.926516 [debug] [MainThread]: Command `dbt test` failed at 11:50:36.926516 after 0.48 seconds
[0m11:50:36.927517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018615ED0590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001860E7D1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000186159F2150>]}
[0m11:50:36.927517 [debug] [MainThread]: Flushing usage events
[0m11:51:52.433054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20CA70150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20C0C2E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20CAE6790>]}


============================== 11:51:52.437057 | 505218d5-a6b9-41e9-acdd-4d8e389b794f ==============================
[0m11:51:52.437057 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:51:52.438057 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt test --select source:airbnb.listings', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:51:52.704249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '505218d5-a6b9-41e9-acdd-4d8e389b794f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20D0E25D0>]}
[0m11:51:52.798688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '505218d5-a6b9-41e9-acdd-4d8e389b794f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20C816D50>]}
[0m11:51:52.799688 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:51:52.835873 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:51:53.097161 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:51:53.099161 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m11:51:53.820999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '505218d5-a6b9-41e9-acdd-4d8e389b794f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20EAB1DD0>]}
[0m11:51:53.843566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '505218d5-a6b9-41e9-acdd-4d8e389b794f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20E9A0A10>]}
[0m11:51:53.844566 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m11:51:53.845566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '505218d5-a6b9-41e9-acdd-4d8e389b794f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20D212AD0>]}
[0m11:51:53.847567 [info ] [MainThread]: 
[0m11:51:53.848565 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:51:53.850568 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m11:51:53.862087 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:51:53.862594 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m11:51:53.863601 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:51:55.231662 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m11:51:55.232167 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:51:55.232167 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m11:51:55.279163 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m11:51:55.281164 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m11:51:55.310651 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m11:51:55.321794 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:55.323511 [debug] [MainThread]: On master: BEGIN
[0m11:51:55.324068 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:51:55.557998 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:51:55.559230 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:55.559230 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:51:55.626439 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m11:51:55.630392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '505218d5-a6b9-41e9-acdd-4d8e389b794f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20D4123D0>]}
[0m11:51:55.630392 [debug] [MainThread]: On master: ROLLBACK
[0m11:51:55.665341 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:55.665341 [debug] [MainThread]: On master: BEGIN
[0m11:51:55.737738 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:51:55.738777 [debug] [MainThread]: On master: COMMIT
[0m11:51:55.738777 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:55.739737 [debug] [MainThread]: On master: COMMIT
[0m11:51:55.780593 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:51:55.782144 [debug] [MainThread]: On master: Close
[0m11:51:55.783151 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:51:55.784151 [info ] [MainThread]: 
[0m11:51:55.789150 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:51:55.789150 [info ] [Thread-1 (]: 1 of 3 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m11:51:55.791455 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m11:51:55.791455 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:51:55.868205 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:51:55.870206 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 11:51:55.792454 => 11:51:55.869205
[0m11:51:55.870206 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:51:55.885220 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:51:55.887221 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:51:55.887221 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m11:51:55.888222 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:51:56.118650 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:51:56.119678 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:51:56.120645 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m11:51:56.190323 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:51:56.192831 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 11:51:55.871206 => 11:51:56.192328
[0m11:51:56.192831 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m11:51:56.228948 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m11:51:56.229955 [info ] [Thread-1 (]: 1 of 3 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.44s]
[0m11:51:56.230953 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:51:56.232463 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:51:56.232463 [info ] [Thread-1 (]: 2 of 3 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m11:51:56.234507 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m11:51:56.234507 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:51:56.240507 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:51:56.242012 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 11:51:56.235504 => 11:51:56.242012
[0m11:51:56.243023 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:51:56.248029 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:51:56.251028 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:51:56.251028 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m11:51:56.252548 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:51:56.492095 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:51:56.493269 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:51:56.494270 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m11:51:56.563411 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:51:56.565412 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 11:51:56.244022 => 11:51:56.565412
[0m11:51:56.566414 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m11:51:56.601862 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m11:51:56.602400 [info ] [Thread-1 (]: 2 of 3 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.37s]
[0m11:51:56.603976 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:51:56.604983 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0
[0m11:51:56.604983 [info ] [Thread-1 (]: 3 of 3 START test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [RUN]
[0m11:51:56.605981 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65, now test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0)
[0m11:51:56.606983 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0
[0m11:51:56.612487 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"
[0m11:51:56.614491 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0 (compile): 11:51:56.607983 => 11:51:56.614491
[0m11:51:56.616492 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0
[0m11:51:56.620493 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"
[0m11:51:56.623011 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"
[0m11:51:56.624010 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0: BEGIN
[0m11:51:56.624010 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:51:56.847002 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:51:56.848000 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"
[0m11:51:56.848000 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  


    

coalesce(array_length((select regexp_matches(price, '^\\$[0-9][0-9]\\.]+$', '')), 1), 0)


 > 0
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors





      
    ) dbt_internal_test
[0m11:51:56.948012 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:51:56.950008 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0 (execute): 11:51:56.617524 => 11:51:56.950008
[0m11:51:56.951020 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0: ROLLBACK
[0m11:51:56.987128 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0: Close
[0m11:51:56.988129 [error] [Thread-1 (]: 3 of 3 FAIL 17499 dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [[31mFAIL 17499[0m in 0.38s]
[0m11:51:56.989055 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0
[0m11:51:56.991088 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:56.992096 [debug] [MainThread]: On master: BEGIN
[0m11:51:56.992637 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:51:57.219273 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:51:57.220302 [debug] [MainThread]: On master: COMMIT
[0m11:51:57.221302 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:57.221302 [debug] [MainThread]: On master: COMMIT
[0m11:51:57.255378 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:51:57.255378 [debug] [MainThread]: On master: Close
[0m11:51:57.256380 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:51:57.257379 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:51:57.257379 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.40be710ee0' was properly closed.
[0m11:51:57.258378 [info ] [MainThread]: 
[0m11:51:57.259380 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 3.41 seconds (3.41s).
[0m11:51:57.260379 [debug] [MainThread]: Command end result
[0m11:51:57.276402 [info ] [MainThread]: 
[0m11:51:57.277400 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:51:57.278401 [info ] [MainThread]: 
[0m11:51:57.279405 [error] [MainThread]: [31mFailure in test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_ (dbtlearn/models\sources.yml)[0m
[0m11:51:57.280401 [error] [MainThread]:   Got 17499 results, configured to fail if != 0
[0m11:51:57.280401 [info ] [MainThread]: 
[0m11:51:57.282917 [info ] [MainThread]:   compiled Code at target\compiled\dbtlearn\dbtlearn/models\sources.yml\dbt_expectations_source_expect_a60b59a84fbc4577a11df360c50013bb.sql
[0m11:51:57.284932 [info ] [MainThread]: 
[0m11:51:57.286943 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m11:51:57.288943 [debug] [MainThread]: Command `dbt test` failed at 11:51:57.288943 after 4.95 seconds
[0m11:51:57.288943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E2057D1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20CF41410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E20C775F90>]}
[0m11:51:57.289942 [debug] [MainThread]: Flushing usage events
[0m11:53:27.188888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6C45B6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6AA9B350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6C4A95D0>]}


============================== 11:53:27.192395 | dab19fa5-97b2-4ca3-9a30-c79e43185554 ==============================
[0m11:53:27.192395 [info ] [MainThread]: Running with dbt=1.7.3
[0m11:53:27.193425 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt test --select source:airbnb.listings', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:53:27.403868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dab19fa5-97b2-4ca3-9a30-c79e43185554', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6C45BA90>]}
[0m11:53:27.493098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dab19fa5-97b2-4ca3-9a30-c79e43185554', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6C5C0490>]}
[0m11:53:27.494758 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m11:53:27.536333 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m11:53:27.809017 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:53:27.810521 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m11:53:28.532084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dab19fa5-97b2-4ca3-9a30-c79e43185554', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6DFE79D0>]}
[0m11:53:28.554106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dab19fa5-97b2-4ca3-9a30-c79e43185554', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6E124710>]}
[0m11:53:28.555106 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 1 analysis, 17 tests, 3 sources, 0 exposures, 0 metrics, 786 macros, 0 groups, 0 semantic models
[0m11:53:28.556105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dab19fa5-97b2-4ca3-9a30-c79e43185554', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6DFED050>]}
[0m11:53:28.558109 [info ] [MainThread]: 
[0m11:53:28.559084 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:53:28.562643 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m11:53:28.574132 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:53:28.575131 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m11:53:28.576648 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:53:28.930686 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:53:28.931190 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m11:53:28.931190 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m11:53:28.982800 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m11:53:28.983800 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m11:53:29.016015 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m11:53:29.023630 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:29.023630 [debug] [MainThread]: On master: BEGIN
[0m11:53:29.024628 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:53:29.223985 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:53:29.223985 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:29.225024 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:53:29.290565 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m11:53:29.293153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dab19fa5-97b2-4ca3-9a30-c79e43185554', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6DEEB550>]}
[0m11:53:29.293153 [debug] [MainThread]: On master: ROLLBACK
[0m11:53:29.325039 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:29.325039 [debug] [MainThread]: On master: BEGIN
[0m11:53:29.389894 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:53:29.390894 [debug] [MainThread]: On master: COMMIT
[0m11:53:29.391434 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:29.391434 [debug] [MainThread]: On master: COMMIT
[0m11:53:29.419946 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:53:29.420709 [debug] [MainThread]: On master: Close
[0m11:53:29.421830 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:53:29.422829 [info ] [MainThread]: 
[0m11:53:29.427831 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:53:29.428829 [info ] [Thread-1 (]: 1 of 3 START test dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [RUN]
[0m11:53:29.429830 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214'
[0m11:53:29.430833 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:53:29.508184 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:53:29.509186 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (compile): 11:53:29.431340 => 11:53:29.509186
[0m11:53:29.510691 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:53:29.526203 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:53:29.528208 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:53:29.529206 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: BEGIN
[0m11:53:29.529206 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:53:29.766965 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:53:29.767498 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"
[0m11:53:29.768020 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    with a as (
        
    select
        
        count(*) as expression
    from
        "inttegra_stage"."test"."dim_listings_with_hosts"
    

    ),
    b as (
        
    select
        
        count(*) * 1 as expression
    from
        "inttegra_stage"."test"."raw_listings"
    

    ),
    final as (

        select
            
            a.expression,
            b.expression as compare_expression,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0)) as expression_difference,
            abs(coalesce(a.expression, 0) - coalesce(b.expression, 0))/
                nullif(a.expression * 1.0, 0) as expression_difference_percent
        from
        
            a cross join b
        
    )
    -- DEBUG:
    -- select * from final
    select
        *
    from final
    where
        
        expression_difference > 0.0
        

      
    ) dbt_internal_test
[0m11:53:29.839884 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:53:29.842079 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214 (execute): 11:53:29.510691 => 11:53:29.842079
[0m11:53:29.843079 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: ROLLBACK
[0m11:53:29.879537 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214: Close
[0m11:53:29.881077 [info ] [Thread-1 (]: 1 of 3 PASS dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_  [[32mPASS[0m in 0.45s]
[0m11:53:29.882084 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214
[0m11:53:29.883084 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:53:29.883084 [info ] [Thread-1 (]: 2 of 3 START test dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [RUN]
[0m11:53:29.884084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_expect_table_row_count_to_equal_other_table_dim_listings_with_hosts_source_airbnb_listings_.6df199e214, now test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65)
[0m11:53:29.885083 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:53:29.890083 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:53:29.891588 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (compile): 11:53:29.885083 => 11:53:29.891588
[0m11:53:29.892592 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:53:29.894591 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:53:29.896591 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:53:29.896591 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: BEGIN
[0m11:53:29.897591 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:53:30.138919 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:53:30.139921 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"
[0m11:53:30.140918 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      


    with grouped_expression as (
    select
        
        
    
  
count(distinct room_type) = 4
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors



      
    ) dbt_internal_test
[0m11:53:30.211919 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:53:30.214319 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65 (execute): 11:53:29.892592 => 11:53:30.214319
[0m11:53:30.215318 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: ROLLBACK
[0m11:53:30.251221 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65: Close
[0m11:53:30.252456 [info ] [Thread-1 (]: 2 of 3 PASS dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4  [[32mPASS[0m in 0.37s]
[0m11:53:30.253643 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65
[0m11:53:30.254684 [debug] [Thread-1 (]: Began running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63
[0m11:53:30.255650 [info ] [Thread-1 (]: 3 of 3 START test dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [RUN]
[0m11:53:30.257651 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.dbt_expectations_source_expect_column_distinct_count_to_equal_airbnb_listings_room_type__4.1e56c20a65, now test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63)
[0m11:53:30.257651 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63
[0m11:53:30.266068 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63"
[0m11:53:30.269095 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63 (compile): 11:53:30.258682 => 11:53:30.268095
[0m11:53:30.271076 [debug] [Thread-1 (]: Began executing node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63
[0m11:53:30.276641 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63"
[0m11:53:30.279599 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63"
[0m11:53:30.281106 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63: BEGIN
[0m11:53:30.282114 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:53:30.519221 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:53:30.519221 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63"
[0m11:53:30.520771 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      




    with grouped_expression as (
    select
        
        
    
  


    

coalesce(array_length((select regexp_matches(price, '^\$[0-9][0-9\.]+$', '')), 1), 0)


 > 0
 as expression


    from "inttegra_stage"."test"."raw_listings"
    

),
validation_errors as (

    select
        *
    from
        grouped_expression
    where
        not(expression = true)

)

select *
from validation_errors





      
    ) dbt_internal_test
[0m11:53:30.656433 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:53:30.658228 [debug] [Thread-1 (]: Timing info for test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63 (execute): 11:53:30.272616 => 11:53:30.658228
[0m11:53:30.659233 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63: ROLLBACK
[0m11:53:30.693901 [debug] [Thread-1 (]: On test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63: Close
[0m11:53:30.694908 [info ] [Thread-1 (]: 3 of 3 PASS dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_  [[32mPASS[0m in 0.44s]
[0m11:53:30.695894 [debug] [Thread-1 (]: Finished running node test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63
[0m11:53:30.698577 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:30.698577 [debug] [MainThread]: On master: BEGIN
[0m11:53:30.699617 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:53:30.927170 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:53:30.928176 [debug] [MainThread]: On master: COMMIT
[0m11:53:30.929173 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:30.929173 [debug] [MainThread]: On master: COMMIT
[0m11:53:30.960762 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:53:30.962240 [debug] [MainThread]: On master: Close
[0m11:53:30.963242 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:53:30.964242 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m11:53:30.964242 [debug] [MainThread]: Connection 'test.dbtlearn.dbt_expectations_source_expect_column_values_to_match_regex_airbnb_listings_price___0_9_0_9_.e1269b5d63' was properly closed.
[0m11:53:30.965246 [info ] [MainThread]: 
[0m11:53:30.966245 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 2.41 seconds (2.41s).
[0m11:53:30.968260 [debug] [MainThread]: Command end result
[0m11:53:30.985774 [info ] [MainThread]: 
[0m11:53:30.987777 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:53:30.989796 [info ] [MainThread]: 
[0m11:53:30.991975 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m11:53:30.994983 [debug] [MainThread]: Command `dbt test` succeeded at 11:53:30.994983 after 3.87 seconds
[0m11:53:30.995982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6BC8FF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6C07B2D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E6BC93550>]}
[0m11:53:30.995982 [debug] [MainThread]: Flushing usage events
