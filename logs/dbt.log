[0m23:30:18.177957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EE977EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EC5F3800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EC520DD0>]}


============================== 23:30:18.183958 | f598d1bd-3815-4c39-a336-34d5abe6bc9b ==============================
[0m23:30:18.183958 [info ] [MainThread]: Running with dbt=1.9.3
[0m23:30:18.185432 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt init dbtlearn', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:30:18.220035 [debug] [MainThread]: Starter project path: C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\venv\Lib\site-packages\dbt\include\starter_project
[0m23:30:18.268459 [info ] [MainThread]: 
Your new dbt project "dbtlearn" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m23:30:18.269463 [info ] [MainThread]: Setting up your profile.
[0m23:33:32.341961 [info ] [MainThread]: Profile dbtlearn written to C:\Users\marco\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m23:33:32.343959 [debug] [MainThread]: Command `dbt init` succeeded at 23:33:32.343959 after 194.36 seconds
[0m23:33:32.343959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EF0D9AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EE207D40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EF3F7950>]}
[0m23:33:32.344965 [debug] [MainThread]: Flushing usage events
[0m23:33:33.277981 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:08:08.304736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022371485C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223716A92D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002237122B7D0>]}


============================== 14:08:08.312383 | fa9a4809-69de-499f-925f-a1ac01b2b989 ==============================
[0m14:08:08.312383 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:08:08.313380 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:08:08.314386 [info ] [MainThread]: dbt version: 1.7.3
[0m14:08:08.315892 [info ] [MainThread]: python version: 3.11.7
[0m14:08:08.316901 [info ] [MainThread]: python path: C:\Users\marco\AppData\Local\Programs\Python\Python311\python.exe
[0m14:08:08.317899 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m14:08:08.491461 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.bigquery'
[0m14:08:08.496599 [info ] [MainThread]: Using profiles dir at C:\Users\marco\.dbt
[0m14:08:08.497630 [info ] [MainThread]: Using profiles.yml file at C:\Users\marco\.dbt\profiles.yml
[0m14:08:08.498679 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
[0m14:08:08.499734 [info ] [MainThread]: Configuration:
[0m14:08:08.501296 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:08:08.502380 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m14:08:08.503474 [info ] [MainThread]: Required dependencies:
[0m14:08:08.504483 [debug] [MainThread]: Executing "git --help"
[0m14:08:08.588638 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:08:08.589157 [debug] [MainThread]: STDERR: "b''"
[0m14:08:08.589157 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:08:08.590161 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:08:08.590161 [info ] [MainThread]: [31m2 checks failed:[0m
[0m14:08:08.592537 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "lessons", target "dev" invalid: Runtime Error
    Could not find adapter type bigquery!


[0m14:08:08.593544 [info ] [MainThread]: Project loading failed for the following reason:
 project path <C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml> not found

[0m14:08:08.595023 [debug] [MainThread]: Command `dbt debug` failed at 14:08:08.595023 after 0.38 seconds
[0m14:08:08.595023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002237195A190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002236A2B1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022370B86B10>]}
[0m14:08:08.596030 [debug] [MainThread]: Flushing usage events
[0m14:08:52.914637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F47421E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F47201290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F46C2AA50>]}


============================== 14:08:52.919215 | c31f6dd1-6bb5-481a-8b27-ba9c13df7d43 ==============================
[0m14:08:52.919215 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:08:52.920189 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:08:52.921226 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:08:52.924187 [debug] [MainThread]: Command `dbt run` failed at 14:08:52.923187 after 0.08 seconds
[0m14:08:52.924187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F3FCD1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F46C2A6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F3FFCFD50>]}
[0m14:08:52.925186 [debug] [MainThread]: Flushing usage events
[0m14:10:47.381873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239464468D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023949D03F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239490E4C50>]}


============================== 14:10:47.386877 | 81babd98-3bcb-40dd-9e48-feac09ac0f91 ==============================
[0m14:10:47.386877 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:10:47.387873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:10:47.387873 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:10:47.390273 [debug] [MainThread]: Command `dbt run` failed at 14:10:47.390273 after 0.07 seconds
[0m14:10:47.390273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023942D31010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002394A4D7C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002394A066390>]}
[0m14:10:47.391306 [debug] [MainThread]: Flushing usage events
[0m14:11:35.815548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7D4A550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A823BE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7A50390>]}


============================== 14:11:35.819547 | 7de46b32-0753-4bd6-8afc-8b472f5a4ad4 ==============================
[0m14:11:35.819547 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:11:35.819547 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:11:36.124274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8406750>]}
[0m14:11:36.207136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8203F90>]}
[0m14:11:36.208669 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:11:36.225253 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:11:36.226253 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:11:36.227254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A84CA710>]}
[0m14:11:37.871611 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.src
[0m14:11:37.876642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A83FE710>]}
[0m14:11:37.902965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8623550>]}
[0m14:11:37.903967 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:11:37.905962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A85469D0>]}
[0m14:11:37.908006 [info ] [MainThread]: 
[0m14:11:37.908972 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:11:37.910962 [debug] [MainThread]: Command end result
[0m14:11:37.922033 [debug] [MainThread]: Command `dbt run` succeeded at 14:11:37.922033 after 2.17 seconds
[0m14:11:37.922033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A09BE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7A1DD90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7406B10>]}
[0m14:11:37.923030 [debug] [MainThread]: Flushing usage events
[0m14:16:32.994251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150C18D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025114EB1A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025114C41D90>]}


============================== 14:16:32.998254 | 2c51030f-1bba-456d-ac7f-990e2c5d7b69 ==============================
[0m14:16:32.998254 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:16:32.999252 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:16:33.206891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150E03D0>]}
[0m14:16:33.282673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150E03D0>]}
[0m14:16:33.284878 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:16:33.292531 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:16:33.318143 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:16:33.319137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115279D90>]}
[0m14:16:34.011638 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn
[0m14:16:34.017401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115105010>]}
[0m14:16:34.031922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251152C59D0>]}
[0m14:16:34.031922 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:16:34.032922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115464A50>]}
[0m14:16:34.034922 [info ] [MainThread]: 
[0m14:16:34.035433 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:16:34.037442 [debug] [MainThread]: Command end result
[0m14:16:34.049448 [debug] [MainThread]: Command `dbt run` succeeded at 14:16:34.048447 after 1.13 seconds
[0m14:16:34.050448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002510D971010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251148C3C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002510DBE4390>]}
[0m14:16:34.050448 [debug] [MainThread]: Flushing usage events
[0m14:18:42.716220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1205E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF0EF5150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF0ED2C50>]}


============================== 14:18:42.722229 | eef7ded4-a0c0-458f-aff9-b2fab91772cc ==============================
[0m14:18:42.722229 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:18:42.723219 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:18:42.944981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1702050>]}
[0m14:18:43.020957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF16AA4D0>]}
[0m14:18:43.022957 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:18:43.030487 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:18:43.051073 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m14:18:43.053076 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:18:43.054073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF11D63D0>]}
[0m14:18:43.758533 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.src
[0m14:18:43.763055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1A1EA90>]}
[0m14:18:43.778083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1A88650>]}
[0m14:18:43.779081 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:18:43.780082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF17B5F50>]}
[0m14:18:43.781086 [info ] [MainThread]: 
[0m14:18:43.783107 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:18:43.784114 [debug] [MainThread]: Command end result
[0m14:18:43.792851 [debug] [MainThread]: Command `dbt run` succeeded at 14:18:43.791848 after 1.16 seconds
[0m14:18:43.792851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF11D7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EE9F51010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1914610>]}
[0m14:18:43.793878 [debug] [MainThread]: Flushing usage events
[0m14:19:52.578602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27159950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26C87890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26C86190>]}


============================== 14:19:52.583599 | 65801f51-a4ee-474b-9fba-6a834fa64fc9 ==============================
[0m14:19:52.583599 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:19:52.584601 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:19:52.793040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F271B0090>]}
[0m14:19:52.870409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2726BE10>]}
[0m14:19:52.872053 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:19:52.879230 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:19:52.901295 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:19:52.902296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2731D390>]}
[0m14:19:53.602502 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.models.src
[0m14:19:53.608007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27142BD0>]}
[0m14:19:53.620025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2749B010>]}
[0m14:19:53.621029 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:19:53.621536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27492750>]}
[0m14:19:53.622536 [info ] [MainThread]: 
[0m14:19:53.623540 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:19:53.624538 [debug] [MainThread]: Command end result
[0m14:19:53.636320 [debug] [MainThread]: Command `dbt run` succeeded at 14:19:53.636320 after 1.14 seconds
[0m14:19:53.637320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F1F92E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26995810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27160D10>]}
[0m14:19:53.638320 [debug] [MainThread]: Flushing usage events
[0m14:20:31.630997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016557122A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556C15910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556CA66D0>]}


============================== 14:20:31.635087 | a2e6be0e-07c6-4220-ba75-a9978b8f61dd ==============================
[0m14:20:31.635087 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:20:31.636087 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:20:31.637091 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:20:31.638124 [debug] [MainThread]: Command `dbt run` failed at 14:20:31.638124 after 0.07 seconds
[0m14:20:31.639086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001655691DB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001654F9C1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556921310>]}
[0m14:20:31.639086 [debug] [MainThread]: Flushing usage events
[0m14:20:48.116047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F201310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F2016D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FA05C10>]}


============================== 14:20:48.120140 | 74fa53d7-1e75-447f-b957-20289922a437 ==============================
[0m14:20:48.120140 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:20:48.121107 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:20:48.335102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105ED2EAD0>]}
[0m14:20:48.412802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F2D0410>]}
[0m14:20:48.414721 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:20:48.422114 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:20:48.503415 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:20:48.504420 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:20:48.505421 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.models.src
[0m14:20:48.509776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F7EF010>]}
[0m14:20:48.521893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FC40D50>]}
[0m14:20:48.522894 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:20:48.523901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FB50310>]}
[0m14:20:48.524931 [info ] [MainThread]: 
[0m14:20:48.526443 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:20:48.528009 [debug] [MainThread]: Command end result
[0m14:20:48.580313 [debug] [MainThread]: Command `dbt run` succeeded at 14:20:48.579315 after 0.53 seconds
[0m14:20:48.580313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021058261010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105ECBEED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105854FE10>]}
[0m14:20:48.581313 [debug] [MainThread]: Flushing usage events
[0m14:22:12.507346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B41C310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AC09310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AB76790>]}


============================== 14:22:12.512072 | 3f8faea2-9fc3-4b18-a904-7dea78056716 ==============================
[0m14:22:12.512072 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:22:12.512896 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:22:12.731511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AF41410>]}
[0m14:22:12.812509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B610C10>]}
[0m14:22:12.814478 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:22:12.821344 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:22:12.828752 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:22:12.829715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B5BEFD0>]}
[0m14:22:13.636968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B752A10>]}
[0m14:22:13.648581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B843650>]}
[0m14:22:13.649588 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:22:13.649588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B69C990>]}
[0m14:22:13.651091 [info ] [MainThread]: 
[0m14:22:13.653096 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:22:13.655098 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:22:13.665049 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:22:13.665049 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:22:13.666048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:22:14.998114 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:22:14.999207 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:22:15.001206 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:22:15.007240 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:22:15.007240 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:22:15.007240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:22:15.208959 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.209967 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:22:15.209967 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:22:15.261228 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:22:15.262394 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:22:15.299688 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:22:15.304688 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.305687 [debug] [MainThread]: On master: BEGIN
[0m14:22:15.305687 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:22:15.504276 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.505266 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.505266 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:22:15.568062 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:22:15.569041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B451990>]}
[0m14:22:15.570072 [debug] [MainThread]: On master: ROLLBACK
[0m14:22:15.603384 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.604347 [debug] [MainThread]: On master: BEGIN
[0m14:22:15.662353 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.662353 [debug] [MainThread]: On master: COMMIT
[0m14:22:15.663393 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.664381 [debug] [MainThread]: On master: COMMIT
[0m14:22:15.698906 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:22:15.699967 [debug] [MainThread]: On master: Close
[0m14:22:15.700916 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:22:15.701917 [info ] [MainThread]: 
[0m14:22:15.710978 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:22:15.710978 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:22:15.712977 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:22:15.713979 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:22:15.721345 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:22:15.726358 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:22:15.713979 => 14:22:15.725339
[0m14:22:15.726358 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:22:15.760870 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:22:15.764837 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:22:15.765838 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:22:15.765838 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:22:15.952069 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.953056 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:22:15.953056 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:22:15.991008 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw_listings" does not exist
LINE 10:   raw_listings rl 
           ^
DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.

[0m14:22:15.992023 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: ROLLBACK
[0m14:22:16.027093 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:22:15.727343 => 14:22:16.027093
[0m14:22:16.028110 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:22:16.139655 [debug] [Thread-1 (]: Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings rl 
             ^
  DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
  HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:22:16.140697 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B8C68D0>]}
[0m14:22:16.141674 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.src_listings ......................... [[31mERROR[0m in 0.43s]
[0m14:22:16.142662 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:22:16.144661 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:16.144661 [debug] [MainThread]: On master: BEGIN
[0m14:22:16.145661 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:22:16.342764 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:16.343934 [debug] [MainThread]: On master: COMMIT
[0m14:22:16.343934 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:16.345009 [debug] [MainThread]: On master: COMMIT
[0m14:22:16.379046 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:22:16.379551 [debug] [MainThread]: On master: Close
[0m14:22:16.380561 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:22:16.380561 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:22:16.381557 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:22:16.381557 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:22:16.382558 [info ] [MainThread]: 
[0m14:22:16.383557 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.73 seconds (2.73s).
[0m14:22:16.384556 [debug] [MainThread]: Command end result
[0m14:22:16.394588 [info ] [MainThread]: 
[0m14:22:16.395586 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:22:16.396586 [info ] [MainThread]: 
[0m14:22:16.397588 [error] [MainThread]:   Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings rl 
             ^
  DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
  HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:22:16.399109 [info ] [MainThread]: 
[0m14:22:16.400127 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:22:16.402672 [debug] [MainThread]: Command `dbt run` failed at 14:22:16.402672 after 3.97 seconds
[0m14:22:16.403746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AF413D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B23CAE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AC0A150>]}
[0m14:22:16.405033 [debug] [MainThread]: Flushing usage events
[0m14:23:24.897496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23867810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF235907D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF238F0BD0>]}


============================== 14:23:24.902219 | 79c8ca5e-8f95-4e94-8a8a-bb898296346d ==============================
[0m14:23:24.902219 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:23:24.903187 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:23:25.106658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23F4CD90>]}
[0m14:23:25.183060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23D5B150>]}
[0m14:23:25.184879 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:23:25.193740 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:23:25.213875 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:23:25.215021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF2393ECD0>]}
[0m14:23:26.028667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF240198D0>]}
[0m14:23:26.040178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF24222690>]}
[0m14:23:26.041213 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:23:26.041213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23DB0350>]}
[0m14:23:26.043751 [info ] [MainThread]: 
[0m14:23:26.044881 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:23:26.046881 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:23:26.056145 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:23:26.056145 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:23:26.057148 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:23:27.417248 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:23:27.418258 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:23:27.421243 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:23:27.425839 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:23:27.426847 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:23:27.426847 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:23:27.659333 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:23:27.660302 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:23:27.660302 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:23:27.711350 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:23:27.713378 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:23:27.748149 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:23:27.753772 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:27.754739 [debug] [MainThread]: On master: BEGIN
[0m14:23:27.754739 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:23:27.970376 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:27.971375 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:27.972377 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:23:28.038711 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:23:28.039976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23F48790>]}
[0m14:23:28.040974 [debug] [MainThread]: On master: ROLLBACK
[0m14:23:28.074116 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.074636 [debug] [MainThread]: On master: BEGIN
[0m14:23:28.143471 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.144530 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.145069 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.145590 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.184159 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:23:28.185273 [debug] [MainThread]: On master: Close
[0m14:23:28.186932 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:23:28.187983 [info ] [MainThread]: 
[0m14:23:28.191772 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:23:28.192332 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:23:28.193411 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:23:28.194438 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:23:28.201220 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:23:28.202218 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:23:28.194993 => 14:23:28.202218
[0m14:23:28.203221 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:23:28.235374 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:23:28.237377 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:23:28.237377 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:23:28.238342 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:23:28.468384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.469160 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:23:28.469160 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings_ AS (
	SELECT *
	FROM   
		raw_listings 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings_
  );
[0m14:23:28.512776 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw_listings" does not exist
LINE 10:   raw_listings 
           ^

[0m14:23:28.513826 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: ROLLBACK
[0m14:23:28.555945 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:23:28.204225 => 14:23:28.555945
[0m14:23:28.557889 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:23:28.562921 [debug] [Thread-1 (]: Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings 
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:23:28.562921 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF2415E5D0>]}
[0m14:23:28.563911 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.src_listings ......................... [[31mERROR[0m in 0.37s]
[0m14:23:28.564902 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:23:28.566949 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.567329 [debug] [MainThread]: On master: BEGIN
[0m14:23:28.567969 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:23:28.811311 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.812313 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.812313 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.813330 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.854228 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:23:28.854839 [debug] [MainThread]: On master: Close
[0m14:23:28.855969 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:23:28.857013 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:23:28.857013 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:23:28.858008 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:23:28.858008 [info ] [MainThread]: 
[0m14:23:28.859043 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.81 seconds (2.81s).
[0m14:23:28.860050 [debug] [MainThread]: Command end result
[0m14:23:28.870426 [info ] [MainThread]: 
[0m14:23:28.871409 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:23:28.872407 [info ] [MainThread]: 
[0m14:23:28.873407 [error] [MainThread]:   Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings 
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:23:28.873697 [info ] [MainThread]: 
[0m14:23:28.874703 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:23:28.875704 [debug] [MainThread]: Command `dbt run` failed at 14:23:28.875704 after 4.05 seconds
[0m14:23:28.876704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23D53ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF1C5A1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23546AD0>]}
[0m14:23:28.876704 [debug] [MainThread]: Flushing usage events
[0m14:24:44.702084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAE72E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA770E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAEB99D0>]}


============================== 14:24:44.705622 | 20e8be37-3de7-4264-a23a-bb7e3e8bf8dc ==============================
[0m14:24:44.705622 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:24:44.706624 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:24:44.917075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAFDEB90>]}
[0m14:24:45.003858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA947950>]}
[0m14:24:45.005433 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:24:45.014230 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:24:45.119312 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:24:45.119312 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_listings.sql
[0m14:24:45.282289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB0B2DD0>]}
[0m14:24:45.294479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB386810>]}
[0m14:24:45.295479 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:24:45.296485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB205310>]}
[0m14:24:45.298512 [info ] [MainThread]: 
[0m14:24:45.298897 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:24:45.300752 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:24:45.310434 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:24:45.310434 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:24:45.311397 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:46.659018 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:24:46.660776 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:24:46.662783 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:24:46.668815 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:24:46.668815 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:24:46.669782 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:46.901069 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:24:46.902116 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:24:46.903080 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:24:46.955380 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:24:46.956381 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:24:46.991989 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:24:46.997054 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:46.997054 [debug] [MainThread]: On master: BEGIN
[0m14:24:46.998128 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:24:47.194326 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.195362 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.195876 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:24:47.257223 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:24:47.258782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB0E8850>]}
[0m14:24:47.259297 [debug] [MainThread]: On master: ROLLBACK
[0m14:24:47.289400 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.290419 [debug] [MainThread]: On master: BEGIN
[0m14:24:47.350581 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.351628 [debug] [MainThread]: On master: COMMIT
[0m14:24:47.351628 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.352620 [debug] [MainThread]: On master: COMMIT
[0m14:24:47.387762 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:24:47.388752 [debug] [MainThread]: On master: Close
[0m14:24:47.389753 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:47.390753 [info ] [MainThread]: 
[0m14:24:47.393753 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:24:47.393753 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:24:47.394759 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:24:47.396017 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:24:47.403983 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:24:47.406043 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:24:47.396017 => 14:24:47.406043
[0m14:24:47.407047 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:24:47.440641 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:24:47.442713 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.442713 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:24:47.443940 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:24:47.645384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.646228 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.647273 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:24:47.713429 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:24:47.719504 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.720505 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:24:47.752322 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:24:47.766405 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:24:47.767410 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.768004 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:24:47.797656 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:24:47.804687 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:24:47.809687 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.810688 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:24:47.840036 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:24:47.842037 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:24:47.408048 => 14:24:47.842037
[0m14:24:47.842037 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:24:47.844038 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA9B05D0>]}
[0m14:24:47.844038 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:24:47.846038 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:24:47.847034 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.848071 [debug] [MainThread]: On master: BEGIN
[0m14:24:47.849067 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:24:48.040439 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:48.041436 [debug] [MainThread]: On master: COMMIT
[0m14:24:48.042436 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:48.042942 [debug] [MainThread]: On master: COMMIT
[0m14:24:48.078516 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:24:48.078516 [debug] [MainThread]: On master: Close
[0m14:24:48.079777 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:48.080770 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:24:48.080770 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:24:48.081749 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:24:48.081749 [info ] [MainThread]: 
[0m14:24:48.082737 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.78 seconds (2.78s).
[0m14:24:48.084762 [debug] [MainThread]: Command end result
[0m14:24:48.093343 [info ] [MainThread]: 
[0m14:24:48.093883 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:24:48.094912 [info ] [MainThread]: 
[0m14:24:48.096920 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:24:48.098918 [debug] [MainThread]: Command `dbt run` succeeded at 14:24:48.098918 after 3.46 seconds
[0m14:24:48.099918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAA23010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDB37A1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDB37A0F50>]}
[0m14:24:48.099918 [debug] [MainThread]: Flushing usage events
[0m14:30:46.179498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B5E8C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3ADF75D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3AEA0B10>]}


============================== 14:30:46.183496 | f52816ad-50ab-40d6-ada6-6774a7c16420 ==============================
[0m14:30:46.183496 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:30:46.184500 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:30:46.395034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B609A10>]}
[0m14:30:46.473761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B0C5B10>]}
[0m14:30:46.475884 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:30:46.483889 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:30:46.585065 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:30:46.585065 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\src\src_reviews.sql
[0m14:30:46.747171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B846C10>]}
[0m14:30:46.759880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3BACCD10>]}
[0m14:30:46.759880 [info ] [MainThread]: Found 2 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:30:46.761385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B891210>]}
[0m14:30:46.763394 [info ] [MainThread]: 
[0m14:30:46.764391 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:30:46.766983 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:30:46.776516 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:30:46.777532 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:30:46.777532 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:48.165570 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:30:48.167615 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:30:48.169223 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:30:48.174768 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:48.175767 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:30:48.176778 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:48.418018 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.419523 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:48.420037 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:30:48.471512 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.0 seconds
[0m14:30:48.473564 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:30:48.503929 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:30:48.509161 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.510162 [debug] [MainThread]: On master: BEGIN
[0m14:30:48.510162 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:30:48.741145 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.742141 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.743138 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:30:48.808499 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:48.810499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B86E2D0>]}
[0m14:30:48.810499 [debug] [MainThread]: On master: ROLLBACK
[0m14:30:48.847004 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.847004 [debug] [MainThread]: On master: BEGIN
[0m14:30:48.914062 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.915074 [debug] [MainThread]: On master: COMMIT
[0m14:30:48.915074 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.916074 [debug] [MainThread]: On master: COMMIT
[0m14:30:48.954591 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:30:48.955590 [debug] [MainThread]: On master: Close
[0m14:30:48.956586 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:30:48.957587 [info ] [MainThread]: 
[0m14:30:48.960621 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:30:48.962065 [info ] [Thread-1 (]: 1 of 2 START sql view model test.src_listings .................................. [RUN]
[0m14:30:48.963034 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:30:48.964034 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:30:48.971541 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:30:48.973705 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:30:48.964034 => 14:30:48.973705
[0m14:30:48.974756 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:30:49.009269 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:30:49.010678 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.010678 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:30:49.011679 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:30:49.237193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:30:49.238364 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.238364 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:30:49.291454 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:30:49.297032 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.298119 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:30:49.331468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.335598 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.335598 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:30:49.370526 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.387694 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:30:49.387694 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.388658 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:30:49.422644 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:30:49.429197 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:30:49.435322 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.435322 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:30:49.474248 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:30:49.475838 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:30:48.975755 => 14:30:49.475838
[0m14:30:49.477358 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:30:49.478413 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3CB48450>]}
[0m14:30:49.478413 [info ] [Thread-1 (]: 1 of 2 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.51s]
[0m14:30:49.479452 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:30:49.480418 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:30:49.481418 [info ] [Thread-1 (]: 2 of 2 START sql view model test.src_reviews ................................... [RUN]
[0m14:30:49.482418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:30:49.483452 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:30:49.485419 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:30:49.487419 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:30:49.483452 => 14:30:49.487419
[0m14:30:49.488419 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:30:49.492577 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:30:49.494582 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.495152 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:30:49.495152 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:30:49.720359 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:30:49.721120 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.722119 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:30:49.772134 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:30:49.775669 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.776672 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:30:49.811330 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.813834 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:30:49.814348 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.815353 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:30:49.847495 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:30:49.850030 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:30:49.852561 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.852561 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:30:49.888147 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:30:49.890146 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:30:49.488419 => 14:30:49.889146
[0m14:30:49.890146 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:30:49.891146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3CAFFC10>]}
[0m14:30:49.892146 [info ] [Thread-1 (]: 2 of 2 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:30:49.893147 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:30:49.895150 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:49.896148 [debug] [MainThread]: On master: BEGIN
[0m14:30:49.896148 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:30:50.115779 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:50.116784 [debug] [MainThread]: On master: COMMIT
[0m14:30:50.116784 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:50.117783 [debug] [MainThread]: On master: COMMIT
[0m14:30:50.158363 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:30:50.159365 [debug] [MainThread]: On master: Close
[0m14:30:50.160367 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:30:50.160367 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:30:50.161367 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:30:50.161367 [debug] [MainThread]: Connection 'model.dbtlearn.src_reviews' was properly closed.
[0m14:30:50.162365 [info ] [MainThread]: 
[0m14:30:50.163445 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 3.40 seconds (3.40s).
[0m14:30:50.164656 [debug] [MainThread]: Command end result
[0m14:30:50.172658 [info ] [MainThread]: 
[0m14:30:50.174166 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:30:50.174166 [info ] [MainThread]: 
[0m14:30:50.175898 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m14:30:50.176905 [debug] [MainThread]: Command `dbt run` succeeded at 14:30:50.176905 after 4.06 seconds
[0m14:30:50.177904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB33E11010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3A7CA790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3410FD50>]}
[0m14:30:50.178906 [debug] [MainThread]: Flushing usage events
[0m14:35:40.970476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52FA1D0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D53351B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533541210>]}


============================== 14:35:40.974475 | 9b4809fe-fb41-4c61-b1aa-76904a89487e ==============================
[0m14:35:40.974475 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:35:40.975479 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:35:41.271089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D532D70A50>]}
[0m14:35:41.355146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D532D42B90>]}
[0m14:35:41.357116 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:35:41.365747 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:35:41.478662 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:35:41.479667 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m14:35:41.659839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533817D90>]}
[0m14:35:41.673038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5339033D0>]}
[0m14:35:41.673038 [info ] [MainThread]: Found 3 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:35:41.674043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5337B4CD0>]}
[0m14:35:41.675078 [info ] [MainThread]: 
[0m14:35:41.677593 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:35:41.679992 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:35:41.693031 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:35:41.695023 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:35:41.695023 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:35:43.017657 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:35:43.020658 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:35:43.023688 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:35:43.032687 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:35:43.034195 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:35:43.036108 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:35:43.241126 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.243118 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:35:43.244117 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:35:43.286680 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m14:35:43.287923 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:35:43.321898 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:35:43.327315 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.327315 [debug] [MainThread]: On master: BEGIN
[0m14:35:43.328318 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:35:43.536410 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.537297 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.538296 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:35:43.599176 [debug] [MainThread]: SQL status: SELECT 2 in 0.0 seconds
[0m14:35:43.601480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5339DEA50>]}
[0m14:35:43.602480 [debug] [MainThread]: On master: ROLLBACK
[0m14:35:43.631071 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.632037 [debug] [MainThread]: On master: BEGIN
[0m14:35:43.689808 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.690810 [debug] [MainThread]: On master: COMMIT
[0m14:35:43.690810 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.691805 [debug] [MainThread]: On master: COMMIT
[0m14:35:43.726491 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:35:43.726491 [debug] [MainThread]: On master: Close
[0m14:35:43.727497 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:35:43.728498 [info ] [MainThread]: 
[0m14:35:43.732841 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:35:43.733838 [info ] [Thread-1 (]: 1 of 3 START sql view model test.src_hosts ..................................... [RUN]
[0m14:35:43.734835 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:35:43.735840 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:35:43.744022 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:35:43.749713 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:35:43.736837 => 14:35:43.749713
[0m14:35:43.750745 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:35:43.796399 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:35:43.799369 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:43.800399 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:35:43.800399 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:35:43.992193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.993197 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:43.993197 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:35:44.040502 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.047050 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.048057 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:35:44.079529 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.092615 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:35:44.093620 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.093620 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:35:44.126404 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:44.133167 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:35:44.139163 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.139163 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:35:44.169136 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:44.171173 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:35:43.751715 => 14:35:44.171173
[0m14:35:44.171173 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:35:44.172169 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D534A77190>]}
[0m14:35:44.173170 [info ] [Thread-1 (]: 1 of 3 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.44s]
[0m14:35:44.174146 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:35:44.175170 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:35:44.176136 [info ] [Thread-1 (]: 2 of 3 START sql view model test.src_listings .................................. [RUN]
[0m14:35:44.177650 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:35:44.177650 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:35:44.180658 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:35:44.182649 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:35:44.178648 => 14:35:44.181649
[0m14:35:44.183648 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:35:44.189730 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:35:44.191735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.192725 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:35:44.193725 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:35:44.418402 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:44.419446 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.419446 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:35:44.469960 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.473926 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.474927 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:35:44.511903 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.515627 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.517624 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:35:44.552272 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.556299 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:35:44.557267 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.557267 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:35:44.591761 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:44.594762 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:35:44.595728 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.596728 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:35:44.634902 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:44.636916 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:35:44.183648 => 14:35:44.636916
[0m14:35:44.637914 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:35:44.638946 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D534A982D0>]}
[0m14:35:44.639912 [info ] [Thread-1 (]: 2 of 3 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m14:35:44.640912 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:35:44.640912 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:35:44.641912 [info ] [Thread-1 (]: 3 of 3 START sql view model test.src_reviews ................................... [RUN]
[0m14:35:44.642915 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:35:44.643911 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:35:44.645417 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:35:44.647420 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:35:44.643911 => 14:35:44.646418
[0m14:35:44.648427 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:35:44.652419 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:35:44.654421 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.655421 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:35:44.656931 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:35:44.885384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:44.886361 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.886361 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:35:44.936182 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.940182 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.941183 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:35:44.975771 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.979767 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.979767 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:35:45.014788 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:45.018563 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:35:45.019077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:45.019592 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:35:45.053276 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:45.056452 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:35:45.058052 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:45.058586 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:35:45.094662 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:45.096215 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:35:44.648427 => 14:35:45.096215
[0m14:35:45.096731 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:35:45.097796 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5336ADB50>]}
[0m14:35:45.098402 [info ] [Thread-1 (]: 3 of 3 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:35:45.100411 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:35:45.102920 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:45.103919 [debug] [MainThread]: On master: BEGIN
[0m14:35:45.104247 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:35:45.330162 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:45.331153 [debug] [MainThread]: On master: COMMIT
[0m14:35:45.331153 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:45.332248 [debug] [MainThread]: On master: COMMIT
[0m14:35:45.368397 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:35:45.369177 [debug] [MainThread]: On master: Close
[0m14:35:45.370169 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:35:45.371170 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:35:45.371170 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:35:45.372164 [debug] [MainThread]: Connection 'model.dbtlearn.src_reviews' was properly closed.
[0m14:35:45.372164 [info ] [MainThread]: 
[0m14:35:45.373163 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 3.70 seconds (3.70s).
[0m14:35:45.375197 [debug] [MainThread]: Command end result
[0m14:35:45.388363 [info ] [MainThread]: 
[0m14:35:45.388363 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:35:45.390902 [info ] [MainThread]: 
[0m14:35:45.392012 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m14:35:45.394008 [debug] [MainThread]: Command `dbt run` succeeded at 14:35:45.394008 after 4.49 seconds
[0m14:35:45.395007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533342150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52C0D4390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52C15EF90>]}
[0m14:35:45.396009 [debug] [MainThread]: Flushing usage events
[0m14:57:14.650571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE0EB050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCCD34F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCC6BC810>]}


============================== 14:57:14.654080 | ee50d8b0-c9e3-4a50-a08c-489bcf38536d ==============================
[0m14:57:14.654080 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:57:14.656288 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:57:14.870865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCDB60CD0>]}
[0m14:57:14.947529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC6A25B90>]}
[0m14:57:14.949171 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:57:14.957031 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:57:14.980251 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:57:14.981057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE13FCD0>]}
[0m14:57:15.805139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE4B8F10>]}
[0m14:57:15.817681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF64DD50>]}
[0m14:57:15.817681 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:57:15.819197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE5F7950>]}
[0m14:57:15.821879 [info ] [MainThread]: 
[0m14:57:15.822847 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:57:15.824240 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:57:15.834774 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:57:15.835795 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:57:15.835795 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:17.185752 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:57:17.186746 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:57:17.189255 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:57:17.194765 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:17.194765 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:57:17.195767 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:17.385859 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.386902 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:17.386902 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:57:17.434139 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:57:17.435933 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:57:17.465437 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:57:17.471040 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.472040 [debug] [MainThread]: On master: BEGIN
[0m14:57:17.472040 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:57:17.663341 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.663341 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.664376 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:57:17.727931 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:57:17.729813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE3A0550>]}
[0m14:57:17.731130 [debug] [MainThread]: On master: ROLLBACK
[0m14:57:17.759512 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.760386 [debug] [MainThread]: On master: BEGIN
[0m14:57:17.820097 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.821099 [debug] [MainThread]: On master: COMMIT
[0m14:57:17.822104 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.822104 [debug] [MainThread]: On master: COMMIT
[0m14:57:17.849954 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:17.851074 [debug] [MainThread]: On master: Close
[0m14:57:17.853325 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:57:17.855337 [info ] [MainThread]: 
[0m14:57:17.861343 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:57:17.862328 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:57:17.864543 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:57:17.865560 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:57:17.872540 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:57:17.875615 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:57:17.865560 => 14:57:17.875615
[0m14:57:17.876626 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:57:17.919083 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:57:17.922053 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:17.923217 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:57:17.923580 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:57:18.112282 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:18.113055 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.113055 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:57:18.161309 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:18.168327 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.169328 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:57:18.199224 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.202265 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.203265 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:57:18.234931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.249967 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:57:18.250967 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.250967 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:57:18.280439 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:18.286475 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:57:18.291476 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.291476 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:57:18.327027 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:18.329035 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:57:17.877618 => 14:57:18.328041
[0m14:57:18.329035 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:57:18.330034 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE63B390>]}
[0m14:57:18.331548 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.47s]
[0m14:57:18.332553 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:57:18.333554 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:57:18.333554 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:57:18.335587 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:57:18.335587 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:57:18.337589 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:57:18.339554 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:57:18.336573 => 14:57:18.338588
[0m14:57:18.340554 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:57:18.346592 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:57:18.349600 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.350603 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:57:18.350603 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:18.565238 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:18.566243 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.567239 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:57:18.616003 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:18.619997 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.621007 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:57:18.656783 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.660171 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.660733 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:57:18.694742 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.697745 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:57:18.698743 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.698743 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:57:18.732438 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:18.735478 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:57:18.736478 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.737445 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:57:18.776513 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:18.777521 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:57:18.340554 => 14:57:18.777521
[0m14:57:18.778519 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:57:18.779519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE609C50>]}
[0m14:57:18.780519 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.44s]
[0m14:57:18.781519 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:57:18.782521 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:57:18.783519 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:57:18.784520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:57:18.785519 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:57:18.787518 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:57:18.789031 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:57:18.785519 => 14:57:18.789031
[0m14:57:18.790032 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:57:18.795031 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:57:18.797031 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:18.798033 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:57:18.799543 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:19.010800 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.011808 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.011808 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:57:19.062730 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:19.066462 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.066462 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:57:19.103388 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:19.108205 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.108205 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:57:19.143069 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:19.145074 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:57:19.146075 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.146075 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:57:19.181582 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:19.184615 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:57:19.185687 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.185687 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:57:19.220306 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:19.222589 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:57:18.790032 => 14:57:19.222589
[0m14:57:19.223618 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:57:19.224618 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF713490>]}
[0m14:57:19.224618 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.44s]
[0m14:57:19.226584 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:57:19.226584 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.227583 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:57:19.229621 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:57:19.229621 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.232708 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.235219 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:57:19.230617 => 14:57:19.235219
[0m14:57:19.236222 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.261895 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.263897 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.264902 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:57:19.265896 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:19.511072 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.512073 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.513078 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    listing_id,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:57:19.558268 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "listing_id" does not exist
LINE 20:     listing_id,
             ^
HINT:  Perhaps you meant to reference the column "src_listings.listing_url".

[0m14:57:19.558268 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:57:19.597294 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:57:19.236222 => 14:57:19.597294
[0m14:57:19.598298 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:57:19.603322 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "listing_id" does not exist
  LINE 20:     listing_id,
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.listing_url".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:57:19.603322 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE5D5110>]}
[0m14:57:19.604828 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.37s]
[0m14:57:19.606536 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.607552 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:19.608546 [debug] [MainThread]: On master: BEGIN
[0m14:57:19.608546 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:57:19.831417 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.833440 [debug] [MainThread]: On master: COMMIT
[0m14:57:19.833903 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:19.834446 [debug] [MainThread]: On master: COMMIT
[0m14:57:19.865604 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:19.865604 [debug] [MainThread]: On master: Close
[0m14:57:19.866608 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:57:19.867608 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:57:19.867608 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:57:19.869115 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:57:19.869642 [info ] [MainThread]: 
[0m14:57:19.870644 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 4.05 seconds (4.05s).
[0m14:57:19.871644 [debug] [MainThread]: Command end result
[0m14:57:19.882185 [info ] [MainThread]: 
[0m14:57:19.883586 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:57:19.884586 [info ] [MainThread]: 
[0m14:57:19.885583 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "listing_id" does not exist
  LINE 20:     listing_id,
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.listing_url".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:57:19.887584 [info ] [MainThread]: 
[0m14:57:19.888585 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:57:19.890585 [debug] [MainThread]: Command `dbt run` failed at 14:57:19.890585 after 5.32 seconds
[0m14:57:19.891584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC69E1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF657D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC6CDFD50>]}
[0m14:57:19.893657 [debug] [MainThread]: Flushing usage events
[0m14:58:08.634756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E3544D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E344210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E578DD0>]}


============================== 14:58:08.638373 | 2c8c0016-689d-44d0-8a17-1057e02aeb07 ==============================
[0m14:58:08.638373 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:58:08.639375 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:58:08.852442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E882050>]}
[0m14:58:08.937064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E344350>]}
[0m14:58:08.939158 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:58:08.948121 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:58:09.044040 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:58:09.045010 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:09.206484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E9276D0>]}
[0m14:58:09.220209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EC19950>]}
[0m14:58:09.220209 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:58:09.221649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EA83B10>]}
[0m14:58:09.223682 [info ] [MainThread]: 
[0m14:58:09.224652 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:58:09.227315 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:58:09.239338 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:58:09.240338 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:58:09.241370 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:10.567269 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:58:10.569273 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:58:10.571271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:58:10.577267 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:10.578266 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:58:10.578772 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:10.779414 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:58:10.780450 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:10.780450 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:58:10.829247 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:58:10.831289 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:58:10.860231 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:58:10.865133 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:10.866671 [debug] [MainThread]: On master: BEGIN
[0m14:58:10.866671 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:58:11.057291 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.058324 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.058836 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:58:11.122496 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:58:11.124579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2ED40C50>]}
[0m14:58:11.125622 [debug] [MainThread]: On master: ROLLBACK
[0m14:58:11.154022 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.154572 [debug] [MainThread]: On master: BEGIN
[0m14:58:11.210444 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.211251 [debug] [MainThread]: On master: COMMIT
[0m14:58:11.211251 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.212243 [debug] [MainThread]: On master: COMMIT
[0m14:58:11.237880 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:11.237880 [debug] [MainThread]: On master: Close
[0m14:58:11.239390 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:58:11.240374 [info ] [MainThread]: 
[0m14:58:11.243396 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:58:11.244397 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:58:11.245397 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:58:11.246399 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:58:11.253061 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:58:11.256062 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:58:11.246399 => 14:58:11.255061
[0m14:58:11.257060 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:58:11.291964 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:58:11.293966 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.294965 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:58:11.295967 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:58:11.495613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.496490 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.497488 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:58:11.542539 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:11.548802 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.549807 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:58:11.580122 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:11.584126 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.585123 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:58:11.619216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:11.642311 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:11.643313 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.644311 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:11.678478 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:11.686518 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:58:11.691522 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.692523 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:58:11.724827 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:11.726833 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:58:11.257060 => 14:58:11.725833
[0m14:58:11.727850 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:58:11.728834 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EAC7910>]}
[0m14:58:11.729833 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.48s]
[0m14:58:11.730836 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:58:11.732338 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:58:11.732785 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:58:11.733343 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:58:11.734382 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:58:11.736377 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:58:11.738348 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:58:11.735378 => 14:58:11.737350
[0m14:58:11.738348 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:58:11.742348 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:58:11.744371 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:11.745381 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:58:11.746377 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:11.960449 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.961570 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:11.961570 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:58:12.006706 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:12.010492 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.011491 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:58:12.042743 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.045688 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.046691 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:58:12.079485 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.082759 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:12.082759 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.083759 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:12.113994 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:12.116572 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:58:12.118660 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.119629 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:58:12.151095 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:12.153192 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:58:11.739349 => 14:58:12.153192
[0m14:58:12.154198 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:58:12.155197 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2ED168D0>]}
[0m14:58:12.155197 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.42s]
[0m14:58:12.157199 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:58:12.157199 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:58:12.158225 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:58:12.159203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:58:12.160231 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:58:12.162196 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:58:12.163197 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:58:12.160231 => 14:58:12.163197
[0m14:58:12.163197 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:58:12.169291 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:58:12.171296 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.172292 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:58:12.173292 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:12.375260 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:12.376272 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.376272 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:58:12.420661 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:12.423694 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.424665 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:58:12.455491 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.459386 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.459386 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:58:12.489985 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.493572 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:12.493572 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.494572 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:12.525000 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:12.529232 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:58:12.530232 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.531210 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:58:12.563057 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:12.565062 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:58:12.164701 => 14:58:12.565062
[0m14:58:12.565062 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:58:12.566061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2FE66450>]}
[0m14:58:12.567063 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:58:12.568066 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:58:12.569101 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.569101 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:58:12.570084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:58:12.571097 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.573637 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.574639 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:58:12.571097 => 14:58:12.574639
[0m14:58:12.575640 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.598781 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.600782 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.601784 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:58:12.601784 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:12.824343 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:12.825661 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.825661 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:58:12.870070 [debug] [Thread-1 (]: Postgres adapter: Postgres error: type "number" does not exist
LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                       ^

[0m14:58:12.871028 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:58:12.902215 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:58:12.575640 => 14:58:12.902215
[0m14:58:12.903045 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:58:12.908042 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  type "number" does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                         ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:12.908042 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2FE3F650>]}
[0m14:58:12.910063 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.34s]
[0m14:58:12.911069 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.913103 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:12.913103 [debug] [MainThread]: On master: BEGIN
[0m14:58:12.914069 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:58:13.133413 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:13.134401 [debug] [MainThread]: On master: COMMIT
[0m14:58:13.135393 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:13.135393 [debug] [MainThread]: On master: COMMIT
[0m14:58:13.164936 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:13.165937 [debug] [MainThread]: On master: Close
[0m14:58:13.166938 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:58:13.167937 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:58:13.167937 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:58:13.168939 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:58:13.168939 [info ] [MainThread]: 
[0m14:58:13.169939 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 3.95 seconds (3.95s).
[0m14:58:13.170937 [debug] [MainThread]: Command end result
[0m14:58:13.183403 [info ] [MainThread]: 
[0m14:58:13.184403 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:58:13.186434 [info ] [MainThread]: 
[0m14:58:13.187441 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  type "number" does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                         ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:13.189442 [info ] [MainThread]: 
[0m14:58:13.191443 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:58:13.193442 [debug] [MainThread]: Command `dbt run` failed at 14:58:13.193442 after 4.62 seconds
[0m14:58:13.194444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D27101010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E053950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2B484710>]}
[0m14:58:13.195442 [debug] [MainThread]: Flushing usage events
[0m14:58:54.653131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94063FF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E93F455310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E59990>]}


============================== 14:58:54.658281 | c52e07fe-be0c-4485-be5c-a736a9ce7841 ==============================
[0m14:58:54.658281 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:58:54.659281 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:58:54.956733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E28250>]}
[0m14:58:55.057299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94101DA10>]}
[0m14:58:55.058854 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:58:55.070514 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:58:55.178690 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:58:55.179690 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:55.375045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940951510>]}
[0m14:58:55.390748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94132E810>]}
[0m14:58:55.391738 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:58:55.392735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941105790>]}
[0m14:58:55.394821 [info ] [MainThread]: 
[0m14:58:55.395827 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:58:55.398828 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:58:55.408168 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:58:55.409168 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:58:55.410170 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:56.786136 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:58:56.787974 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:58:56.789521 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:58:56.795554 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:56.795554 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:58:56.796518 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:57.026805 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.026805 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:57.028135 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:58:57.082321 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:58:57.084365 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:58:57.117185 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:58:57.122984 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.122984 [debug] [MainThread]: On master: BEGIN
[0m14:58:57.124488 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:58:57.339370 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.339370 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.340917 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:58:57.405158 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:58:57.407152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9412F6F50>]}
[0m14:58:57.408152 [debug] [MainThread]: On master: ROLLBACK
[0m14:58:57.445050 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.445050 [debug] [MainThread]: On master: BEGIN
[0m14:58:57.505997 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.507015 [debug] [MainThread]: On master: COMMIT
[0m14:58:57.508010 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.508010 [debug] [MainThread]: On master: COMMIT
[0m14:58:57.535215 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:57.536225 [debug] [MainThread]: On master: Close
[0m14:58:57.537221 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:58:57.538220 [info ] [MainThread]: 
[0m14:58:57.542223 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:58:57.543223 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:58:57.545224 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:58:57.545224 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:58:57.552847 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:58:57.555853 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:58:57.546275 => 14:58:57.554858
[0m14:58:57.556851 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:58:57.592380 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:58:57.595079 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.596120 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:58:57.596120 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:58:57.792739 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.792739 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.793776 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:58:57.838741 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:57.845542 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.845542 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:58:57.877611 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:57.882123 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.882123 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:58:57.916076 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:57.931852 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:57.932851 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.932851 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:57.963329 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:57.969879 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:58:57.973874 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.974874 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:58:58.006736 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.008743 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:58:57.556851 => 14:58:58.008743
[0m14:58:58.008743 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:58:58.010743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9411FB450>]}
[0m14:58:58.010743 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.47s]
[0m14:58:58.012744 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:58:58.012744 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:58:58.013742 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:58:58.014913 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:58:58.015917 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:58:58.017921 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:58:58.019938 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:58:58.015917 => 14:58:58.019938
[0m14:58:58.020919 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:58:58.027451 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:58:58.029451 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.030471 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:58:58.031464 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:58.205063 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:58.205828 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.207067 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:58:58.252504 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:58.256511 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.256511 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:58:58.287752 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.291466 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.291466 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:58:58.320488 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.322461 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:58.323460 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.324460 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:58.354301 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:58.357828 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:58:58.358828 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.358828 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:58:58.390988 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.392751 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:58:58.020919 => 14:58:58.392751
[0m14:58:58.393752 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:58:58.394785 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941392A10>]}
[0m14:58:58.394785 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m14:58:58.396751 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:58:58.396751 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:58:58.398255 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:58:58.399267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:58:58.400272 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:58:58.402270 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:58:58.404274 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:58:58.400272 => 14:58:58.404274
[0m14:58:58.405272 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:58:58.410782 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:58:58.413791 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.414790 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:58:58.414790 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:58.595749 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:58.596756 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.596756 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:58:58.640610 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:58.643616 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.644616 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:58:58.674356 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.678016 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.678016 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:58:58.709181 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.712218 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:58.712218 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.713213 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:58.744139 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:58.747812 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:58:58.748821 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.749819 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:58:58.782099 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.784189 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:58:58.405272 => 14:58:58.784189
[0m14:58:58.785202 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:58:58.786189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941476BD0>]}
[0m14:58:58.786189 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.39s]
[0m14:58:58.787319 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:58:58.788359 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.789328 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:58:58.791087 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:58:58.791087 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.794051 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.795573 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:58:58.792106 => 14:58:58.795573
[0m14:58:58.796575 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.822288 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.825259 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.825259 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:58:58.826257 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:59.019282 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:59.020276 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:59.020276 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:58:59.059634 [debug] [Thread-1 (]: Postgres adapter: Postgres error: function replace(text, unknown) does not exist
LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
             ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m14:58:59.060641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:58:59.088666 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:58:58.796575 => 14:58:59.088666
[0m14:58:59.089696 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:58:59.093664 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  function replace(text, unknown) does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:59.095202 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94142CDD0>]}
[0m14:58:59.096179 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.31s]
[0m14:58:59.097431 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:58:59.098438 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:59.099470 [debug] [MainThread]: On master: BEGIN
[0m14:58:59.100470 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:58:59.280985 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:59.281962 [debug] [MainThread]: On master: COMMIT
[0m14:58:59.281962 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:59.282918 [debug] [MainThread]: On master: COMMIT
[0m14:58:59.309027 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:59.309027 [debug] [MainThread]: On master: Close
[0m14:58:59.310075 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:58:59.312860 [info ] [MainThread]: 
[0m14:58:59.313868 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 3.92 seconds (3.92s).
[0m14:58:59.314884 [debug] [MainThread]: Command end result
[0m14:58:59.324371 [info ] [MainThread]: 
[0m14:58:59.326377 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:58:59.326377 [info ] [MainThread]: 
[0m14:58:59.327380 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  function replace(text, unknown) does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:59.329379 [info ] [MainThread]: 
[0m14:58:59.330378 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:58:59.333381 [debug] [MainThread]: Command `dbt run` failed at 14:58:59.332387 after 4.76 seconds
[0m14:58:59.334383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E62150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9395DE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9396A6810>]}
[0m14:58:59.334383 [debug] [MainThread]: Flushing usage events
[0m14:59:50.993696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A60A1250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A56F2E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6112610>]}


============================== 14:59:50.998212 | 7d9c0351-338b-49aa-84cd-816b84e4922a ==============================
[0m14:59:50.998212 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:59:50.999216 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:59:51.208561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A65B0810>]}
[0m14:59:51.284538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A667EC90>]}
[0m14:59:51.286540 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:59:51.294541 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:59:51.391129 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:59:51.392129 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:51.569458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A68B0AD0>]}
[0m14:59:51.582652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A682F910>]}
[0m14:59:51.584165 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:59:51.585202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A60875D0>]}
[0m14:59:51.587209 [info ] [MainThread]: 
[0m14:59:51.588207 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:59:51.590211 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:59:51.599641 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:59:51.600642 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:59:51.600642 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:52.957813 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:59:52.959806 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:59:52.961804 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:59:52.967189 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:52.967789 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:59:52.967789 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:53.203567 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.204578 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:53.204578 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:59:53.254035 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:59:53.255327 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:59:53.289143 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:59:53.294233 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.295231 [debug] [MainThread]: On master: BEGIN
[0m14:59:53.295231 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:59:53.491330 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.491330 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.492376 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:59:53.555404 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:59:53.558011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6826350>]}
[0m14:59:53.558011 [debug] [MainThread]: On master: ROLLBACK
[0m14:59:53.587367 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.587367 [debug] [MainThread]: On master: BEGIN
[0m14:59:53.643860 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.643860 [debug] [MainThread]: On master: COMMIT
[0m14:59:53.644899 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.645892 [debug] [MainThread]: On master: COMMIT
[0m14:59:53.680155 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:53.680155 [debug] [MainThread]: On master: Close
[0m14:59:53.681168 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:59:53.682461 [info ] [MainThread]: 
[0m14:59:53.686466 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:59:53.687470 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:59:53.688885 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:59:53.688885 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:59:53.696444 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:59:53.699913 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:59:53.689887 => 14:59:53.699403
[0m14:59:53.700510 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:59:53.737270 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:59:53.739274 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.739274 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:59:53.740272 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:59:53.935844 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.936367 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.936896 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:59:53.984069 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:53.990503 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.991501 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:59:54.019376 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.022403 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.023948 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:59:54.054309 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.069828 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:59:54.070824 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.070824 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:59:54.102435 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:54.109217 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:59:54.113217 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.114217 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:59:54.146318 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:54.148357 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:59:53.700510 => 14:59:54.148357
[0m14:59:54.149357 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:59:54.150357 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6A65E90>]}
[0m14:59:54.150357 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.46s]
[0m14:59:54.152325 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:59:54.153324 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:59:54.153324 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:59:54.155360 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:59:54.155360 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:59:54.157432 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:59:54.159466 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:59:54.156326 => 14:59:54.159466
[0m14:59:54.160441 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:59:54.165484 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:59:54.167438 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.169045 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:59:54.170047 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:54.403716 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:54.404715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.404715 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:59:54.454427 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:54.458936 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.458936 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:59:54.493124 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.496758 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.496758 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:59:54.531722 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.534730 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:59:54.534730 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.535732 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:59:54.572000 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:54.574993 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:59:54.575994 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.576994 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:59:54.613999 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:54.615042 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:59:54.160441 => 14:59:54.615042
[0m14:59:54.616042 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:59:54.617039 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6B41810>]}
[0m14:59:54.618007 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m14:59:54.619005 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:59:54.620008 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:59:54.620008 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:59:54.622005 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:59:54.622005 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:59:54.624004 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:59:54.626079 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:59:54.623004 => 14:59:54.625512
[0m14:59:54.626079 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:59:54.631191 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:59:54.633215 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.634198 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:59:54.635203 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:54.862711 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:54.863702 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.863702 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:59:54.914340 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:54.918177 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.919147 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:59:54.953876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.957715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.958712 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:59:54.990748 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.992749 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:59:54.992749 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.993751 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:59:55.026273 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:55.031020 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:59:55.032059 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:55.032059 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:59:55.067847 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:55.069845 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:59:54.626079 => 14:59:55.069845
[0m14:59:55.070348 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:59:55.071363 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6BD67D0>]}
[0m14:59:55.072368 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:59:55.073368 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:59:55.074371 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.074371 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:59:55.076369 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:59:55.076369 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.079402 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.081385 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:59:55.077368 => 14:59:55.080402
[0m14:59:55.081890 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.107903 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.109903 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.109903 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:59:55.110903 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:55.332793 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:55.334298 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.335307 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:59:55.378446 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "updatede_at" does not exist
LINE 30:     updatede_at
             ^
HINT:  Perhaps you meant to reference the column "src_listings.updated_at".

[0m14:59:55.379447 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:59:55.418095 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:59:55.082899 => 14:59:55.416587
[0m14:59:55.419627 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:59:55.430145 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "updatede_at" does not exist
  LINE 30:     updatede_at
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:55.430670 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6BD9BD0>]}
[0m14:59:55.432679 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.36s]
[0m14:59:55.434678 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.437679 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:55.438678 [debug] [MainThread]: On master: BEGIN
[0m14:59:55.439677 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:59:55.667203 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:55.668204 [debug] [MainThread]: On master: COMMIT
[0m14:59:55.669587 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:55.671095 [debug] [MainThread]: On master: COMMIT
[0m14:59:55.702340 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:55.703340 [debug] [MainThread]: On master: Close
[0m14:59:55.704345 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:59:55.705344 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:59:55.706850 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:59:55.707838 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:59:55.708861 [info ] [MainThread]: 
[0m14:59:55.709859 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m14:59:55.712855 [debug] [MainThread]: Command end result
[0m14:59:55.724591 [info ] [MainThread]: 
[0m14:59:55.727593 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:59:55.729591 [info ] [MainThread]: 
[0m14:59:55.730593 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "updatede_at" does not exist
  LINE 30:     updatede_at
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:55.731674 [info ] [MainThread]: 
[0m14:59:55.733839 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:59:55.739841 [debug] [MainThread]: Command `dbt run` failed at 14:59:55.738839 after 4.81 seconds
[0m14:59:55.740840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002939EDE1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A5DB5850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A5DB5DD0>]}
[0m14:59:55.742842 [debug] [MainThread]: Flushing usage events
[0m15:00:07.871689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DE8DD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830CAD5150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830A38C490>]}


============================== 15:00:07.875687 | 15f63cf1-32ae-46ff-8b62-81075beb7f18 ==============================
[0m15:00:07.875687 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:00:07.876686 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:00:08.086575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DEE2050>]}
[0m15:00:08.161938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DFDC310>]}
[0m15:00:08.163901 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:00:08.173943 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:00:08.270209 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:00:08.271211 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m15:00:08.441083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E1FCE90>]}
[0m15:00:08.461114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E27D810>]}
[0m15:00:08.462113 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:00:08.463112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E1CE810>]}
[0m15:00:08.466114 [info ] [MainThread]: 
[0m15:00:08.468117 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:00:08.470616 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:00:08.488172 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:00:08.489148 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:00:08.490146 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:08.718420 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:00:08.720420 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:00:08.722387 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:00:08.729133 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:00:08.730166 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:00:08.730166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:08.910933 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:00:08.910933 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:00:08.911930 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:00:08.957759 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m15:00:08.959798 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:00:08.988020 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:00:08.993849 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:08.993849 [debug] [MainThread]: On master: BEGIN
[0m15:00:08.994815 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:00:09.184392 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.184910 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.185944 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:00:09.237947 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:00:09.240430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F3C0790>]}
[0m15:00:09.240430 [debug] [MainThread]: On master: ROLLBACK
[0m15:00:09.270708 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.271714 [debug] [MainThread]: On master: BEGIN
[0m15:00:09.328884 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.329900 [debug] [MainThread]: On master: COMMIT
[0m15:00:09.329900 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.330898 [debug] [MainThread]: On master: COMMIT
[0m15:00:09.357073 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:00:09.358081 [debug] [MainThread]: On master: Close
[0m15:00:09.359079 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:00:09.360239 [info ] [MainThread]: 
[0m15:00:09.363243 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:00:09.364245 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m15:00:09.365245 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:00:09.366245 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:00:09.372756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:00:09.375758 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:00:09.366245 => 15:00:09.374760
[0m15:00:09.376771 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:00:09.413576 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:00:09.415597 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.416547 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:00:09.416547 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:00:09.599723 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.600836 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.600836 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:00:09.642463 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:09.651644 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.652644 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:00:09.685874 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:09.689880 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.690881 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:00:09.720320 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:09.735525 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:00:09.736524 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.737524 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:00:09.765327 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:09.771378 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:00:09.776378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.777371 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:00:09.808308 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:09.810342 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:00:09.376771 => 15:00:09.810342
[0m15:00:09.811329 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:00:09.812343 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E13FFD0>]}
[0m15:00:09.813309 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.45s]
[0m15:00:09.814308 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:00:09.815822 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:00:09.815822 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m15:00:09.817212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:00:09.818246 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:00:09.820243 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:00:09.821214 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:00:09.818246 => 15:00:09.821214
[0m15:00:09.822212 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:00:09.826243 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:00:09.828326 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:09.829368 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:00:09.830346 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.006647 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.008683 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.009199 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:00:10.048525 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:10.052524 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.053526 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:00:10.087493 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.090487 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.091487 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:00:10.121727 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.124721 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:00:10.125724 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.126721 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:00:10.156397 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:10.159397 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:00:10.160397 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.161395 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:00:10.195267 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:10.199262 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:00:09.822212 => 15:00:10.198259
[0m15:00:10.200261 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:00:10.201776 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F422B10>]}
[0m15:00:10.202772 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m15:00:10.203772 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:00:10.203772 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:00:10.204773 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m15:00:10.205773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:00:10.206771 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:00:10.208771 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:00:10.210771 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:00:10.206771 => 15:00:10.210771
[0m15:00:10.210771 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:00:10.215806 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:00:10.217808 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.217808 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:00:10.218842 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.404553 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.404553 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.404553 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:00:10.447362 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:10.451227 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.451227 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:00:10.488796 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.492297 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.493297 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:00:10.524031 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.526056 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:00:10.527056 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.527056 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:00:10.559587 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:10.563682 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:00:10.564679 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.565713 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:00:10.599341 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:10.601347 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:00:10.210771 => 15:00:10.601347
[0m15:00:10.601347 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:00:10.602348 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F4C6A50>]}
[0m15:00:10.603347 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.40s]
[0m15:00:10.604351 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:00:10.605385 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.606347 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:00:10.607349 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m15:00:10.607349 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.610374 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.612375 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:00:10.607349 => 15:00:10.611374
[0m15:00:10.612375 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.635173 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.638576 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.641580 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:00:10.643592 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.847334 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.849346 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.850887 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:00:10.967836 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:00:10.971360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.972358 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:00:11.000999 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:11.006697 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:00:11.007868 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:11.008836 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:00:11.038332 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:11.042932 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:00:11.046361 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:11.046361 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:00:11.077018 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:00:11.079232 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:00:10.613374 => 15:00:11.079232
[0m15:00:11.080232 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:00:11.081267 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F3D8450>]}
[0m15:00:11.081267 [info ] [Thread-1 (]: 4 of 4 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.47s]
[0m15:00:11.083233 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:00:11.085232 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:11.085232 [debug] [MainThread]: On master: BEGIN
[0m15:00:11.086272 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:00:11.272963 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:11.273964 [debug] [MainThread]: On master: COMMIT
[0m15:00:11.274965 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:11.274965 [debug] [MainThread]: On master: COMMIT
[0m15:00:11.303017 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:00:11.304171 [debug] [MainThread]: On master: Close
[0m15:00:11.305793 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:00:11.306306 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:00:11.307348 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:00:11.308428 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:00:11.309472 [info ] [MainThread]: 
[0m15:00:11.310567 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 2.84 seconds (2.84s).
[0m15:00:11.312743 [debug] [MainThread]: Command end result
[0m15:00:11.324359 [info ] [MainThread]: 
[0m15:00:11.325470 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:00:11.327170 [info ] [MainThread]: 
[0m15:00:11.328795 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m15:00:11.330333 [debug] [MainThread]: Command `dbt run` succeeded at 15:00:11.330333 after 3.52 seconds
[0m15:00:11.330333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018306701010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830D6B2550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183069EFED0>]}
[0m15:00:11.331871 [debug] [MainThread]: Flushing usage events
[0m15:08:21.198391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C723810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C2E93D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C6EAAD0>]}


============================== 15:08:21.201903 | 9bdd196a-2021-4bec-bb96-0e65581100dc ==============================
[0m15:08:21.201903 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:08:21.202935 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:08:21.414590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C246710>]}
[0m15:08:21.494253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C82FF10>]}
[0m15:08:21.496567 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:08:21.504602 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:08:21.610884 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m15:08:21.611885 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:21.611885 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m15:08:21.781410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C1F9210>]}
[0m15:08:21.794897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CBCBCD0>]}
[0m15:08:21.794897 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:08:21.795897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CC2D6D0>]}
[0m15:08:21.797925 [info ] [MainThread]: 
[0m15:08:21.798939 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:08:21.802027 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:08:21.813960 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:08:21.815257 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:08:21.816235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:22.051920 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:08:22.052960 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:08:22.055158 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:08:22.061161 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:08:22.062162 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:08:22.062162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:22.262932 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.262932 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:08:22.263973 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:08:22.310785 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:08:22.312827 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:08:22.341545 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:08:22.347803 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.348837 [debug] [MainThread]: On master: BEGIN
[0m15:08:22.349803 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:08:22.555755 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.556770 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.556770 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:08:22.621778 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:08:22.623785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CA7ACD0>]}
[0m15:08:22.624796 [debug] [MainThread]: On master: ROLLBACK
[0m15:08:22.655537 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.655537 [debug] [MainThread]: On master: BEGIN
[0m15:08:22.714120 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.715347 [debug] [MainThread]: On master: COMMIT
[0m15:08:22.715347 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.716354 [debug] [MainThread]: On master: COMMIT
[0m15:08:22.741300 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:08:22.742205 [debug] [MainThread]: On master: Close
[0m15:08:22.743215 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:08:22.744198 [info ] [MainThread]: 
[0m15:08:22.747422 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.748429 [info ] [Thread-1 (]: 1 of 5 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:08:22.749936 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:08:22.751014 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.758019 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.760028 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:08:22.752023 => 15:08:22.760028
[0m15:08:22.762022 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.803739 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.805721 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.806707 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:08:22.807705 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:08:23.024835 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.025858 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:23.026363 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        
)
SELECT
    review_id,
	CASE 
        WHEN review_name IS NULL THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:08:23.066839 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ")"
LINE 17: )
         ^

[0m15:08:23.067837 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: ROLLBACK
[0m15:08:23.098622 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:08:22.762536 => 15:08:23.098622
[0m15:08:23.099840 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:08:23.104845 [debug] [Thread-1 (]: Database Error in model dim_hosts_cleansed (dbtlearn/models\dim\dim_hosts_cleansed.sql)
  syntax error at or near ")"
  LINE 17: )
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:23.105843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C873F50>]}
[0m15:08:23.106846 [error] [Thread-1 (]: 1 of 5 ERROR creating sql table model test.dim_hosts_cleansed .................. [[31mERROR[0m in 0.36s]
[0m15:08:23.107388 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:08:23.108428 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:08:23.109396 [info ] [Thread-1 (]: 2 of 5 START sql view model test.src_hosts ..................................... [RUN]
[0m15:08:23.110397 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.src_hosts)
[0m15:08:23.110397 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:08:23.113835 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:08:23.115854 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:08:23.111883 => 15:08:23.114867
[0m15:08:23.115854 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:08:23.139839 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:08:23.142847 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.143843 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:08:23.143843 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:23.372926 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.373933 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.373933 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:08:23.422797 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:23.429290 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.430291 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:08:23.463980 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.467053 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.468019 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:08:23.502636 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.517723 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:08:23.517723 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.519247 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:08:23.552002 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:23.558603 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:08:23.563603 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.563603 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:08:23.604534 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:23.606077 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:08:23.116838 => 15:08:23.606077
[0m15:08:23.607092 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:08:23.608077 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CC45250>]}
[0m15:08:23.609077 [info ] [Thread-1 (]: 2 of 5 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.50s]
[0m15:08:23.609407 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:08:23.610443 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:08:23.611415 [info ] [Thread-1 (]: 3 of 5 START sql view model test.src_listings .................................. [RUN]
[0m15:08:23.612443 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:08:23.612443 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:08:23.614413 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:08:23.616765 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:08:23.613442 => 15:08:23.615413
[0m15:08:23.617778 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:08:23.623762 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:08:23.625766 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.627800 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:08:23.628806 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:23.850110 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.850859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.851856 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:08:23.901612 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:23.905149 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.906148 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:08:23.946216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.949222 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.950221 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:08:23.985099 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.988143 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:08:23.988683 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.989178 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:08:24.023192 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:24.026717 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:08:24.027715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:24.028718 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:08:24.066403 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:24.068551 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:08:23.617778 => 15:08:24.068551
[0m15:08:24.069096 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:08:24.070162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DCC33D0>]}
[0m15:08:24.071191 [info ] [Thread-1 (]: 3 of 5 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m15:08:24.072236 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:08:24.073269 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:08:24.073806 [info ] [Thread-1 (]: 4 of 5 START sql view model test.src_reviews ................................... [RUN]
[0m15:08:24.074845 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:08:24.075955 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:08:24.077511 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:08:24.079032 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:08:24.076475 => 15:08:24.079032
[0m15:08:24.079032 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:08:24.087521 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:08:24.090043 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.091039 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:08:24.092039 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:24.332205 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:24.333213 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.333213 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:08:24.383303 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:24.386814 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.387815 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:08:24.427732 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.431730 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.431730 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:08:24.466992 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.468535 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:08:24.469789 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.470789 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:08:24.505937 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:24.508516 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:08:24.509480 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.510516 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:08:24.548030 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:24.550074 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:08:24.079032 => 15:08:24.549084
[0m15:08:24.550074 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:08:24.551036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DD69CD0>]}
[0m15:08:24.552576 [info ] [Thread-1 (]: 4 of 5 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.48s]
[0m15:08:24.553584 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:08:24.554594 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.554594 [info ] [Thread-1 (]: 5 of 5 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:08:24.556581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m15:08:24.556581 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.559580 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.562585 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:08:24.557581 => 15:08:24.561587
[0m15:08:24.563586 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.570120 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.572122 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.572122 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:08:24.573123 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:24.780714 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:24.781498 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.782548 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:08:24.933609 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:08:24.937189 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.937189 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:08:24.974789 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.977797 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.978797 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:08:25.008142 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:25.014280 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:08:25.014280 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:25.015281 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:08:25.046021 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:25.049689 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:08:25.052689 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:25.053689 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:08:25.094052 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:08:25.096085 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:08:24.563586 => 15:08:25.094828
[0m15:08:25.096085 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:08:25.097070 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DD8E6D0>]}
[0m15:08:25.098088 [info ] [Thread-1 (]: 5 of 5 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.54s]
[0m15:08:25.099053 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:08:25.101420 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:25.101420 [debug] [MainThread]: On master: BEGIN
[0m15:08:25.102420 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:08:25.301094 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:25.302106 [debug] [MainThread]: On master: COMMIT
[0m15:08:25.302106 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:25.303109 [debug] [MainThread]: On master: COMMIT
[0m15:08:25.329306 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:08:25.329306 [debug] [MainThread]: On master: Close
[0m15:08:25.330313 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:08:25.331313 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:08:25.331313 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:08:25.332312 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:08:25.332312 [info ] [MainThread]: 
[0m15:08:25.334427 [info ] [MainThread]: Finished running 2 table models, 3 view models in 0 hours 0 minutes and 3.53 seconds (3.53s).
[0m15:08:25.336467 [debug] [MainThread]: Command end result
[0m15:08:25.345978 [info ] [MainThread]: 
[0m15:08:25.346645 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:08:25.347655 [info ] [MainThread]: 
[0m15:08:25.348653 [error] [MainThread]:   Database Error in model dim_hosts_cleansed (dbtlearn/models\dim\dim_hosts_cleansed.sql)
  syntax error at or near ")"
  LINE 17: )
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:25.350655 [info ] [MainThread]: 
[0m15:08:25.351656 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m15:08:25.354665 [debug] [MainThread]: Command `dbt run` failed at 15:08:25.353668 after 4.22 seconds
[0m15:08:25.355666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B54FC1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5BFBAE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5BEF5490>]}
[0m15:08:25.356655 [debug] [MainThread]: Flushing usage events
[0m15:09:24.348636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855FCBB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855AF7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855AF6790>]}


============================== 15:09:24.352631 | b1207066-8e8b-4cb2-954f-2675086edf64 ==============================
[0m15:09:24.352631 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:09:24.352631 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:09:24.587362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855B003D0>]}
[0m15:09:24.680259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855FE2E10>]}
[0m15:09:24.681260 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:09:24.692070 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:09:24.794357 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:09:24.795359 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:09:24.983689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85624AA50>]}
[0m15:09:24.998795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8563BF950>]}
[0m15:09:24.999323 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:09:25.000418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F856295750>]}
[0m15:09:25.002454 [info ] [MainThread]: 
[0m15:09:25.004493 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:09:25.006256 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:09:25.018746 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:09:25.018746 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:09:25.019745 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:25.258777 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:09:25.260740 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:09:25.262740 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:09:25.268977 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:09:25.268977 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:09:25.270015 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:25.470039 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.471012 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:09:25.471981 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:09:25.519158 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:09:25.521333 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:09:25.548946 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:09:25.557462 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.558469 [debug] [MainThread]: On master: BEGIN
[0m15:09:25.558469 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:09:25.745741 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.746741 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.746741 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:09:25.796273 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:09:25.798281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8562AD690>]}
[0m15:09:25.798281 [debug] [MainThread]: On master: ROLLBACK
[0m15:09:25.828034 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.829036 [debug] [MainThread]: On master: BEGIN
[0m15:09:25.955009 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.956011 [debug] [MainThread]: On master: COMMIT
[0m15:09:25.956011 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.957009 [debug] [MainThread]: On master: COMMIT
[0m15:09:25.986792 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:09:25.986792 [debug] [MainThread]: On master: Close
[0m15:09:25.988324 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:09:25.988833 [info ] [MainThread]: 
[0m15:09:25.992137 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:09:25.993137 [info ] [Thread-1 (]: 1 of 5 START sql view model test.src_hosts ..................................... [RUN]
[0m15:09:25.995139 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:09:25.995139 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:09:26.001155 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:09:26.003168 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:09:25.996138 => 15:09:26.002161
[0m15:09:26.004168 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:09:26.044416 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:09:26.046411 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.046411 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:09:26.047414 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:09:26.264267 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:26.264958 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.266091 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:09:26.314995 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:26.322756 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.322756 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:09:26.358645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.362750 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.363754 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:09:26.397989 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.413012 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:09:26.414011 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.414011 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:09:26.453233 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:26.460506 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:09:26.465505 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.465505 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:09:26.502800 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:26.503799 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:09:26.004168 => 15:09:26.503799
[0m15:09:26.505304 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:09:26.506306 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85654DA90>]}
[0m15:09:26.506825 [info ] [Thread-1 (]: 1 of 5 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.51s]
[0m15:09:26.507828 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:09:26.508828 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:09:26.508828 [info ] [Thread-1 (]: 2 of 5 START sql view model test.src_listings .................................. [RUN]
[0m15:09:26.510830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:09:26.510830 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:09:26.512861 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:09:26.514830 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:09:26.511843 => 15:09:26.513827
[0m15:09:26.515829 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:09:26.520855 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:09:26.522859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.522859 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:09:26.524856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:26.733844 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:26.735016 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.735557 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:09:26.786291 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:26.790122 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.790122 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:09:26.827365 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.831391 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.832392 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:09:26.866613 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.868616 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:09:26.869616 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.869616 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:09:26.904045 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:26.907054 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:09:26.909054 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.909054 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:09:26.945468 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:26.947271 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:09:26.515829 => 15:09:26.947271
[0m15:09:26.948244 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:09:26.949267 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F856539E50>]}
[0m15:09:26.949267 [info ] [Thread-1 (]: 2 of 5 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.44s]
[0m15:09:26.950234 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:09:26.951637 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:09:26.952620 [info ] [Thread-1 (]: 3 of 5 START sql view model test.src_reviews ................................... [RUN]
[0m15:09:26.953611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:09:26.954605 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:09:26.955637 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:09:26.957633 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:09:26.954605 => 15:09:26.957633
[0m15:09:26.958638 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:09:26.962658 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:09:26.964124 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:26.964124 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:09:26.965124 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:27.179300 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:27.180060 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.180564 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:09:27.228979 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:27.232975 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.232975 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:09:27.268776 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.272813 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.273778 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:09:27.308772 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.311272 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:09:27.312278 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.312278 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:09:27.346778 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:27.350289 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:09:27.351288 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.352256 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:09:27.388070 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:27.390038 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:09:26.958638 => 15:09:27.390038
[0m15:09:27.391059 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:09:27.393037 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85663B250>]}
[0m15:09:27.393037 [info ] [Thread-1 (]: 3 of 5 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.44s]
[0m15:09:27.394036 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:09:27.395605 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.395605 [info ] [Thread-1 (]: 4 of 5 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:09:27.397609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:09:27.397609 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.401609 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.403609 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:09:27.398613 => 15:09:27.402610
[0m15:09:27.404609 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.427198 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.429198 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.429198 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:09:27.430721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:27.640401 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:27.641369 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.642368 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name IS NULL THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:09:27.739488 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:09:27.742485 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.743484 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:09:27.777239 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.782747 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:09:27.782747 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.783747 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:09:27.822801 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:27.825807 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:09:27.828833 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.829838 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:09:27.863300 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:09:27.864844 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:09:27.404609 => 15:09:27.864844
[0m15:09:27.865842 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:09:27.866877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85664A790>]}
[0m15:09:27.867875 [info ] [Thread-1 (]: 4 of 5 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.47s]
[0m15:09:27.869877 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.869877 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.870877 [info ] [Thread-1 (]: 5 of 5 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:09:27.871846 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:09:27.873105 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.876197 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.877937 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:09:27.873105 => 15:09:27.876764
[0m15:09:27.877937 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.882941 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.884939 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.884939 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:09:27.885946 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:28.083139 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:28.084091 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.085059 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:09:28.235996 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:09:28.239874 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.240874 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:09:28.271456 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:28.275193 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.275193 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:09:28.306544 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:28.308637 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:09:28.309674 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.310641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:09:28.345767 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:28.348638 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:09:28.349638 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.350637 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:09:28.400405 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:09:28.402286 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:09:27.878937 => 15:09:28.402286
[0m15:09:28.403285 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:09:28.404286 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85663ABD0>]}
[0m15:09:28.405369 [info ] [Thread-1 (]: 5 of 5 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.53s]
[0m15:09:28.405796 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:09:28.407798 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:28.408801 [debug] [MainThread]: On master: BEGIN
[0m15:09:28.409818 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:09:28.593987 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:28.593987 [debug] [MainThread]: On master: COMMIT
[0m15:09:28.594996 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:28.594996 [debug] [MainThread]: On master: COMMIT
[0m15:09:28.623274 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:09:28.624278 [debug] [MainThread]: On master: Close
[0m15:09:28.625305 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:09:28.625305 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:09:28.626275 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:09:28.626275 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:09:28.626275 [info ] [MainThread]: 
[0m15:09:28.627274 [info ] [MainThread]: Finished running 3 view models, 2 table models in 0 hours 0 minutes and 3.62 seconds (3.62s).
[0m15:09:28.629309 [debug] [MainThread]: Command end result
[0m15:09:28.638413 [info ] [MainThread]: 
[0m15:09:28.639411 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:09:28.640409 [info ] [MainThread]: 
[0m15:09:28.641412 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m15:09:28.643460 [debug] [MainThread]: Command `dbt run` succeeded at 15:09:28.643460 after 4.36 seconds
[0m15:09:28.643460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855B7EB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F84E8C1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F84E8C1B50>]}
[0m15:09:28.644966 [debug] [MainThread]: Flushing usage events
[0m15:11:31.920847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE7D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F70F1F42D0>]}


============================== 15:11:31.924389 | cba3c832-f59b-49fc-ba7e-c1417bf3be1d ==============================
[0m15:11:31.924389 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:11:31.925357 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s dim_hosts_cleansed', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:11:32.133993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710C1C550>]}
[0m15:11:32.210809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAF290>]}
[0m15:11:32.211838 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:11:32.220883 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:11:32.321059 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:11:32.322028 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:11:32.495970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710E9C410>]}
[0m15:11:32.508660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710F6E850>]}
[0m15:11:32.509627 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:11:32.510625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710EFC1D0>]}
[0m15:11:32.511626 [info ] [MainThread]: 
[0m15:11:32.512625 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:11:32.514659 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:11:32.523553 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:11:32.524554 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:11:32.525555 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:32.870576 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:11:32.872569 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:11:32.874393 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:11:32.879516 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:11:32.880522 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:11:32.881516 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:33.075317 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.076364 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:11:33.076364 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:11:33.126071 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:11:33.127087 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:11:33.157751 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:11:33.163749 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.164754 [debug] [MainThread]: On master: BEGIN
[0m15:11:33.164754 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:11:33.376107 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.376107 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.377102 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:11:33.435577 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:11:33.438578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710EFD590>]}
[0m15:11:33.438578 [debug] [MainThread]: On master: ROLLBACK
[0m15:11:33.467909 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.468870 [debug] [MainThread]: On master: BEGIN
[0m15:11:33.526888 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.527437 [debug] [MainThread]: On master: COMMIT
[0m15:11:33.528478 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.528478 [debug] [MainThread]: On master: COMMIT
[0m15:11:33.557443 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:11:33.557443 [debug] [MainThread]: On master: Close
[0m15:11:33.558480 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:11:33.559474 [info ] [MainThread]: 
[0m15:11:33.562970 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.563967 [info ] [Thread-1 (]: 1 of 1 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:11:33.564968 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:11:33.565970 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.574694 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.576703 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:11:33.565970 => 15:11:33.576703
[0m15:11:33.577702 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.618805 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.619805 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.621313 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:11:33.622508 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:11:33.826233 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.826765 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.827899 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	COALESCE(review_name, 'Anonymous') AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:11:33.923142 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:11:33.930875 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.931395 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:11:33.960947 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:11:33.963978 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.964981 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:11:33.993824 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:11:34.011593 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:11:34.012594 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:34.013595 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:11:34.046163 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:11:34.053149 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:11:34.057690 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:34.058691 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:11:34.097962 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:11:34.099960 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:11:33.577702 => 15:11:34.098958
[0m15:11:34.099960 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:11:34.100924 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F712102050>]}
[0m15:11:34.101924 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.54s]
[0m15:11:34.103208 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:11:34.105389 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:34.105389 [debug] [MainThread]: On master: BEGIN
[0m15:11:34.106422 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:11:34.319848 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:34.320790 [debug] [MainThread]: On master: COMMIT
[0m15:11:34.321788 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:34.321788 [debug] [MainThread]: On master: COMMIT
[0m15:11:34.353104 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:11:34.353104 [debug] [MainThread]: On master: Close
[0m15:11:34.355136 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:11:34.355136 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:11:34.355136 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:11:34.356163 [debug] [MainThread]: Connection 'model.dbtlearn.dim_hosts_cleansed' was properly closed.
[0m15:11:34.357141 [info ] [MainThread]: 
[0m15:11:34.357141 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.84 seconds (1.84s).
[0m15:11:34.359146 [debug] [MainThread]: Command end result
[0m15:11:34.369804 [info ] [MainThread]: 
[0m15:11:34.370805 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:11:34.371802 [info ] [MainThread]: 
[0m15:11:34.374805 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:11:34.376803 [debug] [MainThread]: Command `dbt run` succeeded at 15:11:34.376803 after 2.52 seconds
[0m15:11:34.378329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F709401090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F709400FD0>]}
[0m15:11:34.378953 [debug] [MainThread]: Flushing usage events
[0m15:13:13.155385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A8CAED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A0FF490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A0FE790>]}


============================== 15:13:13.158837 | 8e8710da-ad90-485a-a7f6-b053e0339ea0 ==============================
[0m15:13:13.158837 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:13:13.159805 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s dim_hosts_cleansed', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:13:13.374417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AAD8E50>]}
[0m15:13:13.451700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AAD8C90>]}
[0m15:13:13.453210 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:13:13.462435 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:13:13.575078 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:13:13.576076 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:13:13.751558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AC7FDD0>]}
[0m15:13:13.766321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB7C490>]}
[0m15:13:13.767330 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:13:13.768330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB74F90>]}
[0m15:13:13.769828 [info ] [MainThread]: 
[0m15:13:13.771416 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:13:13.772968 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:13:13.788235 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:13:13.788750 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:13:13.789781 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:15.147222 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:13:15.148729 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:13:15.151169 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:13:15.155687 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:13:15.156688 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:13:15.156688 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:15.376586 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.377630 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:13:15.378205 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:13:15.425483 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:13:15.427466 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:13:15.456348 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:13:15.461832 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.462832 [debug] [MainThread]: On master: BEGIN
[0m15:13:15.462832 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:13:15.706045 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.706984 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.707983 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:13:15.769569 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:13:15.771574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AA40850>]}
[0m15:13:15.771574 [debug] [MainThread]: On master: ROLLBACK
[0m15:13:15.799651 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.800665 [debug] [MainThread]: On master: BEGIN
[0m15:13:15.866256 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.867266 [debug] [MainThread]: On master: COMMIT
[0m15:13:15.867266 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.868300 [debug] [MainThread]: On master: COMMIT
[0m15:13:15.896489 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:13:15.897490 [debug] [MainThread]: On master: Close
[0m15:13:15.898490 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:13:15.898490 [info ] [MainThread]: 
[0m15:13:15.902491 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.903493 [info ] [Thread-1 (]: 1 of 1 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:13:15.903493 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:13:15.904999 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.915313 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.919859 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:13:15.906298 => 15:13:15.919208
[0m15:13:15.919859 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.966917 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.968500 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.969883 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:13:15.970442 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:13:16.198221 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:13:16.199234 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.199234 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:13:16.301748 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:13:16.308859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.309826 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:13:16.342355 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:13:16.346360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.346360 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:13:16.381957 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:13:16.399249 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:13:16.400286 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.401251 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:13:16.441828 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:13:16.451315 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:13:16.460170 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.462169 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:13:16.507179 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:13:16.509190 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:13:15.920865 => 15:13:16.509190
[0m15:13:16.510197 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:13:16.511189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB7C490>]}
[0m15:13:16.512191 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.61s]
[0m15:13:16.513194 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:13:16.515539 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:16.515539 [debug] [MainThread]: On master: BEGIN
[0m15:13:16.516522 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:13:16.764752 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:16.765716 [debug] [MainThread]: On master: COMMIT
[0m15:13:16.765716 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:16.766712 [debug] [MainThread]: On master: COMMIT
[0m15:13:16.809575 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:13:16.810569 [debug] [MainThread]: On master: Close
[0m15:13:16.811533 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:13:16.812531 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:13:16.812531 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:13:16.813532 [debug] [MainThread]: Connection 'model.dbtlearn.dim_hosts_cleansed' was properly closed.
[0m15:13:16.813532 [info ] [MainThread]: 
[0m15:13:16.814532 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.04 seconds (3.04s).
[0m15:13:16.815531 [debug] [MainThread]: Command end result
[0m15:13:16.825944 [info ] [MainThread]: 
[0m15:13:16.827944 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:13:16.827944 [info ] [MainThread]: 
[0m15:13:16.828943 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:13:16.830448 [debug] [MainThread]: Command `dbt run` succeeded at 15:13:16.830448 after 3.74 seconds
[0m15:13:16.831445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A9191D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A424BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E83141090>]}
[0m15:13:16.831969 [debug] [MainThread]: Flushing usage events
[0m15:22:02.572071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A352A2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A34695150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A352A2250>]}


============================== 15:22:02.576049 | 2c080157-7759-4b00-8088-84a5f178852c ==============================
[0m15:22:02.576049 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:22:02.577048 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:22:02.784691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A352A15D0>]}
[0m15:22:02.865222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A35C5E110>]}
[0m15:22:02.867236 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:22:02.874769 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:22:02.900872 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:22:02.901843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36E16490>]}
[0m15:22:03.748392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36F79AD0>]}
[0m15:22:03.760420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36F0B850>]}
[0m15:22:03.761416 [info ] [MainThread]: Found 6 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:22:03.762415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36DD0190>]}
[0m15:22:03.764509 [info ] [MainThread]: 
[0m15:22:03.765051 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:22:03.766986 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:22:03.777146 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:22:03.777146 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:22:03.778189 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:05.140419 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:22:05.141381 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:22:05.144381 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:22:05.150153 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:22:05.150153 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:22:05.151154 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:05.333369 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:22:05.334120 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:22:05.334120 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:22:05.383089 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:22:05.384943 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:22:05.419820 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:22:05.425782 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:05.426783 [debug] [MainThread]: On master: BEGIN
[0m15:22:05.426783 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:22:05.634192 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:05.635193 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:05.635193 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:22:05.698697 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:22:05.700740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A35CF73D0>]}
[0m15:22:05.701738 [debug] [MainThread]: On master: ROLLBACK
[0m15:22:05.735253 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:05.735253 [debug] [MainThread]: On master: BEGIN
[0m15:22:05.787169 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:05.788170 [debug] [MainThread]: On master: COMMIT
[0m15:22:05.788170 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:05.789170 [debug] [MainThread]: On master: COMMIT
[0m15:22:05.827048 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:05.828346 [debug] [MainThread]: On master: Close
[0m15:22:05.829448 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:22:05.830492 [info ] [MainThread]: 
[0m15:22:05.834226 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:22:05.835296 [info ] [Thread-1 (]: 1 of 6 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:22:05.836353 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.fact_reviews'
[0m15:22:05.837364 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:22:05.845645 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:22:05.848978 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:22:05.837875 => 15:22:05.848450
[0m15:22:05.850020 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:22:05.914054 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:22:05.916553 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:22:05.916553 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:22:05.917559 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:22:06.135488 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:06.136543 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:22:06.137505 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      
  
    

  create  table "inttegra_stage"."test"."fact_reviews"
  
  
    as
  
  (
    WITH src_reviews AS (
    SELECT
        *
    FROM
        refsrc_reviews
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_text IS NOT NULL
  );
  
  
[0m15:22:06.170568 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "refsrc_reviews" does not exist
LINE 17:         refsrc_reviews
                 ^

[0m15:22:06.170568 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: ROLLBACK
[0m15:22:06.199239 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:22:05.850550 => 15:22:06.199239
[0m15:22:06.200259 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:22:06.205291 [debug] [Thread-1 (]: Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  relation "refsrc_reviews" does not exist
  LINE 17:         refsrc_reviews
                   ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\fact\fact_reviews.sql
[0m15:22:06.206291 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36F67490>]}
[0m15:22:06.207291 [error] [Thread-1 (]: 1 of 6 ERROR creating sql incremental model test.fact_reviews .................. [[31mERROR[0m in 0.37s]
[0m15:22:06.208292 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:22:06.209291 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:22:06.210290 [info ] [Thread-1 (]: 2 of 6 START sql view model test.src_hosts ..................................... [RUN]
[0m15:22:06.211289 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.src_hosts)
[0m15:22:06.211289 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:22:06.213321 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:22:06.214322 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:22:06.212322 => 15:22:06.214322
[0m15:22:06.215827 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:22:06.236417 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:22:06.237418 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.238417 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:22:06.238417 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:06.481683 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:06.482696 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.482696 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:22:06.533116 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:06.539155 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.540151 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:22:06.576571 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:06.580591 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.580591 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:22:06.619950 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:06.634993 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:22:06.636500 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.638038 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:22:06.676218 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:06.682224 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:22:06.686733 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:06.688238 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:22:06.724782 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:06.726542 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:22:06.215827 => 15:22:06.726542
[0m15:22:06.727537 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:22:06.728537 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A36F5E650>]}
[0m15:22:06.728537 [info ] [Thread-1 (]: 2 of 6 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.52s]
[0m15:22:06.730571 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:22:06.730571 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:22:06.731593 [info ] [Thread-1 (]: 3 of 6 START sql view model test.src_listings .................................. [RUN]
[0m15:22:06.732538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:22:06.732538 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:22:06.734894 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:22:06.736792 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:22:06.733928 => 15:22:06.736792
[0m15:22:06.736792 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:22:06.741831 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:22:06.742797 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:06.742797 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:22:06.744336 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:06.950035 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:06.951084 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:06.951084 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:22:06.995406 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:07.002600 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:07.003539 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:22:07.046920 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:07.050934 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:07.051933 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:22:07.090964 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:07.093441 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:22:07.094070 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:07.094580 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:22:07.131874 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:07.134882 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:22:07.135884 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:07.136885 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:22:07.174819 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:07.175833 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:22:06.737834 => 15:22:07.175833
[0m15:22:07.177349 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:22:07.178409 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A35D459D0>]}
[0m15:22:07.178871 [info ] [Thread-1 (]: 3 of 6 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.45s]
[0m15:22:07.179871 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:22:07.180904 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:22:07.181908 [info ] [Thread-1 (]: 4 of 6 START sql view model test.src_reviews ................................... [RUN]
[0m15:22:07.182888 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:22:07.183901 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:22:07.185870 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:22:07.186904 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:22:07.183901 => 15:22:07.186904
[0m15:22:07.187904 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:22:07.192661 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:22:07.193665 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.194637 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:22:07.195637 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:07.419146 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:07.420152 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.421145 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:22:07.465972 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:07.469977 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.470976 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:22:07.505118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:07.509118 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.510119 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:22:07.552938 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:07.554944 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:22:07.555944 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.555944 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:22:07.589690 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:07.592697 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:22:07.593697 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:07.594697 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:22:07.635142 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:07.637147 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:22:07.188879 => 15:22:07.637147
[0m15:22:07.637147 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:22:07.638149 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A370ABAD0>]}
[0m15:22:07.639206 [info ] [Thread-1 (]: 4 of 6 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.46s]
[0m15:22:07.641148 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:22:07.641148 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:22:07.642147 [info ] [Thread-1 (]: 5 of 6 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:22:07.643150 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:22:07.644148 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:22:07.646660 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.648649 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:22:07.644148 => 15:22:07.648649
[0m15:22:07.649683 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:22:07.665884 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.668874 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.670379 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:22:07.671387 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:07.890365 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:07.891378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.891378 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:22:07.990966 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:22:07.996081 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:07.997080 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:22:08.036051 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:08.040374 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:08.040896 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:22:08.080006 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:08.085779 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:22:08.086351 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:08.087434 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:22:08.122844 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:08.125644 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:22:08.130735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:08.131705 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:22:08.176001 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:08.178034 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:22:07.649683 => 15:22:08.177002
[0m15:22:08.178034 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:22:08.179033 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A37139210>]}
[0m15:22:08.180033 [info ] [Thread-1 (]: 5 of 6 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.54s]
[0m15:22:08.181002 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:22:08.182002 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:22:08.182002 [info ] [Thread-1 (]: 6 of 6 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:22:08.182983 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:22:08.184378 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:22:08.186913 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.187900 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:22:08.184378 => 15:22:08.187900
[0m15:22:08.187900 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:22:08.192907 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.194912 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.195914 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:22:08.196907 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:08.439292 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:08.440581 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.441581 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:22:08.596628 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:22:08.600242 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.600242 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:22:08.634927 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:08.637859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.638856 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:22:08.674079 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:08.676866 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:22:08.677831 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.677831 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:22:08.713699 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:08.717214 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:22:08.718214 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:08.718214 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:22:08.765820 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:08.767827 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:22:08.188940 => 15:22:08.766829
[0m15:22:08.767827 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:22:08.768826 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c080157-7759-4b00-8088-84a5f178852c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A37138D10>]}
[0m15:22:08.769826 [info ] [Thread-1 (]: 6 of 6 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.59s]
[0m15:22:08.770830 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:22:08.772828 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:08.772828 [debug] [MainThread]: On master: BEGIN
[0m15:22:08.773860 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:22:09.006169 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:09.007197 [debug] [MainThread]: On master: COMMIT
[0m15:22:09.007197 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:09.008212 [debug] [MainThread]: On master: COMMIT
[0m15:22:09.043509 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:09.044514 [debug] [MainThread]: On master: Close
[0m15:22:09.045499 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:22:09.046519 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:22:09.046519 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:22:09.047531 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:22:09.048532 [info ] [MainThread]: 
[0m15:22:09.049499 [info ] [MainThread]: Finished running 1 incremental model, 3 view models, 2 table models in 0 hours 0 minutes and 5.28 seconds (5.28s).
[0m15:22:09.050498 [debug] [MainThread]: Command end result
[0m15:22:09.061557 [info ] [MainThread]: 
[0m15:22:09.062536 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:22:09.065374 [info ] [MainThread]: 
[0m15:22:09.066938 [error] [MainThread]:   Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  relation "refsrc_reviews" does not exist
  LINE 17:         refsrc_reviews
                   ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\fact\fact_reviews.sql
[0m15:22:09.067916 [info ] [MainThread]: 
[0m15:22:09.068917 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m15:22:09.073521 [debug] [MainThread]: Command `dbt run` failed at 15:22:09.072922 after 6.57 seconds
[0m15:22:09.073521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A3527C350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A2E361010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A35280DD0>]}
[0m15:22:09.074530 [debug] [MainThread]: Flushing usage events
[0m15:22:44.293343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B309510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869AAE21D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028697E78790>]}


============================== 15:22:44.297375 | c48c021b-df7e-40b5-9ad6-21b248c53992 ==============================
[0m15:22:44.297375 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:22:44.299341 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:22:44.544211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B312050>]}
[0m15:22:44.634165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869AE70790>]}
[0m15:22:44.636166 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:22:44.646596 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:22:44.766078 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:22:44.767078 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\fact\fact_reviews.sql
[0m15:22:44.959582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B5FBC90>]}
[0m15:22:44.975629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B7FE810>]}
[0m15:22:44.976629 [info ] [MainThread]: Found 6 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:22:44.977630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B7BD410>]}
[0m15:22:44.979630 [info ] [MainThread]: 
[0m15:22:44.980629 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:22:44.982629 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:22:44.999355 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:22:45.001857 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:22:45.002854 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:46.359833 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:22:46.360831 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:22:46.362833 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:22:46.369343 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:22:46.369868 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:22:46.369868 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:46.588140 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:22:46.588140 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:22:46.589141 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:22:46.641214 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:22:46.643718 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:22:46.682185 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:22:46.688150 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:46.689150 [debug] [MainThread]: On master: BEGIN
[0m15:22:46.689150 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:22:46.947342 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:46.948309 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:46.948309 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:22:47.015628 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:22:47.018668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869AB04CD0>]}
[0m15:22:47.018668 [debug] [MainThread]: On master: ROLLBACK
[0m15:22:47.053558 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:47.054666 [debug] [MainThread]: On master: BEGIN
[0m15:22:47.123412 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:47.123412 [debug] [MainThread]: On master: COMMIT
[0m15:22:47.124371 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:47.124371 [debug] [MainThread]: On master: COMMIT
[0m15:22:47.155892 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:47.155892 [debug] [MainThread]: On master: Close
[0m15:22:47.156892 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:22:47.158890 [info ] [MainThread]: 
[0m15:22:47.162497 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:22:47.163504 [info ] [Thread-1 (]: 1 of 6 START sql view model test.src_hosts ..................................... [RUN]
[0m15:22:47.164503 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:22:47.165504 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:22:47.172504 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:22:47.176032 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:22:47.166506 => 15:22:47.175034
[0m15:22:47.177031 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:22:47.217898 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:22:47.219896 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.221405 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:22:47.222337 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:22:47.432229 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:47.433296 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.433840 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:22:47.481240 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:47.487283 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.488287 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:22:47.517305 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:47.522816 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.523325 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:22:47.559657 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:47.574680 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:22:47.575681 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.575681 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:22:47.604770 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:47.610462 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:22:47.615430 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:22:47.616465 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:22:47.652081 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:47.654081 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:22:47.178032 => 15:22:47.654081
[0m15:22:47.654081 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:22:47.656549 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B4886D0>]}
[0m15:22:47.656549 [info ] [Thread-1 (]: 1 of 6 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.49s]
[0m15:22:47.658510 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:22:47.659544 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:22:47.659544 [info ] [Thread-1 (]: 2 of 6 START sql view model test.src_listings .................................. [RUN]
[0m15:22:47.661514 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:22:47.661514 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:22:47.663543 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:22:47.665510 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:22:47.662546 => 15:22:47.665510
[0m15:22:47.666514 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:22:47.670654 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:22:47.672650 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:47.673621 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:22:47.673621 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:47.881602 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:47.881602 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:47.882584 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:22:47.923292 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:47.926290 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:47.927326 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:22:47.957151 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:47.960151 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:47.961151 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:22:47.997505 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.001471 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:22:48.001471 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:48.001471 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:22:48.036838 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:48.040146 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:22:48.041145 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:22:48.041145 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:22:48.074829 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:48.076977 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:22:47.666514 => 15:22:48.076977
[0m15:22:48.077974 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:22:48.078975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869ADE7E10>]}
[0m15:22:48.079940 [info ] [Thread-1 (]: 2 of 6 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.42s]
[0m15:22:48.080940 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:22:48.081939 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:22:48.082940 [info ] [Thread-1 (]: 3 of 6 START sql view model test.src_reviews ................................... [RUN]
[0m15:22:48.083940 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:22:48.084940 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:22:48.086940 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:22:48.088450 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:22:48.084940 => 15:22:48.088450
[0m15:22:48.088450 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:22:48.093450 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:22:48.095456 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.096452 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:22:48.097454 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:48.307356 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:48.307356 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.308392 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:22:48.347753 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:22:48.351295 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.352349 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:22:48.383804 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.387788 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.388792 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:22:48.416827 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.418827 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:22:48.419828 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.420828 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:22:48.457593 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:48.461557 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:22:48.462556 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:22:48.463589 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:22:48.502245 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:22:48.504212 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:22:48.089450 => 15:22:48.504212
[0m15:22:48.505245 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:22:48.506245 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869C90FA50>]}
[0m15:22:48.506245 [info ] [Thread-1 (]: 3 of 6 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.42s]
[0m15:22:48.507750 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:22:48.507750 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:22:48.508757 [info ] [Thread-1 (]: 4 of 6 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:22:48.510758 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:22:48.511758 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:22:48.513756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.515757 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:22:48.511758 => 15:22:48.515757
[0m15:22:48.516757 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:22:48.547694 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.548685 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.549685 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:22:48.549685 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:48.744897 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:48.745902 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.746904 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:22:48.838570 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:22:48.842570 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.842570 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:22:48.869474 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.872474 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.873473 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:22:48.906560 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:48.912562 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:22:48.913561 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.913561 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:22:48.950517 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:48.953598 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:22:48.956598 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:22:48.957562 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:22:48.996574 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:48.998574 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:22:48.517756 => 15:22:48.998574
[0m15:22:48.998574 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:22:49.000115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B638110>]}
[0m15:22:49.001346 [info ] [Thread-1 (]: 4 of 6 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.49s]
[0m15:22:49.002354 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:22:49.003389 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:22:49.004352 [info ] [Thread-1 (]: 5 of 6 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:22:49.005352 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:22:49.006352 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:22:49.010354 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.013871 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:22:49.006352 => 15:22:49.012863
[0m15:22:49.014880 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:22:49.021964 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.025501 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.025501 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:22:49.026771 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:49.213771 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:49.214771 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.214771 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:22:49.357735 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:22:49.360769 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.362109 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:22:49.393052 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:49.396052 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.397562 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:22:49.428173 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:49.430163 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:22:49.431162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.432132 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:22:49.460005 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:49.463002 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:22:49.464002 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:22:49.464979 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:22:49.499769 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:49.501770 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:22:49.015921 => 15:22:49.501770
[0m15:22:49.502768 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:22:49.503769 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869C7F3F50>]}
[0m15:22:49.505276 [info ] [Thread-1 (]: 5 of 6 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.50s]
[0m15:22:49.506294 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:22:49.507283 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:22:49.508320 [info ] [Thread-1 (]: 6 of 6 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:22:49.509318 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m15:22:49.510289 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:22:49.515288 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:22:49.516289 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:22:49.511287 => 15:22:49.516289
[0m15:22:49.517289 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:22:49.556776 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:22:49.559032 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:22:49.560089 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:22:49.560643 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:49.778132 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:49.779132 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:22:49.779132 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      
  
    

  create  table "inttegra_stage"."test"."fact_reviews"
  
  
    as
  
  (
    WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_text IS NOT NULL
  );
  
  
[0m15:22:49.820955 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "review_text" does not exist
LINE 24:     review_text IS NOT NULL
             ^
HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".

[0m15:22:49.821962 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: ROLLBACK
[0m15:22:49.858035 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:22:49.517289 => 15:22:49.857035
[0m15:22:49.858035 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:22:49.864036 [debug] [Thread-1 (]: Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  column "review_text" does not exist
  LINE 24:     review_text IS NOT NULL
               ^
  HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".
  compiled Code at target\run\dbtlearn\dbtlearn/models\fact\fact_reviews.sql
[0m15:22:49.864036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c48c021b-df7e-40b5-9ad6-21b248c53992', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869C880450>]}
[0m15:22:49.865540 [error] [Thread-1 (]: 6 of 6 ERROR creating sql incremental model test.fact_reviews .................. [[31mERROR[0m in 0.35s]
[0m15:22:49.866051 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:22:49.868056 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:49.868056 [debug] [MainThread]: On master: BEGIN
[0m15:22:49.869054 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:22:50.092243 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:50.092243 [debug] [MainThread]: On master: COMMIT
[0m15:22:50.094266 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:50.094266 [debug] [MainThread]: On master: COMMIT
[0m15:22:50.133569 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:50.134536 [debug] [MainThread]: On master: Close
[0m15:22:50.135535 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:22:50.136536 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:22:50.136536 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:22:50.137535 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m15:22:50.138537 [info ] [MainThread]: 
[0m15:22:50.139539 [info ] [MainThread]: Finished running 3 view models, 2 table models, 1 incremental model in 0 hours 0 minutes and 5.16 seconds (5.16s).
[0m15:22:50.142045 [debug] [MainThread]: Command end result
[0m15:22:50.150589 [info ] [MainThread]: 
[0m15:22:50.151588 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:22:50.152588 [info ] [MainThread]: 
[0m15:22:50.154094 [error] [MainThread]:   Database Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  column "review_text" does not exist
  LINE 24:     review_text IS NOT NULL
               ^
  HINT:  Perhaps you meant to reference the column "src_reviews.review_txt".
  compiled Code at target\run\dbtlearn\dbtlearn/models\fact\fact_reviews.sql
[0m15:22:50.155337 [info ] [MainThread]: 
[0m15:22:50.157332 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m15:22:50.160333 [debug] [MainThread]: Command `dbt run` failed at 15:22:50.160333 after 5.95 seconds
[0m15:22:50.161337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028693A9E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869B4FE110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002869AAECE10>]}
[0m15:22:50.162335 [debug] [MainThread]: Flushing usage events
[0m15:23:28.853724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7F795D190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB479CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FACB2510>]}


============================== 15:23:28.858721 | d61215f0-a709-4eda-b232-73cae1fe553d ==============================
[0m15:23:28.858721 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:23:28.859721 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:23:29.116032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB6672D0>]}
[0m15:23:29.198657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FAF780D0>]}
[0m15:23:29.200163 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:23:29.210168 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:23:29.310228 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:23:29.311229 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\fact\fact_reviews.sql
[0m15:23:29.501139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB59E190>]}
[0m15:23:29.514726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB854550>]}
[0m15:23:29.515726 [info ] [MainThread]: Found 6 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:23:29.515726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB944250>]}
[0m15:23:29.517722 [info ] [MainThread]: 
[0m15:23:29.519723 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:23:29.521723 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:23:29.531061 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:23:29.531061 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:23:29.532062 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:23:30.889402 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:23:30.891437 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:23:30.893437 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:23:30.899015 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:23:30.899986 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:23:30.899986 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:23:31.131254 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:23:31.131777 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:23:31.132304 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:23:31.186708 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:23:31.188280 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:23:31.217275 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:23:31.224307 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:31.225306 [debug] [MainThread]: On master: BEGIN
[0m15:23:31.225306 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:23:31.450676 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:23:31.451645 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:31.451645 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:23:31.515846 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:23:31.517850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB9CB810>]}
[0m15:23:31.517850 [debug] [MainThread]: On master: ROLLBACK
[0m15:23:31.554028 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:31.555576 [debug] [MainThread]: On master: BEGIN
[0m15:23:31.629303 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:23:31.629303 [debug] [MainThread]: On master: COMMIT
[0m15:23:31.630302 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:31.631300 [debug] [MainThread]: On master: COMMIT
[0m15:23:31.662860 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:23:31.663862 [debug] [MainThread]: On master: Close
[0m15:23:31.665905 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:23:31.666905 [info ] [MainThread]: 
[0m15:23:31.670905 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:23:31.671905 [info ] [Thread-1 (]: 1 of 6 START sql view model test.src_hosts ..................................... [RUN]
[0m15:23:31.672907 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:23:31.673907 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:23:31.683061 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:23:31.686029 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:23:31.674907 => 15:23:31.685043
[0m15:23:31.686029 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:23:31.721455 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:23:31.722421 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:31.723960 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:23:31.723960 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:23:31.934649 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:31.934649 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:31.935650 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:23:31.986866 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:23:31.994462 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:31.995491 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:23:32.029818 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.033784 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:32.033784 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:23:32.068668 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.084781 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:23:32.085355 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:32.085866 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:23:32.120802 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:32.127805 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:23:32.133578 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:23:32.133578 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:23:32.169778 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:23:32.171800 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:23:31.687538 => 15:23:32.171800
[0m15:23:32.171800 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:23:32.172765 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB84BCD0>]}
[0m15:23:32.173800 [info ] [Thread-1 (]: 1 of 6 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.50s]
[0m15:23:32.174769 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:23:32.175776 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:23:32.176767 [info ] [Thread-1 (]: 2 of 6 START sql view model test.src_listings .................................. [RUN]
[0m15:23:32.177764 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:23:32.178798 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:23:32.180894 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:23:32.182404 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:23:32.178798 => 15:23:32.181394
[0m15:23:32.182404 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:23:32.186398 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:23:32.188405 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.188405 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:23:32.189401 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:32.364934 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:32.365929 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.366928 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:23:32.411090 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:23:32.415082 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.416083 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:23:32.446055 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.449595 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.449595 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:23:32.477958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.480915 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:23:32.480915 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.481921 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:23:32.520653 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:32.523686 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:23:32.524689 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:23:32.524689 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:23:32.553637 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:23:32.555644 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:23:32.183402 => 15:23:32.554644
[0m15:23:32.555644 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:23:32.556643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB741190>]}
[0m15:23:32.557643 [info ] [Thread-1 (]: 2 of 6 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m15:23:32.558643 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:23:32.559643 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:23:32.559643 [info ] [Thread-1 (]: 3 of 6 START sql view model test.src_reviews ................................... [RUN]
[0m15:23:32.561643 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:23:32.561643 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:23:32.563648 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:23:32.565154 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:23:32.562643 => 15:23:32.565154
[0m15:23:32.566188 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:23:32.570555 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:23:32.572517 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.573522 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:23:32.574518 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:32.772686 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:32.772686 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.773721 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:23:32.817527 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:23:32.821858 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.821858 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:23:32.854571 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.858149 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.859148 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:23:32.887327 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:32.889833 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:23:32.890325 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.891335 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:23:32.917214 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:32.920210 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:23:32.921208 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:23:32.922209 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:23:32.954971 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:23:32.955963 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:23:32.566518 => 15:23:32.955963
[0m15:23:32.956999 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:23:32.957963 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FBACBD90>]}
[0m15:23:32.958996 [info ] [Thread-1 (]: 3 of 6 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.40s]
[0m15:23:32.959962 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:23:32.959962 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:23:32.959962 [info ] [Thread-1 (]: 4 of 6 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:23:32.961501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:23:32.962839 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:23:32.965840 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:32.966846 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:23:32.962839 => 15:23:32.966846
[0m15:23:32.967840 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:23:32.988700 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:32.990703 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:32.991701 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:23:32.992702 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:33.204163 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:33.205163 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.206164 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:23:33.329797 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:23:33.333541 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.334590 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:23:33.394145 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:33.398257 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.399257 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:23:33.458931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:33.464929 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:23:33.464929 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.466435 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:23:33.524341 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:33.527349 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:23:33.531357 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:23:33.531357 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:23:33.590126 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:23:33.592112 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:23:32.967840 => 15:23:33.592112
[0m15:23:33.593115 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:23:33.594114 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FBAB6E10>]}
[0m15:23:33.595114 [info ] [Thread-1 (]: 4 of 6 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.63s]
[0m15:23:33.596114 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:23:33.596114 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:23:33.597147 [info ] [Thread-1 (]: 5 of 6 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:23:33.598652 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:23:33.598652 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:23:33.601864 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:23:33.603831 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:23:33.599608 => 15:23:33.602865
[0m15:23:33.603831 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:23:33.608834 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:23:33.610870 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:33.610870 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:23:33.611872 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:34.017705 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:34.017705 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.019731 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:23:34.170694 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:23:34.173697 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.175200 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:23:34.224846 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:34.228871 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.228871 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:23:34.293129 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:23:34.295727 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:23:34.296819 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.296819 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:23:34.362836 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:34.366836 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:23:34.368344 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:23:34.369384 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:23:34.432262 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:23:34.434268 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:23:33.604831 => 15:23:34.434268
[0m15:23:34.435268 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:23:34.436270 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FBA2E210>]}
[0m15:23:34.437268 [info ] [Thread-1 (]: 5 of 6 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.84s]
[0m15:23:34.438271 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:23:34.438271 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:23:34.439777 [info ] [Thread-1 (]: 6 of 6 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:23:34.440847 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m15:23:34.440847 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:23:34.444115 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:23:34.446085 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:23:34.442083 => 15:23:34.445082
[0m15:23:34.446085 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:23:34.477007 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:23:34.478430 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:23:34.479430 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:23:34.479430 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:23:34.845284 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:23:34.846060 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:23:34.847051 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      
  
    

  create  table "inttegra_stage"."test"."fact_reviews"
  
  
    as
  
  (
    WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL
  );
  
  
[0m15:23:36.894221 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m15:23:36.896217 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:23:36.896217 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:23:36.897217 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:23:36.933330 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:23:36.934339 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:23:34.447085 => 15:23:36.934339
[0m15:23:36.935363 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:23:36.936364 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd61215f0-a709-4eda-b232-73cae1fe553d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FB567DD0>]}
[0m15:23:36.936364 [info ] [Thread-1 (]: 6 of 6 OK created sql incremental model test.fact_reviews ...................... [[32mSELECT 410284[0m in 2.49s]
[0m15:23:36.938334 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:23:36.939840 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:36.940880 [debug] [MainThread]: On master: BEGIN
[0m15:23:36.941428 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:23:37.240139 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:23:37.241237 [debug] [MainThread]: On master: COMMIT
[0m15:23:37.241237 [debug] [MainThread]: Using postgres connection "master"
[0m15:23:37.242243 [debug] [MainThread]: On master: COMMIT
[0m15:23:37.276563 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:23:37.276952 [debug] [MainThread]: On master: Close
[0m15:23:37.277959 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:23:37.277959 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:23:37.278957 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:23:37.278957 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m15:23:37.279957 [info ] [MainThread]: 
[0m15:23:37.280959 [info ] [MainThread]: Finished running 3 view models, 2 table models, 1 incremental model in 0 hours 0 minutes and 7.76 seconds (7.76s).
[0m15:23:37.282956 [debug] [MainThread]: Command end result
[0m15:23:37.292459 [info ] [MainThread]: 
[0m15:23:37.293458 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:23:37.295455 [info ] [MainThread]: 
[0m15:23:37.296453 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m15:23:37.297454 [debug] [MainThread]: Command `dbt run` succeeded at 15:23:37.297454 after 8.51 seconds
[0m15:23:37.298268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7FAF917D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7F3C8E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B7F3D10FD0>]}
[0m15:23:37.298268 [debug] [MainThread]: Flushing usage events
[0m15:30:18.508682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F65B2A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6A88550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6401DD0>]}


============================== 15:30:18.512202 | 307ef2a7-98fa-4cfa-98fe-81c00f3fb010 ==============================
[0m15:30:18.512202 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:30:18.513707 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s fact_reviews', 'send_anonymous_usage_stats': 'True'}
[0m15:30:18.733747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '307ef2a7-98fa-4cfa-98fe-81c00f3fb010', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6C5F990>]}
[0m15:30:18.814554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '307ef2a7-98fa-4cfa-98fe-81c00f3fb010', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F62A3A10>]}
[0m15:30:18.816584 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:30:18.826494 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:30:18.851624 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:30:18.852628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '307ef2a7-98fa-4cfa-98fe-81c00f3fb010', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6D1A950>]}
[0m15:30:19.668509 [error] [MainThread]: Encountered an error:
Compilation Error in model fact_reviews (dbtlearn/models\fact\fact_reviews.sql)
  Encountered unknown tag 'IF'.
    line 19
      {% IF is_incremental() %}
[0m15:30:19.670516 [debug] [MainThread]: Command `dbt run` failed at 15:30:19.670516 after 1.24 seconds
[0m15:30:19.671515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266EF2D1050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6596190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000266F6596850>]}
[0m15:30:19.672515 [debug] [MainThread]: Flushing usage events
[0m15:30:44.993206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3324D210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC31E25790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC336F2190>]}


============================== 15:30:44.997206 | 8d56c09d-2d45-43a6-9bf6-9965d93c0e93 ==============================
[0m15:30:44.997206 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:30:44.997582 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s fact_reviews', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:30:45.204579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33037190>]}
[0m15:30:45.283508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3370A890>]}
[0m15:30:45.285510 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:30:45.294223 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:30:45.302694 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:30:45.303697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33BD6F50>]}
[0m15:30:46.164573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33D012D0>]}
[0m15:30:46.176692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33CEE250>]}
[0m15:30:46.177690 [info ] [MainThread]: Found 6 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:30:46.178231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33AAD450>]}
[0m15:30:46.179736 [info ] [MainThread]: 
[0m15:30:46.180712 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:30:46.182260 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:30:46.191765 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:30:46.192774 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:30:46.192774 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:30:47.554841 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:30:47.556835 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:30:47.559799 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:30:47.566422 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:30:47.567422 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:30:47.567422 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:30:47.804184 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:30:47.805233 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:30:47.806212 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:30:47.857772 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m15:30:47.859804 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:30:47.893433 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:30:47.899509 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:47.900509 [debug] [MainThread]: On master: BEGIN
[0m15:30:47.900509 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:30:48.104712 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:48.105713 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:48.106710 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:30:48.171105 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:30:48.173172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33D18C90>]}
[0m15:30:48.173686 [debug] [MainThread]: On master: ROLLBACK
[0m15:30:48.203687 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:48.204209 [debug] [MainThread]: On master: BEGIN
[0m15:30:48.262380 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:48.263368 [debug] [MainThread]: On master: COMMIT
[0m15:30:48.263368 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:48.264368 [debug] [MainThread]: On master: COMMIT
[0m15:30:48.293955 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:30:48.294888 [debug] [MainThread]: On master: Close
[0m15:30:48.295970 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:30:48.295970 [info ] [MainThread]: 
[0m15:30:48.299976 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:30:48.299976 [info ] [Thread-1 (]: 1 of 1 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:30:48.301976 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.fact_reviews'
[0m15:30:48.301976 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:30:48.315035 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:30:48.317037 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:30:48.302978 => 15:30:48.317037
[0m15:30:48.318544 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:30:48.370114 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:48.370114 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp153048346075"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m15:30:48.371114 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:30:49.639591 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m15:30:49.646072 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.647111 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:30:49.678944 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:30:49.679968 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.680950 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp153048346075'
        
      order by ordinal_position

  
[0m15:30:49.740975 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:30:49.745968 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.746969 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:30:49.786370 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:30:49.797984 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.799191 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp153048346075'
        
      order by ordinal_position

  
[0m15:30:49.844730 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:30:49.847834 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.848835 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:30:49.885596 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:30:49.893175 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m15:30:49.903587 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:30:49.906109 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.906109 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp153048346075"
    )


  
[0m15:30:49.936644 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m15:30:49.949676 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:30:49.950683 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:30:49.950683 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:30:49.979488 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:30:49.980488 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:30:48.318544 => 15:30:49.980488
[0m15:30:49.981488 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:30:49.982489 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d56c09d-2d45-43a6-9bf6-9965d93c0e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33CAA510>]}
[0m15:30:49.982489 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.68s]
[0m15:30:49.983488 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:30:49.985488 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:49.986488 [debug] [MainThread]: On master: BEGIN
[0m15:30:49.986488 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:30:50.180123 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:50.180123 [debug] [MainThread]: On master: COMMIT
[0m15:30:50.181486 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:50.181486 [debug] [MainThread]: On master: COMMIT
[0m15:30:50.208395 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:30:50.209226 [debug] [MainThread]: On master: Close
[0m15:30:50.210217 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:30:50.211205 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:30:50.211205 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:30:50.212228 [debug] [MainThread]: Connection 'model.dbtlearn.fact_reviews' was properly closed.
[0m15:30:50.212228 [info ] [MainThread]: 
[0m15:30:50.213159 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.03 seconds (4.03s).
[0m15:30:50.214170 [debug] [MainThread]: Command end result
[0m15:30:50.224209 [info ] [MainThread]: 
[0m15:30:50.225206 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:30:50.226203 [info ] [MainThread]: 
[0m15:30:50.227204 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:30:50.229719 [debug] [MainThread]: Command `dbt run` succeeded at 15:30:50.229719 after 5.30 seconds
[0m15:30:50.230766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC2C061050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC33003010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC2C34FE10>]}
[0m15:30:50.232826 [debug] [MainThread]: Flushing usage events
[0m16:18:09.840172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66446290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF6696BE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66668E10>]}


============================== 16:18:09.845350 | f9e8f67e-8a4f-490c-8171-3c2b2e1ba354 ==============================
[0m16:18:09.845350 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:18:09.846352 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:18:10.089596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66972050>]}
[0m16:18:10.171719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF6696BED0>]}
[0m16:18:10.173716 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:18:10.182808 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:18:10.299130 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:18:10.299635 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:18:10.478855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66B2A890>]}
[0m16:18:10.492021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66ED2350>]}
[0m16:18:10.492021 [info ] [MainThread]: Found 7 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m16:18:10.494030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66BFD990>]}
[0m16:18:10.495061 [info ] [MainThread]: 
[0m16:18:10.496237 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:18:10.500278 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:18:10.509754 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:18:10.509754 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:18:10.510757 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:18:11.856316 [debug] [ThreadPool]: SQL status: SELECT 9 in 1.0 seconds
[0m16:18:11.857831 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:18:11.860371 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:18:11.867902 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:18:11.868902 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:18:11.868902 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:18:12.053042 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:18:12.053815 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:18:12.054822 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:18:12.100671 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m16:18:12.103038 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:18:12.132119 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:18:12.138382 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:12.139385 [debug] [MainThread]: On master: BEGIN
[0m16:18:12.139385 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:18:12.326837 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:18:12.326837 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:12.327839 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:18:12.389337 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:18:12.391395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66BE4DD0>]}
[0m16:18:12.392385 [debug] [MainThread]: On master: ROLLBACK
[0m16:18:12.422738 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:12.423737 [debug] [MainThread]: On master: BEGIN
[0m16:18:12.485149 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:18:12.486379 [debug] [MainThread]: On master: COMMIT
[0m16:18:12.487379 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:12.488379 [debug] [MainThread]: On master: COMMIT
[0m16:18:12.512848 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:18:12.513845 [debug] [MainThread]: On master: Close
[0m16:18:12.514847 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:18:12.515846 [info ] [MainThread]: 
[0m16:18:12.519846 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:18:12.519846 [info ] [Thread-1 (]: 1 of 7 START sql view model test.src_hosts ..................................... [RUN]
[0m16:18:12.521352 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:18:12.522439 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:18:12.529445 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:18:12.532489 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:18:12.522439 => 16:18:12.531450
[0m16:18:12.533447 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:18:12.577225 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m16:18:12.579225 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.580226 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m16:18:12.580226 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:18:12.794526 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:12.795564 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.795564 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m16:18:12.846835 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:18:12.853087 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.854123 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m16:18:12.890905 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:12.894400 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.895405 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m16:18:12.928415 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:12.944183 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:18:12.944183 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.945150 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:18:12.980749 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:12.986750 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m16:18:12.992289 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:18:12.993283 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m16:18:13.030291 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:18:13.032321 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:18:12.534576 => 16:18:13.031322
[0m16:18:13.032321 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m16:18:13.033287 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66E3CAD0>]}
[0m16:18:13.034288 [info ] [Thread-1 (]: 1 of 7 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.51s]
[0m16:18:13.035290 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:18:13.036287 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:18:13.036287 [info ] [Thread-1 (]: 2 of 7 START sql view model test.src_listings .................................. [RUN]
[0m16:18:13.037828 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:18:13.037828 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:18:13.041079 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:18:13.043077 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:18:13.039109 => 16:18:13.042075
[0m16:18:13.043077 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:18:13.047076 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m16:18:13.049077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.050585 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m16:18:13.051137 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:13.267586 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:13.268607 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.268607 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m16:18:13.317665 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:18:13.320668 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.321699 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m16:18:13.357961 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:13.360805 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.362310 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m16:18:13.397682 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:13.400194 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:18:13.401195 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.401195 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:18:13.436840 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:13.440023 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m16:18:13.441106 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:18:13.441660 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m16:18:13.479830 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:18:13.481410 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:18:13.043077 => 16:18:13.481410
[0m16:18:13.481930 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m16:18:13.483003 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66B2AA10>]}
[0m16:18:13.484081 [info ] [Thread-1 (]: 2 of 7 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.45s]
[0m16:18:13.485210 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:18:13.485952 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:18:13.487109 [info ] [Thread-1 (]: 3 of 7 START sql view model test.src_reviews ................................... [RUN]
[0m16:18:13.488156 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:18:13.488677 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:18:13.490747 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:18:13.491788 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:18:13.489197 => 16:18:13.491788
[0m16:18:13.492825 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:18:13.497661 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m16:18:13.499788 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.500863 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m16:18:13.501385 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:13.708221 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:13.708221 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.709220 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m16:18:13.755381 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:18:13.760897 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.761902 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m16:18:13.797842 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:13.801882 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.801882 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m16:18:13.838102 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:13.840894 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:18:13.840894 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.841894 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:18:13.876686 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:13.880371 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m16:18:13.881378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:18:13.882378 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m16:18:13.918991 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:18:13.920978 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:18:13.492825 => 16:18:13.919943
[0m16:18:13.920978 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m16:18:13.921941 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66C8BCD0>]}
[0m16:18:13.922978 [info ] [Thread-1 (]: 3 of 7 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.43s]
[0m16:18:13.923943 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:18:13.924943 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:18:13.924943 [info ] [Thread-1 (]: 4 of 7 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m16:18:13.925940 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m16:18:13.927445 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:18:13.930968 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:13.932967 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:18:13.927967 => 16:18:13.932967
[0m16:18:13.932967 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:18:13.959901 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:13.961900 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:13.963418 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m16:18:13.964823 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:14.194620 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:14.195642 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.195642 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m16:18:14.297883 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m16:18:14.301450 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.302418 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m16:18:14.337281 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:14.341280 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.341280 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m16:18:14.380383 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:14.385881 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:18:14.386881 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.387879 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:18:14.424499 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:14.428509 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m16:18:14.433108 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:18:14.434154 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m16:18:14.480125 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:18:14.484665 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:18:13.933970 => 16:18:14.484665
[0m16:18:14.485664 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m16:18:14.487667 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66F97150>]}
[0m16:18:14.487667 [info ] [Thread-1 (]: 4 of 7 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.56s]
[0m16:18:14.489666 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:18:14.490664 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:18:14.490664 [info ] [Thread-1 (]: 5 of 7 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m16:18:14.493227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:18:14.493699 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:18:14.498700 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.500701 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:18:14.494699 => 16:18:14.499701
[0m16:18:14.500701 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:18:14.508745 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.510735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.511735 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m16:18:14.512739 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:14.699328 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:14.700329 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.700329 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m16:18:14.846169 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:18:14.849162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.850195 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m16:18:14.880506 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:14.884549 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.885546 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m16:18:14.915259 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:18:14.918259 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:18:14.918259 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.919259 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:18:14.948553 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:14.952211 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m16:18:14.953211 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:18:14.953211 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m16:18:14.992245 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:18:14.994239 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:18:14.501700 => 16:18:14.994239
[0m16:18:14.995231 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m16:18:14.996231 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66FC9ED0>]}
[0m16:18:14.997231 [info ] [Thread-1 (]: 5 of 7 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.50s]
[0m16:18:14.998741 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:18:14.998741 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:18:14.999740 [info ] [Thread-1 (]: 6 of 7 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:18:15.000743 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:18:15.001741 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:18:15.009281 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:18:15.010320 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:18:15.001741 => 16:18:15.010320
[0m16:18:15.011287 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:18:15.045126 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:15.046427 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp161815034263"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:18:15.047430 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:16.175422 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:18:16.182819 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.182819 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:18:16.214084 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:16.215088 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.215088 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp161815034263'
        
      order by ordinal_position

  
[0m16:18:16.270836 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:18:16.277368 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.278363 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:18:16.316413 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:18:16.331200 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.333480 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp161815034263'
        
      order by ordinal_position

  
[0m16:18:16.369347 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:18:16.372386 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.373354 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:18:16.410608 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:18:16.419317 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m16:18:16.429522 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:18:16.431813 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.431813 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp161815034263"
    )


  
[0m16:18:16.464196 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m16:18:16.465775 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:18:16.466773 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:18:16.466773 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:18:16.496136 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:18:16.498128 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:18:15.012295 => 16:18:16.497128
[0m16:18:16.498128 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:18:16.499633 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66CE4A10>]}
[0m16:18:16.500104 [info ] [Thread-1 (]: 6 of 7 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.50s]
[0m16:18:16.501648 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:18:16.501648 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:18:16.502647 [info ] [Thread-1 (]: 7 of 7 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m16:18:16.503647 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:18:16.504646 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:18:16.507645 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:18:16.511154 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:18:16.504646 => 16:18:16.509647
[0m16:18:16.511672 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:18:16.517677 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:18:16.520682 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:18:16.521699 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m16:18:16.523213 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:18:16.823559 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:18:16.824809 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:18:16.824809 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.listing_id,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.update_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m16:18:16.864508 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column h.host_id does not exist
LINE 39:     h ON l.host_Id = h.host_id
                              ^
HINT:  Perhaps you meant to reference the column "l.host_id".

[0m16:18:16.864508 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: ROLLBACK
[0m16:18:16.892349 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:18:16.512682 => 16:18:16.892349
[0m16:18:16.893337 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m16:18:16.899362 [debug] [Thread-1 (]: Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column h.host_id does not exist
  LINE 39:     h ON l.host_Id = h.host_id
                                ^
  HINT:  Perhaps you meant to reference the column "l.host_id".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:18:16.900356 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9e8f67e-8a4f-490c-8171-3c2b2e1ba354', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF66FE9E10>]}
[0m16:18:16.901361 [error] [Thread-1 (]: 7 of 7 ERROR creating sql table model test.dim_listings_with_hosts ............. [[31mERROR[0m in 0.40s]
[0m16:18:16.902361 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:18:16.904361 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:16.905364 [debug] [MainThread]: On master: BEGIN
[0m16:18:16.906357 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:18:17.550586 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m16:18:17.551324 [debug] [MainThread]: On master: COMMIT
[0m16:18:17.551324 [debug] [MainThread]: Using postgres connection "master"
[0m16:18:17.552331 [debug] [MainThread]: On master: COMMIT
[0m16:18:17.578247 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:18:17.579247 [debug] [MainThread]: On master: Close
[0m16:18:17.583822 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:18:17.584865 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:18:17.584865 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:18:17.585833 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_with_hosts' was properly closed.
[0m16:18:17.586830 [info ] [MainThread]: 
[0m16:18:17.587853 [info ] [MainThread]: Finished running 3 view models, 3 table models, 1 incremental model in 0 hours 0 minutes and 7.09 seconds (7.09s).
[0m16:18:17.591843 [debug] [MainThread]: Command end result
[0m16:18:17.606353 [info ] [MainThread]: 
[0m16:18:17.607360 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:18:17.608360 [info ] [MainThread]: 
[0m16:18:17.611344 [error] [MainThread]:   Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column h.host_id does not exist
  LINE 39:     h ON l.host_Id = h.host_id
                                ^
  HINT:  Perhaps you meant to reference the column "l.host_id".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:18:17.612362 [info ] [MainThread]: 
[0m16:18:17.613347 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m16:18:17.618589 [debug] [MainThread]: Command `dbt run` failed at 16:18:17.615344 after 7.85 seconds
[0m16:18:17.620880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF5F171010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF6653E5D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AF661EB1D0>]}
[0m16:18:17.622879 [debug] [MainThread]: Flushing usage events
[0m16:21:32.962303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248172FD5D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024816F90D50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817568E90>]}


============================== 16:21:32.966808 | bd32c307-b870-4a43-9767-c4ebd90d551a ==============================
[0m16:21:32.966808 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:21:32.967329 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:21:33.173806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817661D10>]}
[0m16:21:33.253701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248176A3210>]}
[0m16:21:33.255240 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:21:33.264238 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:21:33.365681 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m16:21:33.366649 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m16:21:33.366649 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m16:21:33.532518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002481790D0D0>]}
[0m16:21:33.545206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817A53C90>]}
[0m16:21:33.546211 [info ] [MainThread]: Found 7 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m16:21:33.546867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817815C90>]}
[0m16:21:33.548872 [info ] [MainThread]: 
[0m16:21:33.549875 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:21:33.552727 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:21:33.563242 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:21:33.564237 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:21:33.565237 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:21:34.893582 [debug] [ThreadPool]: SQL status: SELECT 11 in 1.0 seconds
[0m16:21:34.895354 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:21:34.897505 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:21:34.903036 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:21:34.903036 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:21:34.904037 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:21:35.104609 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:21:35.106157 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:21:35.106686 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:21:35.156606 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m16:21:35.158612 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:21:35.188974 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:21:35.195322 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:35.196305 [debug] [MainThread]: On master: BEGIN
[0m16:21:35.196305 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:21:35.385826 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:21:35.386826 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:35.387826 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:21:35.447417 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:21:35.450377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817984A50>]}
[0m16:21:35.451381 [debug] [MainThread]: On master: ROLLBACK
[0m16:21:35.480865 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:35.481860 [debug] [MainThread]: On master: BEGIN
[0m16:21:35.539750 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:21:35.539750 [debug] [MainThread]: On master: COMMIT
[0m16:21:35.541024 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:35.542026 [debug] [MainThread]: On master: COMMIT
[0m16:21:35.567575 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:21:35.568583 [debug] [MainThread]: On master: Close
[0m16:21:35.569583 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:21:35.570583 [info ] [MainThread]: 
[0m16:21:35.575648 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:21:35.576653 [info ] [Thread-1 (]: 1 of 7 START sql view model test.src_hosts ..................................... [RUN]
[0m16:21:35.577656 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:21:35.578653 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:21:35.585667 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:21:35.589176 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:21:35.578653 => 16:21:35.589176
[0m16:21:35.590172 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:21:35.631246 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m16:21:35.633211 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.633211 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m16:21:35.634717 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:21:35.828409 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:35.828409 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.829454 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m16:21:35.872965 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:21:35.879919 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.879919 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m16:21:35.920238 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:35.923277 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.924390 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m16:21:35.954514 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:35.969572 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:21:35.971077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:35.971593 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:21:36.003953 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:36.010985 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m16:21:36.016986 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:21:36.016986 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m16:21:36.048780 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:21:36.050784 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:21:35.591172 => 16:21:36.050784
[0m16:21:36.051785 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m16:21:36.052782 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817A590D0>]}
[0m16:21:36.052782 [info ] [Thread-1 (]: 1 of 7 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.48s]
[0m16:21:36.053781 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:21:36.055286 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:21:36.055849 [info ] [Thread-1 (]: 2 of 7 START sql view model test.src_listings .................................. [RUN]
[0m16:21:36.056858 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:21:36.057856 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:21:36.059855 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:21:36.060855 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:21:36.057856 => 16:21:36.060855
[0m16:21:36.061854 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:21:36.065854 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m16:21:36.067360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.067360 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m16:21:36.068867 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:36.279750 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:36.280536 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.281535 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m16:21:36.328378 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:21:36.331958 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.333012 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m16:21:36.363016 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:36.366022 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.367022 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m16:21:36.398849 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:36.401891 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:21:36.402432 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.402432 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:21:36.435768 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:36.438778 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m16:21:36.440278 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:21:36.440278 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m16:21:36.480787 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:21:36.482790 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:21:36.061854 => 16:21:36.482790
[0m16:21:36.482790 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m16:21:36.484787 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248178DD050>]}
[0m16:21:36.484787 [info ] [Thread-1 (]: 2 of 7 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.43s]
[0m16:21:36.486788 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:21:36.486788 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:21:36.488293 [info ] [Thread-1 (]: 3 of 7 START sql view model test.src_reviews ................................... [RUN]
[0m16:21:36.489827 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:21:36.490368 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:21:36.492997 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:21:36.495175 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:21:36.490883 => 16:21:36.494620
[0m16:21:36.495715 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:21:36.504524 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m16:21:36.507037 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.508832 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m16:21:36.509946 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:36.731968 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:36.732903 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.733859 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m16:21:36.784136 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:21:36.787145 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.788649 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m16:21:36.823497 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:36.827122 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.827122 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m16:21:36.863716 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:36.865722 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:21:36.866720 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.866720 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:21:36.900499 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:36.904068 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m16:21:36.905036 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:21:36.906065 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m16:21:36.943038 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:21:36.945037 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:21:36.496241 => 16:21:36.944038
[0m16:21:36.945559 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m16:21:36.946564 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024818B10CD0>]}
[0m16:21:36.947565 [info ] [Thread-1 (]: 3 of 7 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.46s]
[0m16:21:36.948565 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:21:36.949570 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:21:36.950565 [info ] [Thread-1 (]: 4 of 7 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m16:21:36.951580 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m16:21:36.952569 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:21:36.955568 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:36.958080 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:21:36.952569 => 16:21:36.957631
[0m16:21:36.959089 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:21:36.986192 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:36.989194 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:36.990194 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m16:21:36.991193 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:37.202936 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:37.203948 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.203948 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m16:21:37.305130 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m16:21:37.308817 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.308817 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m16:21:37.342969 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:37.346233 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.347234 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m16:21:37.384525 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:37.390649 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:21:37.390649 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.391655 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:21:37.427793 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:37.430793 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m16:21:37.434793 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:21:37.434793 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m16:21:37.478514 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:21:37.480640 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:21:36.960078 => 16:21:37.480640
[0m16:21:37.481607 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m16:21:37.482641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817594A10>]}
[0m16:21:37.482641 [info ] [Thread-1 (]: 4 of 7 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.53s]
[0m16:21:37.484606 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:21:37.485607 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:21:37.486197 [info ] [Thread-1 (]: 5 of 7 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m16:21:37.487212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:21:37.488204 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:21:37.490237 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.492228 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:21:37.488204 => 16:21:37.492228
[0m16:21:37.493203 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:21:37.498221 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.500229 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.501229 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m16:21:37.502231 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:37.734905 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:37.735914 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.736915 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m16:21:37.890988 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:21:37.895503 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.896503 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m16:21:37.930328 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:37.933637 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.934638 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m16:21:37.967556 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:21:37.970333 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:21:37.971333 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:37.971333 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:21:38.012021 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:38.015717 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m16:21:38.016064 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:21:38.017064 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m16:21:38.062732 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:21:38.064519 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:21:37.493203 => 16:21:38.064519
[0m16:21:38.065559 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m16:21:38.066525 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817827ED0>]}
[0m16:21:38.066525 [info ] [Thread-1 (]: 5 of 7 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.58s]
[0m16:21:38.068526 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:21:38.068526 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:21:38.069525 [info ] [Thread-1 (]: 6 of 7 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:21:38.070536 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:21:38.071576 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:21:38.078927 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:21:38.080930 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:21:38.071576 => 16:21:38.080930
[0m16:21:38.081933 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:21:38.111021 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:38.111021 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp162138104008"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:21:38.112024 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:39.343631 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:21:39.350131 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.351131 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:21:39.386486 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:39.387496 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.388494 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162138104008'
        
      order by ordinal_position

  
[0m16:21:39.449994 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:21:39.454825 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.456851 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:21:39.498558 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:21:39.510580 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.510580 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162138104008'
        
      order by ordinal_position

  
[0m16:21:39.551232 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:21:39.554992 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.554992 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:21:39.599582 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:21:39.607123 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m16:21:39.619144 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:21:39.620146 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.621144 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp162138104008"
    )


  
[0m16:21:39.655483 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m16:21:39.657281 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:21:39.658279 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:21:39.659243 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:21:39.694310 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:21:39.695346 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:21:38.081933 => 16:21:39.695346
[0m16:21:39.695346 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:21:39.696852 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002481778FFD0>]}
[0m16:21:39.697404 [info ] [Thread-1 (]: 6 of 7 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.63s]
[0m16:21:39.698406 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:21:39.699440 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:21:39.699440 [info ] [Thread-1 (]: 7 of 7 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m16:21:39.701410 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:21:39.701410 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:21:39.704404 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:21:39.706405 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:21:39.702442 => 16:21:39.705404
[0m16:21:39.706405 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:21:39.712090 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:21:39.714001 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:21:39.714001 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m16:21:39.715041 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:21:39.995887 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:21:39.997133 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:21:39.997133 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.listing_id,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.update_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m16:21:40.036467 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column l.listing_id does not exist
LINE 26:     l.listing_id,
             ^

[0m16:21:40.037564 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: ROLLBACK
[0m16:21:40.064205 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:21:39.707440 => 16:21:40.064205
[0m16:21:40.065253 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m16:21:40.069720 [debug] [Thread-1 (]: Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column l.listing_id does not exist
  LINE 26:     l.listing_id,
               ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:21:40.070785 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd32c307-b870-4a43-9767-c4ebd90d551a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024818BC6650>]}
[0m16:21:40.071791 [error] [Thread-1 (]: 7 of 7 ERROR creating sql table model test.dim_listings_with_hosts ............. [[31mERROR[0m in 0.37s]
[0m16:21:40.072800 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:21:40.074790 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:40.075791 [debug] [MainThread]: On master: BEGIN
[0m16:21:40.075791 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:21:40.263099 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:21:40.264107 [debug] [MainThread]: On master: COMMIT
[0m16:21:40.264107 [debug] [MainThread]: Using postgres connection "master"
[0m16:21:40.265139 [debug] [MainThread]: On master: COMMIT
[0m16:21:40.290986 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:21:40.292002 [debug] [MainThread]: On master: Close
[0m16:21:40.292987 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:21:40.292987 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:21:40.293987 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:21:40.294986 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_with_hosts' was properly closed.
[0m16:21:40.294986 [info ] [MainThread]: 
[0m16:21:40.295768 [info ] [MainThread]: Finished running 3 view models, 3 table models, 1 incremental model in 0 hours 0 minutes and 6.75 seconds (6.75s).
[0m16:21:40.298285 [debug] [MainThread]: Command end result
[0m16:21:40.306817 [info ] [MainThread]: 
[0m16:21:40.307803 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:21:40.309835 [info ] [MainThread]: 
[0m16:21:40.309835 [error] [MainThread]:   Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column l.listing_id does not exist
  LINE 26:     l.listing_id,
               ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:21:40.311980 [info ] [MainThread]: 
[0m16:21:40.313989 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m16:21:40.315970 [debug] [MainThread]: Command `dbt run` failed at 16:21:40.315970 after 7.42 seconds
[0m16:21:40.316968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002480FD81010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024817078250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002480FFF4390>]}
[0m16:21:40.317969 [debug] [MainThread]: Flushing usage events
[0m16:22:13.753435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36E74E610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EF1B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EB193D0>]}


============================== 16:22:13.756902 | 5ea715e1-86bc-42f2-8fad-32f5294e6459 ==============================
[0m16:22:13.756902 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:22:13.759159 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:22:13.968277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EF722D0>]}
[0m16:22:14.047341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36F03F550>]}
[0m16:22:14.049340 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:22:14.058849 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:22:14.158709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:22:14.159709 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:22:14.322350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36F16A450>]}
[0m16:22:14.335293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3702E4F10>]}
[0m16:22:14.336292 [info ] [MainThread]: Found 7 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m16:22:14.337105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36F169090>]}
[0m16:22:14.339110 [info ] [MainThread]: 
[0m16:22:14.340115 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:22:14.343115 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:22:14.353624 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:22:14.353624 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:22:14.354627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:22:15.926496 [debug] [ThreadPool]: SQL status: SELECT 13 in 2.0 seconds
[0m16:22:15.927528 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:22:15.930527 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:22:15.936002 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:22:15.936002 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:22:15.937005 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:22:16.200912 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:22:16.201922 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:22:16.201922 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:22:16.251725 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m16:22:16.253765 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:22:16.289575 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:22:16.296444 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:16.297410 [debug] [MainThread]: On master: BEGIN
[0m16:22:16.297410 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:22:16.514241 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:16.515002 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:16.516016 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:22:16.578636 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:22:16.581338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370356DD0>]}
[0m16:22:16.582346 [debug] [MainThread]: On master: ROLLBACK
[0m16:22:16.616179 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:16.617237 [debug] [MainThread]: On master: BEGIN
[0m16:22:16.683069 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:16.683871 [debug] [MainThread]: On master: COMMIT
[0m16:22:16.684833 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:16.684833 [debug] [MainThread]: On master: COMMIT
[0m16:22:16.715552 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:22:16.716526 [debug] [MainThread]: On master: Close
[0m16:22:16.717518 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:22:16.718518 [info ] [MainThread]: 
[0m16:22:16.722518 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:22:16.722518 [info ] [Thread-1 (]: 1 of 7 START sql view model test.src_hosts ..................................... [RUN]
[0m16:22:16.724521 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:22:16.725535 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:22:16.732070 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:22:16.734043 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:22:16.726034 => 16:22:16.733048
[0m16:22:16.735040 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:22:16.772567 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m16:22:16.774765 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:16.775767 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m16:22:16.775767 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:22:16.997008 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:16.998001 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:16.998001 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m16:22:17.045881 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:17.051980 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:17.052980 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m16:22:17.087537 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.091515 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:17.091515 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m16:22:17.129031 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.143236 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:22:17.144238 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:17.145205 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:22:17.181417 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:17.188840 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m16:22:17.193860 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:17.194865 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m16:22:17.231716 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:17.233473 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:22:16.735040 => 16:22:17.233473
[0m16:22:17.234506 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m16:22:17.235474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EA63F10>]}
[0m16:22:17.236506 [info ] [Thread-1 (]: 1 of 7 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.51s]
[0m16:22:17.238472 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:22:17.238472 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:22:17.239475 [info ] [Thread-1 (]: 2 of 7 START sql view model test.src_listings .................................. [RUN]
[0m16:22:17.240475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:22:17.241474 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:22:17.243690 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:22:17.244691 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:22:17.241474 => 16:22:17.244691
[0m16:22:17.245691 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:22:17.250696 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m16:22:17.253768 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.254781 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m16:22:17.255775 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:17.457992 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:17.458999 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.458999 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m16:22:17.503315 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:17.507313 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.508317 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m16:22:17.537966 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.541968 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.542944 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m16:22:17.572690 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.574723 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:22:17.575726 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.575726 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:22:17.605083 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:17.607114 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m16:22:17.608116 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:17.609114 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m16:22:17.639751 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:17.641758 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:22:17.245691 => 16:22:17.640759
[0m16:22:17.641758 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m16:22:17.642757 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370469810>]}
[0m16:22:17.643757 [info ] [Thread-1 (]: 2 of 7 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.40s]
[0m16:22:17.644758 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:22:17.645757 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:22:17.645757 [info ] [Thread-1 (]: 3 of 7 START sql view model test.src_reviews ................................... [RUN]
[0m16:22:17.646757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:22:17.647791 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:22:17.649791 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:22:17.651023 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:22:17.647791 => 16:22:17.651023
[0m16:22:17.652052 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:22:17.659033 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m16:22:17.662023 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.662023 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m16:22:17.662984 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:17.855385 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:17.856282 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.857278 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m16:22:17.901212 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:17.904232 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.905233 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m16:22:17.931848 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.934955 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.935984 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m16:22:17.965294 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:17.967329 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:22:17.968327 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:17.969328 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:22:17.997474 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:18.000672 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m16:22:18.001230 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:18.002238 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m16:22:18.032629 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:18.034823 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:22:17.652052 => 16:22:18.034306
[0m16:22:18.035359 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m16:22:18.036501 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370510C50>]}
[0m16:22:18.037506 [info ] [Thread-1 (]: 3 of 7 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.39s]
[0m16:22:18.038508 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:22:18.038508 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:22:18.039508 [info ] [Thread-1 (]: 4 of 7 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m16:22:18.041509 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m16:22:18.041509 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:22:18.044507 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.045506 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:22:18.042509 => 16:22:18.045506
[0m16:22:18.046506 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:22:18.072526 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.073520 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.074520 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m16:22:18.075520 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:18.278413 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:18.279215 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.280171 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m16:22:18.370186 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m16:22:18.373735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.373735 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m16:22:18.404435 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:18.408466 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.408466 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m16:22:18.438584 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:18.444596 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:22:18.445596 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.445596 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:22:18.477477 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:18.480892 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m16:22:18.484893 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:18.485895 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m16:22:18.525801 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:18.527849 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:22:18.047535 => 16:22:18.527849
[0m16:22:18.527849 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m16:22:18.529353 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370480450>]}
[0m16:22:18.530359 [info ] [Thread-1 (]: 4 of 7 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.49s]
[0m16:22:18.531364 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:22:18.532360 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:22:18.533360 [info ] [Thread-1 (]: 5 of 7 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m16:22:18.534361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:22:18.534361 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:22:18.537393 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.539360 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:22:18.535359 => 16:22:18.538360
[0m16:22:18.539865 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:22:18.544904 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.545905 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.546908 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m16:22:18.547876 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:18.731335 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:18.731850 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.732857 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m16:22:18.874963 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:22:18.880162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.880162 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m16:22:18.909555 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:18.913169 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.914137 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m16:22:18.942180 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:18.945232 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:22:18.946195 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.946195 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:22:18.977197 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:18.981190 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m16:22:18.982190 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:18.982190 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m16:22:19.024161 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:19.026919 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:22:18.540872 => 16:22:19.025918
[0m16:22:19.026919 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m16:22:19.028918 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D370469810>]}
[0m16:22:19.029918 [info ] [Thread-1 (]: 5 of 7 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.49s]
[0m16:22:19.030416 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:22:19.031425 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:22:19.032323 [info ] [Thread-1 (]: 6 of 7 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:22:19.032879 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:22:19.033890 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:22:19.043885 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:22:19.045394 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:22:19.034889 => 16:22:19.044875
[0m16:22:19.046397 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:22:19.077451 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:19.078450 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp162219069409"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:22:19.078450 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:20.406400 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:22:20.412399 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.413902 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:22:20.448641 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:20.448641 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.450148 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162219069409'
        
      order by ordinal_position

  
[0m16:22:20.510358 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:20.516479 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.517446 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:22:20.558314 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:20.571581 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.572086 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162219069409'
        
      order by ordinal_position

  
[0m16:22:20.614908 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:20.618654 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.619158 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:22:20.660327 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:20.669237 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m16:22:20.679745 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:22:20.681716 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.682716 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp162219069409"
    )


  
[0m16:22:20.719115 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m16:22:20.722121 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:22:20.723129 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:20.724116 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:22:20.756414 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:20.758422 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:22:19.046397 => 16:22:20.757421
[0m16:22:20.758422 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:22:20.759423 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3704BBC90>]}
[0m16:22:20.760422 [info ] [Thread-1 (]: 6 of 7 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.73s]
[0m16:22:20.762455 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:22:20.762455 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:22:20.763664 [info ] [Thread-1 (]: 7 of 7 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m16:22:20.764633 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:22:20.765635 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:22:20.768635 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:20.770634 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:22:20.765635 => 16:22:20.770634
[0m16:22:20.771632 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:22:20.786914 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:20.789045 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:20.790044 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m16:22:20.791044 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:21.142571 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:21.143587 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:21.143587 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.update_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m16:22:21.188582 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column h.update_at does not exist
LINE 35:     GREATEST(l.updated_at, h.update_at) AS update_at
                                    ^
HINT:  Perhaps you meant to reference the column "h.updated_at".

[0m16:22:21.189580 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: ROLLBACK
[0m16:22:21.227445 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:22:20.772630 => 16:22:21.227445
[0m16:22:21.228446 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m16:22:21.233939 [debug] [Thread-1 (]: Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column h.update_at does not exist
  LINE 35:     GREATEST(l.updated_at, h.update_at) AS update_at
                                      ^
  HINT:  Perhaps you meant to reference the column "h.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:22:21.234944 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ea715e1-86bc-42f2-8fad-32f5294e6459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36E751450>]}
[0m16:22:21.235949 [error] [Thread-1 (]: 7 of 7 ERROR creating sql table model test.dim_listings_with_hosts ............. [[31mERROR[0m in 0.47s]
[0m16:22:21.236604 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:22:21.238609 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:21.239611 [debug] [MainThread]: On master: BEGIN
[0m16:22:21.239611 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:22:21.469981 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:21.469981 [debug] [MainThread]: On master: COMMIT
[0m16:22:21.471494 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:21.471494 [debug] [MainThread]: On master: COMMIT
[0m16:22:21.502377 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:22:21.503255 [debug] [MainThread]: On master: Close
[0m16:22:21.504252 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:22:21.505251 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:22:21.505251 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:22:21.506251 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_with_hosts' was properly closed.
[0m16:22:21.506251 [info ] [MainThread]: 
[0m16:22:21.507756 [info ] [MainThread]: Finished running 3 view models, 3 table models, 1 incremental model in 0 hours 0 minutes and 7.17 seconds (7.17s).
[0m16:22:21.509293 [debug] [MainThread]: Command end result
[0m16:22:21.518294 [info ] [MainThread]: 
[0m16:22:21.520845 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:22:21.520845 [info ] [MainThread]: 
[0m16:22:21.521852 [error] [MainThread]:   Database Error in model dim_listings_with_hosts (dbtlearn/models\dim\dim_listings_with_hosts.sql)
  column h.update_at does not exist
  LINE 35:     GREATEST(l.updated_at, h.update_at) AS update_at
                                      ^
  HINT:  Perhaps you meant to reference the column "h.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:22:21.523855 [info ] [MainThread]: 
[0m16:22:21.524853 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m16:22:21.528854 [debug] [MainThread]: Command `dbt run` failed at 16:22:21.528854 after 7.84 seconds
[0m16:22:21.529859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D367791010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36E9F7B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D36EF421D0>]}
[0m16:22:21.530851 [debug] [MainThread]: Flushing usage events
[0m16:22:37.811425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022974DF6810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229755EB710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022974E41D10>]}


============================== 16:22:37.815430 | 405b6fbc-fafe-4943-b918-348baa505995 ==============================
[0m16:22:37.815430 [info ] [MainThread]: Running with dbt=1.7.3
[0m16:22:37.816431 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:22:38.026534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297573F910>]}
[0m16:22:38.134232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022974E41D50>]}
[0m16:22:38.135546 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m16:22:38.144780 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m16:22:38.240608 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:22:38.240608 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_with_hosts.sql
[0m16:22:38.404014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297595BE50>]}
[0m16:22:38.417077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976B72290>]}
[0m16:22:38.418445 [info ] [MainThread]: Found 7 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m16:22:38.419446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229756141D0>]}
[0m16:22:38.421480 [info ] [MainThread]: 
[0m16:22:38.422453 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:22:38.424444 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m16:22:38.436501 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m16:22:38.437501 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m16:22:38.438501 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:22:39.802972 [debug] [ThreadPool]: SQL status: SELECT 15 in 1.0 seconds
[0m16:22:39.804983 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m16:22:39.807985 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m16:22:39.813020 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:22:39.814019 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m16:22:39.815019 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:22:40.030913 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m16:22:40.031870 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m16:22:40.031870 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m16:22:40.084026 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m16:22:40.086063 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m16:22:40.121280 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m16:22:40.128368 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:40.128368 [debug] [MainThread]: On master: BEGIN
[0m16:22:40.129368 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:22:40.356740 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:40.357788 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:40.357788 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:22:40.422798 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m16:22:40.425836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022975617150>]}
[0m16:22:40.426837 [debug] [MainThread]: On master: ROLLBACK
[0m16:22:40.459162 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:40.460667 [debug] [MainThread]: On master: BEGIN
[0m16:22:40.529937 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:40.529937 [debug] [MainThread]: On master: COMMIT
[0m16:22:40.530939 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:40.530939 [debug] [MainThread]: On master: COMMIT
[0m16:22:40.563992 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:22:40.565022 [debug] [MainThread]: On master: Close
[0m16:22:40.566011 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:22:40.566011 [info ] [MainThread]: 
[0m16:22:40.569746 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m16:22:40.570785 [info ] [Thread-1 (]: 1 of 7 START sql view model test.src_hosts ..................................... [RUN]
[0m16:22:40.571751 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m16:22:40.572752 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m16:22:40.578757 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m16:22:40.582091 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 16:22:40.572752 => 16:22:40.581262
[0m16:22:40.583271 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m16:22:40.620198 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m16:22:40.621200 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.622202 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m16:22:40.622202 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:22:40.805199 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:40.806493 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.806493 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m16:22:40.850182 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:40.856179 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.857179 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m16:22:40.886440 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:40.889435 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.890436 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m16:22:40.921359 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:40.936417 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:22:40.937378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.937378 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m16:22:40.968207 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:40.974198 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m16:22:40.979432 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m16:22:40.979432 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m16:22:41.013032 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:41.014774 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 16:22:40.583271 => 16:22:41.014774
[0m16:22:41.015775 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m16:22:41.016810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022975B13E10>]}
[0m16:22:41.016810 [info ] [Thread-1 (]: 1 of 7 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.44s]
[0m16:22:41.018776 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m16:22:41.018776 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m16:22:41.020091 [info ] [Thread-1 (]: 2 of 7 START sql view model test.src_listings .................................. [RUN]
[0m16:22:41.020723 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m16:22:41.022046 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m16:22:41.024046 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m16:22:41.025549 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 16:22:41.022046 => 16:22:41.025037
[0m16:22:41.026141 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m16:22:41.029712 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m16:22:41.031703 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.032680 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m16:22:41.033679 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:41.213407 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:41.214420 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.214420 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m16:22:41.261992 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:41.265482 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.266733 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m16:22:41.296770 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:41.299803 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.300785 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m16:22:41.331180 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:41.333186 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:22:41.334186 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.334186 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m16:22:41.361761 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:41.365313 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m16:22:41.366285 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m16:22:41.367314 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m16:22:41.398804 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:41.400302 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 16:22:41.026677 => 16:22:41.400302
[0m16:22:41.401301 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m16:22:41.402303 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976B71590>]}
[0m16:22:41.403303 [info ] [Thread-1 (]: 2 of 7 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m16:22:41.404305 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m16:22:41.405302 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m16:22:41.406303 [info ] [Thread-1 (]: 3 of 7 START sql view model test.src_reviews ................................... [RUN]
[0m16:22:41.407322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m16:22:41.408302 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m16:22:41.410323 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m16:22:41.412329 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 16:22:41.408302 => 16:22:41.411328
[0m16:22:41.412329 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m16:22:41.419329 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m16:22:41.420328 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.422371 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m16:22:41.422371 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:41.606630 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:41.607679 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.607679 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m16:22:41.654514 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m16:22:41.658554 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.658554 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m16:22:41.690217 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:41.693211 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.693211 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m16:22:41.724133 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:41.725703 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:22:41.726703 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.727670 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m16:22:41.758045 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:41.761431 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m16:22:41.762414 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m16:22:41.763431 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m16:22:41.794506 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m16:22:41.796663 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 16:22:41.413328 => 16:22:41.795656
[0m16:22:41.796663 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m16:22:41.797662 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976BEC110>]}
[0m16:22:41.798695 [info ] [Thread-1 (]: 3 of 7 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.39s]
[0m16:22:41.799661 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m16:22:41.800695 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m16:22:41.801661 [info ] [Thread-1 (]: 4 of 7 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m16:22:41.802661 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m16:22:41.803660 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m16:22:41.806661 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:41.808173 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 16:22:41.803660 => 16:22:41.807165
[0m16:22:41.808173 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m16:22:41.834205 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:41.836172 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:41.837173 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m16:22:41.837173 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:42.010847 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:42.012324 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.013323 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m16:22:42.104089 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m16:22:42.107128 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.108191 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m16:22:42.135434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:42.138230 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.139230 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m16:22:42.170630 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:42.176639 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:22:42.176639 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.177639 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m16:22:42.207609 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:42.210609 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m16:22:42.213638 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m16:22:42.213638 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m16:22:42.253860 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:42.255892 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 16:22:41.809171 => 16:22:42.255892
[0m16:22:42.255892 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m16:22:42.256892 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229758FBE10>]}
[0m16:22:42.257892 [info ] [Thread-1 (]: 4 of 7 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.45s]
[0m16:22:42.258857 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m16:22:42.259892 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m16:22:42.260858 [info ] [Thread-1 (]: 5 of 7 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m16:22:42.261858 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m16:22:42.261858 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m16:22:42.264915 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.266916 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 16:22:42.262859 => 16:22:42.266916
[0m16:22:42.266916 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m16:22:42.273925 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.276397 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.277398 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m16:22:42.278395 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:42.492750 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:42.493272 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.494281 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m16:22:42.637675 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:22:42.642675 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.643676 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m16:22:42.677566 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:42.681573 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.682567 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m16:22:42.711006 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:42.713006 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:22:42.714011 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.715006 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m16:22:42.751002 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:42.754011 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m16:22:42.755011 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m16:22:42.756010 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m16:22:42.794251 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:42.796294 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 16:22:42.267917 => 16:22:42.796294
[0m16:22:42.796294 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m16:22:42.797294 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229756F61D0>]}
[0m16:22:42.798298 [info ] [Thread-1 (]: 5 of 7 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.54s]
[0m16:22:42.799181 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m16:22:42.800220 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m16:22:42.801009 [info ] [Thread-1 (]: 6 of 7 START sql incremental model test.fact_reviews ........................... [RUN]
[0m16:22:42.802015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m16:22:42.802015 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m16:22:42.810524 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m16:22:42.812527 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 16:22:42.803014 => 16:22:42.811527
[0m16:22:42.812527 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m16:22:42.844479 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:42.844479 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp162242837506"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m16:22:42.845446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:44.061735 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m16:22:44.069391 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.069946 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m16:22:44.099892 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:44.100895 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.102404 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162242837506'
        
      order by ordinal_position

  
[0m16:22:44.159038 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:44.164090 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.164090 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:22:44.201752 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:44.213309 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.214309 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp162242837506'
        
      order by ordinal_position

  
[0m16:22:44.251541 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:44.254573 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.255576 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m16:22:44.292535 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m16:22:44.301200 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m16:22:44.310413 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m16:22:44.312412 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.312412 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp162242837506"
    )


  
[0m16:22:44.341012 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m16:22:44.343591 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:22:44.344603 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m16:22:44.344603 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m16:22:44.374810 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:44.375850 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 16:22:42.813528 => 16:22:44.375850
[0m16:22:44.376808 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m16:22:44.376808 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297575EA90>]}
[0m16:22:44.378348 [info ] [Thread-1 (]: 6 of 7 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.58s]
[0m16:22:44.379495 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m16:22:44.380504 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m16:22:44.381501 [info ] [Thread-1 (]: 7 of 7 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m16:22:44.382504 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m16:22:44.383521 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m16:22:44.386499 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.388381 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 16:22:44.383521 => 16:22:44.388381
[0m16:22:44.389387 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m16:22:44.394860 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.396843 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.397833 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m16:22:44.398826 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:22:44.698113 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m16:22:44.699125 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.700122 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m16:22:44.849034 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m16:22:44.854031 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.855032 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m16:22:44.885445 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m16:22:44.887412 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m16:22:44.888413 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.889415 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m16:22:44.927139 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m16:22:44.931136 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m16:22:44.932681 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m16:22:44.932681 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m16:22:44.963193 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m16:22:44.965205 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 16:22:44.389387 => 16:22:44.965205
[0m16:22:44.965205 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m16:22:44.966205 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '405b6fbc-fafe-4943-b918-348baa505995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022975897550>]}
[0m16:22:44.967204 [info ] [Thread-1 (]: 7 of 7 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 0.58s]
[0m16:22:44.968228 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m16:22:44.969715 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:44.969715 [debug] [MainThread]: On master: BEGIN
[0m16:22:44.970714 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:22:45.160543 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m16:22:45.160543 [debug] [MainThread]: On master: COMMIT
[0m16:22:45.161578 [debug] [MainThread]: Using postgres connection "master"
[0m16:22:45.162578 [debug] [MainThread]: On master: COMMIT
[0m16:22:45.190143 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m16:22:45.190874 [debug] [MainThread]: On master: Close
[0m16:22:45.191888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:22:45.191888 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m16:22:45.192914 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m16:22:45.192914 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_with_hosts' was properly closed.
[0m16:22:45.193883 [info ] [MainThread]: 
[0m16:22:45.193883 [info ] [MainThread]: Finished running 3 view models, 3 table models, 1 incremental model in 0 hours 0 minutes and 6.77 seconds (6.77s).
[0m16:22:45.196466 [debug] [MainThread]: Command end result
[0m16:22:45.205473 [info ] [MainThread]: 
[0m16:22:45.206473 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:22:45.207978 [info ] [MainThread]: 
[0m16:22:45.208639 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m16:22:45.210735 [debug] [MainThread]: Command `dbt run` succeeded at 16:22:45.210735 after 7.47 seconds
[0m16:22:45.211731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002296DEAE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002296E22F210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002296E22FD50>]}
[0m16:22:45.211731 [debug] [MainThread]: Flushing usage events
[0m13:38:11.012902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C95C50D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9553D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C441E5D0>]}


============================== 13:38:11.016536 | cefb3a39-d4ae-4877-b62c-5886c8976392 ==============================
[0m13:38:11.016536 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:38:11.016536 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt seed', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:38:11.329397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9ACDBD0>]}
[0m13:38:11.413894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9C8B7D0>]}
[0m13:38:11.416438 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:38:11.434148 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:38:12.423301 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m13:38:12.423301 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/seeds\seed_full_moon_dates.csv
[0m13:38:12.578424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9CC3CD0>]}
[0m13:38:12.609940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9E3E910>]}
[0m13:38:12.609940 [info ] [MainThread]: Found 7 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:38:12.609940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9D17F10>]}
[0m13:38:12.614804 [info ] [MainThread]: 
[0m13:38:12.614804 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:38:12.614804 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:38:12.627090 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:38:12.627965 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:38:12.627965 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:38:13.925539 [debug] [ThreadPool]: SQL status: SELECT 15 in 1.0 seconds
[0m13:38:13.925539 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:38:13.938445 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:38:13.945802 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:38:13.946809 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:38:13.946809 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:38:14.172813 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:38:14.173339 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:38:14.173866 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:38:14.225511 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m13:38:14.230022 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:38:14.262783 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:38:14.262783 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:14.262783 [debug] [MainThread]: On master: BEGIN
[0m13:38:14.272830 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:38:14.465995 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:38:14.465995 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:14.465995 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:38:14.538312 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:38:14.538312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9E68C90>]}
[0m13:38:14.538312 [debug] [MainThread]: On master: ROLLBACK
[0m13:38:14.574883 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:14.574883 [debug] [MainThread]: On master: BEGIN
[0m13:38:14.633706 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:38:14.633706 [debug] [MainThread]: On master: COMMIT
[0m13:38:14.633706 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:14.633706 [debug] [MainThread]: On master: COMMIT
[0m13:38:14.683126 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:38:14.683126 [debug] [MainThread]: On master: Close
[0m13:38:14.683126 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:38:14.683126 [info ] [MainThread]: 
[0m13:38:14.683126 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m13:38:14.683126 [info ] [Thread-1 (]: 1 of 1 START seed file test.seed_full_moon_dates ............................... [RUN]
[0m13:38:14.691862 [debug] [Thread-1 (]: Acquiring new postgres connection 'seed.dbtlearn.seed_full_moon_dates'
[0m13:38:14.692638 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m13:38:14.693789 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 13:38:14.693789 => 13:38:14.693789
[0m13:38:14.694316 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m13:38:14.728568 [debug] [Thread-1 (]: Using postgres connection "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:14.729535 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: BEGIN
[0m13:38:14.729535 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:38:14.957977 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:38:14.957977 [debug] [Thread-1 (]: Using postgres connection "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:14.957977 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "seed.dbtlearn.seed_full_moon_dates"} */

    create table "inttegra_stage"."test"."seed_full_moon_dates" ("full_moon_date" date)
  
[0m13:38:15.018728 [debug] [Thread-1 (]: SQL status: CREATE TABLE in 0.0 seconds
[0m13:38:15.103059 [debug] [Thread-1 (]: Using postgres connection "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:15.103059 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: 
          insert into "inttegra_stage"."test"."seed_full_moon_dates" ("full_moon_date") values
          (%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(%s),(...
[0m13:38:15.141625 [debug] [Thread-1 (]: SQL status: INSERT 0 272 in 0.0 seconds
[0m13:38:15.151271 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:15.169379 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: COMMIT
[0m13:38:15.171384 [debug] [Thread-1 (]: Using postgres connection "seed.dbtlearn.seed_full_moon_dates"
[0m13:38:15.171384 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: COMMIT
[0m13:38:15.198679 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:38:15.204878 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 13:38:14.694316 => 13:38:15.204878
[0m13:38:15.206889 [debug] [Thread-1 (]: On seed.dbtlearn.seed_full_moon_dates: Close
[0m13:38:15.206889 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cefb3a39-d4ae-4877-b62c-5886c8976392', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9FE1450>]}
[0m13:38:15.206889 [info ] [Thread-1 (]: 1 of 1 OK loaded seed file test.seed_full_moon_dates ........................... [[32mINSERT 272[0m in 0.52s]
[0m13:38:15.208895 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m13:38:15.211339 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:15.211339 [debug] [MainThread]: On master: BEGIN
[0m13:38:15.211339 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:38:15.438787 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:38:15.438787 [debug] [MainThread]: On master: COMMIT
[0m13:38:15.438787 [debug] [MainThread]: Using postgres connection "master"
[0m13:38:15.438787 [debug] [MainThread]: On master: COMMIT
[0m13:38:15.477285 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:38:15.477285 [debug] [MainThread]: On master: Close
[0m13:38:15.477285 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:38:15.477285 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:38:15.477285 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:38:15.477285 [debug] [MainThread]: Connection 'seed.dbtlearn.seed_full_moon_dates' was properly closed.
[0m13:38:15.477285 [info ] [MainThread]: 
[0m13:38:15.477285 [info ] [MainThread]: Finished running 1 seed in 0 hours 0 minutes and 2.86 seconds (2.86s).
[0m13:38:15.477285 [debug] [MainThread]: Command end result
[0m13:38:15.494347 [info ] [MainThread]: 
[0m13:38:15.495347 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:38:15.496373 [info ] [MainThread]: 
[0m13:38:15.497350 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:38:15.498891 [debug] [MainThread]: Command `dbt seed` succeeded at 13:38:15.498891 after 4.56 seconds
[0m13:38:15.499926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C9AAD710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C2614390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000152C23A1010>]}
[0m13:38:15.499926 [debug] [MainThread]: Flushing usage events
[0m13:48:37.547093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8301DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF85B8490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF70F5390>]}


============================== 13:48:37.554103 | f61436b8-d8fb-4286-a4be-9c8ca865c998 ==============================
[0m13:48:37.554103 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:48:37.556098 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m13:48:37.929484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF83013D0>]}
[0m13:48:38.073134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8AF9390>]}
[0m13:48:38.077185 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:48:38.093226 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:48:38.224916 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m13:48:38.224916 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:48:38.397634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8FC0A90>]}
[0m13:48:38.411082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8E6E9D0>]}
[0m13:48:38.412223 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:48:38.412698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8666F90>]}
[0m13:48:38.414728 [info ] [MainThread]: 
[0m13:48:38.415389 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:48:38.418499 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:48:38.427519 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:48:38.428521 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:48:38.429520 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:48:39.716541 [debug] [ThreadPool]: SQL status: SELECT 15 in 1.0 seconds
[0m13:48:39.717541 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:48:39.722106 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:48:39.737835 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:48:39.740831 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:48:39.741827 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:48:39.956725 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:48:39.957728 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:48:39.958725 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:48:40.007362 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:48:40.009362 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:48:40.040844 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:48:40.057460 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:40.058897 [debug] [MainThread]: On master: BEGIN
[0m13:48:40.060908 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:48:40.284538 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:48:40.286591 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:40.286591 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:48:40.351251 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:48:40.353288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8BDBF90>]}
[0m13:48:40.354282 [debug] [MainThread]: On master: ROLLBACK
[0m13:48:40.389137 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:40.389137 [debug] [MainThread]: On master: BEGIN
[0m13:48:40.454181 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:48:40.455292 [debug] [MainThread]: On master: COMMIT
[0m13:48:40.455292 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:40.456302 [debug] [MainThread]: On master: COMMIT
[0m13:48:40.484648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:48:40.484648 [debug] [MainThread]: On master: Close
[0m13:48:40.486655 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:48:40.486655 [info ] [MainThread]: 
[0m13:48:40.491685 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m13:48:40.491685 [info ] [Thread-1 (]: 1 of 8 START sql view model test.src_hosts ..................................... [RUN]
[0m13:48:40.493685 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m13:48:40.493685 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m13:48:40.500690 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m13:48:40.504737 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 13:48:40.494684 => 13:48:40.503499
[0m13:48:40.506763 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m13:48:40.550565 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m13:48:40.554581 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.555580 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m13:48:40.556581 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:48:40.752443 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:40.753441 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.754440 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m13:48:40.803944 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:48:40.811053 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.812020 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m13:48:40.846997 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:40.851365 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.852402 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m13:48:40.886875 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:40.904164 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m13:48:40.905162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.905162 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m13:48:40.936385 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:40.945351 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m13:48:40.951077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m13:48:40.951077 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m13:48:40.989277 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:48:40.992452 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 13:48:40.507736 => 13:48:40.991452
[0m13:48:40.992452 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m13:48:40.993454 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8C67AD0>]}
[0m13:48:40.994960 [info ] [Thread-1 (]: 1 of 8 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.50s]
[0m13:48:40.994960 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m13:48:40.996201 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m13:48:40.998202 [info ] [Thread-1 (]: 2 of 8 START sql view model test.src_listings .................................. [RUN]
[0m13:48:41.000202 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m13:48:41.001204 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m13:48:41.003200 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m13:48:41.007203 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 13:48:41.001204 => 13:48:41.006203
[0m13:48:41.007203 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m13:48:41.014661 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m13:48:41.017662 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.019170 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m13:48:41.020363 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:41.229625 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:41.231129 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.232139 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m13:48:41.279057 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:48:41.282030 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.283568 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m13:48:41.317791 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:41.320821 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.321820 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m13:48:41.357420 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:41.359428 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m13:48:41.360460 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.360460 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m13:48:41.392854 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:41.395896 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m13:48:41.396893 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m13:48:41.397892 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m13:48:41.437095 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:48:41.438106 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 13:48:41.008661 => 13:48:41.438106
[0m13:48:41.439612 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m13:48:41.440127 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CFA01FDD0>]}
[0m13:48:41.441132 [info ] [Thread-1 (]: 2 of 8 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.44s]
[0m13:48:41.441874 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m13:48:41.442880 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m13:48:41.443880 [info ] [Thread-1 (]: 3 of 8 START sql view model test.src_reviews ................................... [RUN]
[0m13:48:41.444879 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m13:48:41.444879 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m13:48:41.446878 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m13:48:41.447879 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 13:48:41.444879 => 13:48:41.447879
[0m13:48:41.448879 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m13:48:41.454323 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m13:48:41.456324 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.457324 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m13:48:41.458326 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:41.670397 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:41.671442 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.671442 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m13:48:41.714536 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m13:48:41.718576 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.718576 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m13:48:41.755431 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:41.758464 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.758464 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m13:48:41.791872 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:41.793869 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m13:48:41.794870 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.794870 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m13:48:41.827942 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:41.830948 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m13:48:41.832458 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m13:48:41.832458 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m13:48:41.870389 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m13:48:41.872826 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 13:48:41.448879 => 13:48:41.872826
[0m13:48:41.872826 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m13:48:41.873829 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8CCE710>]}
[0m13:48:41.874865 [info ] [Thread-1 (]: 3 of 8 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.43s]
[0m13:48:41.876862 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m13:48:41.876862 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m13:48:41.877829 [info ] [Thread-1 (]: 4 of 8 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m13:48:41.878875 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m13:48:41.879863 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m13:48:41.881861 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:41.882862 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 13:48:41.879863 => 13:48:41.882862
[0m13:48:41.884371 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m13:48:41.908428 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:41.910811 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:41.910811 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m13:48:41.911809 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:42.098843 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:42.099640 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.100631 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m13:48:42.196757 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m13:48:42.201156 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.202153 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m13:48:42.235874 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:42.238865 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.239864 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m13:48:42.272234 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:42.278096 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m13:48:42.279106 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.279106 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m13:48:42.312318 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:42.315319 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m13:48:42.321046 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m13:48:42.322046 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m13:48:42.365901 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:48:42.369074 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 13:48:41.885387 => 13:48:42.368496
[0m13:48:42.370081 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m13:48:42.371591 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8604150>]}
[0m13:48:42.371591 [info ] [Thread-1 (]: 4 of 8 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.49s]
[0m13:48:42.373601 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m13:48:42.374598 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m13:48:42.375104 [info ] [Thread-1 (]: 5 of 8 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m13:48:42.376111 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m13:48:42.377109 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m13:48:42.380196 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.381753 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 13:48:42.377613 => 13:48:42.381236
[0m13:48:42.382760 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m13:48:42.390283 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.393135 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.394245 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m13:48:42.396116 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:42.596261 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:42.597282 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.597282 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m13:48:42.751768 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m13:48:42.755773 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.756774 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m13:48:42.788226 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:42.792234 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.793250 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m13:48:42.823690 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:42.826695 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m13:48:42.826695 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.827695 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m13:48:42.859767 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:42.862775 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m13:48:42.863777 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m13:48:42.865787 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m13:48:42.905864 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:48:42.907406 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 13:48:42.382760 => 13:48:42.907406
[0m13:48:42.908417 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m13:48:42.909406 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8E9BC90>]}
[0m13:48:42.909406 [info ] [Thread-1 (]: 5 of 8 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.53s]
[0m13:48:42.911410 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m13:48:42.911410 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m13:48:42.912407 [info ] [Thread-1 (]: 6 of 8 START sql incremental model test.fact_reviews ........................... [RUN]
[0m13:48:42.913409 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m13:48:42.914448 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m13:48:42.922192 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m13:48:42.925056 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 13:48:42.914448 => 13:48:42.924047
[0m13:48:42.925056 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m13:48:42.959887 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:42.960887 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp134842951734"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m13:48:42.961890 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:44.174736 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m13:48:44.181598 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.181598 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m13:48:44.212089 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:44.213104 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.213104 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp134842951734'
        
      order by ordinal_position

  
[0m13:48:44.279103 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m13:48:44.284230 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.285231 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m13:48:44.326434 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m13:48:44.338098 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.338098 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp134842951734'
        
      order by ordinal_position

  
[0m13:48:44.376898 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m13:48:44.380690 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.380690 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m13:48:44.421664 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m13:48:44.428663 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m13:48:44.443400 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m13:48:44.445893 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.445893 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp134842951734"
    )


  
[0m13:48:44.478791 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m13:48:44.481358 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m13:48:44.482671 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m13:48:44.483673 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m13:48:44.514908 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:44.516415 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 13:48:42.926089 => 13:48:44.514908
[0m13:48:44.517482 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m13:48:44.518947 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8EADA50>]}
[0m13:48:44.519948 [info ] [Thread-1 (]: 6 of 8 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.61s]
[0m13:48:44.521949 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m13:48:44.522949 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m13:48:44.524949 [info ] [Thread-1 (]: 7 of 8 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m13:48:44.526957 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m13:48:44.529000 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m13:48:44.535009 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:44.541111 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 13:48:44.530013 => 13:48:44.539011
[0m13:48:44.541789 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m13:48:44.554214 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:44.556461 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:44.557507 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m13:48:44.558582 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:44.848414 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:44.848414 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:44.849525 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m13:48:45.003639 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m13:48:45.007639 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:45.007639 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts" rename to "dim_listings_with_hosts__dbt_backup"
[0m13:48:45.040393 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:45.044900 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:45.045916 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m13:48:45.077507 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:48:45.079503 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m13:48:45.079503 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:45.081008 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m13:48:45.111355 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:48:45.114395 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m13:48:45.115383 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m13:48:45.116395 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m13:48:45.157884 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:48:45.159926 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 13:48:44.542903 => 13:48:45.158934
[0m13:48:45.159926 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m13:48:45.160923 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CFA10F6D0>]}
[0m13:48:45.161924 [info ] [Thread-1 (]: 7 of 8 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 0.63s]
[0m13:48:45.162890 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m13:48:45.163894 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:48:45.163894 [info ] [Thread-1 (]: 8 of 8 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:48:45.165399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m13:48:45.166661 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:48:45.169659 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:48:45.171690 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:48:45.166661 => 13:48:45.171690
[0m13:48:45.172690 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:48:45.177164 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:48:45.179329 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:48:45.180328 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:48:45.181328 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:48:45.380204 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:48:45.382323 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:48:45.382323 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon,
FROM
    fact_reviews AS r
LEFT JOIN
    full_moon_dates AS fm ON TO_DATE(r.reviw_date) = DATEADD(DAR, 1, fm.full_moon_date)
  );
  
[0m13:48:45.420887 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "FROM"
LINE 33: FROM
         ^

[0m13:48:45.420887 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:48:45.452440 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:48:45.172690 => 13:48:45.452440
[0m13:48:45.453998 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:48:45.568412 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  syntax error at or near "FROM"
  LINE 33: FROM
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:48:45.569431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f61436b8-d8fb-4286-a4be-9c8ca865c998', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8B03190>]}
[0m13:48:45.570411 [error] [Thread-1 (]: 8 of 8 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.40s]
[0m13:48:45.571377 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:48:45.573884 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:45.574456 [debug] [MainThread]: On master: BEGIN
[0m13:48:45.574940 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:48:45.802228 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:48:45.803258 [debug] [MainThread]: On master: COMMIT
[0m13:48:45.803258 [debug] [MainThread]: Using postgres connection "master"
[0m13:48:45.804269 [debug] [MainThread]: On master: COMMIT
[0m13:48:45.835069 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:48:45.835069 [debug] [MainThread]: On master: Close
[0m13:48:45.837074 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:48:45.837074 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:48:45.837074 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:48:45.838597 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:48:45.839080 [info ] [MainThread]: 
[0m13:48:45.839605 [info ] [MainThread]: Finished running 3 view models, 4 table models, 1 incremental model in 0 hours 0 minutes and 7.42 seconds (7.42s).
[0m13:48:45.841637 [debug] [MainThread]: Command end result
[0m13:48:45.851457 [info ] [MainThread]: 
[0m13:48:45.852424 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:48:45.853425 [info ] [MainThread]: 
[0m13:48:45.853425 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  syntax error at or near "FROM"
  LINE 33: FROM
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:48:45.854929 [info ] [MainThread]: 
[0m13:48:45.854929 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
[0m13:48:45.856931 [debug] [MainThread]: Command `dbt run` failed at 13:48:45.856931 after 8.40 seconds
[0m13:48:45.857932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF8AE0A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF1351010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027CF82F7E50>]}
[0m13:48:45.858951 [debug] [MainThread]: Flushing usage events
[0m13:49:57.188683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A243B410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2467C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A23D01D0>]}


============================== 13:49:57.192680 | fdf0bb57-4069-4022-a144-1e588ac45f95 ==============================
[0m13:49:57.192680 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:49:57.193682 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'send_anonymous_usage_stats': 'True'}
[0m13:49:57.400333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2C85D90>]}
[0m13:49:57.476300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2696090>]}
[0m13:49:57.478374 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:49:57.485419 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:49:57.589326 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:49:57.590326 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:49:57.755416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A3076950>]}
[0m13:49:57.768081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2F610D0>]}
[0m13:49:57.768081 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:49:57.769114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A2D68550>]}
[0m13:49:57.771084 [info ] [MainThread]: 
[0m13:49:57.771669 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:49:57.773710 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:49:57.783233 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:49:57.783740 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:49:57.783740 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:59.110731 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:49:59.112729 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:49:59.114733 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:49:59.122155 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:49:59.123273 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:49:59.124271 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:59.327204 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:49:59.327806 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:49:59.328817 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:49:59.378613 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:49:59.380638 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:49:59.411908 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:49:59.419952 [debug] [MainThread]: Using postgres connection "master"
[0m13:49:59.420950 [debug] [MainThread]: On master: BEGIN
[0m13:49:59.420950 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:49:59.622104 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:49:59.623164 [debug] [MainThread]: Using postgres connection "master"
[0m13:49:59.624131 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:49:59.688723 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:49:59.690719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A23A3810>]}
[0m13:49:59.691719 [debug] [MainThread]: On master: ROLLBACK
[0m13:49:59.723673 [debug] [MainThread]: Using postgres connection "master"
[0m13:49:59.724681 [debug] [MainThread]: On master: BEGIN
[0m13:49:59.788752 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:49:59.789525 [debug] [MainThread]: On master: COMMIT
[0m13:49:59.790520 [debug] [MainThread]: Using postgres connection "master"
[0m13:49:59.790520 [debug] [MainThread]: On master: COMMIT
[0m13:49:59.818445 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:49:59.818445 [debug] [MainThread]: On master: Close
[0m13:49:59.819919 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:49:59.821893 [info ] [MainThread]: 
[0m13:49:59.825326 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:49:59.826325 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:49:59.827326 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:49:59.828327 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:49:59.835832 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:49:59.837836 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:49:59.828327 => 13:49:59.837836
[0m13:49:59.838848 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:49:59.881950 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:49:59.883982 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:49:59.884946 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:49:59.884946 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:50:00.101436 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:50:00.102203 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:50:00.103199 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon,
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DAR, 1, fm.full_moon_date)
  );
  
[0m13:50:00.142813 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "FROM"
LINE 33: FROM
         ^

[0m13:50:00.144279 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:50:00.173113 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:49:59.839876 => 13:50:00.173113
[0m13:50:00.174160 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:50:00.179110 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  syntax error at or near "FROM"
  LINE 33: FROM
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:50:00.180063 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fdf0bb57-4069-4022-a144-1e588ac45f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A3125610>]}
[0m13:50:00.181368 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.35s]
[0m13:50:00.182369 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:50:00.183368 [debug] [MainThread]: Using postgres connection "master"
[0m13:50:00.184367 [debug] [MainThread]: On master: BEGIN
[0m13:50:00.185264 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:50:00.412083 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:50:00.413491 [debug] [MainThread]: On master: COMMIT
[0m13:50:00.414502 [debug] [MainThread]: Using postgres connection "master"
[0m13:50:00.415502 [debug] [MainThread]: On master: COMMIT
[0m13:50:00.441733 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:50:00.441733 [debug] [MainThread]: On master: Close
[0m13:50:00.443276 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:50:00.444468 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:50:00.444468 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:50:00.445510 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:50:00.445510 [info ] [MainThread]: 
[0m13:50:00.446479 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.67 seconds (2.67s).
[0m13:50:00.448480 [debug] [MainThread]: Command end result
[0m13:50:00.456994 [info ] [MainThread]: 
[0m13:50:00.457994 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:50:00.458991 [info ] [MainThread]: 
[0m13:50:00.460011 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  syntax error at or near "FROM"
  LINE 33: FROM
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:50:00.461028 [info ] [MainThread]: 
[0m13:50:00.462025 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:50:00.464006 [debug] [MainThread]: Command `dbt run` failed at 13:50:00.464006 after 3.34 seconds
[0m13:50:00.464991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001739B39E550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A23C2150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173A26B1A90>]}
[0m13:50:00.464991 [debug] [MainThread]: Flushing usage events
[0m13:51:05.652968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9C863FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9C82E990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9C842ED0>]}


============================== 13:51:05.652968 | 31bfab3a-0b2a-44d1-bf2a-7c64144b771a ==============================
[0m13:51:05.652968 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:51:05.652968 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:51:05.980059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9C887190>]}
[0m13:51:06.086037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D032190>]}
[0m13:51:06.087612 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:51:06.096807 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:51:06.203066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:51:06.204008 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:06.375224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D2FA1D0>]}
[0m13:51:06.387922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D5D5B50>]}
[0m13:51:06.388922 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:51:06.389921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D249110>]}
[0m13:51:06.391368 [info ] [MainThread]: 
[0m13:51:06.393101 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:51:06.394101 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:51:06.403767 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:51:06.405494 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:51:06.406502 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:07.714269 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:51:07.715274 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:51:07.719297 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:51:07.726865 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:51:07.726865 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:51:07.728873 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:07.931429 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:51:07.931429 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:51:07.931429 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:51:07.990763 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:51:07.991834 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:51:08.023334 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:51:08.031535 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.031535 [debug] [MainThread]: On master: BEGIN
[0m13:51:08.031535 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:51:08.218704 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:08.229436 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.229436 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:51:08.293840 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:51:08.293840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D573750>]}
[0m13:51:08.293840 [debug] [MainThread]: On master: ROLLBACK
[0m13:51:08.327339 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.327339 [debug] [MainThread]: On master: BEGIN
[0m13:51:08.390624 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:08.390624 [debug] [MainThread]: On master: COMMIT
[0m13:51:08.390624 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.390624 [debug] [MainThread]: On master: COMMIT
[0m13:51:08.423475 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:51:08.424160 [debug] [MainThread]: On master: Close
[0m13:51:08.424160 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:51:08.426124 [info ] [MainThread]: 
[0m13:51:08.429529 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:08.430535 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:51:08.432162 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:51:08.433026 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:08.440665 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:08.440665 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:51:08.433026 => 13:51:08.440665
[0m13:51:08.445487 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:08.483281 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:08.483281 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:08.483281 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:51:08.483281 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:51:08.677428 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:51:08.677428 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:08.677428 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DAR, 1, fm.full_moon_date)
  );
  
[0m13:51:08.718887 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column r.reviw_date does not exist
LINE 36:     full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DA...
                                           ^
HINT:  Perhaps you meant to reference the column "r.review_date".

[0m13:51:08.718887 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:51:08.747856 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:51:08.445487 => 13:51:08.747856
[0m13:51:08.755858 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:51:08.760892 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  column r.reviw_date does not exist
  LINE 36:     full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DA...
                                             ^
  HINT:  Perhaps you meant to reference the column "r.review_date".
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:08.760892 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31bfab3a-0b2a-44d1-bf2a-7c64144b771a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9D5ABC90>]}
[0m13:51:08.760892 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.33s]
[0m13:51:08.760892 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:08.760892 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.760892 [debug] [MainThread]: On master: BEGIN
[0m13:51:08.760892 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:51:08.987671 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:08.988814 [debug] [MainThread]: On master: COMMIT
[0m13:51:08.988814 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:08.988814 [debug] [MainThread]: On master: COMMIT
[0m13:51:09.019580 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:51:09.019580 [debug] [MainThread]: On master: Close
[0m13:51:09.024797 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:51:09.024797 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:51:09.025363 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:51:09.025363 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:51:09.025363 [info ] [MainThread]: 
[0m13:51:09.025363 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.63 seconds (2.63s).
[0m13:51:09.025363 [debug] [MainThread]: Command end result
[0m13:51:09.036041 [info ] [MainThread]: 
[0m13:51:09.036041 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:51:09.039354 [info ] [MainThread]: 
[0m13:51:09.040354 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  column r.reviw_date does not exist
  LINE 36:     full_moon_dates fm ON TO_DATE(r.reviw_date) = DATEADD(DA...
                                             ^
  HINT:  Perhaps you meant to reference the column "r.review_date".
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:09.041379 [info ] [MainThread]: 
[0m13:51:09.042379 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:51:09.045642 [debug] [MainThread]: Command `dbt run` failed at 13:51:09.044791 after 3.46 seconds
[0m13:51:09.045642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B95891090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B9CB888D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022B95B8F210>]}
[0m13:51:09.045642 [debug] [MainThread]: Flushing usage events
[0m13:51:24.979385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF78E97D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF790778D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF75A8CBD0>]}


============================== 13:51:24.984391 | cbf34c46-9914-4813-b27c-75ba589282ec ==============================
[0m13:51:24.984391 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:51:24.984391 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:51:25.213353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF795F2050>]}
[0m13:51:25.288547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF795B3250>]}
[0m13:51:25.288547 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:51:25.297745 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:51:25.404915 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:51:25.404915 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:25.568380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF79AC3A50>]}
[0m13:51:25.586556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF7995E7D0>]}
[0m13:51:25.587978 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:51:25.589037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF79751D50>]}
[0m13:51:25.591244 [info ] [MainThread]: 
[0m13:51:25.592841 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:51:25.594965 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:51:25.610563 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:51:25.612971 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:51:25.614044 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:26.907972 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:51:26.909711 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:51:26.909711 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:51:26.919741 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:51:26.919741 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:51:26.919741 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:27.113098 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:51:27.113098 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:51:27.113098 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:51:27.159724 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:51:27.167177 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:51:27.199736 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:51:27.208398 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.208398 [debug] [MainThread]: On master: BEGIN
[0m13:51:27.208398 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:51:27.423724 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:27.423724 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.423724 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:51:27.484530 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:51:27.492651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF79866950>]}
[0m13:51:27.492651 [debug] [MainThread]: On master: ROLLBACK
[0m13:51:27.524491 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.524491 [debug] [MainThread]: On master: BEGIN
[0m13:51:27.580205 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:27.588199 [debug] [MainThread]: On master: COMMIT
[0m13:51:27.588199 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.588199 [debug] [MainThread]: On master: COMMIT
[0m13:51:27.624344 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:51:27.624344 [debug] [MainThread]: On master: Close
[0m13:51:27.624344 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:51:27.627996 [info ] [MainThread]: 
[0m13:51:27.632154 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:27.632154 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:51:27.635082 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:51:27.635082 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:27.646245 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:27.652281 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:51:27.636089 => 13:51:27.651260
[0m13:51:27.654060 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:27.693983 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:27.693983 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:27.693983 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:51:27.699836 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:51:27.896737 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:51:27.897290 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:51:27.897854 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON TO_DATE(r.review_date) = DATEADD(DAR, 1, fm.full_moon_date)
  );
  
[0m13:51:27.932158 [debug] [Thread-1 (]: Postgres adapter: Postgres error: function to_date(timestamp without time zone) does not exist
LINE 36:     full_moon_dates fm ON TO_DATE(r.review_date) = DATEADD(D...
                                   ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m13:51:27.932158 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:51:27.966036 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:51:27.656071 => 13:51:27.966036
[0m13:51:27.966036 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:51:27.972666 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  function to_date(timestamp without time zone) does not exist
  LINE 36:     full_moon_dates fm ON TO_DATE(r.review_date) = DATEADD(D...
                                     ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:27.972666 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf34c46-9914-4813-b27c-75ba589282ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF7AB1C890>]}
[0m13:51:27.972666 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.34s]
[0m13:51:27.977206 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:51:27.977706 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:27.977706 [debug] [MainThread]: On master: BEGIN
[0m13:51:27.977706 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:51:28.181816 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:51:28.181816 [debug] [MainThread]: On master: COMMIT
[0m13:51:28.181816 [debug] [MainThread]: Using postgres connection "master"
[0m13:51:28.181816 [debug] [MainThread]: On master: COMMIT
[0m13:51:28.222648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:51:28.222648 [debug] [MainThread]: On master: Close
[0m13:51:28.222648 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:51:28.222648 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:51:28.222648 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:51:28.222648 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:51:28.222648 [info ] [MainThread]: 
[0m13:51:28.228976 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.63 seconds (2.63s).
[0m13:51:28.229948 [debug] [MainThread]: Command end result
[0m13:51:28.238531 [info ] [MainThread]: 
[0m13:51:28.239518 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:51:28.240872 [info ] [MainThread]: 
[0m13:51:28.241866 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  function to_date(timestamp without time zone) does not exist
  LINE 36:     full_moon_dates fm ON TO_DATE(r.review_date) = DATEADD(D...
                                     ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:51:28.241866 [info ] [MainThread]: 
[0m13:51:28.243207 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:51:28.243207 [debug] [MainThread]: Command `dbt run` failed at 13:51:28.243207 after 3.33 seconds
[0m13:51:28.243207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF71DF1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF790E87D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF790EA150>]}
[0m13:51:28.243207 [debug] [MainThread]: Flushing usage events
[0m13:52:09.175118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D435CA6BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D435C148D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D435C153D0>]}


============================== 13:52:09.175118 | dda1fec9-1254-43a9-aeda-efabd3ca6730 ==============================
[0m13:52:09.175118 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:52:09.179417 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:52:09.392151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436162050>]}
[0m13:52:09.464479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436257C10>]}
[0m13:52:09.464479 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:52:09.480784 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:52:09.573920 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:52:09.583913 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:52:09.798303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D43645B810>]}
[0m13:52:09.811653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436658F50>]}
[0m13:52:09.812548 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:52:09.813207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D43615BE90>]}
[0m13:52:09.815070 [info ] [MainThread]: 
[0m13:52:09.816515 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:52:09.817584 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:52:09.827026 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:52:09.827978 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:52:09.827978 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:52:11.110584 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:52:11.113906 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:52:11.113906 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:52:11.122223 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:52:11.124880 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:52:11.124880 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:52:11.331012 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:52:11.332024 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:52:11.333020 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:52:11.377222 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:52:11.377222 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:52:11.410108 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:52:11.410108 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:11.410108 [debug] [MainThread]: On master: BEGIN
[0m13:52:11.410108 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:52:11.614616 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:52:11.614616 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:11.614616 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:52:11.678644 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:52:11.678644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436622290>]}
[0m13:52:11.678644 [debug] [MainThread]: On master: ROLLBACK
[0m13:52:11.711030 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:11.711030 [debug] [MainThread]: On master: BEGIN
[0m13:52:11.783583 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:52:11.783583 [debug] [MainThread]: On master: COMMIT
[0m13:52:11.783583 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:11.785631 [debug] [MainThread]: On master: COMMIT
[0m13:52:11.807768 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:52:11.807768 [debug] [MainThread]: On master: Close
[0m13:52:11.817317 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:52:11.817317 [info ] [MainThread]: 
[0m13:52:11.822050 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:52:11.823097 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:52:11.824668 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:52:11.825806 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:52:11.838162 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:52:11.841184 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:52:11.826344 => 13:52:11.840651
[0m13:52:11.841716 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:52:11.893211 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:52:11.895347 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:52:11.896415 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:52:11.896956 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:52:12.109691 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:52:12.109691 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:52:12.109691 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_dates IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m13:52:12.143446 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column fm.full_moon_dates does not exist
LINE 30:         WHEN fm.full_moon_dates IS NULL THEN 'not full moon'...
                      ^
HINT:  Perhaps you meant to reference the column "fm.full_moon_date".

[0m13:52:12.155439 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: ROLLBACK
[0m13:52:12.179735 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:52:11.842772 => 13:52:12.179735
[0m13:52:12.179735 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:52:12.189440 [debug] [Thread-1 (]: Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  column fm.full_moon_dates does not exist
  LINE 30:         WHEN fm.full_moon_dates IS NULL THEN 'not full moon'...
                        ^
  HINT:  Perhaps you meant to reference the column "fm.full_moon_date".
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:52:12.191960 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda1fec9-1254-43a9-aeda-efabd3ca6730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D436504890>]}
[0m13:52:12.192393 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model test.mart_fullmoon_reviews ............... [[31mERROR[0m in 0.37s]
[0m13:52:12.192393 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:52:12.192393 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:12.192393 [debug] [MainThread]: On master: BEGIN
[0m13:52:12.192393 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:52:12.408056 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:52:12.408056 [debug] [MainThread]: On master: COMMIT
[0m13:52:12.408056 [debug] [MainThread]: Using postgres connection "master"
[0m13:52:12.408056 [debug] [MainThread]: On master: COMMIT
[0m13:52:12.434308 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:52:12.434308 [debug] [MainThread]: On master: Close
[0m13:52:12.443726 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:52:12.443726 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:52:12.443726 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:52:12.443726 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:52:12.443726 [info ] [MainThread]: 
[0m13:52:12.443726 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.63 seconds (2.63s).
[0m13:52:12.443726 [debug] [MainThread]: Command end result
[0m13:52:12.457121 [info ] [MainThread]: 
[0m13:52:12.457121 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:52:12.459103 [info ] [MainThread]: 
[0m13:52:12.459896 [error] [MainThread]:   Database Error in model mart_fullmoon_reviews (dbtlearn/models\mart\mart_fullmoon_reviews.sql)
  column fm.full_moon_dates does not exist
  LINE 30:         WHEN fm.full_moon_dates IS NULL THEN 'not full moon'...
                        ^
  HINT:  Perhaps you meant to reference the column "fm.full_moon_date".
  compiled Code at target\run\dbtlearn\dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:52:12.460983 [info ] [MainThread]: 
[0m13:52:12.461843 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:52:12.463352 [debug] [MainThread]: Command `dbt run` failed at 13:52:12.463352 after 3.35 seconds
[0m13:52:12.463352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D42E9C1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D435C14890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D42EA05BD0>]}
[0m13:52:12.463352 [debug] [MainThread]: Flushing usage events
[0m13:53:21.745326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B504308CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5011D8E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5040C84D0>]}


============================== 13:53:21.753359 | 933be3af-eb59-432d-8559-949fcb373952 ==============================
[0m13:53:21.753359 [info ] [MainThread]: Running with dbt=1.7.3
[0m13:53:21.753359 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s mart_fullmoon_reviews', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:53:21.961781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5047C9B90>]}
[0m13:53:22.035441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5043E2750>]}
[0m13:53:22.042144 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m13:53:22.042144 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m13:53:22.174503 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:53:22.175628 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\mart\mart_fullmoon_reviews.sql
[0m13:53:22.355250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B504738850>]}
[0m13:53:22.366127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5049B1090>]}
[0m13:53:22.366127 [info ] [MainThread]: Found 8 models, 1 seed, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m13:53:22.371314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5048B5B50>]}
[0m13:53:22.371314 [info ] [MainThread]: 
[0m13:53:22.371314 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m13:53:22.371314 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m13:53:22.377420 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m13:53:22.377420 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m13:53:22.377420 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:53:23.672515 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m13:53:23.672515 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m13:53:23.675842 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m13:53:23.675842 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:53:23.686363 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m13:53:23.687374 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:53:23.887750 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m13:53:23.888749 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m13:53:23.889750 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m13:53:23.940443 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m13:53:23.940443 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m13:53:23.972194 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m13:53:23.976598 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:23.976598 [debug] [MainThread]: On master: BEGIN
[0m13:53:23.976598 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:53:24.182616 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:53:24.183944 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:24.184904 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m13:53:24.241623 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m13:53:24.252094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B505B09790>]}
[0m13:53:24.253109 [debug] [MainThread]: On master: ROLLBACK
[0m13:53:24.283336 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:24.284845 [debug] [MainThread]: On master: BEGIN
[0m13:53:24.346621 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:53:24.347730 [debug] [MainThread]: On master: COMMIT
[0m13:53:24.348245 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:24.348767 [debug] [MainThread]: On master: COMMIT
[0m13:53:24.377703 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:53:24.378214 [debug] [MainThread]: On master: Close
[0m13:53:24.379261 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:53:24.380298 [info ] [MainThread]: 
[0m13:53:24.383509 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m13:53:24.384161 [info ] [Thread-1 (]: 1 of 1 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m13:53:24.386292 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.mart_fullmoon_reviews'
[0m13:53:24.387379 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m13:53:24.398759 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:24.401705 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 13:53:24.387996 => 13:53:24.401049
[0m13:53:24.402785 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m13:53:24.448816 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:24.451586 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:24.451586 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m13:53:24.451586 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:53:24.664141 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m13:53:24.664141 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:24.666146 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_date IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m13:53:26.412865 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m13:53:26.420582 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:26.420582 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp" rename to "mart_fullmoon_reviews"
[0m13:53:26.452475 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m13:53:26.482327 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m13:53:26.483106 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:26.483106 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m13:53:26.517005 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m13:53:26.524052 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup"
[0m13:53:26.533469 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m13:53:26.533988 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
drop table if exists "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup" cascade
[0m13:53:26.578655 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m13:53:26.581706 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 13:53:24.403945 => 13:53:26.581165
[0m13:53:26.582853 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m13:53:26.584434 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933be3af-eb59-432d-8559-949fcb373952', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5048F4C10>]}
[0m13:53:26.585505 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.mart_fullmoon_reviews ................... [[32mSELECT 410284[0m in 2.20s]
[0m13:53:26.587204 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m13:53:26.588763 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:26.589805 [debug] [MainThread]: On master: BEGIN
[0m13:53:26.590326 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:53:26.812480 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m13:53:26.813208 [debug] [MainThread]: On master: COMMIT
[0m13:53:26.813208 [debug] [MainThread]: Using postgres connection "master"
[0m13:53:26.814214 [debug] [MainThread]: On master: COMMIT
[0m13:53:26.837678 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m13:53:26.837678 [debug] [MainThread]: On master: Close
[0m13:53:26.837678 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:53:26.845808 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m13:53:26.845808 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m13:53:26.847315 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m13:53:26.847827 [info ] [MainThread]: 
[0m13:53:26.848340 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 4.48 seconds (4.48s).
[0m13:53:26.848340 [debug] [MainThread]: Command end result
[0m13:53:26.860069 [info ] [MainThread]: 
[0m13:53:26.861045 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:53:26.861045 [info ] [MainThread]: 
[0m13:53:26.861045 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:53:26.864048 [debug] [MainThread]: Command `dbt run` succeeded at 13:53:26.861045 after 5.18 seconds
[0m13:53:26.864048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B57CE51090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B57D13FE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5048B6690>]}
[0m13:53:26.864875 [debug] [MainThread]: Flushing usage events
[0m14:00:50.378827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64DD8C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE646628D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64DDBD90>]}


============================== 14:00:50.382827 | 0352332d-4821-4d08-84a7-caf07b002cdf ==============================
[0m14:00:50.382827 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:00:50.384332 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s src_listings', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:00:50.590386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64662050>]}
[0m14:00:50.668965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64E05890>]}
[0m14:00:50.670401 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:00:50.679104 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:00:50.781044 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m14:00:50.781553 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\sources.yml
[0m14:00:50.783556 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_listings.sql
[0m14:00:51.016518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE66378F10>]}
[0m14:00:51.029281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE66420B90>]}
[0m14:00:51.030279 [info ] [MainThread]: Found 8 models, 1 seed, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:00:51.031278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE652B4510>]}
[0m14:00:51.032280 [info ] [MainThread]: 
[0m14:00:51.033278 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:00:51.035341 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:00:51.046551 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:00:51.047551 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:00:51.048550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:00:52.347884 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m14:00:52.348882 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:00:52.350883 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:00:52.357913 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:00:52.358913 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:00:52.359913 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:00:52.576692 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:00:52.578039 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:00:52.578039 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:00:52.628240 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:00:52.629238 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:00:52.661696 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:00:52.669496 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:52.669496 [debug] [MainThread]: On master: BEGIN
[0m14:00:52.670498 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:00:52.877741 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:00:52.878787 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:52.878787 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:00:52.944632 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:00:52.947335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64ED1010>]}
[0m14:00:52.947335 [debug] [MainThread]: On master: ROLLBACK
[0m14:00:52.979608 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:52.980155 [debug] [MainThread]: On master: BEGIN
[0m14:00:53.049829 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:00:53.049829 [debug] [MainThread]: On master: COMMIT
[0m14:00:53.050828 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:53.050828 [debug] [MainThread]: On master: COMMIT
[0m14:00:53.080461 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:00:53.080461 [debug] [MainThread]: On master: Close
[0m14:00:53.081499 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:00:53.082470 [info ] [MainThread]: 
[0m14:00:53.086746 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:00:53.086746 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:00:53.088250 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:00:53.089913 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:00:53.096923 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:00:53.098921 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:00:53.089913 => 14:00:53.098921
[0m14:00:53.098921 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:00:53.138092 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:00:53.140108 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:00:53.142129 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:00:53.142129 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:00:53.353398 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:00:53.354437 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:00:53.354957 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."raw"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:00:53.392510 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.raw_listings" does not exist
LINE 11:   "inttegra_stage"."raw"."raw_listings"
           ^

[0m14:00:53.393510 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: ROLLBACK
[0m14:00:53.423725 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:00:53.101009 => 14:00:53.423725
[0m14:00:53.425259 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:00:53.430264 [debug] [Thread-1 (]: Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw.raw_listings" does not exist
  LINE 11:   "inttegra_stage"."raw"."raw_listings"
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:00:53.430264 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0352332d-4821-4d08-84a7-caf07b002cdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE66444090>]}
[0m14:00:53.431264 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.src_listings ......................... [[31mERROR[0m in 0.34s]
[0m14:00:53.432266 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:00:53.433266 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:53.434298 [debug] [MainThread]: On master: BEGIN
[0m14:00:53.434298 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:00:53.626400 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:00:53.627159 [debug] [MainThread]: On master: COMMIT
[0m14:00:53.628156 [debug] [MainThread]: Using postgres connection "master"
[0m14:00:53.628156 [debug] [MainThread]: On master: COMMIT
[0m14:00:53.657227 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:00:53.657227 [debug] [MainThread]: On master: Close
[0m14:00:53.658227 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:00:53.659262 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:00:53.660226 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:00:53.660226 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:00:53.661278 [info ] [MainThread]: 
[0m14:00:53.662228 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.63 seconds (2.63s).
[0m14:00:53.663227 [debug] [MainThread]: Command end result
[0m14:00:53.675756 [info ] [MainThread]: 
[0m14:00:53.678844 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:00:53.680352 [info ] [MainThread]: 
[0m14:00:53.681392 [error] [MainThread]:   Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw.raw_listings" does not exist
  LINE 11:   "inttegra_stage"."raw"."raw_listings"
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:00:53.683400 [info ] [MainThread]: 
[0m14:00:53.685361 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:00:53.687359 [debug] [MainThread]: Command `dbt run` failed at 14:00:53.687359 after 3.37 seconds
[0m14:00:53.688359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE645BCA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE5D631050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE64DA2AD0>]}
[0m14:00:53.689357 [debug] [MainThread]: Flushing usage events
[0m14:01:25.361216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDB5AB750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDB5ABB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDD40A4450>]}


============================== 14:01:25.365215 | 6f6ed5e2-0e85-480c-95d6-ec2108969d88 ==============================
[0m14:01:25.365215 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:01:25.365625 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s src_listings', 'send_anonymous_usage_stats': 'True'}
[0m14:01:25.582386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDB0F2050>]}
[0m14:01:25.660495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDADD3A10>]}
[0m14:01:25.661462 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:01:25.675989 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:01:25.783305 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:01:25.784306 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m14:01:26.030301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDCB87450>]}
[0m14:01:26.043319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDCAF7490>]}
[0m14:01:26.043319 [info ] [MainThread]: Found 8 models, 1 seed, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:01:26.044583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDCB29D90>]}
[0m14:01:26.046582 [info ] [MainThread]: 
[0m14:01:26.047583 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:01:26.049805 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:01:26.060428 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:01:26.062428 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:01:26.063432 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:01:27.376392 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m14:01:27.377600 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:01:27.379598 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:01:27.385628 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:01:27.385628 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:01:27.386595 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:01:27.591152 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:01:27.592664 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:01:27.592664 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:01:27.641991 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:01:27.643994 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:01:27.676762 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:01:27.683396 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:27.684396 [debug] [MainThread]: On master: BEGIN
[0m14:01:27.685364 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:01:27.891274 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:01:27.892288 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:27.892837 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:01:27.949991 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:01:27.952034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDCB87BD0>]}
[0m14:01:27.953035 [debug] [MainThread]: On master: ROLLBACK
[0m14:01:27.985619 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:27.986579 [debug] [MainThread]: On master: BEGIN
[0m14:01:28.045973 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:01:28.046974 [debug] [MainThread]: On master: COMMIT
[0m14:01:28.046974 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:28.047975 [debug] [MainThread]: On master: COMMIT
[0m14:01:28.074829 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:01:28.076060 [debug] [MainThread]: On master: Close
[0m14:01:28.077092 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:01:28.078057 [info ] [MainThread]: 
[0m14:01:28.081057 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:01:28.082058 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:01:28.084062 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:01:28.085064 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:01:28.093580 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:01:28.095578 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:01:28.085064 => 14:01:28.095578
[0m14:01:28.096577 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:01:28.134176 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:01:28.136396 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.136396 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:01:28.137633 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:01:28.331411 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:01:28.332458 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.332458 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."test"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:01:28.381172 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:01:28.388727 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.389726 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:01:28.422055 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:01:28.426242 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.427281 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:01:28.458491 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:01:28.475612 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:01:28.476676 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.477722 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:01:28.508061 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:01:28.517589 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:01:28.526033 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:01:28.527067 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:01:28.559558 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:01:28.561518 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:01:28.097578 => 14:01:28.561518
[0m14:01:28.562519 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:01:28.562519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f6ed5e2-0e85-480c-95d6-ec2108969d88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDAF41790>]}
[0m14:01:28.563554 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.48s]
[0m14:01:28.564568 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:01:28.566632 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:28.567095 [debug] [MainThread]: On master: BEGIN
[0m14:01:28.567095 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:01:28.769632 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:01:28.771149 [debug] [MainThread]: On master: COMMIT
[0m14:01:28.771846 [debug] [MainThread]: Using postgres connection "master"
[0m14:01:28.771846 [debug] [MainThread]: On master: COMMIT
[0m14:01:28.801067 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:01:28.801067 [debug] [MainThread]: On master: Close
[0m14:01:28.803094 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:01:28.803094 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:01:28.804080 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:01:28.805064 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:01:28.805064 [info ] [MainThread]: 
[0m14:01:28.806573 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.76 seconds (2.76s).
[0m14:01:28.807528 [debug] [MainThread]: Command end result
[0m14:01:28.816541 [info ] [MainThread]: 
[0m14:01:28.817537 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:01:28.818540 [info ] [MainThread]: 
[0m14:01:28.819899 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:01:28.820898 [debug] [MainThread]: Command `dbt run` succeeded at 14:01:28.820898 after 3.53 seconds
[0m14:01:28.821902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDD3E31050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDAD22710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDDB0D4290>]}
[0m14:01:28.822901 [debug] [MainThread]: Flushing usage events
[0m14:02:44.176490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276250650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2765B6090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2767D6050>]}


============================== 14:02:44.181484 | da4064dc-02a6-4f26-a9c9-14deea0bee3c ==============================
[0m14:02:44.181484 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:02:44.182486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:02:44.400450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276231350>]}
[0m14:02:44.477955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F275C13010>]}
[0m14:02:44.479768 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:02:44.488404 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:02:44.593426 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m14:02:44.593948 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_reviews.sql
[0m14:02:44.593948 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m14:02:44.759886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276DE2D90>]}
[0m14:02:44.773421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2769FB790>]}
[0m14:02:44.774427 [info ] [MainThread]: Found 8 models, 1 seed, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:02:44.774892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276E09310>]}
[0m14:02:44.776901 [info ] [MainThread]: 
[0m14:02:44.777666 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:02:44.779878 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:02:44.790407 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:02:44.791395 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:02:44.792395 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:02:46.107655 [debug] [ThreadPool]: SQL status: SELECT 17 in 1.0 seconds
[0m14:02:46.108665 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:02:46.111664 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:02:46.116663 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:02:46.116663 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:02:46.117664 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:02:46.577230 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:02:46.578232 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:02:46.578232 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:02:46.631735 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:02:46.633778 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:02:46.666140 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:02:46.673188 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:46.674189 [debug] [MainThread]: On master: BEGIN
[0m14:02:46.675189 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:02:46.880917 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:02:46.881679 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:46.882710 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:02:46.948158 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:02:46.949886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276B839D0>]}
[0m14:02:46.950923 [debug] [MainThread]: On master: ROLLBACK
[0m14:02:46.982479 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:46.983477 [debug] [MainThread]: On master: BEGIN
[0m14:02:47.045929 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:02:47.046935 [debug] [MainThread]: On master: COMMIT
[0m14:02:47.046935 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:47.047935 [debug] [MainThread]: On master: COMMIT
[0m14:02:47.071627 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:02:47.071627 [debug] [MainThread]: On master: Close
[0m14:02:47.073626 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:02:47.074636 [info ] [MainThread]: 
[0m14:02:47.078625 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:02:47.078625 [info ] [Thread-1 (]: 1 of 8 START sql view model test.src_hosts ..................................... [RUN]
[0m14:02:47.080625 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:02:47.082135 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:02:47.091137 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:02:47.094164 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:02:47.082135 => 14:02:47.093845
[0m14:02:47.095162 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:02:47.131009 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:02:47.132975 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.132975 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:02:47.133980 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:02:47.341327 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:47.341327 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.342361 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		"inttegra_stage"."test"."raw_hosts" rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:02:47.388762 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:02:47.395281 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.396278 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:02:47.427635 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:47.432511 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.433511 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:02:47.463630 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:47.479668 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:02:47.479668 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.480637 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:02:47.509635 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:47.515654 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:02:47.520654 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:02:47.520654 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:02:47.554857 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:02:47.556849 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:02:47.095162 => 14:02:47.556849
[0m14:02:47.557849 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:02:47.558849 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276DB7D50>]}
[0m14:02:47.559850 [info ] [Thread-1 (]: 1 of 8 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.48s]
[0m14:02:47.559850 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:02:47.561355 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:02:47.562460 [info ] [Thread-1 (]: 2 of 8 START sql view model test.src_listings .................................. [RUN]
[0m14:02:47.563145 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:02:47.564184 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:02:47.567178 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:02:47.569151 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:02:47.564184 => 14:02:47.568179
[0m14:02:47.569151 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:02:47.574279 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:02:47.576352 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.577288 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:02:47.578287 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:47.775676 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:47.776695 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.776695 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."test"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:02:47.822681 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:02:47.826597 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.827195 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:02:47.857434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:47.860321 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.861829 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:02:47.892231 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:47.895067 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:02:47.895067 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.896036 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:02:47.928932 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:47.931937 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:02:47.932938 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:02:47.933938 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:02:47.967803 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:02:47.969809 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:02:47.570186 => 14:02:47.968811
[0m14:02:47.970313 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:02:47.971319 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277FA7DD0>]}
[0m14:02:47.972319 [info ] [Thread-1 (]: 2 of 8 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:02:47.973104 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:02:47.974143 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:02:47.975111 [info ] [Thread-1 (]: 3 of 8 START sql view model test.src_reviews ................................... [RUN]
[0m14:02:47.976132 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:02:47.977116 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:02:47.979116 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:02:47.981115 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:02:47.977116 => 14:02:47.981115
[0m14:02:47.982115 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:02:47.987668 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:02:47.989665 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:47.991668 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:02:47.992681 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:48.213325 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:48.214330 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.214330 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT 
		*
	FROM
		"inttegra_stage"."test"."raw_reviews" rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:02:48.260833 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:02:48.263985 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.264983 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:02:48.295457 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:48.298163 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.299162 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:02:48.339628 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:48.341658 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:02:48.342641 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.343152 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:02:48.373721 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:48.376728 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:02:48.377729 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:02:48.378728 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:02:48.412931 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:02:48.414679 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:02:47.982636 => 14:02:48.414679
[0m14:02:48.415735 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:02:48.416775 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277FF2050>]}
[0m14:02:48.417741 [info ] [Thread-1 (]: 3 of 8 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.44s]
[0m14:02:48.418750 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:02:48.419742 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m14:02:48.420741 [info ] [Thread-1 (]: 4 of 8 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m14:02:48.421754 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m14:02:48.422775 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m14:02:48.425779 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.426739 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 14:02:48.422775 => 14:02:48.426739
[0m14:02:48.428010 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m14:02:48.453082 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.454593 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.456601 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m14:02:48.457601 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:48.663782 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:48.664791 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.664791 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m14:02:48.765035 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m14:02:48.768041 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.769041 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m14:02:48.801118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:48.805124 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.806125 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m14:02:48.838603 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:48.844392 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m14:02:48.844392 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.845358 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m14:02:48.879821 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:48.881815 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m14:02:48.886536 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m14:02:48.887534 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m14:02:48.931329 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:02:48.933666 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 14:02:48.428010 => 14:02:48.933666
[0m14:02:48.934627 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m14:02:48.935628 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277F31D50>]}
[0m14:02:48.936628 [info ] [Thread-1 (]: 4 of 8 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.51s]
[0m14:02:48.937661 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m14:02:48.937661 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:02:48.938741 [info ] [Thread-1 (]: 5 of 8 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:02:48.939746 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m14:02:48.939746 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:02:48.943318 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:02:48.944294 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:02:48.940747 => 14:02:48.944294
[0m14:02:48.945491 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:02:48.949494 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:02:48.951491 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:48.952495 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:02:48.953496 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:49.170145 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:49.170145 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.171653 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m14:02:49.322510 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m14:02:49.326507 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.328011 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m14:02:49.360986 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:49.364495 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.365058 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m14:02:49.398071 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:49.400580 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m14:02:49.401584 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.401584 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m14:02:49.435342 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:49.438406 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m14:02:49.439373 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:02:49.440406 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m14:02:49.480927 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:02:49.482969 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:02:48.945491 => 14:02:49.482969
[0m14:02:49.483935 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:02:49.483935 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F276D93990>]}
[0m14:02:49.485105 [info ] [Thread-1 (]: 5 of 8 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.54s]
[0m14:02:49.486111 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:02:49.487146 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m14:02:49.488274 [info ] [Thread-1 (]: 6 of 8 START sql incremental model test.fact_reviews ........................... [RUN]
[0m14:02:49.488830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m14:02:49.489937 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m14:02:49.498257 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m14:02:49.500258 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 14:02:49.489937 => 14:02:49.500258
[0m14:02:49.501287 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m14:02:49.532153 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:49.532672 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp140249525580"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m14:02:49.533233 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:50.729065 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m14:02:50.735316 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.736341 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m14:02:50.769643 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:50.770475 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.771551 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp140249525580'
        
      order by ordinal_position

  
[0m14:02:50.830584 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m14:02:50.835595 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.836593 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:02:50.882163 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m14:02:50.894419 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.895382 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp140249525580'
        
      order by ordinal_position

  
[0m14:02:50.937961 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m14:02:50.941628 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:50.942627 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:02:50.983269 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m14:02:50.991744 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m14:02:51.001430 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m14:02:51.003402 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:51.004396 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp140249525580"
    )


  
[0m14:02:51.036754 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m14:02:51.038785 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m14:02:51.038785 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m14:02:51.039775 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m14:02:51.073033 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:51.074044 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 14:02:49.502278 => 14:02:51.074044
[0m14:02:51.075039 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m14:02:51.076038 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2780469D0>]}
[0m14:02:51.077039 [info ] [Thread-1 (]: 6 of 8 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.59s]
[0m14:02:51.077389 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m14:02:51.078428 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m14:02:51.079411 [info ] [Thread-1 (]: 7 of 8 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m14:02:51.080410 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m14:02:51.081395 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m14:02:51.085913 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.087917 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 14:02:51.081395 => 14:02:51.086914
[0m14:02:51.088918 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m14:02:51.095729 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.097737 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.098740 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m14:02:51.099738 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:51.388528 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:51.389333 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.390292 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m14:02:51.547827 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m14:02:51.551194 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.552440 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts" rename to "dim_listings_with_hosts__dbt_backup"
[0m14:02:51.584839 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:51.587938 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.587938 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m14:02:51.620724 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:51.624278 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m14:02:51.624830 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.625801 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m14:02:51.659523 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:51.663044 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m14:02:51.664044 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m14:02:51.665044 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m14:02:51.705912 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:02:51.708451 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 14:02:51.089915 => 14:02:51.708451
[0m14:02:51.709462 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m14:02:51.710457 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277FF3350>]}
[0m14:02:51.711461 [info ] [Thread-1 (]: 7 of 8 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 0.63s]
[0m14:02:51.712474 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m14:02:51.713463 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m14:02:51.714461 [info ] [Thread-1 (]: 8 of 8 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m14:02:51.714979 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m14:02:51.716019 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m14:02:51.718019 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:51.720604 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 14:02:51.716019 => 14:02:51.720604
[0m14:02:51.720604 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m14:02:51.726612 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:51.728618 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:51.728618 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m14:02:51.729611 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:02:51.947699 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:02:51.947699 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:51.948868 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_date IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m14:02:53.595498 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m14:02:53.598538 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:53.599537 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews" rename to "mart_fullmoon_reviews__dbt_backup"
[0m14:02:53.631631 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:53.634235 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:53.635236 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp" rename to "mart_fullmoon_reviews"
[0m14:02:53.667156 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:02:53.669159 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m14:02:53.670192 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:53.671197 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m14:02:53.703989 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:02:53.707020 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup"
[0m14:02:53.707992 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m14:02:53.707992 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
drop table if exists "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup" cascade
[0m14:02:53.794345 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:02:53.796560 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 14:02:51.721646 => 14:02:53.795560
[0m14:02:53.796560 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m14:02:53.797527 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da4064dc-02a6-4f26-a9c9-14deea0bee3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F277FA7ED0>]}
[0m14:02:53.798560 [info ] [Thread-1 (]: 8 of 8 OK created sql table model test.mart_fullmoon_reviews ................... [[32mSELECT 410284[0m in 2.08s]
[0m14:02:53.799607 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m14:02:53.801616 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:53.802612 [debug] [MainThread]: On master: BEGIN
[0m14:02:53.802612 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:02:54.006925 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:02:54.007890 [debug] [MainThread]: On master: COMMIT
[0m14:02:54.008890 [debug] [MainThread]: Using postgres connection "master"
[0m14:02:54.008890 [debug] [MainThread]: On master: COMMIT
[0m14:02:54.037322 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:02:54.037322 [debug] [MainThread]: On master: Close
[0m14:02:54.038827 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:02:54.039825 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:02:54.039825 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:02:54.041176 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m14:02:54.042178 [info ] [MainThread]: 
[0m14:02:54.042178 [info ] [MainThread]: Finished running 3 view models, 4 table models, 1 incremental model in 0 hours 0 minutes and 9.26 seconds (9.26s).
[0m14:02:54.044176 [debug] [MainThread]: Command end result
[0m14:02:54.055684 [info ] [MainThread]: 
[0m14:02:54.056685 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:02:54.057685 [info ] [MainThread]: 
[0m14:02:54.058684 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m14:02:54.060686 [debug] [MainThread]: Command `dbt run` succeeded at 14:02:54.059685 after 9.96 seconds
[0m14:02:54.060686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F26F271010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F275D4EAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F26F56EF90>]}
[0m14:02:54.061684 [debug] [MainThread]: Flushing usage events
[0m14:03:56.226594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1E741050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1EEF07D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1E741AD0>]}


============================== 14:03:56.230592 | a999e460-d347-464b-b485-6dbbe4f46da3 ==============================
[0m14:03:56.230592 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:03:56.231591 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt compile', 'send_anonymous_usage_stats': 'True'}
[0m14:03:56.537784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F0FABD0>]}
[0m14:03:56.642431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F101810>]}
[0m14:03:56.643437 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:03:56.653318 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:03:56.817737 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:03:56.818770 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:03:56.828185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F0C3190>]}
[0m14:03:56.898876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F227350>]}
[0m14:03:56.899412 [info ] [MainThread]: Found 8 models, 1 seed, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:03:56.900481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1EF10E50>]}
[0m14:03:56.902597 [info ] [MainThread]: 
[0m14:03:56.904177 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:03:56.906783 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:03:56.924726 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:03:56.925713 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:03:56.926994 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:03:58.252603 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m14:03:58.253609 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:03:58.253609 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:03:58.302801 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:03:58.305813 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:03:58.340474 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:03:58.351821 [debug] [MainThread]: Using postgres connection "master"
[0m14:03:58.352823 [debug] [MainThread]: On master: BEGIN
[0m14:03:58.354835 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:03:58.568872 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:03:58.570883 [debug] [MainThread]: Using postgres connection "master"
[0m14:03:58.572882 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:03:58.633990 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:03:58.641066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a999e460-d347-464b-b485-6dbbe4f46da3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1F1CEB10>]}
[0m14:03:58.643034 [debug] [MainThread]: On master: ROLLBACK
[0m14:03:58.676086 [debug] [MainThread]: On master: Close
[0m14:03:58.679083 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:03:58.682082 [info ] [MainThread]: 
[0m14:03:58.699079 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:03:58.755400 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:03:58.758481 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:03:58.784248 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:03:58.791216 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:03:58.760516 => 14:03:58.789215
[0m14:03:58.795343 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:03:58.797343 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:03:58.796341 => 14:03:58.796341
[0m14:03:58.800342 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:03:58.801342 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:03:58.802344 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:03:58.803342 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:03:58.808399 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:03:58.811401 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:03:58.805386 => 14:03:58.810399
[0m14:03:58.813399 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:03:58.814398 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:03:58.814398 => 14:03:58.814398
[0m14:03:58.815397 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:03:58.818439 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:03:58.821439 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:03:58.822438 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:03:58.827440 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:03:58.830394 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:03:58.822438 => 14:03:58.830394
[0m14:03:58.832397 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:03:58.834395 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:03:58.833406 => 14:03:58.833406
[0m14:03:58.836394 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:03:58.838395 [debug] [Thread-1 (]: Began running node seed.dbtlearn.seed_full_moon_dates
[0m14:03:58.840951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now seed.dbtlearn.seed_full_moon_dates)
[0m14:03:58.841492 [debug] [Thread-1 (]: Began compiling node seed.dbtlearn.seed_full_moon_dates
[0m14:03:58.847022 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (compile): 14:03:58.842498 => 14:03:58.846018
[0m14:03:58.848018 [debug] [Thread-1 (]: Began executing node seed.dbtlearn.seed_full_moon_dates
[0m14:03:58.849020 [debug] [Thread-1 (]: Timing info for seed.dbtlearn.seed_full_moon_dates (execute): 14:03:58.849020 => 14:03:58.849020
[0m14:03:58.851021 [debug] [Thread-1 (]: Finished running node seed.dbtlearn.seed_full_moon_dates
[0m14:03:58.852016 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m14:03:58.854449 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.dbtlearn.seed_full_moon_dates, now model.dbtlearn.dim_hosts_cleansed)
[0m14:03:58.855489 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m14:03:58.860486 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m14:03:58.862487 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 14:03:58.856487 => 14:03:58.862487
[0m14:03:58.863486 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m14:03:58.863486 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 14:03:58.863486 => 14:03:58.863486
[0m14:03:58.867516 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m14:03:58.868523 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:03:58.870517 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m14:03:58.870517 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:03:58.875519 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:03:58.878552 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:03:58.871517 => 14:03:58.878089
[0m14:03:58.879554 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:03:58.881580 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:03:58.880553 => 14:03:58.880553
[0m14:03:58.883550 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:03:58.885550 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m14:03:58.890777 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m14:03:58.892296 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m14:03:58.911309 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m14:03:58.913933 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 14:03:58.893305 => 14:03:58.912819
[0m14:03:58.914318 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m14:03:58.916336 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 14:03:58.915319 => 14:03:58.915319
[0m14:03:58.918316 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m14:03:58.919315 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m14:03:58.920315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m14:03:58.922317 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m14:03:58.930379 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m14:03:58.932364 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 14:03:58.923326 => 14:03:58.932364
[0m14:03:58.933364 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m14:03:58.934364 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 14:03:58.934364 => 14:03:58.934364
[0m14:03:58.937451 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m14:03:58.939018 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m14:03:58.940027 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m14:03:58.941026 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m14:03:58.946051 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m14:03:58.949559 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 14:03:58.942028 => 14:03:58.948052
[0m14:03:58.951605 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m14:03:58.953566 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 14:03:58.952572 => 14:03:58.952572
[0m14:03:58.955571 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m14:03:58.958579 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:03:58.959570 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:03:58.959570 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m14:03:58.963611 [debug] [MainThread]: Command end result
[0m14:03:58.986706 [debug] [MainThread]: Command `dbt compile` succeeded at 14:03:58.985689 after 2.83 seconds
[0m14:03:58.987699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E17741010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E1EB0B010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021E17785A10>]}
[0m14:03:58.988704 [debug] [MainThread]: Flushing usage events
[0m14:30:28.898101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B6C15150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B64050D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B67B6850>]}


============================== 14:30:28.898101 | 0c406270-213f-4b28-a3d9-30f909955738 ==============================
[0m14:30:28.898101 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:30:28.898101 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt source freshness', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:30:29.137943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B64568D0>]}
[0m14:30:29.230447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B64DB050>]}
[0m14:30:29.230447 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:30:29.239170 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:30:29.331136 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:30:29.331136 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\sources.yml
[0m14:30:29.643904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B700F210>]}
[0m14:30:29.660196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B700EE50>]}
[0m14:30:29.660196 [info ] [MainThread]: Found 1 seed, 8 models, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:30:29.660196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B6C4E8D0>]}
[0m14:30:29.660196 [info ] [MainThread]: 
[0m14:30:29.667174 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:30:29.671191 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:30:29.702917 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:29.704056 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:30:29.705935 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:30.004653 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:30.004653 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:30.004653 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:30:30.052812 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:30:30.052812 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:30:30.087211 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:30:30.092747 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:30.094487 [debug] [MainThread]: On master: BEGIN
[0m14:30:30.094487 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:30:30.296635 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:30.296635 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:30.296635 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:30:30.358956 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:30:30.363645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0c406270-213f-4b28-a3d9-30f909955738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B6457990>]}
[0m14:30:30.363645 [debug] [MainThread]: On master: ROLLBACK
[0m14:30:30.393786 [debug] [MainThread]: On master: Close
[0m14:30:30.393786 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:30:30.393786 [info ] [MainThread]: 
[0m14:30:30.400738 [debug] [Thread-1 (]: Began running node source.dbtlearn.airbnb.reviews
[0m14:30:30.400738 [info ] [Thread-1 (]: 1 of 1 START freshness of airbnb.reviews ....................................... [RUN]
[0m14:30:30.400738 [debug] [Thread-1 (]: Acquiring new postgres connection 'source.dbtlearn.airbnb.reviews'
[0m14:30:30.407209 [debug] [Thread-1 (]: Began compiling node source.dbtlearn.airbnb.reviews
[0m14:30:30.408222 [debug] [Thread-1 (]: Timing info for source.dbtlearn.airbnb.reviews (compile): 14:30:30.408222 => 14:30:30.408222
[0m14:30:30.409217 [debug] [Thread-1 (]: Began executing node source.dbtlearn.airbnb.reviews
[0m14:30:30.410217 [debug] [Thread-1 (]: Using postgres connection "source.dbtlearn.airbnb.reviews"
[0m14:30:30.410217 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: BEGIN
[0m14:30:30.412259 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:30:30.596121 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:30:30.596121 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: COMMIT
[0m14:30:30.596121 [debug] [Thread-1 (]: Using postgres connection "source.dbtlearn.airbnb.reviews"
[0m14:30:30.596121 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: COMMIT
[0m14:30:30.628063 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:30:30.628063 [debug] [Thread-1 (]: Using postgres connection "source.dbtlearn.airbnb.reviews"
[0m14:30:30.628063 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "source.dbtlearn.airbnb.reviews"} */
select
      max(date) as max_loaded_at,
      now() as snapshotted_at
    from "inttegra_stage"."test"."raw_reviews"
    
  
[0m14:30:30.904680 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:30.905782 [debug] [Thread-1 (]: On source.dbtlearn.airbnb.reviews: Close
[0m14:30:30.905782 [debug] [Thread-1 (]: Timing info for source.dbtlearn.airbnb.reviews (execute): 14:30:30.409217 => 14:30:30.905782
[0m14:30:30.910685 [error] [Thread-1 (]: 1 of 1 ERROR STALE freshness of airbnb.reviews ................................. [[31mERROR STALE[0m in 0.51s]
[0m14:30:30.910685 [debug] [Thread-1 (]: Finished running node source.dbtlearn.airbnb.reviews
[0m14:30:30.910685 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:30:30.910685 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:30:30.910685 [debug] [MainThread]: Connection 'source.dbtlearn.airbnb.reviews' was properly closed.
[0m14:30:30.927546 [info ] [MainThread]: 
[0m14:30:30.929125 [info ] [MainThread]: Done.
[0m14:30:30.932787 [debug] [MainThread]: Command `dbt source freshness` failed at 14:30:30.932068 after 2.11 seconds
[0m14:30:30.934074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B67B6850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B3851190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1B6CF7510>]}
[0m14:30:30.934735 [debug] [MainThread]: Flushing usage events
[0m14:51:22.996986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FC5FCF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FC5FE790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FCE01A50>]}


============================== 14:51:23.005982 | dd9300bd-cd9a-424b-becb-5b4d479a3750 ==============================
[0m14:51:23.005982 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:51:23.007491 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:51:23.379680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd9300bd-cd9a-424b-becb-5b4d479a3750', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FCF5F010>]}
[0m14:51:23.525390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dd9300bd-cd9a-424b-becb-5b4d479a3750', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FCE40D50>]}
[0m14:51:23.527618 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:51:23.558516 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:51:23.803254 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:51:23.804233 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/snapshots\scd_raw_listings.sql
[0m14:51:23.810232 [error] [MainThread]: Encountered an error:
Compilation Error
  Reached EOF without finding a close tag for snapshot (searched from line 1)
[0m14:51:23.813921 [debug] [MainThread]: Command `dbt snapshot` failed at 14:51:23.813292 after 0.91 seconds
[0m14:51:23.813921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1F5641010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1F593FD50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E1FD1870D0>]}
[0m14:51:23.816180 [debug] [MainThread]: Flushing usage events
[0m14:53:16.632440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAAB2C050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE22E450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE40D5D0>]}


============================== 14:53:16.642986 | 44d8bde8-93a7-4029-bdac-c4a2ce89780a ==============================
[0m14:53:16.642986 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:53:16.703277 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:53:17.026440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CADE815D0>]}
[0m14:53:17.111578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE773A90>]}
[0m14:53:17.113084 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:53:17.123143 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:53:17.230870 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:53:17.231871 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/snapshots\scd_raw_listings.sql
[0m14:53:17.431933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE699110>]}
[0m14:53:17.446947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAEC19950>]}
[0m14:53:17.447936 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:53:17.448937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE9E2550>]}
[0m14:53:17.449971 [info ] [MainThread]: 
[0m14:53:17.450968 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:53:17.453547 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:53:17.468057 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:53:17.469059 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:53:17.469059 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:53:18.789552 [debug] [ThreadPool]: SQL status: SELECT 19 in 1.0 seconds
[0m14:53:18.791087 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:53:18.796050 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:53:18.803357 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:53:18.804347 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:53:18.805346 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:53:19.009573 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:53:19.010568 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:53:19.012073 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:53:19.061681 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:53:19.063701 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:53:19.095461 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:53:19.103436 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:19.104402 [debug] [MainThread]: On master: BEGIN
[0m14:53:19.104402 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:53:19.305590 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:53:19.305590 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:19.307009 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:53:19.369574 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:53:19.371584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE923450>]}
[0m14:53:19.372577 [debug] [MainThread]: On master: ROLLBACK
[0m14:53:19.402246 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:19.403237 [debug] [MainThread]: On master: BEGIN
[0m14:53:19.462327 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:53:19.463320 [debug] [MainThread]: On master: COMMIT
[0m14:53:19.463320 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:19.464328 [debug] [MainThread]: On master: COMMIT
[0m14:53:19.505302 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:53:19.506919 [debug] [MainThread]: On master: Close
[0m14:53:19.507928 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:53:19.509928 [info ] [MainThread]: 
[0m14:53:19.514929 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m14:53:19.515958 [info ] [Thread-1 (]: 1 of 1 START snapshot test.scd_raw_listings .................................... [RUN]
[0m14:53:19.517432 [debug] [Thread-1 (]: Acquiring new postgres connection 'snapshot.dbtlearn.scd_raw_listings'
[0m14:53:19.518442 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m14:53:19.531491 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 14:53:19.519440 => 14:53:19.530418
[0m14:53:19.532489 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m14:53:19.594381 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.dbtlearn.scd_raw_listings"
[0m14:53:19.596381 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:53:19.597382 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: BEGIN
[0m14:53:19.597382 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:53:19.796543 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:53:19.798537 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:53:19.799538 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      
  
    

  create  table "inttegra_stage"."test"."scd_raw_listings"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        



SELECT
    *
FROM
    "inttegra_stage"."test"."raw_listings"

    ) sbq



  );
  
  
[0m14:53:19.933955 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m14:53:19.952845 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:53:19.952845 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:53:19.953844 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:53:19.993410 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:53:19.995384 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 14:53:19.533488 => 14:53:19.994383
[0m14:53:19.995384 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: Close
[0m14:53:19.996402 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44d8bde8-93a7-4029-bdac-c4a2ce89780a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAEC2B590>]}
[0m14:53:19.997929 [info ] [Thread-1 (]: 1 of 1 OK snapshotted test.scd_raw_listings .................................... [[32mSELECT 17499[0m in 0.48s]
[0m14:53:19.999533 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m14:53:20.000940 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:20.000940 [debug] [MainThread]: On master: BEGIN
[0m14:53:20.001940 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:53:20.204146 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:53:20.205031 [debug] [MainThread]: On master: COMMIT
[0m14:53:20.206030 [debug] [MainThread]: Using postgres connection "master"
[0m14:53:20.207028 [debug] [MainThread]: On master: COMMIT
[0m14:53:20.233812 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:53:20.234612 [debug] [MainThread]: On master: Close
[0m14:53:20.235569 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:53:20.236571 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:53:20.236571 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:53:20.236571 [debug] [MainThread]: Connection 'snapshot.dbtlearn.scd_raw_listings' was properly closed.
[0m14:53:20.238076 [info ] [MainThread]: 
[0m14:53:20.239153 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 2.79 seconds (2.79s).
[0m14:53:20.239153 [debug] [MainThread]: Command end result
[0m14:53:20.248160 [info ] [MainThread]: 
[0m14:53:20.249195 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:53:20.250672 [info ] [MainThread]: 
[0m14:53:20.251676 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:53:20.252675 [debug] [MainThread]: Command `dbt snapshot` succeeded at 14:53:20.252675 after 3.81 seconds
[0m14:53:20.253678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CA6EAE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE157F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019CAE1558D0>]}
[0m14:53:20.253678 [debug] [MainThread]: Flushing usage events
[0m14:57:43.494521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1C30950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC184B010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1785390>]}


============================== 14:57:43.498884 | 8908006f-3e92-47a7-850a-ff8261d2284f ==============================
[0m14:57:43.498884 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:57:43.499884 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:57:43.722401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1C82050>]}
[0m14:57:43.804650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1D92A50>]}
[0m14:57:43.806615 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:57:43.817139 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:57:43.923276 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:57:43.924276 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:57:43.930055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1771E50>]}
[0m14:57:43.987213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1F63A50>]}
[0m14:57:43.988213 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:57:43.988213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1E3E3D0>]}
[0m14:57:43.990508 [info ] [MainThread]: 
[0m14:57:43.992510 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:57:43.994511 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:57:44.004593 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:57:44.004593 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:57:44.005594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:45.330068 [debug] [ThreadPool]: SQL status: SELECT 19 in 1.0 seconds
[0m14:57:45.332441 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:57:45.336452 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:57:45.346830 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:45.348319 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:57:45.349415 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:45.549106 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:57:45.549106 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:45.549106 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:57:45.600073 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m14:57:45.600073 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:57:45.647227 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:57:45.655237 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:45.655237 [debug] [MainThread]: On master: BEGIN
[0m14:57:45.656238 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:57:45.868562 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:45.868562 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:45.869560 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:57:45.932855 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:57:45.934896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1436C10>]}
[0m14:57:45.934896 [debug] [MainThread]: On master: ROLLBACK
[0m14:57:45.968122 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:45.968960 [debug] [MainThread]: On master: BEGIN
[0m14:57:46.032077 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:46.033084 [debug] [MainThread]: On master: COMMIT
[0m14:57:46.033084 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:46.034082 [debug] [MainThread]: On master: COMMIT
[0m14:57:46.063280 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:46.063280 [debug] [MainThread]: On master: Close
[0m14:57:46.064287 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:57:46.065287 [info ] [MainThread]: 
[0m14:57:46.069330 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m14:57:46.070329 [info ] [Thread-1 (]: 1 of 1 START snapshot test.scd_raw_listings .................................... [RUN]
[0m14:57:46.072329 [debug] [Thread-1 (]: Acquiring new postgres connection 'snapshot.dbtlearn.scd_raw_listings'
[0m14:57:46.073333 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m14:57:46.082704 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 14:57:46.073333 => 14:57:46.081667
[0m14:57:46.083666 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m14:57:46.127294 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.128412 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: BEGIN
[0m14:57:46.128923 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:57:46.330907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:46.331934 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.332655 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:57:46.397311 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:57:46.431276 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.432277 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

        
  
    

  create temporary table "scd_raw_listings__dbt_tmp145746413072"
  
  
    as
  
  (
    with snapshot_query as (

        



SELECT
    *
FROM
    "inttegra_stage"."test"."raw_listings"


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "inttegra_stage"."test"."scd_raw_listings"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    deletes_source_data as (

        select
            *,
            id as dbt_unique_key
        from snapshot_query
    ),
    

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    ),

    deletes as (

        select
            'delete' as dbt_change_type,
            source_data.*,
            now()::timestamp without time zone as dbt_valid_from,
            now()::timestamp without time zone as dbt_updated_at,
            now()::timestamp without time zone as dbt_valid_to,
            snapshotted_data.dbt_scd_id

        from snapshotted_data
        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where source_data.dbt_unique_key is null
    )

    select * from insertions
    union all
    select * from updates
    union all
    select * from deletes

  );
  
    
[0m14:57:46.716861 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m14:57:46.720062 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.721059 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145746413072'
        
      order by ordinal_position

  
[0m14:57:46.761756 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:57:46.768838 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.769840 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:57:46.810127 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:57:46.814634 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.815642 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145746413072'
        
      order by ordinal_position

  
[0m14:57:46.856433 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:57:46.861510 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.861947 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:57:46.903164 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:57:46.909822 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.909822 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145746413072'
        
      order by ordinal_position

  
[0m14:57:46.952998 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:57:46.959056 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.961026 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:46.962024 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      update "inttegra_stage"."test"."scd_raw_listings"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "scd_raw_listings__dbt_tmp145746413072" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "inttegra_stage"."test"."scd_raw_listings".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "inttegra_stage"."test"."scd_raw_listings".dbt_valid_to is null;

    insert into "inttegra_stage"."test"."scd_raw_listings" ("id", "listing_url", "name", "room_type", "minimum_nights", "host_id", "price", "created_at", "updated_at", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."id",DBT_INTERNAL_SOURCE."listing_url",DBT_INTERNAL_SOURCE."name",DBT_INTERNAL_SOURCE."room_type",DBT_INTERNAL_SOURCE."minimum_nights",DBT_INTERNAL_SOURCE."host_id",DBT_INTERNAL_SOURCE."price",DBT_INTERNAL_SOURCE."created_at",DBT_INTERNAL_SOURCE."updated_at",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "scd_raw_listings__dbt_tmp145746413072" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
[0m14:57:46.995435 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m14:57:47.008680 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:57:47.009642 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:57:47.010643 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:57:47.041936 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:47.044937 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 14:57:46.083666 => 14:57:47.044937
[0m14:57:47.045936 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: Close
[0m14:57:47.046938 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8908006f-3e92-47a7-850a-ff8261d2284f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC145EF10>]}
[0m14:57:47.047935 [info ] [Thread-1 (]: 1 of 1 OK snapshotted test.scd_raw_listings .................................... [[32mINSERT 0 0[0m in 0.98s]
[0m14:57:47.048938 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m14:57:47.049938 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:47.050936 [debug] [MainThread]: On master: BEGIN
[0m14:57:47.050936 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:57:47.247434 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:47.248216 [debug] [MainThread]: On master: COMMIT
[0m14:57:47.249243 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:47.249243 [debug] [MainThread]: On master: COMMIT
[0m14:57:47.277805 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:47.278849 [debug] [MainThread]: On master: Close
[0m14:57:47.279839 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:57:47.279839 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:57:47.280807 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:57:47.281351 [debug] [MainThread]: Connection 'snapshot.dbtlearn.scd_raw_listings' was properly closed.
[0m14:57:47.281351 [info ] [MainThread]: 
[0m14:57:47.282358 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 3.29 seconds (3.29s).
[0m14:57:47.283079 [debug] [MainThread]: Command end result
[0m14:57:47.292086 [info ] [MainThread]: 
[0m14:57:47.293084 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:57:47.294427 [info ] [MainThread]: 
[0m14:57:47.295430 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:57:47.297429 [debug] [MainThread]: Command `dbt snapshot` succeeded at 14:57:47.296429 after 3.87 seconds
[0m14:57:47.297429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDC1492550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDBA4F1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BDBA7DFED0>]}
[0m14:57:47.298426 [debug] [MainThread]: Flushing usage events
[0m14:59:34.146827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB022B210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFD73050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFD721D0>]}


============================== 14:59:34.153672 | 43af5a71-87bc-4486-8586-30aa901cd0a6 ==============================
[0m14:59:34.153672 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:59:34.154671 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt snapshot', 'send_anonymous_usage_stats': 'True'}
[0m14:59:34.429336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFB01D10>]}
[0m14:59:34.530473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFB01D10>]}
[0m14:59:34.533474 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:59:34.543299 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:59:34.653466 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:59:34.654466 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:59:34.663077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB05E7B50>]}
[0m14:59:34.734858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB0340350>]}
[0m14:59:34.735376 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:59:34.736999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB0281350>]}
[0m14:59:34.739661 [info ] [MainThread]: 
[0m14:59:34.741761 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:59:34.744968 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:59:34.760322 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:59:34.762016 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:59:34.762537 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:35.064852 [debug] [ThreadPool]: SQL status: SELECT 21 in 0.0 seconds
[0m14:59:35.064852 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:59:35.075933 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:59:35.080113 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:35.082118 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:59:35.082118 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:35.283251 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:59:35.285250 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:35.286250 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:59:35.339895 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m14:59:35.341437 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:59:35.437453 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:59:35.444648 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:35.445648 [debug] [MainThread]: On master: BEGIN
[0m14:59:35.445648 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:59:35.655322 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:35.656330 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:35.657377 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:59:35.723382 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:59:35.724413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB05A8790>]}
[0m14:59:35.725919 [debug] [MainThread]: On master: ROLLBACK
[0m14:59:35.761662 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:35.762797 [debug] [MainThread]: On master: BEGIN
[0m14:59:35.831222 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:35.831222 [debug] [MainThread]: On master: COMMIT
[0m14:59:35.832222 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:35.832222 [debug] [MainThread]: On master: COMMIT
[0m14:59:35.867656 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:35.868462 [debug] [MainThread]: On master: Close
[0m14:59:35.868462 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:59:35.870001 [info ] [MainThread]: 
[0m14:59:35.875206 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m14:59:35.876205 [info ] [Thread-1 (]: 1 of 1 START snapshot test.scd_raw_listings .................................... [RUN]
[0m14:59:35.877206 [debug] [Thread-1 (]: Acquiring new postgres connection 'snapshot.dbtlearn.scd_raw_listings'
[0m14:59:35.878206 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m14:59:35.884868 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 14:59:35.879207 => 14:59:35.884868
[0m14:59:35.884868 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m14:59:35.932900 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:35.933882 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: BEGIN
[0m14:59:35.933882 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:59:36.132746 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:36.134252 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.134774 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:59:36.196371 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:59:36.227360 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.228360 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

        
  
    

  create temporary table "scd_raw_listings__dbt_tmp145936208956"
  
  
    as
  
  (
    with snapshot_query as (

        



SELECT
    *
FROM
    "inttegra_stage"."test"."raw_listings"


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "inttegra_stage"."test"."scd_raw_listings"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    deletes_source_data as (

        select
            *,
            id as dbt_unique_key
        from snapshot_query
    ),
    

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    ),

    deletes as (

        select
            'delete' as dbt_change_type,
            source_data.*,
            now()::timestamp without time zone as dbt_valid_from,
            now()::timestamp without time zone as dbt_updated_at,
            now()::timestamp without time zone as dbt_valid_to,
            snapshotted_data.dbt_scd_id

        from snapshotted_data
        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where source_data.dbt_unique_key is null
    )

    select * from insertions
    union all
    select * from updates
    union all
    select * from deletes

  );
  
    
[0m14:59:36.593932 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m14:59:36.596936 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.597943 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145936208956'
        
      order by ordinal_position

  
[0m14:59:36.642265 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:59:36.646295 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.646295 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:59:36.688673 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:59:36.692685 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.693672 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145936208956'
        
      order by ordinal_position

  
[0m14:59:36.733674 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:59:36.736696 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.737696 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m14:59:36.776898 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m14:59:36.783364 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.784460 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp145936208956'
        
      order by ordinal_position

  
[0m14:59:36.829723 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m14:59:36.837698 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.840700 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.841700 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      update "inttegra_stage"."test"."scd_raw_listings"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "scd_raw_listings__dbt_tmp145936208956" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "inttegra_stage"."test"."scd_raw_listings".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "inttegra_stage"."test"."scd_raw_listings".dbt_valid_to is null;

    insert into "inttegra_stage"."test"."scd_raw_listings" ("id", "listing_url", "name", "room_type", "minimum_nights", "host_id", "price", "created_at", "updated_at", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."id",DBT_INTERNAL_SOURCE."listing_url",DBT_INTERNAL_SOURCE."name",DBT_INTERNAL_SOURCE."room_type",DBT_INTERNAL_SOURCE."minimum_nights",DBT_INTERNAL_SOURCE."host_id",DBT_INTERNAL_SOURCE."price",DBT_INTERNAL_SOURCE."created_at",DBT_INTERNAL_SOURCE."updated_at",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "scd_raw_listings__dbt_tmp145936208956" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
[0m14:59:36.874170 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m14:59:36.892198 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:59:36.893205 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m14:59:36.893205 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m14:59:36.927146 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:36.931919 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 14:59:35.884868 => 14:59:36.931387
[0m14:59:36.932974 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: Close
[0m14:59:36.934865 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43af5a71-87bc-4486-8586-30aa901cd0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAB0281E50>]}
[0m14:59:36.936509 [info ] [Thread-1 (]: 1 of 1 OK snapshotted test.scd_raw_listings .................................... [[32mINSERT 0 0[0m in 1.06s]
[0m14:59:36.938108 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m14:59:36.940756 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:36.941815 [debug] [MainThread]: On master: BEGIN
[0m14:59:36.943507 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:59:37.146427 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:37.147431 [debug] [MainThread]: On master: COMMIT
[0m14:59:37.147431 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:37.148423 [debug] [MainThread]: On master: COMMIT
[0m14:59:37.175355 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:37.176118 [debug] [MainThread]: On master: Close
[0m14:59:37.177115 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:59:37.178114 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:59:37.178114 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:59:37.179114 [debug] [MainThread]: Connection 'snapshot.dbtlearn.scd_raw_listings' was properly closed.
[0m14:59:37.179114 [info ] [MainThread]: 
[0m14:59:37.180624 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 2.44 seconds (2.44s).
[0m14:59:37.181014 [debug] [MainThread]: Command end result
[0m14:59:37.190054 [info ] [MainThread]: 
[0m14:59:37.191020 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:59:37.192534 [info ] [MainThread]: 
[0m14:59:37.193051 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:59:37.194471 [debug] [MainThread]: Command `dbt snapshot` succeeded at 14:59:37.194471 after 3.15 seconds
[0m14:59:37.195473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAA8AB1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAAFA82150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FAA8DAEF90>]}
[0m14:59:37.196471 [debug] [MainThread]: Flushing usage events
[0m15:01:23.607937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000217133591D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000217118CCA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021712E51D50>]}


============================== 15:01:23.612439 | eea3cbc2-1a36-4459-944e-f85e66c64459 ==============================
[0m15:01:23.612439 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:01:23.613383 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt snapshot', 'send_anonymous_usage_stats': 'True'}
[0m15:01:23.824843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713378390>]}
[0m15:01:23.902353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713058DD0>]}
[0m15:01:23.904031 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:01:23.913248 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:01:23.999472 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:01:23.999472 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:01:24.005477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002171335BFD0>]}
[0m15:01:24.057280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002171349F1D0>]}
[0m15:01:24.057835 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:01:24.058838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713433150>]}
[0m15:01:24.059838 [info ] [MainThread]: 
[0m15:01:24.060939 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:01:24.062609 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:01:24.074497 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:01:24.075495 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:01:24.076490 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:01:25.384502 [debug] [ThreadPool]: SQL status: SELECT 23 in 1.0 seconds
[0m15:01:25.389847 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:01:25.393662 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:01:25.403098 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:01:25.404075 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:01:25.404075 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:01:25.611872 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:01:25.613059 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:01:25.614042 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:01:25.663992 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:01:25.666084 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:01:25.696157 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:01:25.704724 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:25.704724 [debug] [MainThread]: On master: BEGIN
[0m15:01:25.704724 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:01:25.935057 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:01:25.935814 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:25.936809 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:01:25.992241 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:01:25.993511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713706C10>]}
[0m15:01:25.993511 [debug] [MainThread]: On master: ROLLBACK
[0m15:01:26.034364 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:26.035288 [debug] [MainThread]: On master: BEGIN
[0m15:01:26.097375 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:01:26.098387 [debug] [MainThread]: On master: COMMIT
[0m15:01:26.098387 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:26.099391 [debug] [MainThread]: On master: COMMIT
[0m15:01:26.126767 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:01:26.128274 [debug] [MainThread]: On master: Close
[0m15:01:26.129314 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:01:26.130280 [info ] [MainThread]: 
[0m15:01:26.133569 [debug] [Thread-1 (]: Began running node snapshot.dbtlearn.scd_raw_listings
[0m15:01:26.133569 [info ] [Thread-1 (]: 1 of 1 START snapshot test.scd_raw_listings .................................... [RUN]
[0m15:01:26.135573 [debug] [Thread-1 (]: Acquiring new postgres connection 'snapshot.dbtlearn.scd_raw_listings'
[0m15:01:26.136569 [debug] [Thread-1 (]: Began compiling node snapshot.dbtlearn.scd_raw_listings
[0m15:01:26.145750 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (compile): 15:01:26.136569 => 15:01:26.145750
[0m15:01:26.146740 [debug] [Thread-1 (]: Began executing node snapshot.dbtlearn.scd_raw_listings
[0m15:01:26.193986 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.193986 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: BEGIN
[0m15:01:26.194990 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:01:26.388867 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:01:26.390310 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.390310 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:01:26.455599 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m15:01:26.485616 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.485616 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

        
  
    

  create temporary table "scd_raw_listings__dbt_tmp150126468360"
  
  
    as
  
  (
    with snapshot_query as (

        



SELECT
    *
FROM
    "inttegra_stage"."test"."raw_listings"


    ),

    snapshotted_data as (

        select *,
            id as dbt_unique_key

        from "inttegra_stage"."test"."scd_raw_listings"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    deletes_source_data as (

        select
            *,
            id as dbt_unique_key
        from snapshot_query
    ),
    

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    ),

    deletes as (

        select
            'delete' as dbt_change_type,
            source_data.*,
            now()::timestamp without time zone as dbt_valid_from,
            now()::timestamp without time zone as dbt_updated_at,
            now()::timestamp without time zone as dbt_valid_to,
            snapshotted_data.dbt_scd_id

        from snapshotted_data
        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where source_data.dbt_unique_key is null
    )

    select * from insertions
    union all
    select * from updates
    union all
    select * from deletes

  );
  
    
[0m15:01:26.776747 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m15:01:26.780744 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.780744 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp150126468360'
        
      order by ordinal_position

  
[0m15:01:26.825849 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m15:01:26.831816 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.833331 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:01:26.873217 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m15:01:26.876347 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.877347 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp150126468360'
        
      order by ordinal_position

  
[0m15:01:26.922914 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m15:01:26.926914 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.926914 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:01:26.967288 [debug] [Thread-1 (]: SQL status: SELECT 13 in 0.0 seconds
[0m15:01:26.974285 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:26.975285 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'scd_raw_listings__dbt_tmp150126468360'
        
      order by ordinal_position

  
[0m15:01:27.020712 [debug] [Thread-1 (]: SQL status: SELECT 15 in 0.0 seconds
[0m15:01:27.027226 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:27.028227 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:27.029226 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "snapshot.dbtlearn.scd_raw_listings"} */

      update "inttegra_stage"."test"."scd_raw_listings"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "scd_raw_listings__dbt_tmp150126468360" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "inttegra_stage"."test"."scd_raw_listings".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "inttegra_stage"."test"."scd_raw_listings".dbt_valid_to is null;

    insert into "inttegra_stage"."test"."scd_raw_listings" ("id", "listing_url", "name", "room_type", "minimum_nights", "host_id", "price", "created_at", "updated_at", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."id",DBT_INTERNAL_SOURCE."listing_url",DBT_INTERNAL_SOURCE."name",DBT_INTERNAL_SOURCE."room_type",DBT_INTERNAL_SOURCE."minimum_nights",DBT_INTERNAL_SOURCE."host_id",DBT_INTERNAL_SOURCE."price",DBT_INTERNAL_SOURCE."created_at",DBT_INTERNAL_SOURCE."updated_at",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "scd_raw_listings__dbt_tmp150126468360" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
[0m15:01:27.076295 [debug] [Thread-1 (]: SQL status: INSERT 0 1 in 0.0 seconds
[0m15:01:27.089000 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m15:01:27.090002 [debug] [Thread-1 (]: Using postgres connection "snapshot.dbtlearn.scd_raw_listings"
[0m15:01:27.090986 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: COMMIT
[0m15:01:27.121687 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:01:27.125149 [debug] [Thread-1 (]: Timing info for snapshot.dbtlearn.scd_raw_listings (execute): 15:01:26.146740 => 15:01:27.125149
[0m15:01:27.126149 [debug] [Thread-1 (]: On snapshot.dbtlearn.scd_raw_listings: Close
[0m15:01:27.127118 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eea3cbc2-1a36-4459-944e-f85e66c64459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002171354F850>]}
[0m15:01:27.128117 [info ] [Thread-1 (]: 1 of 1 OK snapshotted test.scd_raw_listings .................................... [[32mINSERT 0 1[0m in 0.99s]
[0m15:01:27.130002 [debug] [Thread-1 (]: Finished running node snapshot.dbtlearn.scd_raw_listings
[0m15:01:27.131003 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:27.132005 [debug] [MainThread]: On master: BEGIN
[0m15:01:27.132005 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:01:27.341858 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:01:27.343045 [debug] [MainThread]: On master: COMMIT
[0m15:01:27.343045 [debug] [MainThread]: Using postgres connection "master"
[0m15:01:27.344005 [debug] [MainThread]: On master: COMMIT
[0m15:01:27.376192 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:01:27.376192 [debug] [MainThread]: On master: Close
[0m15:01:27.376192 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:01:27.376192 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:01:27.376192 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:01:27.376192 [debug] [MainThread]: Connection 'snapshot.dbtlearn.scd_raw_listings' was properly closed.
[0m15:01:27.376192 [info ] [MainThread]: 
[0m15:01:27.382481 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 3.32 seconds (3.32s).
[0m15:01:27.382481 [debug] [MainThread]: Command end result
[0m15:01:27.387099 [info ] [MainThread]: 
[0m15:01:27.387099 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:01:27.395325 [info ] [MainThread]: 
[0m15:01:27.396099 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:01:27.398175 [debug] [MainThread]: Command `dbt snapshot` succeeded at 15:01:27.398175 after 3.85 seconds
[0m15:01:27.398690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002170BB81010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021712B484D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021713606690>]}
[0m15:01:27.398690 [debug] [MainThread]: Flushing usage events
[0m15:17:47.363328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F5023D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F4FB110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69ED507D0>]}


============================== 15:17:47.363328 | e202945e-6920-412f-a248-e550b8e0caf3 ==============================
[0m15:17:47.363328 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:17:47.363328 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:17:47.602660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F716150>]}
[0m15:17:47.690833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69ED39190>]}
[0m15:17:47.690833 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:17:47.699126 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:17:47.795880 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m15:17:47.795880 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\schema.yml
[0m15:17:47.987238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F041010>]}
[0m15:17:48.000505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F8F9010>]}
[0m15:17:48.000505 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 2 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:17:48.000505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F041010>]}
[0m15:17:48.007326 [info ] [MainThread]: 
[0m15:17:48.007326 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:17:48.012719 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:17:48.020773 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:17:48.022778 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:17:48.023282 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:17:49.345993 [debug] [ThreadPool]: SQL status: SELECT 25 in 1.0 seconds
[0m15:17:49.353227 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:17:49.353227 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:17:49.361301 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:17:49.361301 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:17:49.361301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:17:49.566422 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:17:49.566422 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:17:49.567421 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:17:49.615645 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:17:49.619644 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:17:49.649511 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:17:49.658584 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:49.660099 [debug] [MainThread]: On master: BEGIN
[0m15:17:49.662099 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:17:49.878451 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:17:49.880474 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:49.881476 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:17:49.943917 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:17:49.946408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F9FB250>]}
[0m15:17:49.947542 [debug] [MainThread]: On master: ROLLBACK
[0m15:17:49.977658 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:49.978675 [debug] [MainThread]: On master: BEGIN
[0m15:17:50.037823 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:17:50.038503 [debug] [MainThread]: On master: COMMIT
[0m15:17:50.039528 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:50.039528 [debug] [MainThread]: On master: COMMIT
[0m15:17:50.072874 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:17:50.073877 [debug] [MainThread]: On master: Close
[0m15:17:50.074873 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:17:50.075873 [info ] [MainThread]: 
[0m15:17:50.078377 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:17:50.080055 [info ] [Thread-1 (]: 1 of 8 START sql view model test.src_hosts ..................................... [RUN]
[0m15:17:50.082063 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:17:50.083067 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:17:50.092141 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:17:50.095154 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:17:50.083067 => 15:17:50.094137
[0m15:17:50.096140 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:17:50.139372 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:17:50.140928 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.140928 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:17:50.141973 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:17:50.329250 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:50.330826 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.331778 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		"inttegra_stage"."test"."raw_hosts" rh 
)
SELECT
	id AS host_id,
	name AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:17:50.366703 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:17:50.373287 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.373287 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:17:50.411621 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:50.415140 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.416245 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:17:50.446756 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:50.462945 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:17:50.463485 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.463485 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:17:50.494710 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:50.500733 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:17:50.505733 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:17:50.506733 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:17:50.548514 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:17:50.550487 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:17:50.097143 => 15:17:50.549486
[0m15:17:50.550487 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:17:50.551486 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69EDD41D0>]}
[0m15:17:50.552487 [info ] [Thread-1 (]: 1 of 8 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.47s]
[0m15:17:50.553490 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:17:50.554489 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:17:50.555485 [info ] [Thread-1 (]: 2 of 8 START sql view model test.src_listings .................................. [RUN]
[0m15:17:50.556488 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:17:50.557487 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:17:50.560417 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:17:50.561924 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:17:50.557487 => 15:17:50.561924
[0m15:17:50.562924 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:17:50.566924 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:17:50.567925 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:50.568925 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:17:50.568925 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:50.968846 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:50.969358 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:50.970362 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT 
        *
	FROM   
		"inttegra_stage"."test"."raw_listings"
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:17:51.019318 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:17:51.026317 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:51.027822 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:17:51.059325 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.062325 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:51.063830 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:17:51.094916 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.096912 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:17:51.097912 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:51.097912 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:17:51.130128 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:51.133162 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:17:51.134162 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:17:51.134162 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:17:51.167702 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:17:51.170163 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:17:50.562924 => 15:17:51.169157
[0m15:17:51.170163 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:17:51.171163 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F9B6B10>]}
[0m15:17:51.172163 [info ] [Thread-1 (]: 2 of 8 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.61s]
[0m15:17:51.173677 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:17:51.173677 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:17:51.174676 [info ] [Thread-1 (]: 3 of 8 START sql view model test.src_reviews ................................... [RUN]
[0m15:17:51.175676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:17:51.176679 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:17:51.179676 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:17:51.182185 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:17:51.176679 => 15:17:51.181679
[0m15:17:51.183193 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:17:51.190583 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:17:51.192580 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.193583 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:17:51.194580 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:51.400540 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:51.401752 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.402756 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT 
		*
	FROM
		"inttegra_stage"."test"."raw_reviews" rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:17:51.450956 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:17:51.454921 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.454921 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:17:51.486946 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.489943 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.490939 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:17:51.523873 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.525874 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:17:51.526873 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.527872 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:17:51.561019 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:51.564016 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:17:51.564978 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:17:51.564978 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:17:51.599294 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:17:51.601326 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:17:51.183193 => 15:17:51.600294
[0m15:17:51.601326 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:17:51.603326 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69FB5A990>]}
[0m15:17:51.603326 [info ] [Thread-1 (]: 3 of 8 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.43s]
[0m15:17:51.604832 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:17:51.604832 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:17:51.606233 [info ] [Thread-1 (]: 4 of 8 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:17:51.607233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:17:51.608232 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:17:51.611233 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.612232 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:17:51.608232 => 15:17:51.612232
[0m15:17:51.613232 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:17:51.639367 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.642413 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.643412 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:17:51.644411 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:51.847141 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:51.847141 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.848184 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    host_id,
	CASE 
        WHEN host_name = '' THEN 'Anonymous' 
        ELSE  host_name
    END AS host_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:17:51.942512 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:17:51.945619 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.946617 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:17:51.978361 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:51.982371 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:51.983368 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:17:52.020101 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:52.027193 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:17:52.028195 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:52.028195 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:17:52.061451 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:52.064029 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:17:52.068030 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:17:52.069030 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:17:52.108381 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:17:52.110595 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:17:51.613232 => 15:17:52.109347
[0m15:17:52.110595 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:17:52.111597 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69FBE3590>]}
[0m15:17:52.112597 [info ] [Thread-1 (]: 4 of 8 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.50s]
[0m15:17:52.113597 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:17:52.114599 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:17:52.115596 [info ] [Thread-1 (]: 5 of 8 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:17:52.116597 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:17:52.116597 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:17:52.119595 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.121599 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:17:52.117596 => 15:17:52.120596
[0m15:17:52.121599 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:17:52.127092 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.131092 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.132093 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:17:52.133599 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:52.339610 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:52.340601 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.341608 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:17:52.496572 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:17:52.500606 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.501571 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:17:52.542003 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:52.546365 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.547365 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:17:52.577220 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:52.579641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:17:52.580641 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.581641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:17:52.611596 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:52.615102 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:17:52.616107 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:17:52.616107 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:17:52.659139 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:17:52.661147 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:17:52.122576 => 15:17:52.661147
[0m15:17:52.661147 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:17:52.662653 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69FBE2A90>]}
[0m15:17:52.663659 [info ] [Thread-1 (]: 5 of 8 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.55s]
[0m15:17:52.664665 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:17:52.665664 [debug] [Thread-1 (]: Began running node model.dbtlearn.fact_reviews
[0m15:17:52.666664 [info ] [Thread-1 (]: 6 of 8 START sql incremental model test.fact_reviews ........................... [RUN]
[0m15:17:52.667665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_cleansed, now model.dbtlearn.fact_reviews)
[0m15:17:52.667665 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.fact_reviews
[0m15:17:52.676304 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.fact_reviews"
[0m15:17:52.677982 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (compile): 15:17:52.667665 => 15:17:52.677982
[0m15:17:52.677982 [debug] [Thread-1 (]: Began executing node model.dbtlearn.fact_reviews
[0m15:17:52.713840 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:52.713840 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

    
  
    

  create temporary table "fact_reviews__dbt_tmp151752706821"
  
  
    as
  
  (
    
WITH src_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_reviews"
)
SELECT
    *
FROM
    src_reviews
WHERE
    review_txt IS NOT NULL

    AND review_date > (SELECT 
                           MAX(review_date)
                       FROM
                           "inttegra_stage"."test"."fact_reviews"        
    )

  );
  
  
[0m15:17:52.714847 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:53.924615 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.0 seconds
[0m15:17:53.930807 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:53.931806 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: BEGIN
[0m15:17:53.965018 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:53.966029 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:53.966029 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp151752706821'
        
      order by ordinal_position

  
[0m15:17:54.028753 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:17:54.036240 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.037212 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:17:54.079756 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:17:54.092770 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.093287 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews__dbt_tmp151752706821'
        
      order by ordinal_position

  
[0m15:17:54.133186 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:17:54.136178 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.137177 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "inttegra_stage".INFORMATION_SCHEMA.columns
      where table_name = 'fact_reviews'
        
        and table_schema = 'test'
        
      order by ordinal_position

  
[0m15:17:54.176964 [debug] [Thread-1 (]: SQL status: SELECT 5 in 0.0 seconds
[0m15:17:54.185975 [debug] [Thread-1 (]: 
    In "inttegra_stage"."test"."fact_reviews":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m15:17:54.195748 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.fact_reviews"
[0m15:17:54.197750 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.197750 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.fact_reviews"} */

      insert into "inttegra_stage"."test"."fact_reviews" ("listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment")
    (
        select "listing_id", "review_date", "reviewer_name", "review_txt", "review_sentiment"
        from "fact_reviews__dbt_tmp151752706821"
    )


  
[0m15:17:54.230297 [debug] [Thread-1 (]: SQL status: INSERT 0 0 in 0.0 seconds
[0m15:17:54.232303 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:17:54.233303 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.fact_reviews"
[0m15:17:54.233303 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: COMMIT
[0m15:17:54.266475 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:54.267516 [debug] [Thread-1 (]: Timing info for model.dbtlearn.fact_reviews (execute): 15:17:52.678983 => 15:17:54.267516
[0m15:17:54.268507 [debug] [Thread-1 (]: On model.dbtlearn.fact_reviews: Close
[0m15:17:54.269477 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F7F5E50>]}
[0m15:17:54.270475 [info ] [Thread-1 (]: 6 of 8 OK created sql incremental model test.fact_reviews ...................... [[32mINSERT 0 0[0m in 1.60s]
[0m15:17:54.271476 [debug] [Thread-1 (]: Finished running node model.dbtlearn.fact_reviews
[0m15:17:54.271476 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_with_hosts
[0m15:17:54.273531 [info ] [Thread-1 (]: 7 of 8 START sql table model test.dim_listings_with_hosts ...................... [RUN]
[0m15:17:54.275140 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.fact_reviews, now model.dbtlearn.dim_listings_with_hosts)
[0m15:17:54.275140 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_with_hosts
[0m15:17:54.278144 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.279146 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (compile): 15:17:54.276148 => 15:17:54.279146
[0m15:17:54.280146 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_with_hosts
[0m15:17:54.284648 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.286015 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.287013 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: BEGIN
[0m15:17:54.289016 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:54.541339 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:54.542348 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.543379 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp"
  
  
    as
  
  (
    WITH l AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_listings_cleansed"
),
h AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."dim_hosts_cleansed"
)

SELECT
    l.id_listings,
    l.listing_name,
    l.room_type,
    l.minimum_nights,
    l.price,
    l.host_id,
    h.host_name,
    h.is_superhost AS host_is_superhost,
    l.created_at,
    GREATEST(l.updated_at, h.updated_at) AS update_at
FROM
    l
LEFT JOIN
    h ON l.host_Id = h.host_id
  );
  
[0m15:17:54.698575 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:17:54.701563 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.702568 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts" rename to "dim_listings_with_hosts__dbt_backup"
[0m15:17:54.733973 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:54.737013 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.738011 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
alter table "inttegra_stage"."test"."dim_listings_with_hosts__dbt_tmp" rename to "dim_listings_with_hosts"
[0m15:17:54.769020 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:54.771051 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m15:17:54.772051 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.773023 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: COMMIT
[0m15:17:54.803133 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:54.806169 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup"
[0m15:17:54.807168 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_with_hosts"
[0m15:17:54.808141 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_with_hosts"} */
drop table if exists "inttegra_stage"."test"."dim_listings_with_hosts__dbt_backup" cascade
[0m15:17:54.849975 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:17:54.851994 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_with_hosts (execute): 15:17:54.280146 => 15:17:54.851994
[0m15:17:54.852992 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_with_hosts: Close
[0m15:17:54.853992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69FB590D0>]}
[0m15:17:54.853992 [info ] [Thread-1 (]: 7 of 8 OK created sql table model test.dim_listings_with_hosts ................. [[32mSELECT 17499[0m in 0.58s]
[0m15:17:54.854992 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_with_hosts
[0m15:17:54.855993 [debug] [Thread-1 (]: Began running node model.dbtlearn.mart_fullmoon_reviews
[0m15:17:54.856993 [info ] [Thread-1 (]: 8 of 8 START sql table model test.mart_fullmoon_reviews ........................ [RUN]
[0m15:17:54.857994 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_listings_with_hosts, now model.dbtlearn.mart_fullmoon_reviews)
[0m15:17:54.857994 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.mart_fullmoon_reviews
[0m15:17:54.861563 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:54.863003 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (compile): 15:17:54.859028 => 15:17:54.863003
[0m15:17:54.863003 [debug] [Thread-1 (]: Began executing node model.dbtlearn.mart_fullmoon_reviews
[0m15:17:54.868008 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:54.870010 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:54.870010 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: BEGIN
[0m15:17:54.871015 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:17:55.063321 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:17:55.064115 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:55.065073 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */

  
    

  create  table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp"
  
  
    as
  
  (
    

WITH fact_reviews AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."fact_reviews"
),
full_moon_dates AS (
    SELECT
        *
    FROM
        "inttegra_stage"."test"."seed_full_moon_dates"
)

SELECT
    r.*,
    CASE 
        WHEN fm.full_moon_date IS NULL THEN 'not full moon'  
        ELSE 'full moon'
    END AS is_full_moon
FROM
    fact_reviews r
LEFT JOIN
    full_moon_dates fm ON r.review_date = fm.full_moon_date + INTERVAL '1 day'
  );
  
[0m15:17:56.996701 [debug] [Thread-1 (]: SQL status: SELECT 410284 in 2.0 seconds
[0m15:17:56.999698 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:57.000700 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews" rename to "mart_fullmoon_reviews__dbt_backup"
[0m15:17:57.039173 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:57.042184 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:57.042184 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
alter table "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_tmp" rename to "mart_fullmoon_reviews"
[0m15:17:57.073213 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:17:57.077343 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m15:17:57.077343 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:57.078308 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: COMMIT
[0m15:17:57.127428 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:17:57.130463 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup"
[0m15:17:57.131461 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.mart_fullmoon_reviews"
[0m15:17:57.132966 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.mart_fullmoon_reviews"} */
drop table if exists "inttegra_stage"."test"."mart_fullmoon_reviews__dbt_backup" cascade
[0m15:17:57.220649 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:17:57.222688 [debug] [Thread-1 (]: Timing info for model.dbtlearn.mart_fullmoon_reviews (execute): 15:17:54.864010 => 15:17:57.221657
[0m15:17:57.222688 [debug] [Thread-1 (]: On model.dbtlearn.mart_fullmoon_reviews: Close
[0m15:17:57.223688 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e202945e-6920-412f-a248-e550b8e0caf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69EDD41D0>]}
[0m15:17:57.224657 [info ] [Thread-1 (]: 8 of 8 OK created sql table model test.mart_fullmoon_reviews ................... [[32mSELECT 410284[0m in 2.37s]
[0m15:17:57.225656 [debug] [Thread-1 (]: Finished running node model.dbtlearn.mart_fullmoon_reviews
[0m15:17:57.227658 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:57.227658 [debug] [MainThread]: On master: BEGIN
[0m15:17:57.227658 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:17:57.435183 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:17:57.436413 [debug] [MainThread]: On master: COMMIT
[0m15:17:57.437459 [debug] [MainThread]: Using postgres connection "master"
[0m15:17:57.437982 [debug] [MainThread]: On master: COMMIT
[0m15:17:57.467280 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:17:57.468323 [debug] [MainThread]: On master: Close
[0m15:17:57.469420 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:17:57.469946 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:17:57.470478 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:17:57.471029 [debug] [MainThread]: Connection 'model.dbtlearn.mart_fullmoon_reviews' was properly closed.
[0m15:17:57.472114 [info ] [MainThread]: 
[0m15:17:57.473756 [info ] [MainThread]: Finished running 3 view models, 4 table models, 1 incremental model in 0 hours 0 minutes and 9.46 seconds (9.46s).
[0m15:17:57.476436 [debug] [MainThread]: Command end result
[0m15:17:57.489498 [info ] [MainThread]: 
[0m15:17:57.491169 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:17:57.492832 [info ] [MainThread]: 
[0m15:17:57.494457 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m15:17:57.499321 [debug] [MainThread]: Command `dbt run` succeeded at 15:17:57.498796 after 10.20 seconds
[0m15:17:57.500427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69ED2F550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B697DE1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B69F0431D0>]}
[0m15:17:57.501478 [debug] [MainThread]: Flushing usage events
[0m15:18:07.608737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6DF44F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6D55A890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E360650>]}


============================== 15:18:07.618457 | 3238f417-bb71-4f51-9cfd-cb07d9f5638f ==============================
[0m15:18:07.618457 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:18:07.622222 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt test', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:18:07.964976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6DE72710>]}
[0m15:18:08.046806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E375510>]}
[0m15:18:08.058286 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:18:08.060428 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:18:08.171031 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:18:08.171031 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:18:08.174032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E73D8D0>]}
[0m15:18:08.238575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E3A1A10>]}
[0m15:18:08.239146 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 2 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:18:08.239146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E6D3E50>]}
[0m15:18:08.239146 [info ] [MainThread]: 
[0m15:18:08.239146 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:18:08.244437 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:18:08.257083 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:18:08.257083 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:18:08.257083 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:18:09.548906 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:18:09.548906 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:18:09.548906 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:18:09.597413 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:18:09.599476 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:18:09.628441 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:18:09.633103 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:09.633103 [debug] [MainThread]: On master: BEGIN
[0m15:18:09.633103 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:18:09.849002 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:09.849002 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:09.849002 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:18:09.908621 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:18:09.908621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3238f417-bb71-4f51-9cfd-cb07d9f5638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6E5D6D90>]}
[0m15:18:09.908621 [debug] [MainThread]: On master: ROLLBACK
[0m15:18:09.932478 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:09.932478 [debug] [MainThread]: On master: BEGIN
[0m15:18:09.992588 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:09.992588 [debug] [MainThread]: On master: COMMIT
[0m15:18:09.992588 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:10.002704 [debug] [MainThread]: On master: COMMIT
[0m15:18:10.028599 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:10.028599 [debug] [MainThread]: On master: Close
[0m15:18:10.034636 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:18:10.034636 [info ] [MainThread]: 
[0m15:18:10.040511 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9
[0m15:18:10.041487 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_listings_cleansed_listing_id .................... [RUN]
[0m15:18:10.041487 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9'
[0m15:18:10.041487 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9
[0m15:18:10.067442 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"
[0m15:18:10.071211 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9 (compile): 15:18:10.041487 => 15:18:10.071211
[0m15:18:10.071211 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9
[0m15:18:10.088572 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"
[0m15:18:10.090919 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"
[0m15:18:10.090919 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9: BEGIN
[0m15:18:10.090919 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:18:10.283796 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:10.283796 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"
[0m15:18:10.283796 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listing_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where listing_id is null



      
    ) dbt_internal_test
[0m15:18:10.317349 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "listing_id" does not exist
LINE 13: select listing_id
                ^

[0m15:18:10.317349 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9: ROLLBACK
[0m15:18:10.353730 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9 (execute): 15:18:10.071211 => 15:18:10.353730
[0m15:18:10.353730 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9: Close
[0m15:18:10.376962 [debug] [Thread-1 (]: Database Error in test not_null_dim_listings_cleansed_listing_id (dbtlearn/models\schema.yml)
  column "listing_id" does not exist
  LINE 13: select listing_id
                  ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\not_null_dim_listings_cleansed_listing_id.sql
[0m15:18:10.376962 [error] [Thread-1 (]: 1 of 2 ERROR not_null_dim_listings_cleansed_listing_id ......................... [[31mERROR[0m in 0.34s]
[0m15:18:10.376962 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9
[0m15:18:10.382550 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e
[0m15:18:10.382550 [info ] [Thread-1 (]: 2 of 2 START test unique_dim_listings_cleansed_listing_id ...................... [RUN]
[0m15:18:10.382550 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_listing_id.2da437bec9, now test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e)
[0m15:18:10.382550 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e
[0m15:18:10.390024 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"
[0m15:18:10.393650 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e (compile): 15:18:10.382550 => 15:18:10.392728
[0m15:18:10.393650 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e
[0m15:18:10.398021 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"
[0m15:18:10.398021 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"
[0m15:18:10.401219 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e: BEGIN
[0m15:18:10.402158 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:18:10.594644 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:10.594644 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"
[0m15:18:10.594644 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    listing_id as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where listing_id is not null
group by listing_id
having count(*) > 1



      
    ) dbt_internal_test
[0m15:18:10.635137 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "listing_id" does not exist
LINE 12:     listing_id as unique_field,
             ^

[0m15:18:10.636176 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e: ROLLBACK
[0m15:18:10.665711 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e (execute): 15:18:10.395157 => 15:18:10.665711
[0m15:18:10.667477 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e: Close
[0m15:18:10.670745 [debug] [Thread-1 (]: Database Error in test unique_dim_listings_cleansed_listing_id (dbtlearn/models\schema.yml)
  column "listing_id" does not exist
  LINE 12:     listing_id as unique_field,
               ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\unique_dim_listings_cleansed_listing_id.sql
[0m15:18:10.671149 [error] [Thread-1 (]: 2 of 2 ERROR unique_dim_listings_cleansed_listing_id ........................... [[31mERROR[0m in 0.29s]
[0m15:18:10.672849 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e
[0m15:18:10.675960 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:10.675960 [debug] [MainThread]: On master: BEGIN
[0m15:18:10.679834 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:18:10.878550 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:10.878887 [debug] [MainThread]: On master: COMMIT
[0m15:18:10.878887 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:10.879911 [debug] [MainThread]: On master: COMMIT
[0m15:18:10.906125 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:10.906125 [debug] [MainThread]: On master: Close
[0m15:18:10.910343 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:18:10.910343 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:18:10.911514 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_listing_id.930e4e859e' was properly closed.
[0m15:18:10.911514 [info ] [MainThread]: 
[0m15:18:10.912418 [info ] [MainThread]: Finished running 2 tests in 0 hours 0 minutes and 2.67 seconds (2.67s).
[0m15:18:10.913424 [debug] [MainThread]: Command end result
[0m15:18:10.925152 [info ] [MainThread]: 
[0m15:18:10.925152 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m15:18:10.925152 [info ] [MainThread]: 
[0m15:18:10.929727 [error] [MainThread]:   Database Error in test not_null_dim_listings_cleansed_listing_id (dbtlearn/models\schema.yml)
  column "listing_id" does not exist
  LINE 13: select listing_id
                  ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\not_null_dim_listings_cleansed_listing_id.sql
[0m15:18:10.930762 [info ] [MainThread]: 
[0m15:18:10.932774 [error] [MainThread]:   Database Error in test unique_dim_listings_cleansed_listing_id (dbtlearn/models\schema.yml)
  column "listing_id" does not exist
  LINE 12:     listing_id as unique_field,
               ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\unique_dim_listings_cleansed_listing_id.sql
[0m15:18:10.934142 [info ] [MainThread]: 
[0m15:18:10.937905 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=0 TOTAL=2
[0m15:18:10.940625 [debug] [MainThread]: Command `dbt test` failed at 15:18:10.939907 after 3.45 seconds
[0m15:18:10.940625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B66C21010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6DB36AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B6DC27F50>]}
[0m15:18:10.942134 [debug] [MainThread]: Flushing usage events
[0m15:18:51.725151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0F36010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0FC5E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0E80C90>]}


============================== 15:18:51.730167 | ac8ab8d3-159f-417f-baa1-6dfb43beb8bb ==============================
[0m15:18:51.730167 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:18:51.731673 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt test', 'send_anonymous_usage_stats': 'True'}
[0m15:18:51.951587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0C61550>]}
[0m15:18:52.033040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F14585D0>]}
[0m15:18:52.033040 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:18:52.039591 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:18:52.132451 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:18:52.133451 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:18:52.483094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F16E0D50>]}
[0m15:18:52.498087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F17DC650>]}
[0m15:18:52.498087 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 2 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:18:52.499116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F1A0E710>]}
[0m15:18:52.501585 [info ] [MainThread]: 
[0m15:18:52.502180 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:18:52.504180 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:18:52.513008 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:18:52.513008 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:18:52.513008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:18:53.810737 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:18:53.812168 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:18:53.813168 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:18:53.864315 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:18:53.864315 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:18:53.895227 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:18:53.909833 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:53.910843 [debug] [MainThread]: On master: BEGIN
[0m15:18:53.911842 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:18:54.121521 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:54.123029 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:54.123545 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:18:54.184761 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:18:54.187525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac8ab8d3-159f-417f-baa1-6dfb43beb8bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F1947490>]}
[0m15:18:54.187525 [debug] [MainThread]: On master: ROLLBACK
[0m15:18:54.219261 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:54.219261 [debug] [MainThread]: On master: BEGIN
[0m15:18:54.289990 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:54.289990 [debug] [MainThread]: On master: COMMIT
[0m15:18:54.291498 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:54.292016 [debug] [MainThread]: On master: COMMIT
[0m15:18:54.316511 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:54.316511 [debug] [MainThread]: On master: Close
[0m15:18:54.316511 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:18:54.316511 [info ] [MainThread]: 
[0m15:18:54.316511 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:18:54.316511 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:18:54.328569 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485'
[0m15:18:54.329082 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:18:54.346446 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:18:54.353595 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:18:54.329082 => 15:18:54.352781
[0m15:18:54.353595 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:18:54.369730 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:18:54.371626 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:18:54.373050 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:18:54.373050 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:18:54.585081 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:54.585609 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:18:54.586129 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:18:54.639869 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:18:54.641811 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:18:54.355689 => 15:18:54.641811
[0m15:18:54.641811 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:18:54.671285 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:18:54.672292 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.34s]
[0m15:18:54.673281 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:18:54.674279 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:18:54.675246 [info ] [Thread-1 (]: 2 of 2 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:18:54.676246 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:18:54.676751 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:18:54.682760 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:18:54.685741 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:18:54.677240 => 15:18:54.685096
[0m15:18:54.686771 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:18:54.688895 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:18:54.692472 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:18:54.694480 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:18:54.694480 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:18:54.894923 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:54.895956 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:18:54.895956 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:18:54.955871 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:18:54.965012 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:18:54.686771 => 15:18:54.965012
[0m15:18:54.965527 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:18:55.000685 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:18:55.002288 [info ] [Thread-1 (]: 2 of 2 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.33s]
[0m15:18:55.003294 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:18:55.004290 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:55.005324 [debug] [MainThread]: On master: BEGIN
[0m15:18:55.005324 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:18:55.202281 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:55.202281 [debug] [MainThread]: On master: COMMIT
[0m15:18:55.203463 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:55.203463 [debug] [MainThread]: On master: COMMIT
[0m15:18:55.240733 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:55.240733 [debug] [MainThread]: On master: Close
[0m15:18:55.242087 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:18:55.243307 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:18:55.243307 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:18:55.244273 [info ] [MainThread]: 
[0m15:18:55.245274 [info ] [MainThread]: Finished running 2 tests in 0 hours 0 minutes and 2.74 seconds (2.74s).
[0m15:18:55.245835 [debug] [MainThread]: Command end result
[0m15:18:55.255371 [info ] [MainThread]: 
[0m15:18:55.256375 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:18:55.257375 [info ] [MainThread]: 
[0m15:18:55.258390 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:18:55.260372 [debug] [MainThread]: Command `dbt test` succeeded at 15:18:55.260372 after 3.61 seconds
[0m15:18:55.261376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0F65190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267F0C43E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000267E9FDFED0>]}
[0m15:18:55.263375 [debug] [MainThread]: Flushing usage events
[0m15:22:55.988212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D63B9C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D498C890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D63BA3D0>]}


============================== 15:22:55.991842 | f59ba261-d304-49a6-be80-447cb96c77d2 ==============================
[0m15:22:55.991842 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:22:55.992841 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt test', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:22:56.211016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f59ba261-d304-49a6-be80-447cb96c77d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D63BA710>]}
[0m15:22:56.291911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f59ba261-d304-49a6-be80-447cb96c77d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D6520690>]}
[0m15:22:56.293911 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:22:56.302945 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:22:56.421493 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:22:56.422499 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:22:56.746912 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in dbtlearn/models\schema.yml:
  	test definition dictionary must have exactly one key, got [('relationships', None), ('to', "ref('dim_hosts_cleansed')"), ('field', 'host_id')] instead (3 keys)
  	@: UnparsedModelUpdate(original_file_path='dbtl...ne)
[0m15:22:56.748911 [debug] [MainThread]: Command `dbt test` failed at 15:22:56.748911 after 0.83 seconds
[0m15:22:56.749913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D5EDB110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7CECA1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7D640BA10>]}
[0m15:22:56.750914 [debug] [MainThread]: Flushing usage events
[0m15:23:51.783931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35FC8ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35F7B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35FC8410>]}


============================== 15:23:51.786961 | b61cfff0-db09-4e62-b270-79fc89ec2201 ==============================
[0m15:23:51.786961 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:23:51.788471 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt test', 'send_anonymous_usage_stats': 'True'}
[0m15:23:52.011234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b61cfff0-db09-4e62-b270-79fc89ec2201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35CC9490>]}
[0m15:23:52.087454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b61cfff0-db09-4e62-b270-79fc89ec2201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE3525AC50>]}
[0m15:23:52.090136 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:23:52.098789 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:23:52.186321 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:23:52.186321 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:23:52.485306 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in dbtlearn/models\schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['Entire home/apt', 'Private room', 'Shared room', 'Hotel room'])] instead (2 keys)
  	@: UnparsedModelUpdate(original_file_path='dbtl...ne)
[0m15:23:52.487628 [debug] [MainThread]: Command `dbt test` failed at 15:23:52.486390 after 0.77 seconds
[0m15:23:52.487628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35A90990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE2E82E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AE35FD1B10>]}
[0m15:23:52.488662 [debug] [MainThread]: Flushing usage events
[0m15:24:42.483487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4993AAB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EC0910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EC0A50>]}


============================== 15:24:42.487486 | dd119fc9-218b-42f3-b78b-491579cbb5c7 ==============================
[0m15:24:42.487486 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:24:42.487486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt test', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:24:42.708415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EF26D0>]}
[0m15:24:42.782346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F499510B50>]}
[0m15:24:42.782346 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:24:42.794356 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:24:42.892333 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:24:42.893300 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:24:43.204409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49AA49F50>]}
[0m15:24:43.214071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49AA770D0>]}
[0m15:24:43.214071 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 5 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:24:43.214071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49A9C3690>]}
[0m15:24:43.222491 [info ] [MainThread]: 
[0m15:24:43.222491 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:24:43.226786 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:24:43.238214 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:24:43.240247 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:24:43.241939 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:24:44.568948 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:24:44.569949 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:24:44.570948 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:24:44.620945 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:24:44.621952 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:24:44.648786 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:24:44.656835 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:44.656835 [debug] [MainThread]: On master: BEGIN
[0m15:24:44.657850 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:24:44.849899 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:24:44.849899 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:44.849899 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:24:44.917284 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:24:44.919323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd119fc9-218b-42f3-b78b-491579cbb5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F49AA80790>]}
[0m15:24:44.919323 [debug] [MainThread]: On master: ROLLBACK
[0m15:24:44.950941 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:44.951975 [debug] [MainThread]: On master: BEGIN
[0m15:24:45.015355 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:24:45.015355 [debug] [MainThread]: On master: COMMIT
[0m15:24:45.018449 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:45.018449 [debug] [MainThread]: On master: COMMIT
[0m15:24:45.045562 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:24:45.046562 [debug] [MainThread]: On master: Close
[0m15:24:45.048535 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:24:45.049531 [info ] [MainThread]: 
[0m15:24:45.054008 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502
[0m15:24:45.055197 [info ] [Thread-1 (]: 1 of 5 START test accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:24:45.057209 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502'
[0m15:24:45.058195 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502
[0m15:24:45.069233 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"
[0m15:24:45.071227 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502 (compile): 15:24:45.058195 => 15:24:45.071227
[0m15:24:45.072226 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502
[0m15:24:45.094098 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"
[0m15:24:45.096106 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"
[0m15:24:45.096106 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502: BEGIN
[0m15:24:45.096106 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:24:45.295871 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:45.295871 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"
[0m15:24:45.295871 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        romm_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by romm_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:24:45.347753 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "romm_type" does not exist
LINE 14:         romm_type as value_field,
                 ^
HINT:  Perhaps you meant to reference the column "dim_listings_cleansed.room_type".

[0m15:24:45.348779 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502: ROLLBACK
[0m15:24:45.379294 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502 (execute): 15:24:45.073226 => 15:24:45.378697
[0m15:24:45.380301 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502: Close
[0m15:24:45.384300 [debug] [Thread-1 (]: Database Error in test accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room (dbtlearn/models\schema.yml)
  column "romm_type" does not exist
  LINE 14:         romm_type as value_field,
                   ^
  HINT:  Perhaps you meant to reference the column "dim_listings_cleansed.room_type".
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\accepted_values_dim_listings_c_b00575739adcaecd53bcd93ce8f6c13a.sql
[0m15:24:45.385335 [error] [Thread-1 (]: 1 of 5 ERROR accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[31mERROR[0m in 0.33s]
[0m15:24:45.386330 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502
[0m15:24:45.387300 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:24:45.388300 [info ] [Thread-1 (]: 2 of 5 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:24:45.389808 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.15b734a502, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:24:45.389808 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:24:45.396809 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:24:45.397813 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:24:45.390810 => 15:24:45.397813
[0m15:24:45.398812 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:24:45.401357 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:24:45.403566 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:24:45.403566 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:24:45.404601 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:24:45.593903 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:45.593903 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:24:45.593903 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:24:45.656803 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:24:45.659846 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:24:45.399818 => 15:24:45.658814
[0m15:24:45.659846 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:24:45.692223 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:24:45.693384 [info ] [Thread-1 (]: 2 of 5 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.30s]
[0m15:24:45.694364 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:24:45.695374 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:24:45.696360 [info ] [Thread-1 (]: 3 of 5 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:24:45.697374 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:24:45.697374 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:24:45.701912 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:24:45.703987 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:24:45.698340 => 15:24:45.702981
[0m15:24:45.703987 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:24:45.706987 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:24:45.708986 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:24:45.709990 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:24:45.710987 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:24:45.934061 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:45.935023 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:24:45.936021 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:24:45.986561 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:24:45.987572 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:24:45.704988 => 15:24:45.987572
[0m15:24:45.988567 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:24:46.020273 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:24:46.021279 [info ] [Thread-1 (]: 3 of 5 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.32s]
[0m15:24:46.022278 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:24:46.023315 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:24:46.024068 [info ] [Thread-1 (]: 4 of 5 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:24:46.025073 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:24:46.025073 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:24:46.030106 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:24:46.032106 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:24:46.026578 => 15:24:46.032106
[0m15:24:46.033107 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:24:46.037106 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:24:46.038611 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:24:46.039170 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:24:46.040183 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:24:46.245648 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:46.246201 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:24:46.246753 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:24:46.320962 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:24:46.322604 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:24:46.033107 => 15:24:46.322604
[0m15:24:46.323604 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:24:46.354787 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:24:46.356577 [info ] [Thread-1 (]: 4 of 5 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.33s]
[0m15:24:46.357544 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:24:46.357544 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:24:46.358543 [info ] [Thread-1 (]: 5 of 5 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:24:46.359542 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:24:46.360543 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:24:46.365829 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:24:46.368179 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:24:46.360543 => 15:24:46.366828
[0m15:24:46.368179 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:24:46.371178 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:24:46.372179 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:24:46.373180 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:24:46.373180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:24:46.568234 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:24:46.569242 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:24:46.569242 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:24:46.639630 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:24:46.640978 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:24:46.369179 => 15:24:46.640978
[0m15:24:46.642028 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:24:46.667597 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:24:46.674043 [info ] [Thread-1 (]: 5 of 5 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.31s]
[0m15:24:46.676726 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:24:46.678545 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:46.678545 [debug] [MainThread]: On master: BEGIN
[0m15:24:46.679543 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:24:46.875018 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:24:46.876017 [debug] [MainThread]: On master: COMMIT
[0m15:24:46.877016 [debug] [MainThread]: Using postgres connection "master"
[0m15:24:46.878016 [debug] [MainThread]: On master: COMMIT
[0m15:24:46.904890 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:24:46.905537 [debug] [MainThread]: On master: Close
[0m15:24:46.906555 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:24:46.906555 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:24:46.907578 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:24:46.908578 [info ] [MainThread]: 
[0m15:24:46.909544 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 3.69 seconds (3.69s).
[0m15:24:46.910548 [debug] [MainThread]: Command end result
[0m15:24:46.920062 [info ] [MainThread]: 
[0m15:24:46.921061 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:24:46.922061 [info ] [MainThread]: 
[0m15:24:46.924061 [error] [MainThread]:   Database Error in test accepted_values_dim_listings_cleansed_romm_type__Entire_home_apt__Private_room__Shared_room__Hotel_room (dbtlearn/models\schema.yml)
  column "romm_type" does not exist
  LINE 14:         romm_type as value_field,
                   ^
  HINT:  Perhaps you meant to reference the column "dim_listings_cleansed.room_type".
  compiled Code at target\run\dbtlearn\dbtlearn/models\schema.yml\accepted_values_dim_listings_c_b00575739adcaecd53bcd93ce8f6c13a.sql
[0m15:24:46.925059 [info ] [MainThread]: 
[0m15:24:46.926059 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m15:24:46.928631 [debug] [MainThread]: Command `dbt test` failed at 15:24:46.928212 after 4.51 seconds
[0m15:24:46.929643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F491C11010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EC0910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F498EC0A50>]}
[0m15:24:46.930642 [debug] [MainThread]: Flushing usage events
[0m15:25:21.392608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D2D2C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2CAE18D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D2EBFD0>]}


============================== 15:25:21.397607 | f0f2351d-9afc-4226-8124-fe7e4afd72a1 ==============================
[0m15:25:21.397607 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:25:21.398607 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt test', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:25:21.708143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2CDF8450>]}
[0m15:25:21.816150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D0D5090>]}
[0m15:25:21.818147 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:25:21.833141 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:25:21.982245 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:25:21.983244 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\schema.yml
[0m15:25:22.359017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2E90B3D0>]}
[0m15:25:22.385592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D498150>]}
[0m15:25:22.385592 [info ] [MainThread]: Found 1 seed, 8 models, 1 snapshot, 5 tests, 3 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:25:22.387831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2E8FA350>]}
[0m15:25:22.390958 [info ] [MainThread]: 
[0m15:25:22.393765 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:25:22.396774 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:25:22.414149 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:25:22.415348 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:25:22.416339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:25:22.719895 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:25:22.720900 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:25:22.721900 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:25:22.771526 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m15:25:22.775588 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:25:22.798492 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:25:22.811389 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:22.811389 [debug] [MainThread]: On master: BEGIN
[0m15:25:22.811389 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:25:23.016973 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:25:23.017995 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:23.018975 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:25:23.081923 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:25:23.086132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0f2351d-9afc-4226-8124-fe7e4afd72a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D7AC610>]}
[0m15:25:23.086643 [debug] [MainThread]: On master: ROLLBACK
[0m15:25:23.117882 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:23.118885 [debug] [MainThread]: On master: BEGIN
[0m15:25:23.181951 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:25:23.182494 [debug] [MainThread]: On master: COMMIT
[0m15:25:23.183540 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:23.184497 [debug] [MainThread]: On master: COMMIT
[0m15:25:23.213159 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:25:23.214161 [debug] [MainThread]: On master: Close
[0m15:25:23.215159 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:25:23.216159 [info ] [MainThread]: 
[0m15:25:23.221245 [debug] [Thread-1 (]: Began running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:25:23.223241 [info ] [Thread-1 (]: 1 of 5 START test accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [RUN]
[0m15:25:23.224932 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af'
[0m15:25:23.226928 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:25:23.243488 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:25:23.259238 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (compile): 15:25:23.227930 => 15:25:23.251494
[0m15:25:23.267117 [debug] [Thread-1 (]: Began executing node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:25:23.300762 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:25:23.305295 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:25:23.306292 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: BEGIN
[0m15:25:23.307293 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:25:23.535680 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:23.537236 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"
[0m15:25:23.538191 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        room_type as value_field,
        count(*) as n_records

    from "inttegra_stage"."test"."dim_listings_cleansed"
    group by room_type

)

select *
from all_values
where value_field not in (
    'Entire home/apt','Private room','Shared room','Hotel room'
)



      
    ) dbt_internal_test
[0m15:25:23.599024 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:23.602594 [debug] [Thread-1 (]: Timing info for test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af (execute): 15:25:23.268311 => 15:25:23.602082
[0m15:25:23.603109 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: ROLLBACK
[0m15:25:23.636042 [debug] [Thread-1 (]: On test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af: Close
[0m15:25:23.637043 [info ] [Thread-1 (]: 1 of 5 PASS accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room  [[32mPASS[0m in 0.41s]
[0m15:25:23.638556 [debug] [Thread-1 (]: Finished running node test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af
[0m15:25:23.639747 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:25:23.639747 [info ] [Thread-1 (]: 2 of 5 START test not_null_dim_listings_cleansed_host_id ....................... [RUN]
[0m15:25:23.641132 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.accepted_values_dim_listings_cleansed_room_type__Entire_home_apt__Private_room__Shared_room__Hotel_room.a95127e3af, now test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be)
[0m15:25:23.642132 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:25:23.648130 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:25:23.650642 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (compile): 15:25:23.642132 => 15:25:23.649133
[0m15:25:23.651722 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:25:23.653730 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:25:23.656255 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:25:23.657269 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: BEGIN
[0m15:25:23.657269 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:25:23.856242 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:23.857126 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"
[0m15:25:23.858300 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select host_id
from "inttegra_stage"."test"."dim_listings_cleansed"
where host_id is null



      
    ) dbt_internal_test
[0m15:25:23.908648 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:23.911649 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be (execute): 15:25:23.651722 => 15:25:23.911649
[0m15:25:23.913669 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: ROLLBACK
[0m15:25:23.946047 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be: Close
[0m15:25:23.949015 [info ] [Thread-1 (]: 2 of 5 PASS not_null_dim_listings_cleansed_host_id ............................. [[32mPASS[0m in 0.31s]
[0m15:25:23.951521 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be
[0m15:25:23.952527 [debug] [Thread-1 (]: Began running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:25:23.953528 [info ] [Thread-1 (]: 3 of 5 START test not_null_dim_listings_cleansed_id_listings ................... [RUN]
[0m15:25:23.954529 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_host_id.084e4105be, now test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485)
[0m15:25:23.955562 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:25:23.960704 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:25:23.965274 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (compile): 15:25:23.956669 => 15:25:23.965274
[0m15:25:23.967281 [debug] [Thread-1 (]: Began executing node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:25:23.973286 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:25:23.979563 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:25:23.980565 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: BEGIN
[0m15:25:23.982564 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:25:24.186733 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:24.187733 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"
[0m15:25:24.188734 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id_listings
from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is null



      
    ) dbt_internal_test
[0m15:25:24.242814 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:24.244805 [debug] [Thread-1 (]: Timing info for test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485 (execute): 15:25:23.968283 => 15:25:24.244805
[0m15:25:24.245804 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: ROLLBACK
[0m15:25:24.278572 [debug] [Thread-1 (]: On test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485: Close
[0m15:25:24.280573 [info ] [Thread-1 (]: 3 of 5 PASS not_null_dim_listings_cleansed_id_listings ......................... [[32mPASS[0m in 0.33s]
[0m15:25:24.281572 [debug] [Thread-1 (]: Finished running node test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485
[0m15:25:24.282574 [debug] [Thread-1 (]: Began running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:25:24.283574 [info ] [Thread-1 (]: 4 of 5 START test relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [RUN]
[0m15:25:24.285575 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.not_null_dim_listings_cleansed_id_listings.89daf95485, now test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad)
[0m15:25:24.286573 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:25:24.293090 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:25:24.295091 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (compile): 15:25:24.286573 => 15:25:24.295091
[0m15:25:24.296090 [debug] [Thread-1 (]: Began executing node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:25:24.305146 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:25:24.309146 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:25:24.310145 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: BEGIN
[0m15:25:24.311656 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:25:24.513907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:24.515032 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"
[0m15:25:24.516241 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select host_id as from_field
    from "inttegra_stage"."test"."dim_listings_cleansed"
    where host_id is not null
),

parent as (
    select host_id as to_field
    from "inttegra_stage"."test"."dim_hosts_cleansed"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m15:25:24.592396 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:24.596389 [debug] [Thread-1 (]: Timing info for test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad (execute): 15:25:24.297129 => 15:25:24.595391
[0m15:25:24.597390 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: ROLLBACK
[0m15:25:24.630703 [debug] [Thread-1 (]: On test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad: Close
[0m15:25:24.633704 [info ] [Thread-1 (]: 4 of 5 PASS relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_  [[32mPASS[0m in 0.35s]
[0m15:25:24.637778 [debug] [Thread-1 (]: Finished running node test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad
[0m15:25:24.638778 [debug] [Thread-1 (]: Began running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:25:24.639774 [info ] [Thread-1 (]: 5 of 5 START test unique_dim_listings_cleansed_id_listings ..................... [RUN]
[0m15:25:24.641775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbtlearn.relationships_dim_listings_cleansed_host_id__host_id__ref_dim_hosts_cleansed_.b53b94b2ad, now test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066)
[0m15:25:24.642774 [debug] [Thread-1 (]: Began compiling node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:25:24.657360 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:25:24.662543 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (compile): 15:25:24.643777 => 15:25:24.662543
[0m15:25:24.664544 [debug] [Thread-1 (]: Began executing node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:25:24.672049 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:25:24.674605 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:25:24.676607 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: BEGIN
[0m15:25:24.678606 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:25:24.874951 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:25:24.876459 [debug] [Thread-1 (]: Using postgres connection "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"
[0m15:25:24.877994 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id_listings as unique_field,
    count(*) as n_records

from "inttegra_stage"."test"."dim_listings_cleansed"
where id_listings is not null
group by id_listings
having count(*) > 1



      
    ) dbt_internal_test
[0m15:25:24.945953 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:25:24.948989 [debug] [Thread-1 (]: Timing info for test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066 (execute): 15:25:24.666546 => 15:25:24.948462
[0m15:25:24.952999 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: ROLLBACK
[0m15:25:24.985928 [debug] [Thread-1 (]: On test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066: Close
[0m15:25:24.989449 [info ] [Thread-1 (]: 5 of 5 PASS unique_dim_listings_cleansed_id_listings ........................... [[32mPASS[0m in 0.35s]
[0m15:25:24.991452 [debug] [Thread-1 (]: Finished running node test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066
[0m15:25:24.994451 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:24.995450 [debug] [MainThread]: On master: BEGIN
[0m15:25:24.996960 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:25:25.215002 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:25:25.216911 [debug] [MainThread]: On master: COMMIT
[0m15:25:25.217920 [debug] [MainThread]: Using postgres connection "master"
[0m15:25:25.218920 [debug] [MainThread]: On master: COMMIT
[0m15:25:25.254616 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:25:25.254616 [debug] [MainThread]: On master: Close
[0m15:25:25.258161 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:25:25.262025 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:25:25.262791 [debug] [MainThread]: Connection 'test.dbtlearn.unique_dim_listings_cleansed_id_listings.f512de0066' was properly closed.
[0m15:25:25.264127 [info ] [MainThread]: 
[0m15:25:25.266136 [info ] [MainThread]: Finished running 5 tests in 0 hours 0 minutes and 2.87 seconds (2.87s).
[0m15:25:25.269571 [debug] [MainThread]: Command end result
[0m15:25:25.288373 [info ] [MainThread]: 
[0m15:25:25.290390 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:25:25.294386 [info ] [MainThread]: 
[0m15:25:25.298323 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m15:25:25.301496 [debug] [MainThread]: Command `dbt test` succeeded at 15:25:25.300497 after 3.99 seconds
[0m15:25:25.301496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D2C1E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2D5AC1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE25B01010>]}
[0m15:25:25.302494 [debug] [MainThread]: Flushing usage events
