[0m23:30:18.177957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EE977EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EC5F3800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EC520DD0>]}


============================== 23:30:18.183958 | f598d1bd-3815-4c39-a336-34d5abe6bc9b ==============================
[0m23:30:18.183958 [info ] [MainThread]: Running with dbt=1.9.3
[0m23:30:18.185432 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt init dbtlearn', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:30:18.220035 [debug] [MainThread]: Starter project path: C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\venv\Lib\site-packages\dbt\include\starter_project
[0m23:30:18.268459 [info ] [MainThread]: 
Your new dbt project "dbtlearn" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m23:30:18.269463 [info ] [MainThread]: Setting up your profile.
[0m23:33:32.341961 [info ] [MainThread]: Profile dbtlearn written to C:\Users\marco\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m23:33:32.343959 [debug] [MainThread]: Command `dbt init` succeeded at 23:33:32.343959 after 194.36 seconds
[0m23:33:32.343959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EF0D9AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EE207D40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000283EF3F7950>]}
[0m23:33:32.344965 [debug] [MainThread]: Flushing usage events
[0m23:33:33.277981 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:08:08.304736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022371485C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223716A92D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002237122B7D0>]}


============================== 14:08:08.312383 | fa9a4809-69de-499f-925f-a1ac01b2b989 ==============================
[0m14:08:08.312383 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:08:08.313380 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:08:08.314386 [info ] [MainThread]: dbt version: 1.7.3
[0m14:08:08.315892 [info ] [MainThread]: python version: 3.11.7
[0m14:08:08.316901 [info ] [MainThread]: python path: C:\Users\marco\AppData\Local\Programs\Python\Python311\python.exe
[0m14:08:08.317899 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m14:08:08.491461 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.bigquery'
[0m14:08:08.496599 [info ] [MainThread]: Using profiles dir at C:\Users\marco\.dbt
[0m14:08:08.497630 [info ] [MainThread]: Using profiles.yml file at C:\Users\marco\.dbt\profiles.yml
[0m14:08:08.498679 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
[0m14:08:08.499734 [info ] [MainThread]: Configuration:
[0m14:08:08.501296 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:08:08.502380 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m14:08:08.503474 [info ] [MainThread]: Required dependencies:
[0m14:08:08.504483 [debug] [MainThread]: Executing "git --help"
[0m14:08:08.588638 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:08:08.589157 [debug] [MainThread]: STDERR: "b''"
[0m14:08:08.589157 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:08:08.590161 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:08:08.590161 [info ] [MainThread]: [31m2 checks failed:[0m
[0m14:08:08.592537 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "lessons", target "dev" invalid: Runtime Error
    Could not find adapter type bigquery!


[0m14:08:08.593544 [info ] [MainThread]: Project loading failed for the following reason:
 project path <C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml> not found

[0m14:08:08.595023 [debug] [MainThread]: Command `dbt debug` failed at 14:08:08.595023 after 0.38 seconds
[0m14:08:08.595023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002237195A190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002236A2B1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022370B86B10>]}
[0m14:08:08.596030 [debug] [MainThread]: Flushing usage events
[0m14:08:52.914637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F47421E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F47201290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F46C2AA50>]}


============================== 14:08:52.919215 | c31f6dd1-6bb5-481a-8b27-ba9c13df7d43 ==============================
[0m14:08:52.919215 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:08:52.920189 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:08:52.921226 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:08:52.924187 [debug] [MainThread]: Command `dbt run` failed at 14:08:52.923187 after 0.08 seconds
[0m14:08:52.924187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F3FCD1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F46C2A6D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F3FFCFD50>]}
[0m14:08:52.925186 [debug] [MainThread]: Flushing usage events
[0m14:10:47.381873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239464468D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023949D03F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239490E4C50>]}


============================== 14:10:47.386877 | 81babd98-3bcb-40dd-9e48-feac09ac0f91 ==============================
[0m14:10:47.386877 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:10:47.387873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:10:47.387873 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:10:47.390273 [debug] [MainThread]: Command `dbt run` failed at 14:10:47.390273 after 0.07 seconds
[0m14:10:47.390273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023942D31010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002394A4D7C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002394A066390>]}
[0m14:10:47.391306 [debug] [MainThread]: Flushing usage events
[0m14:11:35.815548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7D4A550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A823BE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7A50390>]}


============================== 14:11:35.819547 | 7de46b32-0753-4bd6-8afc-8b472f5a4ad4 ==============================
[0m14:11:35.819547 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:11:35.819547 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:11:36.124274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8406750>]}
[0m14:11:36.207136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8203F90>]}
[0m14:11:36.208669 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:11:36.225253 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:11:36.226253 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:11:36.227254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A84CA710>]}
[0m14:11:37.871611 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.src
[0m14:11:37.876642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A83FE710>]}
[0m14:11:37.902965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A8623550>]}
[0m14:11:37.903967 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:11:37.905962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7de46b32-0753-4bd6-8afc-8b472f5a4ad4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A85469D0>]}
[0m14:11:37.908006 [info ] [MainThread]: 
[0m14:11:37.908972 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:11:37.910962 [debug] [MainThread]: Command end result
[0m14:11:37.922033 [debug] [MainThread]: Command `dbt run` succeeded at 14:11:37.922033 after 2.17 seconds
[0m14:11:37.922033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A09BE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7A1DD90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9A7406B10>]}
[0m14:11:37.923030 [debug] [MainThread]: Flushing usage events
[0m14:16:32.994251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150C18D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025114EB1A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025114C41D90>]}


============================== 14:16:32.998254 | 2c51030f-1bba-456d-ac7f-990e2c5d7b69 ==============================
[0m14:16:32.998254 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:16:32.999252 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:16:33.206891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150E03D0>]}
[0m14:16:33.282673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251150E03D0>]}
[0m14:16:33.284878 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:16:33.292531 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:16:33.318143 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:16:33.319137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115279D90>]}
[0m14:16:34.011638 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn
[0m14:16:34.017401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115105010>]}
[0m14:16:34.031922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251152C59D0>]}
[0m14:16:34.031922 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:16:34.032922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c51030f-1bba-456d-ac7f-990e2c5d7b69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025115464A50>]}
[0m14:16:34.034922 [info ] [MainThread]: 
[0m14:16:34.035433 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:16:34.037442 [debug] [MainThread]: Command end result
[0m14:16:34.049448 [debug] [MainThread]: Command `dbt run` succeeded at 14:16:34.048447 after 1.13 seconds
[0m14:16:34.050448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002510D971010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000251148C3C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002510DBE4390>]}
[0m14:16:34.050448 [debug] [MainThread]: Flushing usage events
[0m14:18:42.716220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1205E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF0EF5150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF0ED2C50>]}


============================== 14:18:42.722229 | eef7ded4-a0c0-458f-aff9-b2fab91772cc ==============================
[0m14:18:42.722229 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:18:42.723219 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:18:42.944981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1702050>]}
[0m14:18:43.020957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF16AA4D0>]}
[0m14:18:43.022957 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:18:43.030487 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:18:43.051073 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m14:18:43.053076 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:18:43.054073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF11D63D0>]}
[0m14:18:43.758533 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.src
[0m14:18:43.763055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1A1EA90>]}
[0m14:18:43.778083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1A88650>]}
[0m14:18:43.779081 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:18:43.780082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eef7ded4-a0c0-458f-aff9-b2fab91772cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF17B5F50>]}
[0m14:18:43.781086 [info ] [MainThread]: 
[0m14:18:43.783107 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:18:43.784114 [debug] [MainThread]: Command end result
[0m14:18:43.792851 [debug] [MainThread]: Command `dbt run` succeeded at 14:18:43.791848 after 1.16 seconds
[0m14:18:43.792851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF11D7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EE9F51010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018EF1914610>]}
[0m14:18:43.793878 [debug] [MainThread]: Flushing usage events
[0m14:19:52.578602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27159950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26C87890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26C86190>]}


============================== 14:19:52.583599 | 65801f51-a4ee-474b-9fba-6a834fa64fc9 ==============================
[0m14:19:52.583599 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:19:52.584601 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:19:52.793040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F271B0090>]}
[0m14:19:52.870409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2726BE10>]}
[0m14:19:52.872053 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:19:52.879230 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:19:52.901295 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:19:52.902296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2731D390>]}
[0m14:19:53.602502 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.models.src
[0m14:19:53.608007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27142BD0>]}
[0m14:19:53.620025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F2749B010>]}
[0m14:19:53.621029 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:19:53.621536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65801f51-a4ee-474b-9fba-6a834fa64fc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27492750>]}
[0m14:19:53.622536 [info ] [MainThread]: 
[0m14:19:53.623540 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:19:53.624538 [debug] [MainThread]: Command end result
[0m14:19:53.636320 [debug] [MainThread]: Command `dbt run` succeeded at 14:19:53.636320 after 1.14 seconds
[0m14:19:53.637320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F1F92E410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F26995810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F27160D10>]}
[0m14:19:53.638320 [debug] [MainThread]: Flushing usage events
[0m14:20:31.630997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016557122A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556C15910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556CA66D0>]}


============================== 14:20:31.635087 | a2e6be0e-07c6-4220-ba75-a9978b8f61dd ==============================
[0m14:20:31.635087 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:20:31.636087 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:20:31.637091 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path C:\Users\marco\OneDrive\Documentos\triade\dbt_course_1\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:20:31.638124 [debug] [MainThread]: Command `dbt run` failed at 14:20:31.638124 after 0.07 seconds
[0m14:20:31.639086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001655691DB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001654F9C1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016556921310>]}
[0m14:20:31.639086 [debug] [MainThread]: Flushing usage events
[0m14:20:48.116047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F201310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F2016D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FA05C10>]}


============================== 14:20:48.120140 | 74fa53d7-1e75-447f-b957-20289922a437 ==============================
[0m14:20:48.120140 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:20:48.121107 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:20:48.335102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105ED2EAD0>]}
[0m14:20:48.412802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F2D0410>]}
[0m14:20:48.414721 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:20:48.422114 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:20:48.503415 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:20:48.504420 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:20:48.505421 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbtlearn.models.src
[0m14:20:48.509776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105F7EF010>]}
[0m14:20:48.521893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FC40D50>]}
[0m14:20:48.522894 [info ] [MainThread]: Found 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:20:48.523901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '74fa53d7-1e75-447f-b957-20289922a437', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105FB50310>]}
[0m14:20:48.524931 [info ] [MainThread]: 
[0m14:20:48.526443 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:20:48.528009 [debug] [MainThread]: Command end result
[0m14:20:48.580313 [debug] [MainThread]: Command `dbt run` succeeded at 14:20:48.579315 after 0.53 seconds
[0m14:20:48.580313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021058261010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105ECBEED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002105854FE10>]}
[0m14:20:48.581313 [debug] [MainThread]: Flushing usage events
[0m14:22:12.507346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B41C310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AC09310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AB76790>]}


============================== 14:22:12.512072 | 3f8faea2-9fc3-4b18-a904-7dea78056716 ==============================
[0m14:22:12.512072 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:22:12.512896 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:22:12.731511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AF41410>]}
[0m14:22:12.812509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B610C10>]}
[0m14:22:12.814478 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:22:12.821344 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:22:12.828752 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:22:12.829715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B5BEFD0>]}
[0m14:22:13.636968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B752A10>]}
[0m14:22:13.648581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B843650>]}
[0m14:22:13.649588 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:22:13.649588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B69C990>]}
[0m14:22:13.651091 [info ] [MainThread]: 
[0m14:22:13.653096 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:22:13.655098 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:22:13.665049 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:22:13.665049 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:22:13.666048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:22:14.998114 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:22:14.999207 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:22:15.001206 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:22:15.007240 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:22:15.007240 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:22:15.007240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:22:15.208959 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.209967 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:22:15.209967 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:22:15.261228 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:22:15.262394 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:22:15.299688 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:22:15.304688 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.305687 [debug] [MainThread]: On master: BEGIN
[0m14:22:15.305687 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:22:15.504276 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.505266 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.505266 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:22:15.568062 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:22:15.569041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B451990>]}
[0m14:22:15.570072 [debug] [MainThread]: On master: ROLLBACK
[0m14:22:15.603384 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.604347 [debug] [MainThread]: On master: BEGIN
[0m14:22:15.662353 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.662353 [debug] [MainThread]: On master: COMMIT
[0m14:22:15.663393 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:15.664381 [debug] [MainThread]: On master: COMMIT
[0m14:22:15.698906 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:22:15.699967 [debug] [MainThread]: On master: Close
[0m14:22:15.700916 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:22:15.701917 [info ] [MainThread]: 
[0m14:22:15.710978 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:22:15.710978 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:22:15.712977 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:22:15.713979 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:22:15.721345 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:22:15.726358 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:22:15.713979 => 14:22:15.725339
[0m14:22:15.726358 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:22:15.760870 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:22:15.764837 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:22:15.765838 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:22:15.765838 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:22:15.952069 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:22:15.953056 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:22:15.953056 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:22:15.991008 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw_listings" does not exist
LINE 10:   raw_listings rl 
           ^
DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.

[0m14:22:15.992023 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: ROLLBACK
[0m14:22:16.027093 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:22:15.727343 => 14:22:16.027093
[0m14:22:16.028110 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:22:16.139655 [debug] [Thread-1 (]: Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings rl 
             ^
  DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
  HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:22:16.140697 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f8faea2-9fc3-4b18-a904-7dea78056716', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2B8C68D0>]}
[0m14:22:16.141674 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.src_listings ......................... [[31mERROR[0m in 0.43s]
[0m14:22:16.142662 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:22:16.144661 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:16.144661 [debug] [MainThread]: On master: BEGIN
[0m14:22:16.145661 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:22:16.342764 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:22:16.343934 [debug] [MainThread]: On master: COMMIT
[0m14:22:16.343934 [debug] [MainThread]: Using postgres connection "master"
[0m14:22:16.345009 [debug] [MainThread]: On master: COMMIT
[0m14:22:16.379046 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:22:16.379551 [debug] [MainThread]: On master: Close
[0m14:22:16.380561 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:22:16.380561 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:22:16.381557 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:22:16.381557 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:22:16.382558 [info ] [MainThread]: 
[0m14:22:16.383557 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.73 seconds (2.73s).
[0m14:22:16.384556 [debug] [MainThread]: Command end result
[0m14:22:16.394588 [info ] [MainThread]: 
[0m14:22:16.395586 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:22:16.396586 [info ] [MainThread]: 
[0m14:22:16.397588 [error] [MainThread]:   Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings rl 
             ^
  DETAIL:  There is a WITH item named "raw_listings", but it cannot be referenced from this part of the query.
  HINT:  Use WITH RECURSIVE, or re-order the WITH items to remove forward references.
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:22:16.399109 [info ] [MainThread]: 
[0m14:22:16.400127 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:22:16.402672 [debug] [MainThread]: Command `dbt run` failed at 14:22:16.402672 after 3.97 seconds
[0m14:22:16.403746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AF413D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B23CAE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B2AC0A150>]}
[0m14:22:16.405033 [debug] [MainThread]: Flushing usage events
[0m14:23:24.897496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23867810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF235907D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF238F0BD0>]}


============================== 14:23:24.902219 | 79c8ca5e-8f95-4e94-8a8a-bb898296346d ==============================
[0m14:23:24.902219 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:23:24.903187 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:23:25.106658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23F4CD90>]}
[0m14:23:25.183060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23D5B150>]}
[0m14:23:25.184879 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:23:25.193740 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:23:25.213875 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:23:25.215021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF2393ECD0>]}
[0m14:23:26.028667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF240198D0>]}
[0m14:23:26.040178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF24222690>]}
[0m14:23:26.041213 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:23:26.041213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23DB0350>]}
[0m14:23:26.043751 [info ] [MainThread]: 
[0m14:23:26.044881 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:23:26.046881 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:23:26.056145 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:23:26.056145 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:23:26.057148 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:23:27.417248 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:23:27.418258 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:23:27.421243 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:23:27.425839 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:23:27.426847 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:23:27.426847 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:23:27.659333 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:23:27.660302 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:23:27.660302 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:23:27.711350 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:23:27.713378 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:23:27.748149 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:23:27.753772 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:27.754739 [debug] [MainThread]: On master: BEGIN
[0m14:23:27.754739 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:23:27.970376 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:27.971375 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:27.972377 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:23:28.038711 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:23:28.039976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23F48790>]}
[0m14:23:28.040974 [debug] [MainThread]: On master: ROLLBACK
[0m14:23:28.074116 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.074636 [debug] [MainThread]: On master: BEGIN
[0m14:23:28.143471 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.144530 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.145069 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.145590 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.184159 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:23:28.185273 [debug] [MainThread]: On master: Close
[0m14:23:28.186932 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:23:28.187983 [info ] [MainThread]: 
[0m14:23:28.191772 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:23:28.192332 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:23:28.193411 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:23:28.194438 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:23:28.201220 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:23:28.202218 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:23:28.194993 => 14:23:28.202218
[0m14:23:28.203221 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:23:28.235374 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:23:28.237377 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:23:28.237377 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:23:28.238342 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:23:28.468384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.469160 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:23:28.469160 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings_ AS (
	SELECT *
	FROM   
		raw_listings 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings_
  );
[0m14:23:28.512776 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw_listings" does not exist
LINE 10:   raw_listings 
           ^

[0m14:23:28.513826 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: ROLLBACK
[0m14:23:28.555945 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:23:28.204225 => 14:23:28.555945
[0m14:23:28.557889 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:23:28.562921 [debug] [Thread-1 (]: Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings 
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:23:28.562921 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79c8ca5e-8f95-4e94-8a8a-bb898296346d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF2415E5D0>]}
[0m14:23:28.563911 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model test.src_listings ......................... [[31mERROR[0m in 0.37s]
[0m14:23:28.564902 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:23:28.566949 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.567329 [debug] [MainThread]: On master: BEGIN
[0m14:23:28.567969 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:23:28.811311 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:23:28.812313 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.812313 [debug] [MainThread]: Using postgres connection "master"
[0m14:23:28.813330 [debug] [MainThread]: On master: COMMIT
[0m14:23:28.854228 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:23:28.854839 [debug] [MainThread]: On master: Close
[0m14:23:28.855969 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:23:28.857013 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:23:28.857013 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:23:28.858008 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:23:28.858008 [info ] [MainThread]: 
[0m14:23:28.859043 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.81 seconds (2.81s).
[0m14:23:28.860050 [debug] [MainThread]: Command end result
[0m14:23:28.870426 [info ] [MainThread]: 
[0m14:23:28.871409 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:23:28.872407 [info ] [MainThread]: 
[0m14:23:28.873407 [error] [MainThread]:   Database Error in model src_listings (dbtlearn/models\src\src_listings.sql)
  relation "raw_listings" does not exist
  LINE 10:   raw_listings 
             ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\src\src_listings.sql
[0m14:23:28.873697 [info ] [MainThread]: 
[0m14:23:28.874703 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:23:28.875704 [debug] [MainThread]: Command `dbt run` failed at 14:23:28.875704 after 4.05 seconds
[0m14:23:28.876704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23D53ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF1C5A1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002CF23546AD0>]}
[0m14:23:28.876704 [debug] [MainThread]: Flushing usage events
[0m14:24:44.702084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAE72E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA770E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAEB99D0>]}


============================== 14:24:44.705622 | 20e8be37-3de7-4264-a23a-bb7e3e8bf8dc ==============================
[0m14:24:44.705622 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:24:44.706624 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:24:44.917075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAFDEB90>]}
[0m14:24:45.003858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA947950>]}
[0m14:24:45.005433 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:24:45.014230 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:24:45.119312 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:24:45.119312 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_listings.sql
[0m14:24:45.282289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB0B2DD0>]}
[0m14:24:45.294479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB386810>]}
[0m14:24:45.295479 [info ] [MainThread]: Found 1 model, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:24:45.296485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB205310>]}
[0m14:24:45.298512 [info ] [MainThread]: 
[0m14:24:45.298897 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:24:45.300752 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:24:45.310434 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:24:45.310434 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:24:45.311397 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:46.659018 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:24:46.660776 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:24:46.662783 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:24:46.668815 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:24:46.668815 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:24:46.669782 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:46.901069 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:24:46.902116 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:24:46.903080 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:24:46.955380 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m14:24:46.956381 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:24:46.991989 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:24:46.997054 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:46.997054 [debug] [MainThread]: On master: BEGIN
[0m14:24:46.998128 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:24:47.194326 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.195362 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.195876 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:24:47.257223 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:24:47.258782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBB0E8850>]}
[0m14:24:47.259297 [debug] [MainThread]: On master: ROLLBACK
[0m14:24:47.289400 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.290419 [debug] [MainThread]: On master: BEGIN
[0m14:24:47.350581 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.351628 [debug] [MainThread]: On master: COMMIT
[0m14:24:47.351628 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.352620 [debug] [MainThread]: On master: COMMIT
[0m14:24:47.387762 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:24:47.388752 [debug] [MainThread]: On master: Close
[0m14:24:47.389753 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:47.390753 [info ] [MainThread]: 
[0m14:24:47.393753 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:24:47.393753 [info ] [Thread-1 (]: 1 of 1 START sql view model test.src_listings .................................. [RUN]
[0m14:24:47.394759 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:24:47.396017 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:24:47.403983 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:24:47.406043 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:24:47.396017 => 14:24:47.406043
[0m14:24:47.407047 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:24:47.440641 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:24:47.442713 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.442713 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:24:47.443940 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:24:47.645384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:24:47.646228 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.647273 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:24:47.713429 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:24:47.719504 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.720505 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:24:47.752322 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:24:47.766405 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:24:47.767410 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.768004 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:24:47.797656 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:24:47.804687 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:24:47.809687 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:24:47.810688 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:24:47.840036 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:24:47.842037 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:24:47.408048 => 14:24:47.842037
[0m14:24:47.842037 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:24:47.844038 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20e8be37-3de7-4264-a23a-bb7e3e8bf8dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBA9B05D0>]}
[0m14:24:47.844038 [info ] [Thread-1 (]: 1 of 1 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:24:47.846038 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:24:47.847034 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:47.848071 [debug] [MainThread]: On master: BEGIN
[0m14:24:47.849067 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:24:48.040439 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:24:48.041436 [debug] [MainThread]: On master: COMMIT
[0m14:24:48.042436 [debug] [MainThread]: Using postgres connection "master"
[0m14:24:48.042942 [debug] [MainThread]: On master: COMMIT
[0m14:24:48.078516 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:24:48.078516 [debug] [MainThread]: On master: Close
[0m14:24:48.079777 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:48.080770 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:24:48.080770 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:24:48.081749 [debug] [MainThread]: Connection 'model.dbtlearn.src_listings' was properly closed.
[0m14:24:48.081749 [info ] [MainThread]: 
[0m14:24:48.082737 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.78 seconds (2.78s).
[0m14:24:48.084762 [debug] [MainThread]: Command end result
[0m14:24:48.093343 [info ] [MainThread]: 
[0m14:24:48.093883 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:24:48.094912 [info ] [MainThread]: 
[0m14:24:48.096920 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:24:48.098918 [debug] [MainThread]: Command `dbt run` succeeded at 14:24:48.098918 after 3.46 seconds
[0m14:24:48.099918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDBAA23010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDB37A1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDB37A0F50>]}
[0m14:24:48.099918 [debug] [MainThread]: Flushing usage events
[0m14:30:46.179498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B5E8C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3ADF75D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3AEA0B10>]}


============================== 14:30:46.183496 | f52816ad-50ab-40d6-ada6-6774a7c16420 ==============================
[0m14:30:46.183496 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:30:46.184500 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:30:46.395034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B609A10>]}
[0m14:30:46.473761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B0C5B10>]}
[0m14:30:46.475884 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:30:46.483889 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:30:46.585065 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:30:46.585065 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\src\src_reviews.sql
[0m14:30:46.747171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B846C10>]}
[0m14:30:46.759880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3BACCD10>]}
[0m14:30:46.759880 [info ] [MainThread]: Found 2 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:30:46.761385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B891210>]}
[0m14:30:46.763394 [info ] [MainThread]: 
[0m14:30:46.764391 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:30:46.766983 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:30:46.776516 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:30:46.777532 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:30:46.777532 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:48.165570 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:30:48.167615 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:30:48.169223 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:30:48.174768 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:48.175767 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:30:48.176778 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:48.418018 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.419523 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:30:48.420037 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:30:48.471512 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.0 seconds
[0m14:30:48.473564 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:30:48.503929 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:30:48.509161 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.510162 [debug] [MainThread]: On master: BEGIN
[0m14:30:48.510162 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:30:48.741145 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.742141 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.743138 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:30:48.808499 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:48.810499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3B86E2D0>]}
[0m14:30:48.810499 [debug] [MainThread]: On master: ROLLBACK
[0m14:30:48.847004 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.847004 [debug] [MainThread]: On master: BEGIN
[0m14:30:48.914062 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:48.915074 [debug] [MainThread]: On master: COMMIT
[0m14:30:48.915074 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:48.916074 [debug] [MainThread]: On master: COMMIT
[0m14:30:48.954591 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:30:48.955590 [debug] [MainThread]: On master: Close
[0m14:30:48.956586 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:30:48.957587 [info ] [MainThread]: 
[0m14:30:48.960621 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:30:48.962065 [info ] [Thread-1 (]: 1 of 2 START sql view model test.src_listings .................................. [RUN]
[0m14:30:48.963034 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_listings'
[0m14:30:48.964034 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:30:48.971541 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:30:48.973705 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:30:48.964034 => 14:30:48.973705
[0m14:30:48.974756 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:30:49.009269 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:30:49.010678 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.010678 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:30:49.011679 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:30:49.237193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:30:49.238364 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.238364 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:30:49.291454 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:30:49.297032 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.298119 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:30:49.331468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.335598 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.335598 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:30:49.370526 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.387694 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:30:49.387694 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.388658 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:30:49.422644 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:30:49.429197 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:30:49.435322 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:30:49.435322 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:30:49.474248 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:30:49.475838 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:30:48.975755 => 14:30:49.475838
[0m14:30:49.477358 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:30:49.478413 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3CB48450>]}
[0m14:30:49.478413 [info ] [Thread-1 (]: 1 of 2 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.51s]
[0m14:30:49.479452 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:30:49.480418 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:30:49.481418 [info ] [Thread-1 (]: 2 of 2 START sql view model test.src_reviews ................................... [RUN]
[0m14:30:49.482418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:30:49.483452 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:30:49.485419 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:30:49.487419 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:30:49.483452 => 14:30:49.487419
[0m14:30:49.488419 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:30:49.492577 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:30:49.494582 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.495152 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:30:49.495152 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:30:49.720359 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:30:49.721120 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.722119 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:30:49.772134 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:30:49.775669 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.776672 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:30:49.811330 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:30:49.813834 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:30:49.814348 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.815353 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:30:49.847495 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:30:49.850030 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:30:49.852561 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:30:49.852561 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:30:49.888147 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:30:49.890146 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:30:49.488419 => 14:30:49.889146
[0m14:30:49.890146 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:30:49.891146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f52816ad-50ab-40d6-ada6-6774a7c16420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3CAFFC10>]}
[0m14:30:49.892146 [info ] [Thread-1 (]: 2 of 2 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:30:49.893147 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:30:49.895150 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:49.896148 [debug] [MainThread]: On master: BEGIN
[0m14:30:49.896148 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:30:50.115779 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:50.116784 [debug] [MainThread]: On master: COMMIT
[0m14:30:50.116784 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:50.117783 [debug] [MainThread]: On master: COMMIT
[0m14:30:50.158363 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:30:50.159365 [debug] [MainThread]: On master: Close
[0m14:30:50.160367 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:30:50.160367 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:30:50.161367 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:30:50.161367 [debug] [MainThread]: Connection 'model.dbtlearn.src_reviews' was properly closed.
[0m14:30:50.162365 [info ] [MainThread]: 
[0m14:30:50.163445 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 3.40 seconds (3.40s).
[0m14:30:50.164656 [debug] [MainThread]: Command end result
[0m14:30:50.172658 [info ] [MainThread]: 
[0m14:30:50.174166 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:30:50.174166 [info ] [MainThread]: 
[0m14:30:50.175898 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m14:30:50.176905 [debug] [MainThread]: Command `dbt run` succeeded at 14:30:50.176905 after 4.06 seconds
[0m14:30:50.177904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB33E11010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3A7CA790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB3410FD50>]}
[0m14:30:50.178906 [debug] [MainThread]: Flushing usage events
[0m14:35:40.970476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52FA1D0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D53351B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533541210>]}


============================== 14:35:40.974475 | 9b4809fe-fb41-4c61-b1aa-76904a89487e ==============================
[0m14:35:40.974475 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:35:40.975479 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:35:41.271089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D532D70A50>]}
[0m14:35:41.355146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D532D42B90>]}
[0m14:35:41.357116 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:35:41.365747 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:35:41.478662 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:35:41.479667 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m14:35:41.659839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533817D90>]}
[0m14:35:41.673038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5339033D0>]}
[0m14:35:41.673038 [info ] [MainThread]: Found 3 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:35:41.674043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5337B4CD0>]}
[0m14:35:41.675078 [info ] [MainThread]: 
[0m14:35:41.677593 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:35:41.679992 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:35:41.693031 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:35:41.695023 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:35:41.695023 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:35:43.017657 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:35:43.020658 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:35:43.023688 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:35:43.032687 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:35:43.034195 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:35:43.036108 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:35:43.241126 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.243118 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:35:43.244117 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:35:43.286680 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m14:35:43.287923 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:35:43.321898 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:35:43.327315 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.327315 [debug] [MainThread]: On master: BEGIN
[0m14:35:43.328318 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:35:43.536410 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.537297 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.538296 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:35:43.599176 [debug] [MainThread]: SQL status: SELECT 2 in 0.0 seconds
[0m14:35:43.601480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5339DEA50>]}
[0m14:35:43.602480 [debug] [MainThread]: On master: ROLLBACK
[0m14:35:43.631071 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.632037 [debug] [MainThread]: On master: BEGIN
[0m14:35:43.689808 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.690810 [debug] [MainThread]: On master: COMMIT
[0m14:35:43.690810 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:43.691805 [debug] [MainThread]: On master: COMMIT
[0m14:35:43.726491 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:35:43.726491 [debug] [MainThread]: On master: Close
[0m14:35:43.727497 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:35:43.728498 [info ] [MainThread]: 
[0m14:35:43.732841 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:35:43.733838 [info ] [Thread-1 (]: 1 of 3 START sql view model test.src_hosts ..................................... [RUN]
[0m14:35:43.734835 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:35:43.735840 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:35:43.744022 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:35:43.749713 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:35:43.736837 => 14:35:43.749713
[0m14:35:43.750745 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:35:43.796399 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:35:43.799369 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:43.800399 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:35:43.800399 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:35:43.992193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:43.993197 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:43.993197 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:35:44.040502 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.047050 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.048057 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:35:44.079529 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.092615 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:35:44.093620 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.093620 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:35:44.126404 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:44.133167 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:35:44.139163 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:35:44.139163 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:35:44.169136 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:44.171173 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:35:43.751715 => 14:35:44.171173
[0m14:35:44.171173 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:35:44.172169 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D534A77190>]}
[0m14:35:44.173170 [info ] [Thread-1 (]: 1 of 3 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.44s]
[0m14:35:44.174146 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:35:44.175170 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:35:44.176136 [info ] [Thread-1 (]: 2 of 3 START sql view model test.src_listings .................................. [RUN]
[0m14:35:44.177650 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:35:44.177650 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:35:44.180658 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:35:44.182649 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:35:44.178648 => 14:35:44.181649
[0m14:35:44.183648 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:35:44.189730 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:35:44.191735 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.192725 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:35:44.193725 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:35:44.418402 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:44.419446 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.419446 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:35:44.469960 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.473926 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.474927 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:35:44.511903 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.515627 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.517624 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:35:44.552272 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.556299 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:35:44.557267 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.557267 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:35:44.591761 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:44.594762 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:35:44.595728 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:35:44.596728 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:35:44.634902 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:44.636916 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:35:44.183648 => 14:35:44.636916
[0m14:35:44.637914 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:35:44.638946 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D534A982D0>]}
[0m14:35:44.639912 [info ] [Thread-1 (]: 2 of 3 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m14:35:44.640912 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:35:44.640912 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:35:44.641912 [info ] [Thread-1 (]: 3 of 3 START sql view model test.src_reviews ................................... [RUN]
[0m14:35:44.642915 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:35:44.643911 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:35:44.645417 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:35:44.647420 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:35:44.643911 => 14:35:44.646418
[0m14:35:44.648427 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:35:44.652419 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:35:44.654421 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.655421 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:35:44.656931 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:35:44.885384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:35:44.886361 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.886361 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:35:44.936182 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:35:44.940182 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.941183 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:35:44.975771 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:44.979767 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:44.979767 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:35:45.014788 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:35:45.018563 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:35:45.019077 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:45.019592 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:35:45.053276 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:35:45.056452 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:35:45.058052 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:35:45.058586 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:35:45.094662 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:35:45.096215 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:35:44.648427 => 14:35:45.096215
[0m14:35:45.096731 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:35:45.097796 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b4809fe-fb41-4c61-b1aa-76904a89487e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5336ADB50>]}
[0m14:35:45.098402 [info ] [Thread-1 (]: 3 of 3 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:35:45.100411 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:35:45.102920 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:45.103919 [debug] [MainThread]: On master: BEGIN
[0m14:35:45.104247 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:35:45.330162 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:35:45.331153 [debug] [MainThread]: On master: COMMIT
[0m14:35:45.331153 [debug] [MainThread]: Using postgres connection "master"
[0m14:35:45.332248 [debug] [MainThread]: On master: COMMIT
[0m14:35:45.368397 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:35:45.369177 [debug] [MainThread]: On master: Close
[0m14:35:45.370169 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:35:45.371170 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:35:45.371170 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:35:45.372164 [debug] [MainThread]: Connection 'model.dbtlearn.src_reviews' was properly closed.
[0m14:35:45.372164 [info ] [MainThread]: 
[0m14:35:45.373163 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 3.70 seconds (3.70s).
[0m14:35:45.375197 [debug] [MainThread]: Command end result
[0m14:35:45.388363 [info ] [MainThread]: 
[0m14:35:45.388363 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:35:45.390902 [info ] [MainThread]: 
[0m14:35:45.392012 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m14:35:45.394008 [debug] [MainThread]: Command `dbt run` succeeded at 14:35:45.394008 after 4.49 seconds
[0m14:35:45.395007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D533342150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52C0D4390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D52C15EF90>]}
[0m14:35:45.396009 [debug] [MainThread]: Flushing usage events
[0m14:57:14.650571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE0EB050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCCD34F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCC6BC810>]}


============================== 14:57:14.654080 | ee50d8b0-c9e3-4a50-a08c-489bcf38536d ==============================
[0m14:57:14.654080 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:57:14.656288 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:57:14.870865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCDB60CD0>]}
[0m14:57:14.947529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC6A25B90>]}
[0m14:57:14.949171 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:57:14.957031 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:57:14.980251 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:57:14.981057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE13FCD0>]}
[0m14:57:15.805139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE4B8F10>]}
[0m14:57:15.817681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF64DD50>]}
[0m14:57:15.817681 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:57:15.819197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE5F7950>]}
[0m14:57:15.821879 [info ] [MainThread]: 
[0m14:57:15.822847 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:57:15.824240 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:57:15.834774 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:57:15.835795 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:57:15.835795 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:17.185752 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:57:17.186746 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:57:17.189255 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:57:17.194765 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:17.194765 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:57:17.195767 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:17.385859 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.386902 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:57:17.386902 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:57:17.434139 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:57:17.435933 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:57:17.465437 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:57:17.471040 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.472040 [debug] [MainThread]: On master: BEGIN
[0m14:57:17.472040 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:57:17.663341 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.663341 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.664376 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:57:17.727931 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:57:17.729813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE3A0550>]}
[0m14:57:17.731130 [debug] [MainThread]: On master: ROLLBACK
[0m14:57:17.759512 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.760386 [debug] [MainThread]: On master: BEGIN
[0m14:57:17.820097 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:17.821099 [debug] [MainThread]: On master: COMMIT
[0m14:57:17.822104 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:17.822104 [debug] [MainThread]: On master: COMMIT
[0m14:57:17.849954 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:17.851074 [debug] [MainThread]: On master: Close
[0m14:57:17.853325 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:57:17.855337 [info ] [MainThread]: 
[0m14:57:17.861343 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:57:17.862328 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:57:17.864543 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:57:17.865560 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:57:17.872540 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:57:17.875615 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:57:17.865560 => 14:57:17.875615
[0m14:57:17.876626 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:57:17.919083 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:57:17.922053 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:17.923217 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:57:17.923580 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:57:18.112282 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:18.113055 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.113055 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:57:18.161309 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:18.168327 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.169328 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:57:18.199224 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.202265 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.203265 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:57:18.234931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.249967 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:57:18.250967 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.250967 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:57:18.280439 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:18.286475 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:57:18.291476 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:57:18.291476 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:57:18.327027 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:18.329035 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:57:17.877618 => 14:57:18.328041
[0m14:57:18.329035 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:57:18.330034 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE63B390>]}
[0m14:57:18.331548 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.47s]
[0m14:57:18.332553 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:57:18.333554 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:57:18.333554 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:57:18.335587 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:57:18.335587 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:57:18.337589 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:57:18.339554 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:57:18.336573 => 14:57:18.338588
[0m14:57:18.340554 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:57:18.346592 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:57:18.349600 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.350603 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:57:18.350603 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:18.565238 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:18.566243 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.567239 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:57:18.616003 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:18.619997 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.621007 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:57:18.656783 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.660171 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.660733 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:57:18.694742 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:18.697745 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:57:18.698743 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.698743 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:57:18.732438 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:18.735478 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:57:18.736478 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:57:18.737445 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:57:18.776513 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:18.777521 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:57:18.340554 => 14:57:18.777521
[0m14:57:18.778519 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:57:18.779519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE609C50>]}
[0m14:57:18.780519 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.44s]
[0m14:57:18.781519 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:57:18.782521 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:57:18.783519 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:57:18.784520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:57:18.785519 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:57:18.787518 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:57:18.789031 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:57:18.785519 => 14:57:18.789031
[0m14:57:18.790032 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:57:18.795031 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:57:18.797031 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:18.798033 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:57:18.799543 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:19.010800 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.011808 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.011808 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:57:19.062730 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:57:19.066462 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.066462 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:57:19.103388 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:19.108205 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.108205 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:57:19.143069 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:57:19.145074 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:57:19.146075 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.146075 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:57:19.181582 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:57:19.184615 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:57:19.185687 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:57:19.185687 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:57:19.220306 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:57:19.222589 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:57:18.790032 => 14:57:19.222589
[0m14:57:19.223618 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:57:19.224618 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF713490>]}
[0m14:57:19.224618 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.44s]
[0m14:57:19.226584 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:57:19.226584 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.227583 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:57:19.229621 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:57:19.229621 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.232708 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.235219 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:57:19.230617 => 14:57:19.235219
[0m14:57:19.236222 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.261895 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.263897 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.264902 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:57:19.265896 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:57:19.511072 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.512073 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:57:19.513078 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    listing_id,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:57:19.558268 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "listing_id" does not exist
LINE 20:     listing_id,
             ^
HINT:  Perhaps you meant to reference the column "src_listings.listing_url".

[0m14:57:19.558268 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:57:19.597294 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:57:19.236222 => 14:57:19.597294
[0m14:57:19.598298 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:57:19.603322 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "listing_id" does not exist
  LINE 20:     listing_id,
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.listing_url".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:57:19.603322 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee50d8b0-c9e3-4a50-a08c-489bcf38536d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCE5D5110>]}
[0m14:57:19.604828 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.37s]
[0m14:57:19.606536 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:57:19.607552 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:19.608546 [debug] [MainThread]: On master: BEGIN
[0m14:57:19.608546 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:57:19.831417 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:57:19.833440 [debug] [MainThread]: On master: COMMIT
[0m14:57:19.833903 [debug] [MainThread]: Using postgres connection "master"
[0m14:57:19.834446 [debug] [MainThread]: On master: COMMIT
[0m14:57:19.865604 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:57:19.865604 [debug] [MainThread]: On master: Close
[0m14:57:19.866608 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:57:19.867608 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:57:19.867608 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:57:19.869115 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:57:19.869642 [info ] [MainThread]: 
[0m14:57:19.870644 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 4.05 seconds (4.05s).
[0m14:57:19.871644 [debug] [MainThread]: Command end result
[0m14:57:19.882185 [info ] [MainThread]: 
[0m14:57:19.883586 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:57:19.884586 [info ] [MainThread]: 
[0m14:57:19.885583 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "listing_id" does not exist
  LINE 20:     listing_id,
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.listing_url".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:57:19.887584 [info ] [MainThread]: 
[0m14:57:19.888585 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:57:19.890585 [debug] [MainThread]: Command `dbt run` failed at 14:57:19.890585 after 5.32 seconds
[0m14:57:19.891584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC69E1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BCF657D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BC6CDFD50>]}
[0m14:57:19.893657 [debug] [MainThread]: Flushing usage events
[0m14:58:08.634756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E3544D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E344210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E578DD0>]}


============================== 14:58:08.638373 | 2c8c0016-689d-44d0-8a17-1057e02aeb07 ==============================
[0m14:58:08.638373 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:58:08.639375 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:58:08.852442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E882050>]}
[0m14:58:08.937064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E344350>]}
[0m14:58:08.939158 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:58:08.948121 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:58:09.044040 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:58:09.045010 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:09.206484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E9276D0>]}
[0m14:58:09.220209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EC19950>]}
[0m14:58:09.220209 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:58:09.221649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EA83B10>]}
[0m14:58:09.223682 [info ] [MainThread]: 
[0m14:58:09.224652 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:58:09.227315 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:58:09.239338 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:58:09.240338 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:58:09.241370 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:10.567269 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:58:10.569273 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:58:10.571271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:58:10.577267 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:10.578266 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:58:10.578772 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:10.779414 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:58:10.780450 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:10.780450 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:58:10.829247 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:58:10.831289 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:58:10.860231 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:58:10.865133 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:10.866671 [debug] [MainThread]: On master: BEGIN
[0m14:58:10.866671 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:58:11.057291 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.058324 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.058836 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:58:11.122496 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:58:11.124579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2ED40C50>]}
[0m14:58:11.125622 [debug] [MainThread]: On master: ROLLBACK
[0m14:58:11.154022 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.154572 [debug] [MainThread]: On master: BEGIN
[0m14:58:11.210444 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.211251 [debug] [MainThread]: On master: COMMIT
[0m14:58:11.211251 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:11.212243 [debug] [MainThread]: On master: COMMIT
[0m14:58:11.237880 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:11.237880 [debug] [MainThread]: On master: Close
[0m14:58:11.239390 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:58:11.240374 [info ] [MainThread]: 
[0m14:58:11.243396 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:58:11.244397 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:58:11.245397 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:58:11.246399 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:58:11.253061 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:58:11.256062 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:58:11.246399 => 14:58:11.255061
[0m14:58:11.257060 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:58:11.291964 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:58:11.293966 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.294965 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:58:11.295967 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:58:11.495613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.496490 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.497488 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:58:11.542539 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:11.548802 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.549807 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:58:11.580122 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:11.584126 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.585123 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:58:11.619216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:11.642311 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:11.643313 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.644311 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:11.678478 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:11.686518 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:58:11.691522 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:11.692523 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:58:11.724827 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:11.726833 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:58:11.257060 => 14:58:11.725833
[0m14:58:11.727850 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:58:11.728834 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2EAC7910>]}
[0m14:58:11.729833 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.48s]
[0m14:58:11.730836 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:58:11.732338 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:58:11.732785 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:58:11.733343 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:58:11.734382 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:58:11.736377 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:58:11.738348 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:58:11.735378 => 14:58:11.737350
[0m14:58:11.738348 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:58:11.742348 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:58:11.744371 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:11.745381 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:58:11.746377 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:11.960449 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:11.961570 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:11.961570 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:58:12.006706 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:12.010492 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.011491 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:58:12.042743 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.045688 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.046691 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:58:12.079485 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.082759 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:12.082759 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.083759 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:12.113994 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:12.116572 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:58:12.118660 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:12.119629 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:58:12.151095 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:12.153192 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:58:11.739349 => 14:58:12.153192
[0m14:58:12.154198 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:58:12.155197 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2ED168D0>]}
[0m14:58:12.155197 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.42s]
[0m14:58:12.157199 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:58:12.157199 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:58:12.158225 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:58:12.159203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:58:12.160231 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:58:12.162196 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:58:12.163197 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:58:12.160231 => 14:58:12.163197
[0m14:58:12.163197 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:58:12.169291 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:58:12.171296 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.172292 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:58:12.173292 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:12.375260 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:12.376272 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.376272 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:58:12.420661 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:12.423694 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.424665 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:58:12.455491 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.459386 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.459386 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:58:12.489985 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:12.493572 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:12.493572 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.494572 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:12.525000 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:12.529232 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:58:12.530232 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:12.531210 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:58:12.563057 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:12.565062 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:58:12.164701 => 14:58:12.565062
[0m14:58:12.565062 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:58:12.566061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2FE66450>]}
[0m14:58:12.567063 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:58:12.568066 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:58:12.569101 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.569101 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:58:12.570084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:58:12.571097 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.573637 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.574639 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:58:12.571097 => 14:58:12.574639
[0m14:58:12.575640 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.598781 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.600782 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.601784 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:58:12.601784 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:12.824343 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:12.825661 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:12.825661 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:58:12.870070 [debug] [Thread-1 (]: Postgres adapter: Postgres error: type "number" does not exist
LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                       ^

[0m14:58:12.871028 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:58:12.902215 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:58:12.575640 => 14:58:12.902215
[0m14:58:12.903045 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:58:12.908042 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  type "number" does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                         ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:12.908042 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c8c0016-689d-44d0-8a17-1057e02aeb07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2FE3F650>]}
[0m14:58:12.910063 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.34s]
[0m14:58:12.911069 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:58:12.913103 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:12.913103 [debug] [MainThread]: On master: BEGIN
[0m14:58:12.914069 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:58:13.133413 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:13.134401 [debug] [MainThread]: On master: COMMIT
[0m14:58:13.135393 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:13.135393 [debug] [MainThread]: On master: COMMIT
[0m14:58:13.164936 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:13.165937 [debug] [MainThread]: On master: Close
[0m14:58:13.166938 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:58:13.167937 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:58:13.167937 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:58:13.168939 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:58:13.168939 [info ] [MainThread]: 
[0m14:58:13.169939 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 3.95 seconds (3.95s).
[0m14:58:13.170937 [debug] [MainThread]: Command end result
[0m14:58:13.183403 [info ] [MainThread]: 
[0m14:58:13.184403 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:58:13.186434 [info ] [MainThread]: 
[0m14:58:13.187441 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  type "number" does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMBER (10, 2) AS price,
                                         ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:13.189442 [info ] [MainThread]: 
[0m14:58:13.191443 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:58:13.193442 [debug] [MainThread]: Command `dbt run` failed at 14:58:13.193442 after 4.62 seconds
[0m14:58:13.194444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D27101010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2E053950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D2B484710>]}
[0m14:58:13.195442 [debug] [MainThread]: Flushing usage events
[0m14:58:54.653131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94063FF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E93F455310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E59990>]}


============================== 14:58:54.658281 | c52e07fe-be0c-4485-be5c-a736a9ce7841 ==============================
[0m14:58:54.658281 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:58:54.659281 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:58:54.956733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E28250>]}
[0m14:58:55.057299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94101DA10>]}
[0m14:58:55.058854 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:58:55.070514 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:58:55.178690 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:58:55.179690 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:55.375045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940951510>]}
[0m14:58:55.390748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94132E810>]}
[0m14:58:55.391738 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:58:55.392735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941105790>]}
[0m14:58:55.394821 [info ] [MainThread]: 
[0m14:58:55.395827 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:58:55.398828 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:58:55.408168 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:58:55.409168 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:58:55.410170 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:56.786136 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:58:56.787974 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:58:56.789521 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:58:56.795554 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:56.795554 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:58:56.796518 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:58:57.026805 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.026805 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:58:57.028135 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:58:57.082321 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:58:57.084365 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:58:57.117185 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:58:57.122984 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.122984 [debug] [MainThread]: On master: BEGIN
[0m14:58:57.124488 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:58:57.339370 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.339370 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.340917 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:58:57.405158 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:58:57.407152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9412F6F50>]}
[0m14:58:57.408152 [debug] [MainThread]: On master: ROLLBACK
[0m14:58:57.445050 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.445050 [debug] [MainThread]: On master: BEGIN
[0m14:58:57.505997 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.507015 [debug] [MainThread]: On master: COMMIT
[0m14:58:57.508010 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:57.508010 [debug] [MainThread]: On master: COMMIT
[0m14:58:57.535215 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:57.536225 [debug] [MainThread]: On master: Close
[0m14:58:57.537221 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:58:57.538220 [info ] [MainThread]: 
[0m14:58:57.542223 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:58:57.543223 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:58:57.545224 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:58:57.545224 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:58:57.552847 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:58:57.555853 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:58:57.546275 => 14:58:57.554858
[0m14:58:57.556851 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:58:57.592380 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:58:57.595079 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.596120 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:58:57.596120 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:58:57.792739 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:57.792739 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.793776 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:58:57.838741 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:57.845542 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.845542 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:58:57.877611 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:57.882123 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.882123 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:58:57.916076 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:57.931852 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:57.932851 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.932851 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:58:57.963329 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:57.969879 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:58:57.973874 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:58:57.974874 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:58:58.006736 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.008743 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:58:57.556851 => 14:58:58.008743
[0m14:58:58.008743 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:58:58.010743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9411FB450>]}
[0m14:58:58.010743 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.47s]
[0m14:58:58.012744 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:58:58.012744 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:58:58.013742 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:58:58.014913 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:58:58.015917 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:58:58.017921 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:58:58.019938 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:58:58.015917 => 14:58:58.019938
[0m14:58:58.020919 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:58:58.027451 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:58:58.029451 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.030471 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:58:58.031464 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:58.205063 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:58.205828 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.207067 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:58:58.252504 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:58.256511 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.256511 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:58:58.287752 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.291466 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.291466 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:58:58.320488 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.322461 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:58.323460 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.324460 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:58:58.354301 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:58.357828 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:58:58.358828 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:58:58.358828 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:58:58.390988 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.392751 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:58:58.020919 => 14:58:58.392751
[0m14:58:58.393752 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:58:58.394785 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941392A10>]}
[0m14:58:58.394785 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m14:58:58.396751 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:58:58.396751 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:58:58.398255 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:58:58.399267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:58:58.400272 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:58:58.402270 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:58:58.404274 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:58:58.400272 => 14:58:58.404274
[0m14:58:58.405272 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:58:58.410782 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:58:58.413791 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.414790 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:58:58.414790 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:58.595749 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:58.596756 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.596756 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:58:58.640610 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:58:58.643616 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.644616 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:58:58.674356 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.678016 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.678016 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:58:58.709181 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:58:58.712218 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:58.712218 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.713213 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:58:58.744139 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:58:58.747812 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:58:58.748821 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:58:58.749819 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:58:58.782099 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:58:58.784189 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:58:58.405272 => 14:58:58.784189
[0m14:58:58.785202 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:58:58.786189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E941476BD0>]}
[0m14:58:58.786189 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.39s]
[0m14:58:58.787319 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:58:58.788359 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.789328 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:58:58.791087 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:58:58.791087 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.794051 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.795573 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:58:58.792106 => 14:58:58.795573
[0m14:58:58.796575 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:58:58.822288 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.825259 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:58.825259 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:58:58.826257 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:58:59.019282 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:58:59.020276 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:58:59.020276 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:58:59.059634 [debug] [Thread-1 (]: Postgres adapter: Postgres error: function replace(text, unknown) does not exist
LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
             ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m14:58:59.060641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:58:59.088666 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:58:58.796575 => 14:58:59.088666
[0m14:58:59.089696 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:58:59.093664 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  function replace(text, unknown) does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:59.095202 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c52e07fe-be0c-4485-be5c-a736a9ce7841', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E94142CDD0>]}
[0m14:58:59.096179 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.31s]
[0m14:58:59.097431 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:58:59.098438 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:59.099470 [debug] [MainThread]: On master: BEGIN
[0m14:58:59.100470 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:58:59.280985 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:58:59.281962 [debug] [MainThread]: On master: COMMIT
[0m14:58:59.281962 [debug] [MainThread]: Using postgres connection "master"
[0m14:58:59.282918 [debug] [MainThread]: On master: COMMIT
[0m14:58:59.309027 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:58:59.309027 [debug] [MainThread]: On master: Close
[0m14:58:59.310075 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:58:59.311613 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:58:59.312860 [info ] [MainThread]: 
[0m14:58:59.313868 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 3.92 seconds (3.92s).
[0m14:58:59.314884 [debug] [MainThread]: Command end result
[0m14:58:59.324371 [info ] [MainThread]: 
[0m14:58:59.326377 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:58:59.326377 [info ] [MainThread]: 
[0m14:58:59.327380 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  function replace(text, unknown) does not exist
  LINE 28:     REPLACE(price_str,'$') :: NUMERIC (10, 2) AS price,
               ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:58:59.329379 [info ] [MainThread]: 
[0m14:58:59.330378 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:58:59.333381 [debug] [MainThread]: Command `dbt run` failed at 14:58:59.332387 after 4.76 seconds
[0m14:58:59.334383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E940E62150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9395DE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E9396A6810>]}
[0m14:58:59.334383 [debug] [MainThread]: Flushing usage events
[0m14:59:50.993696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A60A1250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A56F2E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6112610>]}


============================== 14:59:50.998212 | 7d9c0351-338b-49aa-84cd-816b84e4922a ==============================
[0m14:59:50.998212 [info ] [MainThread]: Running with dbt=1.7.3
[0m14:59:50.999216 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:59:51.208561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A65B0810>]}
[0m14:59:51.284538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A667EC90>]}
[0m14:59:51.286540 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m14:59:51.294541 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m14:59:51.391129 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:59:51.392129 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:51.569458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A68B0AD0>]}
[0m14:59:51.582652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A682F910>]}
[0m14:59:51.584165 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:59:51.585202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A60875D0>]}
[0m14:59:51.587209 [info ] [MainThread]: 
[0m14:59:51.588207 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:59:51.590211 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m14:59:51.599641 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m14:59:51.600642 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m14:59:51.600642 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:52.957813 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m14:59:52.959806 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m14:59:52.961804 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m14:59:52.967189 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:52.967789 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m14:59:52.967789 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:59:53.203567 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.204578 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m14:59:53.204578 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m14:59:53.254035 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m14:59:53.255327 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m14:59:53.289143 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m14:59:53.294233 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.295231 [debug] [MainThread]: On master: BEGIN
[0m14:59:53.295231 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:59:53.491330 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.491330 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.492376 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:59:53.555404 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m14:59:53.558011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6826350>]}
[0m14:59:53.558011 [debug] [MainThread]: On master: ROLLBACK
[0m14:59:53.587367 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.587367 [debug] [MainThread]: On master: BEGIN
[0m14:59:53.643860 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.643860 [debug] [MainThread]: On master: COMMIT
[0m14:59:53.644899 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:53.645892 [debug] [MainThread]: On master: COMMIT
[0m14:59:53.680155 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:53.680155 [debug] [MainThread]: On master: Close
[0m14:59:53.681168 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:59:53.682461 [info ] [MainThread]: 
[0m14:59:53.686466 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m14:59:53.687470 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m14:59:53.688885 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m14:59:53.688885 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m14:59:53.696444 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m14:59:53.699913 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 14:59:53.689887 => 14:59:53.699403
[0m14:59:53.700510 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m14:59:53.737270 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m14:59:53.739274 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.739274 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m14:59:53.740272 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:59:53.935844 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:53.936367 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.936896 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m14:59:53.984069 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:53.990503 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:53.991501 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m14:59:54.019376 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.022403 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.023948 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m14:59:54.054309 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.069828 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:59:54.070824 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.070824 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m14:59:54.102435 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:54.109217 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m14:59:54.113217 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m14:59:54.114217 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m14:59:54.146318 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:54.148357 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 14:59:53.700510 => 14:59:54.148357
[0m14:59:54.149357 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m14:59:54.150357 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6A65E90>]}
[0m14:59:54.150357 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.46s]
[0m14:59:54.152325 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m14:59:54.153324 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m14:59:54.153324 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m14:59:54.155360 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m14:59:54.155360 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m14:59:54.157432 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m14:59:54.159466 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 14:59:54.156326 => 14:59:54.159466
[0m14:59:54.160441 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m14:59:54.165484 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m14:59:54.167438 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.169045 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m14:59:54.170047 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:54.403716 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:54.404715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.404715 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m14:59:54.454427 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:54.458936 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.458936 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m14:59:54.493124 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.496758 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.496758 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m14:59:54.531722 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.534730 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:59:54.534730 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.535732 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m14:59:54.572000 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:54.574993 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m14:59:54.575994 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m14:59:54.576994 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m14:59:54.613999 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:54.615042 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 14:59:54.160441 => 14:59:54.615042
[0m14:59:54.616042 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m14:59:54.617039 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6B41810>]}
[0m14:59:54.618007 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m14:59:54.619005 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m14:59:54.620008 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m14:59:54.620008 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m14:59:54.622005 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m14:59:54.622005 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m14:59:54.624004 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m14:59:54.626079 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 14:59:54.623004 => 14:59:54.625512
[0m14:59:54.626079 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m14:59:54.631191 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m14:59:54.633215 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.634198 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m14:59:54.635203 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:54.862711 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:54.863702 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.863702 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m14:59:54.914340 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:59:54.918177 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.919147 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m14:59:54.953876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.957715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.958712 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m14:59:54.990748 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:59:54.992749 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:59:54.992749 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:54.993751 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m14:59:55.026273 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:59:55.031020 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m14:59:55.032059 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m14:59:55.032059 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m14:59:55.067847 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:59:55.069845 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 14:59:54.626079 => 14:59:55.069845
[0m14:59:55.070348 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m14:59:55.071363 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6BD67D0>]}
[0m14:59:55.072368 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.45s]
[0m14:59:55.073368 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m14:59:55.074371 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.074371 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m14:59:55.076369 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m14:59:55.076369 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.079402 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.081385 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 14:59:55.077368 => 14:59:55.080402
[0m14:59:55.081890 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.107903 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.109903 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.109903 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m14:59:55.110903 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:59:55.332793 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:59:55.334298 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m14:59:55.335307 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updatede_at
FROM
    src_listings
  );
  
[0m14:59:55.378446 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "updatede_at" does not exist
LINE 30:     updatede_at
             ^
HINT:  Perhaps you meant to reference the column "src_listings.updated_at".

[0m14:59:55.379447 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: ROLLBACK
[0m14:59:55.418095 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 14:59:55.082899 => 14:59:55.416587
[0m14:59:55.419627 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m14:59:55.430145 [debug] [Thread-1 (]: Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "updatede_at" does not exist
  LINE 30:     updatede_at
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:55.430670 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c0351-338b-49aa-84cd-816b84e4922a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A6BD9BD0>]}
[0m14:59:55.432679 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model test.dim_listings_cleansed ............... [[31mERROR[0m in 0.36s]
[0m14:59:55.434678 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m14:59:55.437679 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:55.438678 [debug] [MainThread]: On master: BEGIN
[0m14:59:55.439677 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:59:55.667203 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:59:55.668204 [debug] [MainThread]: On master: COMMIT
[0m14:59:55.669587 [debug] [MainThread]: Using postgres connection "master"
[0m14:59:55.671095 [debug] [MainThread]: On master: COMMIT
[0m14:59:55.702340 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:59:55.703340 [debug] [MainThread]: On master: Close
[0m14:59:55.704345 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:59:55.705344 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m14:59:55.706850 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m14:59:55.707838 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m14:59:55.708861 [info ] [MainThread]: 
[0m14:59:55.709859 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m14:59:55.712855 [debug] [MainThread]: Command end result
[0m14:59:55.724591 [info ] [MainThread]: 
[0m14:59:55.727593 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m14:59:55.729591 [info ] [MainThread]: 
[0m14:59:55.730593 [error] [MainThread]:   Database Error in model dim_listings_cleansed (dbtlearn/models\dim\dim_listings_cleansed.sql)
  column "updatede_at" does not exist
  LINE 30:     updatede_at
               ^
  HINT:  Perhaps you meant to reference the column "src_listings.updated_at".
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_listings_cleansed.sql
[0m14:59:55.731674 [info ] [MainThread]: 
[0m14:59:55.733839 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m14:59:55.739841 [debug] [MainThread]: Command `dbt run` failed at 14:59:55.738839 after 4.81 seconds
[0m14:59:55.740840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002939EDE1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A5DB5850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293A5DB5DD0>]}
[0m14:59:55.742842 [debug] [MainThread]: Flushing usage events
[0m15:00:07.871689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DE8DD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830CAD5150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830A38C490>]}


============================== 15:00:07.875687 | 15f63cf1-32ae-46ff-8b62-81075beb7f18 ==============================
[0m15:00:07.875687 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:00:07.876686 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:00:08.086575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DEE2050>]}
[0m15:00:08.161938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830DFDC310>]}
[0m15:00:08.163901 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:00:08.173943 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:00:08.270209 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:00:08.271211 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_listings_cleansed.sql
[0m15:00:08.441083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E1FCE90>]}
[0m15:00:08.461114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E27D810>]}
[0m15:00:08.462113 [info ] [MainThread]: Found 4 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:00:08.463112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E1CE810>]}
[0m15:00:08.466114 [info ] [MainThread]: 
[0m15:00:08.468117 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:00:08.470616 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:00:08.488172 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:00:08.489148 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:00:08.490146 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:08.718420 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:00:08.720420 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:00:08.722387 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:00:08.729133 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:00:08.730166 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:00:08.730166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:08.910933 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:00:08.910933 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:00:08.911930 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:00:08.957759 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m15:00:08.959798 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:00:08.988020 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:00:08.993849 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:08.993849 [debug] [MainThread]: On master: BEGIN
[0m15:00:08.994815 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:00:09.184392 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.184910 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.185944 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:00:09.237947 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:00:09.240430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F3C0790>]}
[0m15:00:09.240430 [debug] [MainThread]: On master: ROLLBACK
[0m15:00:09.270708 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.271714 [debug] [MainThread]: On master: BEGIN
[0m15:00:09.328884 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.329900 [debug] [MainThread]: On master: COMMIT
[0m15:00:09.329900 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:09.330898 [debug] [MainThread]: On master: COMMIT
[0m15:00:09.357073 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:00:09.358081 [debug] [MainThread]: On master: Close
[0m15:00:09.359079 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:00:09.360239 [info ] [MainThread]: 
[0m15:00:09.363243 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:00:09.364245 [info ] [Thread-1 (]: 1 of 4 START sql view model test.src_hosts ..................................... [RUN]
[0m15:00:09.365245 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:00:09.366245 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:00:09.372756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:00:09.375758 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:00:09.366245 => 15:00:09.374760
[0m15:00:09.376771 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:00:09.413576 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:00:09.415597 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.416547 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:00:09.416547 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:00:09.599723 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:09.600836 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.600836 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS reviw_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:00:09.642463 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:09.651644 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.652644 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:00:09.685874 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:09.689880 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.690881 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:00:09.720320 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:09.735525 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:00:09.736524 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.737524 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:00:09.765327 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:09.771378 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:00:09.776378 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:00:09.777371 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:00:09.808308 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:09.810342 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:00:09.376771 => 15:00:09.810342
[0m15:00:09.811329 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:00:09.812343 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830E13FFD0>]}
[0m15:00:09.813309 [info ] [Thread-1 (]: 1 of 4 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.45s]
[0m15:00:09.814308 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:00:09.815822 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:00:09.815822 [info ] [Thread-1 (]: 2 of 4 START sql view model test.src_listings .................................. [RUN]
[0m15:00:09.817212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:00:09.818246 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:00:09.820243 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:00:09.821214 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:00:09.818246 => 15:00:09.821214
[0m15:00:09.822212 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:00:09.826243 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:00:09.828326 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:09.829368 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:00:09.830346 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.006647 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.008683 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.009199 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:00:10.048525 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:10.052524 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.053526 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:00:10.087493 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.090487 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.091487 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:00:10.121727 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.124721 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:00:10.125724 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.126721 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:00:10.156397 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:10.159397 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:00:10.160397 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:00:10.161395 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:00:10.195267 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:10.199262 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:00:09.822212 => 15:00:10.198259
[0m15:00:10.200261 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:00:10.201776 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F422B10>]}
[0m15:00:10.202772 [info ] [Thread-1 (]: 2 of 4 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.38s]
[0m15:00:10.203772 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:00:10.203772 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:00:10.204773 [info ] [Thread-1 (]: 3 of 4 START sql view model test.src_reviews ................................... [RUN]
[0m15:00:10.205773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:00:10.206771 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:00:10.208771 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:00:10.210771 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:00:10.206771 => 15:00:10.210771
[0m15:00:10.210771 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:00:10.215806 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:00:10.217808 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.217808 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:00:10.218842 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.404553 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.404553 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.404553 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:00:10.447362 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:00:10.451227 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.451227 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:00:10.488796 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.492297 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.493297 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:00:10.524031 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:10.526056 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:00:10.527056 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.527056 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:00:10.559587 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:10.563682 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:00:10.564679 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:00:10.565713 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:00:10.599341 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:00:10.601347 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:00:10.210771 => 15:00:10.601347
[0m15:00:10.601347 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:00:10.602348 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F4C6A50>]}
[0m15:00:10.603347 [info ] [Thread-1 (]: 3 of 4 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.40s]
[0m15:00:10.604351 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:00:10.605385 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.606347 [info ] [Thread-1 (]: 4 of 4 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:00:10.607349 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m15:00:10.607349 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.610374 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.612375 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:00:10.607349 => 15:00:10.611374
[0m15:00:10.612375 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:00:10.635173 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.638576 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.641580 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:00:10.643592 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:00:10.847334 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:00:10.849346 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.850887 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:00:10.967836 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:00:10.971360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:10.972358 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:00:11.000999 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:00:11.006697 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:00:11.007868 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:11.008836 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:00:11.038332 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:00:11.042932 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:00:11.046361 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:00:11.046361 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:00:11.077018 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:00:11.079232 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:00:10.613374 => 15:00:11.079232
[0m15:00:11.080232 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:00:11.081267 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15f63cf1-32ae-46ff-8b62-81075beb7f18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830F3D8450>]}
[0m15:00:11.081267 [info ] [Thread-1 (]: 4 of 4 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.47s]
[0m15:00:11.083233 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:00:11.085232 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:11.085232 [debug] [MainThread]: On master: BEGIN
[0m15:00:11.086272 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:00:11.272963 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:00:11.273964 [debug] [MainThread]: On master: COMMIT
[0m15:00:11.274965 [debug] [MainThread]: Using postgres connection "master"
[0m15:00:11.274965 [debug] [MainThread]: On master: COMMIT
[0m15:00:11.303017 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:00:11.304171 [debug] [MainThread]: On master: Close
[0m15:00:11.305793 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:00:11.306306 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:00:11.307348 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:00:11.308428 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:00:11.309472 [info ] [MainThread]: 
[0m15:00:11.310567 [info ] [MainThread]: Finished running 3 view models, 1 table model in 0 hours 0 minutes and 2.84 seconds (2.84s).
[0m15:00:11.312743 [debug] [MainThread]: Command end result
[0m15:00:11.324359 [info ] [MainThread]: 
[0m15:00:11.325470 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:00:11.327170 [info ] [MainThread]: 
[0m15:00:11.328795 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m15:00:11.330333 [debug] [MainThread]: Command `dbt run` succeeded at 15:00:11.330333 after 3.52 seconds
[0m15:00:11.330333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018306701010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001830D6B2550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183069EFED0>]}
[0m15:00:11.331871 [debug] [MainThread]: Flushing usage events
[0m15:08:21.198391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C723810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C2E93D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C6EAAD0>]}


============================== 15:08:21.201903 | 9bdd196a-2021-4bec-bb96-0e65581100dc ==============================
[0m15:08:21.201903 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:08:21.202935 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:08:21.414590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C246710>]}
[0m15:08:21.494253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C82FF10>]}
[0m15:08:21.496567 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:08:21.504602 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:08:21.610884 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m15:08:21.611885 [debug] [MainThread]: Partial parsing: added file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:21.611885 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\src\src_hosts.sql
[0m15:08:21.781410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C1F9210>]}
[0m15:08:21.794897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CBCBCD0>]}
[0m15:08:21.794897 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:08:21.795897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CC2D6D0>]}
[0m15:08:21.797925 [info ] [MainThread]: 
[0m15:08:21.798939 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:08:21.802027 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:08:21.813960 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:08:21.815257 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:08:21.816235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:22.051920 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:08:22.052960 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:08:22.055158 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:08:22.061161 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:08:22.062162 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:08:22.062162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:22.262932 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.262932 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:08:22.263973 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:08:22.310785 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:08:22.312827 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:08:22.341545 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:08:22.347803 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.348837 [debug] [MainThread]: On master: BEGIN
[0m15:08:22.349803 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:08:22.555755 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.556770 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.556770 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:08:22.621778 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:08:22.623785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CA7ACD0>]}
[0m15:08:22.624796 [debug] [MainThread]: On master: ROLLBACK
[0m15:08:22.655537 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.655537 [debug] [MainThread]: On master: BEGIN
[0m15:08:22.714120 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:22.715347 [debug] [MainThread]: On master: COMMIT
[0m15:08:22.715347 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:22.716354 [debug] [MainThread]: On master: COMMIT
[0m15:08:22.741300 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:08:22.742205 [debug] [MainThread]: On master: Close
[0m15:08:22.743215 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:08:22.744198 [info ] [MainThread]: 
[0m15:08:22.747422 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.748429 [info ] [Thread-1 (]: 1 of 5 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:08:22.749936 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:08:22.751014 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.758019 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.760028 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:08:22.752023 => 15:08:22.760028
[0m15:08:22.762022 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:08:22.803739 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.805721 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:22.806707 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:08:22.807705 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:08:23.024835 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.025858 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:08:23.026363 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        
)
SELECT
    review_id,
	CASE 
        WHEN review_name IS NULL THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:08:23.066839 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ")"
LINE 17: )
         ^

[0m15:08:23.067837 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: ROLLBACK
[0m15:08:23.098622 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:08:22.762536 => 15:08:23.098622
[0m15:08:23.099840 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:08:23.104845 [debug] [Thread-1 (]: Database Error in model dim_hosts_cleansed (dbtlearn/models\dim\dim_hosts_cleansed.sql)
  syntax error at or near ")"
  LINE 17: )
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:23.105843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5C873F50>]}
[0m15:08:23.106846 [error] [Thread-1 (]: 1 of 5 ERROR creating sql table model test.dim_hosts_cleansed .................. [[31mERROR[0m in 0.36s]
[0m15:08:23.107388 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:08:23.108428 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:08:23.109396 [info ] [Thread-1 (]: 2 of 5 START sql view model test.src_hosts ..................................... [RUN]
[0m15:08:23.110397 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.src_hosts)
[0m15:08:23.110397 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:08:23.113835 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:08:23.115854 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:08:23.111883 => 15:08:23.114867
[0m15:08:23.115854 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:08:23.139839 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:08:23.142847 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.143843 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:08:23.143843 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:23.372926 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.373933 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.373933 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:08:23.422797 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:23.429290 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.430291 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:08:23.463980 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.467053 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.468019 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:08:23.502636 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.517723 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:08:23.517723 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.519247 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:08:23.552002 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:23.558603 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:08:23.563603 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:08:23.563603 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:08:23.604534 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:23.606077 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:08:23.116838 => 15:08:23.606077
[0m15:08:23.607092 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:08:23.608077 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5CC45250>]}
[0m15:08:23.609077 [info ] [Thread-1 (]: 2 of 5 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.50s]
[0m15:08:23.609407 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:08:23.610443 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:08:23.611415 [info ] [Thread-1 (]: 3 of 5 START sql view model test.src_listings .................................. [RUN]
[0m15:08:23.612443 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:08:23.612443 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:08:23.614413 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:08:23.616765 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:08:23.613442 => 15:08:23.615413
[0m15:08:23.617778 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:08:23.623762 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:08:23.625766 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.627800 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:08:23.628806 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:23.850110 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:23.850859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.851856 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:08:23.901612 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:23.905149 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.906148 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:08:23.946216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.949222 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.950221 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:08:23.985099 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:23.988143 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:08:23.988683 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:23.989178 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:08:24.023192 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:24.026717 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:08:24.027715 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:08:24.028718 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:08:24.066403 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:24.068551 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:08:23.617778 => 15:08:24.068551
[0m15:08:24.069096 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:08:24.070162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DCC33D0>]}
[0m15:08:24.071191 [info ] [Thread-1 (]: 3 of 5 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.46s]
[0m15:08:24.072236 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:08:24.073269 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:08:24.073806 [info ] [Thread-1 (]: 4 of 5 START sql view model test.src_reviews ................................... [RUN]
[0m15:08:24.074845 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:08:24.075955 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:08:24.077511 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:08:24.079032 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:08:24.076475 => 15:08:24.079032
[0m15:08:24.079032 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:08:24.087521 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:08:24.090043 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.091039 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:08:24.092039 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:24.332205 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:24.333213 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.333213 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:08:24.383303 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:08:24.386814 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.387815 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:08:24.427732 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.431730 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.431730 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:08:24.466992 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.468535 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:08:24.469789 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.470789 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:08:24.505937 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:24.508516 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:08:24.509480 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:08:24.510516 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:08:24.548030 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:08:24.550074 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:08:24.079032 => 15:08:24.549084
[0m15:08:24.550074 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:08:24.551036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DD69CD0>]}
[0m15:08:24.552576 [info ] [Thread-1 (]: 4 of 5 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.48s]
[0m15:08:24.553584 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:08:24.554594 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.554594 [info ] [Thread-1 (]: 5 of 5 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:08:24.556581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_listings_cleansed)
[0m15:08:24.556581 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.559580 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.562585 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:08:24.557581 => 15:08:24.561587
[0m15:08:24.563586 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:08:24.570120 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.572122 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.572122 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:08:24.573123 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:08:24.780714 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:08:24.781498 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.782548 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:08:24.933609 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:08:24.937189 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.937189 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:08:24.974789 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:24.977797 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:24.978797 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:08:25.008142 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:08:25.014280 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:08:25.014280 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:25.015281 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:08:25.046021 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:08:25.049689 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:08:25.052689 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:08:25.053689 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:08:25.094052 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:08:25.096085 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:08:24.563586 => 15:08:25.094828
[0m15:08:25.096085 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:08:25.097070 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bdd196a-2021-4bec-bb96-0e65581100dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5DD8E6D0>]}
[0m15:08:25.098088 [info ] [Thread-1 (]: 5 of 5 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.54s]
[0m15:08:25.099053 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:08:25.101420 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:25.101420 [debug] [MainThread]: On master: BEGIN
[0m15:08:25.102420 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:08:25.301094 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:08:25.302106 [debug] [MainThread]: On master: COMMIT
[0m15:08:25.302106 [debug] [MainThread]: Using postgres connection "master"
[0m15:08:25.303109 [debug] [MainThread]: On master: COMMIT
[0m15:08:25.329306 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:08:25.329306 [debug] [MainThread]: On master: Close
[0m15:08:25.330313 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:08:25.331313 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:08:25.331313 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:08:25.332312 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:08:25.332312 [info ] [MainThread]: 
[0m15:08:25.334427 [info ] [MainThread]: Finished running 2 table models, 3 view models in 0 hours 0 minutes and 3.53 seconds (3.53s).
[0m15:08:25.336467 [debug] [MainThread]: Command end result
[0m15:08:25.345978 [info ] [MainThread]: 
[0m15:08:25.346645 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:08:25.347655 [info ] [MainThread]: 
[0m15:08:25.348653 [error] [MainThread]:   Database Error in model dim_hosts_cleansed (dbtlearn/models\dim\dim_hosts_cleansed.sql)
  syntax error at or near ")"
  LINE 17: )
           ^
  compiled Code at target\run\dbtlearn\dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:08:25.350655 [info ] [MainThread]: 
[0m15:08:25.351656 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m15:08:25.354665 [debug] [MainThread]: Command `dbt run` failed at 15:08:25.353668 after 4.22 seconds
[0m15:08:25.355666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B54FC1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5BFBAE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017B5BEF5490>]}
[0m15:08:25.356655 [debug] [MainThread]: Flushing usage events
[0m15:09:24.348636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855FCBB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855AF7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855AF6790>]}


============================== 15:09:24.352631 | b1207066-8e8b-4cb2-954f-2675086edf64 ==============================
[0m15:09:24.352631 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:09:24.352631 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:09:24.587362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855B003D0>]}
[0m15:09:24.680259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855FE2E10>]}
[0m15:09:24.681260 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:09:24.692070 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:09:24.794357 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:09:24.795359 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:09:24.983689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85624AA50>]}
[0m15:09:24.998795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8563BF950>]}
[0m15:09:24.999323 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:09:25.000418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F856295750>]}
[0m15:09:25.002454 [info ] [MainThread]: 
[0m15:09:25.004493 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:09:25.006256 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:09:25.018746 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:09:25.018746 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:09:25.019745 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:25.258777 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:09:25.260740 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:09:25.262740 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:09:25.268977 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:09:25.268977 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:09:25.270015 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:09:25.470039 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.471012 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:09:25.471981 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:09:25.519158 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:09:25.521333 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:09:25.548946 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:09:25.557462 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.558469 [debug] [MainThread]: On master: BEGIN
[0m15:09:25.558469 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:09:25.745741 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.746741 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.746741 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:09:25.796273 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:09:25.798281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8562AD690>]}
[0m15:09:25.798281 [debug] [MainThread]: On master: ROLLBACK
[0m15:09:25.828034 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.829036 [debug] [MainThread]: On master: BEGIN
[0m15:09:25.955009 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:25.956011 [debug] [MainThread]: On master: COMMIT
[0m15:09:25.956011 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:25.957009 [debug] [MainThread]: On master: COMMIT
[0m15:09:25.986792 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:09:25.986792 [debug] [MainThread]: On master: Close
[0m15:09:25.988324 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:09:25.988833 [info ] [MainThread]: 
[0m15:09:25.992137 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_hosts
[0m15:09:25.993137 [info ] [Thread-1 (]: 1 of 5 START sql view model test.src_hosts ..................................... [RUN]
[0m15:09:25.995139 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.src_hosts'
[0m15:09:25.995139 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_hosts
[0m15:09:26.001155 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_hosts"
[0m15:09:26.003168 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (compile): 15:09:25.996138 => 15:09:26.002161
[0m15:09:26.004168 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_hosts
[0m15:09:26.044416 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_hosts"
[0m15:09:26.046411 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.046411 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: BEGIN
[0m15:09:26.047414 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:09:26.264267 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:26.264958 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.266091 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */

  create view "inttegra_stage"."test"."src_hosts__dbt_tmp"
    
    
  as (
    WITH raw_hosts AS(
	SELECT *
	FROM 
		test.raw_hosts rh 
)
SELECT
	id AS review_id,
	name AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
	raw_hosts
  );
[0m15:09:26.314995 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:26.322756 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.322756 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts" rename to "src_hosts__dbt_backup"
[0m15:09:26.358645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.362750 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.363754 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
alter table "inttegra_stage"."test"."src_hosts__dbt_tmp" rename to "src_hosts"
[0m15:09:26.397989 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.413012 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:09:26.414011 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.414011 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: COMMIT
[0m15:09:26.453233 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:26.460506 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_hosts__dbt_backup"
[0m15:09:26.465505 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_hosts"
[0m15:09:26.465505 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_hosts"} */
drop view if exists "inttegra_stage"."test"."src_hosts__dbt_backup" cascade
[0m15:09:26.502800 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:26.503799 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_hosts (execute): 15:09:26.004168 => 15:09:26.503799
[0m15:09:26.505304 [debug] [Thread-1 (]: On model.dbtlearn.src_hosts: Close
[0m15:09:26.506306 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85654DA90>]}
[0m15:09:26.506825 [info ] [Thread-1 (]: 1 of 5 OK created sql view model test.src_hosts ................................ [[32mCREATE VIEW[0m in 0.51s]
[0m15:09:26.507828 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_hosts
[0m15:09:26.508828 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_listings
[0m15:09:26.508828 [info ] [Thread-1 (]: 2 of 5 START sql view model test.src_listings .................................. [RUN]
[0m15:09:26.510830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_hosts, now model.dbtlearn.src_listings)
[0m15:09:26.510830 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_listings
[0m15:09:26.512861 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_listings"
[0m15:09:26.514830 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (compile): 15:09:26.511843 => 15:09:26.513827
[0m15:09:26.515829 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_listings
[0m15:09:26.520855 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_listings"
[0m15:09:26.522859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.522859 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: BEGIN
[0m15:09:26.524856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:26.733844 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:26.735016 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.735557 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */

  create view "inttegra_stage"."test"."src_listings__dbt_tmp"
    
    
  as (
    WITH raw_listings AS (
	SELECT *
	FROM   
		test.raw_listings rl 
)
SELECT 
	id AS id_listings,
    name AS listing_name,
    listing_url,
    room_type,
    minimum_nights,
    host_id,
    price AS price_str,
    created_at,
    updated_at
FROM
	raw_listings
  );
[0m15:09:26.786291 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:26.790122 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.790122 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings" rename to "src_listings__dbt_backup"
[0m15:09:26.827365 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.831391 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.832392 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
alter table "inttegra_stage"."test"."src_listings__dbt_tmp" rename to "src_listings"
[0m15:09:26.866613 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:26.868616 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:09:26.869616 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.869616 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: COMMIT
[0m15:09:26.904045 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:26.907054 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_listings__dbt_backup"
[0m15:09:26.909054 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_listings"
[0m15:09:26.909054 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_listings"} */
drop view if exists "inttegra_stage"."test"."src_listings__dbt_backup" cascade
[0m15:09:26.945468 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:26.947271 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_listings (execute): 15:09:26.515829 => 15:09:26.947271
[0m15:09:26.948244 [debug] [Thread-1 (]: On model.dbtlearn.src_listings: Close
[0m15:09:26.949267 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F856539E50>]}
[0m15:09:26.949267 [info ] [Thread-1 (]: 2 of 5 OK created sql view model test.src_listings ............................. [[32mCREATE VIEW[0m in 0.44s]
[0m15:09:26.950234 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_listings
[0m15:09:26.951637 [debug] [Thread-1 (]: Began running node model.dbtlearn.src_reviews
[0m15:09:26.952620 [info ] [Thread-1 (]: 3 of 5 START sql view model test.src_reviews ................................... [RUN]
[0m15:09:26.953611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_listings, now model.dbtlearn.src_reviews)
[0m15:09:26.954605 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.src_reviews
[0m15:09:26.955637 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.src_reviews"
[0m15:09:26.957633 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (compile): 15:09:26.954605 => 15:09:26.957633
[0m15:09:26.958638 [debug] [Thread-1 (]: Began executing node model.dbtlearn.src_reviews
[0m15:09:26.962658 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.src_reviews"
[0m15:09:26.964124 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:26.964124 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: BEGIN
[0m15:09:26.965124 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:27.179300 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:27.180060 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.180564 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */

  create view "inttegra_stage"."test"."src_reviews__dbt_tmp"
    
    
  as (
    WITH raw_reviews AS(
	SELECT *
	FROM
		test.raw_reviews rr 
)
SELECT
	listing_id,
	date AS review_date,
	reviewer_name,
	COMMENTS AS review_txt,
	sentiment AS review_sentiment 
FROM 
	raw_reviews
  );
[0m15:09:27.228979 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:09:27.232975 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.232975 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews" rename to "src_reviews__dbt_backup"
[0m15:09:27.268776 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.272813 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.273778 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
alter table "inttegra_stage"."test"."src_reviews__dbt_tmp" rename to "src_reviews"
[0m15:09:27.308772 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.311272 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:09:27.312278 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.312278 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: COMMIT
[0m15:09:27.346778 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:27.350289 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."src_reviews__dbt_backup"
[0m15:09:27.351288 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.src_reviews"
[0m15:09:27.352256 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.src_reviews"} */
drop view if exists "inttegra_stage"."test"."src_reviews__dbt_backup" cascade
[0m15:09:27.388070 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:09:27.390038 [debug] [Thread-1 (]: Timing info for model.dbtlearn.src_reviews (execute): 15:09:26.958638 => 15:09:27.390038
[0m15:09:27.391059 [debug] [Thread-1 (]: On model.dbtlearn.src_reviews: Close
[0m15:09:27.393037 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85663B250>]}
[0m15:09:27.393037 [info ] [Thread-1 (]: 3 of 5 OK created sql view model test.src_reviews .............................. [[32mCREATE VIEW[0m in 0.44s]
[0m15:09:27.394036 [debug] [Thread-1 (]: Finished running node model.dbtlearn.src_reviews
[0m15:09:27.395605 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.395605 [info ] [Thread-1 (]: 4 of 5 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:09:27.397609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.src_reviews, now model.dbtlearn.dim_hosts_cleansed)
[0m15:09:27.397609 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.401609 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.403609 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:09:27.398613 => 15:09:27.402610
[0m15:09:27.404609 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.427198 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.429198 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.429198 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:09:27.430721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:27.640401 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:27.641369 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.642368 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name IS NULL THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:09:27.739488 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:09:27.742485 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.743484 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:09:27.777239 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:27.782747 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:09:27.782747 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.783747 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:09:27.822801 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:27.825807 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:09:27.828833 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:09:27.829838 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:09:27.863300 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:09:27.864844 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:09:27.404609 => 15:09:27.864844
[0m15:09:27.865842 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:09:27.866877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85664A790>]}
[0m15:09:27.867875 [info ] [Thread-1 (]: 4 of 5 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.47s]
[0m15:09:27.869877 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:09:27.869877 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.870877 [info ] [Thread-1 (]: 5 of 5 START sql table model test.dim_listings_cleansed ........................ [RUN]
[0m15:09:27.871846 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbtlearn.dim_hosts_cleansed, now model.dbtlearn.dim_listings_cleansed)
[0m15:09:27.873105 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.876197 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.877937 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (compile): 15:09:27.873105 => 15:09:27.876764
[0m15:09:27.877937 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_listings_cleansed
[0m15:09:27.882941 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.884939 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:27.884939 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: BEGIN
[0m15:09:27.885946 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:09:28.083139 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:09:28.084091 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.085059 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH src_listings AS (
    SELECT 
        *
    FROM
        "inttegra_stage"."test"."src_listings"
)

SELECT
    id_listings,
    listing_name,
    room_type,
    CASE 
        WHEN  minimum_nights = 0 THEN  1
        ELSE  minimum_nights
    END AS minimum_nights,
    host_id,
    CAST(REPLACE(price_str, '$', '') AS NUMERIC(10,2)) AS price,
    created_at,
    updated_at
FROM
    src_listings
  );
  
[0m15:09:28.235996 [debug] [Thread-1 (]: SQL status: SELECT 17499 in 0.0 seconds
[0m15:09:28.239874 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.240874 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed" rename to "dim_listings_cleansed__dbt_backup"
[0m15:09:28.271456 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:28.275193 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.275193 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
alter table "inttegra_stage"."test"."dim_listings_cleansed__dbt_tmp" rename to "dim_listings_cleansed"
[0m15:09:28.306544 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:09:28.308637 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:09:28.309674 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.310641 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: COMMIT
[0m15:09:28.345767 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:09:28.348638 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup"
[0m15:09:28.349638 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_listings_cleansed"
[0m15:09:28.350637 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_listings_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_listings_cleansed__dbt_backup" cascade
[0m15:09:28.400405 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:09:28.402286 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_listings_cleansed (execute): 15:09:27.878937 => 15:09:28.402286
[0m15:09:28.403285 [debug] [Thread-1 (]: On model.dbtlearn.dim_listings_cleansed: Close
[0m15:09:28.404286 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1207066-8e8b-4cb2-954f-2675086edf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85663ABD0>]}
[0m15:09:28.405369 [info ] [Thread-1 (]: 5 of 5 OK created sql table model test.dim_listings_cleansed ................... [[32mSELECT 17499[0m in 0.53s]
[0m15:09:28.405796 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_listings_cleansed
[0m15:09:28.407798 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:28.408801 [debug] [MainThread]: On master: BEGIN
[0m15:09:28.409818 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:09:28.593987 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:09:28.593987 [debug] [MainThread]: On master: COMMIT
[0m15:09:28.594996 [debug] [MainThread]: Using postgres connection "master"
[0m15:09:28.594996 [debug] [MainThread]: On master: COMMIT
[0m15:09:28.623274 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:09:28.624278 [debug] [MainThread]: On master: Close
[0m15:09:28.625305 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:09:28.625305 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:09:28.626275 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:09:28.626275 [debug] [MainThread]: Connection 'model.dbtlearn.dim_listings_cleansed' was properly closed.
[0m15:09:28.626275 [info ] [MainThread]: 
[0m15:09:28.627274 [info ] [MainThread]: Finished running 3 view models, 2 table models in 0 hours 0 minutes and 3.62 seconds (3.62s).
[0m15:09:28.629309 [debug] [MainThread]: Command end result
[0m15:09:28.638413 [info ] [MainThread]: 
[0m15:09:28.639411 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:09:28.640409 [info ] [MainThread]: 
[0m15:09:28.641412 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m15:09:28.643460 [debug] [MainThread]: Command `dbt run` succeeded at 15:09:28.643460 after 4.36 seconds
[0m15:09:28.643460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F855B7EB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F84E8C1010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F84E8C1B50>]}
[0m15:09:28.644966 [debug] [MainThread]: Flushing usage events
[0m15:11:31.920847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE7D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F70F1F42D0>]}


============================== 15:11:31.924389 | cba3c832-f59b-49fc-ba7e-c1417bf3be1d ==============================
[0m15:11:31.924389 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:11:31.925357 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s dim_hosts_cleansed', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:11:32.133993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710C1C550>]}
[0m15:11:32.210809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAF290>]}
[0m15:11:32.211838 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:11:32.220883 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:11:32.321059 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:11:32.322028 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:11:32.495970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710E9C410>]}
[0m15:11:32.508660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710F6E850>]}
[0m15:11:32.509627 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:11:32.510625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710EFC1D0>]}
[0m15:11:32.511626 [info ] [MainThread]: 
[0m15:11:32.512625 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:11:32.514659 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:11:32.523553 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:11:32.524554 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:11:32.525555 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:32.870576 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m15:11:32.872569 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:11:32.874393 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:11:32.879516 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:11:32.880522 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:11:32.881516 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:33.075317 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.076364 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:11:33.076364 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:11:33.126071 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:11:33.127087 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:11:33.157751 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:11:33.163749 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.164754 [debug] [MainThread]: On master: BEGIN
[0m15:11:33.164754 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:11:33.376107 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.376107 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.377102 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:11:33.435577 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:11:33.438578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710EFD590>]}
[0m15:11:33.438578 [debug] [MainThread]: On master: ROLLBACK
[0m15:11:33.467909 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.468870 [debug] [MainThread]: On master: BEGIN
[0m15:11:33.526888 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.527437 [debug] [MainThread]: On master: COMMIT
[0m15:11:33.528478 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:33.528478 [debug] [MainThread]: On master: COMMIT
[0m15:11:33.557443 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:11:33.557443 [debug] [MainThread]: On master: Close
[0m15:11:33.558480 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:11:33.559474 [info ] [MainThread]: 
[0m15:11:33.562970 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.563967 [info ] [Thread-1 (]: 1 of 1 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:11:33.564968 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:11:33.565970 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.574694 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.576703 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:11:33.565970 => 15:11:33.576703
[0m15:11:33.577702 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:11:33.618805 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.619805 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.621313 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:11:33.622508 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:11:33.826233 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:11:33.826765 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.827899 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	COALESCE(review_name, 'Anonymous') AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:11:33.923142 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:11:33.930875 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.931395 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:11:33.960947 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:11:33.963978 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:33.964981 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:11:33.993824 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:11:34.011593 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:11:34.012594 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:34.013595 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:11:34.046163 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:11:34.053149 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:11:34.057690 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:11:34.058691 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:11:34.097962 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:11:34.099960 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:11:33.577702 => 15:11:34.098958
[0m15:11:34.099960 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:11:34.100924 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cba3c832-f59b-49fc-ba7e-c1417bf3be1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F712102050>]}
[0m15:11:34.101924 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.54s]
[0m15:11:34.103208 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:11:34.105389 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:34.105389 [debug] [MainThread]: On master: BEGIN
[0m15:11:34.106422 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:11:34.319848 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:11:34.320790 [debug] [MainThread]: On master: COMMIT
[0m15:11:34.321788 [debug] [MainThread]: Using postgres connection "master"
[0m15:11:34.321788 [debug] [MainThread]: On master: COMMIT
[0m15:11:34.353104 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:11:34.353104 [debug] [MainThread]: On master: Close
[0m15:11:34.355136 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:11:34.355136 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:11:34.355136 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:11:34.356163 [debug] [MainThread]: Connection 'model.dbtlearn.dim_hosts_cleansed' was properly closed.
[0m15:11:34.357141 [info ] [MainThread]: 
[0m15:11:34.357141 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.84 seconds (1.84s).
[0m15:11:34.359146 [debug] [MainThread]: Command end result
[0m15:11:34.369804 [info ] [MainThread]: 
[0m15:11:34.370805 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:11:34.371802 [info ] [MainThread]: 
[0m15:11:34.374805 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:11:34.376803 [debug] [MainThread]: Command `dbt run` succeeded at 15:11:34.376803 after 2.52 seconds
[0m15:11:34.378329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F710BAE890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F709401090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F709400FD0>]}
[0m15:11:34.378953 [debug] [MainThread]: Flushing usage events
[0m15:13:13.155385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A8CAED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A0FF490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A0FE790>]}


============================== 15:13:13.158837 | 8e8710da-ad90-485a-a7f6-b053e0339ea0 ==============================
[0m15:13:13.158837 [info ] [MainThread]: Running with dbt=1.7.3
[0m15:13:13.159805 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\marco\\.dbt', 'log_path': 'C:\\Users\\marco\\OneDrive\\Documentos\\triade\\dbt_course_1\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s dim_hosts_cleansed', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:13:13.374417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AAD8E50>]}
[0m15:13:13.451700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AAD8C90>]}
[0m15:13:13.453210 [info ] [MainThread]: Registered adapter: postgres=1.7.3
[0m15:13:13.462435 [debug] [MainThread]: checksum: c95636796e12235e48c0560a0bb6a50e98827ef72e7ea1fe07a97c38c91661e1, vars: {}, profile: , target: , version: 1.7.3
[0m15:13:13.575078 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:13:13.576076 [debug] [MainThread]: Partial parsing: updated file: dbtlearn://dbtlearn/models\dim\dim_hosts_cleansed.sql
[0m15:13:13.751558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AC7FDD0>]}
[0m15:13:13.766321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB7C490>]}
[0m15:13:13.767330 [info ] [MainThread]: Found 5 models, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m15:13:13.768330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB74F90>]}
[0m15:13:13.769828 [info ] [MainThread]: 
[0m15:13:13.771416 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:13:13.772968 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage'
[0m15:13:13.788235 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage"
[0m15:13:13.788750 [debug] [ThreadPool]: On list_inttegra_stage: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage"} */

    select distinct nspname from pg_namespace
  
[0m15:13:13.789781 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:15.147222 [debug] [ThreadPool]: SQL status: SELECT 7 in 1.0 seconds
[0m15:13:15.148729 [debug] [ThreadPool]: On list_inttegra_stage: Close
[0m15:13:15.151169 [debug] [ThreadPool]: Acquiring new postgres connection 'list_inttegra_stage_test'
[0m15:13:15.155687 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:13:15.156688 [debug] [ThreadPool]: On list_inttegra_stage_test: BEGIN
[0m15:13:15.156688 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:15.376586 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.377630 [debug] [ThreadPool]: Using postgres connection "list_inttegra_stage_test"
[0m15:13:15.378205 [debug] [ThreadPool]: On list_inttegra_stage_test: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "list_inttegra_stage_test"} */
select
      'inttegra_stage' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'test'
    union all
    select
      'inttegra_stage' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'test'
  
[0m15:13:15.425483 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:13:15.427466 [debug] [ThreadPool]: On list_inttegra_stage_test: ROLLBACK
[0m15:13:15.456348 [debug] [ThreadPool]: On list_inttegra_stage_test: Close
[0m15:13:15.461832 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.462832 [debug] [MainThread]: On master: BEGIN
[0m15:13:15.462832 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:13:15.706045 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.706984 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.707983 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:13:15.769569 [debug] [MainThread]: SQL status: SELECT 3 in 0.0 seconds
[0m15:13:15.771574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AA40850>]}
[0m15:13:15.771574 [debug] [MainThread]: On master: ROLLBACK
[0m15:13:15.799651 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.800665 [debug] [MainThread]: On master: BEGIN
[0m15:13:15.866256 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:15.867266 [debug] [MainThread]: On master: COMMIT
[0m15:13:15.867266 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:15.868300 [debug] [MainThread]: On master: COMMIT
[0m15:13:15.896489 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:13:15.897490 [debug] [MainThread]: On master: Close
[0m15:13:15.898490 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:13:15.898490 [info ] [MainThread]: 
[0m15:13:15.902491 [debug] [Thread-1 (]: Began running node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.903493 [info ] [Thread-1 (]: 1 of 1 START sql table model test.dim_hosts_cleansed ........................... [RUN]
[0m15:13:15.903493 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbtlearn.dim_hosts_cleansed'
[0m15:13:15.904999 [debug] [Thread-1 (]: Began compiling node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.915313 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.919859 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (compile): 15:13:15.906298 => 15:13:15.919208
[0m15:13:15.919859 [debug] [Thread-1 (]: Began executing node model.dbtlearn.dim_hosts_cleansed
[0m15:13:15.966917 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.968500 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:15.969883 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: BEGIN
[0m15:13:15.970442 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:13:16.198221 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:13:16.199234 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.199234 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */

  
    

  create  table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp"
  
  
    as
  
  (
    WITH dim_hosts_cleansed AS(
    SELECT
        *
    FROM
        "inttegra_stage"."test"."src_hosts"
)
SELECT
    review_id,
	CASE 
        WHEN review_name = '' THEN 'Anonymous' 
        ELSE  review_name
    END AS review_name,
	is_superhost,
	created_at,
	updated_at
FROM
    dim_hosts_cleansed
  );
  
[0m15:13:16.301748 [debug] [Thread-1 (]: SQL status: SELECT 14111 in 0.0 seconds
[0m15:13:16.308859 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.309826 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed" rename to "dim_hosts_cleansed__dbt_backup"
[0m15:13:16.342355 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:13:16.346360 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.346360 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
alter table "inttegra_stage"."test"."dim_hosts_cleansed__dbt_tmp" rename to "dim_hosts_cleansed"
[0m15:13:16.381957 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:13:16.399249 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:13:16.400286 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.401251 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: COMMIT
[0m15:13:16.441828 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:13:16.451315 [debug] [Thread-1 (]: Applying DROP to: "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup"
[0m15:13:16.460170 [debug] [Thread-1 (]: Using postgres connection "model.dbtlearn.dim_hosts_cleansed"
[0m15:13:16.462169 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: /* {"app": "dbt", "dbt_version": "1.7.3", "profile_name": "dbtlearn", "target_name": "dev", "node_id": "model.dbtlearn.dim_hosts_cleansed"} */
drop table if exists "inttegra_stage"."test"."dim_hosts_cleansed__dbt_backup" cascade
[0m15:13:16.507179 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:13:16.509190 [debug] [Thread-1 (]: Timing info for model.dbtlearn.dim_hosts_cleansed (execute): 15:13:15.920865 => 15:13:16.509190
[0m15:13:16.510197 [debug] [Thread-1 (]: On model.dbtlearn.dim_hosts_cleansed: Close
[0m15:13:16.511189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e8710da-ad90-485a-a7f6-b053e0339ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8AB7C490>]}
[0m15:13:16.512191 [info ] [Thread-1 (]: 1 of 1 OK created sql table model test.dim_hosts_cleansed ...................... [[32mSELECT 14111[0m in 0.61s]
[0m15:13:16.513194 [debug] [Thread-1 (]: Finished running node model.dbtlearn.dim_hosts_cleansed
[0m15:13:16.515539 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:16.515539 [debug] [MainThread]: On master: BEGIN
[0m15:13:16.516522 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:13:16.764752 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:13:16.765716 [debug] [MainThread]: On master: COMMIT
[0m15:13:16.765716 [debug] [MainThread]: Using postgres connection "master"
[0m15:13:16.766712 [debug] [MainThread]: On master: COMMIT
[0m15:13:16.809575 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:13:16.810569 [debug] [MainThread]: On master: Close
[0m15:13:16.811533 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:13:16.812531 [debug] [MainThread]: Connection 'list_inttegra_stage' was properly closed.
[0m15:13:16.812531 [debug] [MainThread]: Connection 'list_inttegra_stage_test' was properly closed.
[0m15:13:16.813532 [debug] [MainThread]: Connection 'model.dbtlearn.dim_hosts_cleansed' was properly closed.
[0m15:13:16.813532 [info ] [MainThread]: 
[0m15:13:16.814532 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.04 seconds (3.04s).
[0m15:13:16.815531 [debug] [MainThread]: Command end result
[0m15:13:16.825944 [info ] [MainThread]: 
[0m15:13:16.827944 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:13:16.827944 [info ] [MainThread]: 
[0m15:13:16.828943 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:13:16.830448 [debug] [MainThread]: Command `dbt run` succeeded at 15:13:16.830448 after 3.74 seconds
[0m15:13:16.831445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A9191D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E8A424BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E83141090>]}
[0m15:13:16.831969 [debug] [MainThread]: Flushing usage events
